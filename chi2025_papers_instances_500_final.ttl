@prefix chi: <http://example.org/chi2025#> .
@prefix foaf: <http://xmlns.com/foaf/0.1/> .
@prefix dcterms: <http://purl.org/dc/terms/> .
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .

# CHI 2025 Paper Instances

# ============================================
# Paper Instances
# ============================================
chi:paper_188208 rdf:type chi:Paper ;
    dcterms:title "Like Adding a Small Weight to a Scale About to Tip: Personalizing Micro-Financial Incentives for Digital Wellbeing" ;
    dcterms:abstract "Personalized behavior change interventions can be effective as they dynamically adapt to an individual’s context. Financial incentives, a commonly used intervention in commercial applications and policy-making, offer a mechanism for creating personalized micro-interventions that are both quantifiable and amenable to systematic evaluation. However, the effectiveness of such personalized micro-financial incentives in real-world settings remains largely unexplored. In this study, we propose a personalization strategy that dynamically adjusts the amount of micro-financial incentives to promote smartphone use regulation and explore its efficacy and user experience through a four-week, in-the-wild user study. The results demonstrate that the proposed method is highly cost-effective without compromising intervention effectiveness. Based on these findings, we discuss the role of micro-financial incentives in enhancing awareness, design considerations for personalized micro-financial incentive systems, and their potential benefits and limitations concerning motivation change." ;
    dcterms:identifier "3706598.3714208" ;
    chi:hasAuthor chi:person_186026, chi:person_182960, chi:person_184762, chi:person_185610 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:SmartphoneUseAndIncentives ;
    chi:paperIncludesStudy chi:study_188208_FieldStudy ;
    chi:paperIncludesStudy chi:study_188208_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188208_SoftwareArtifact .

chi:study_188208_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188208 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188208_QualitativeResult ;
    chi:reportsResult chi:result_188208_StatisticalResult .

chi:study_188208_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188208 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188208_QualitativeResult ;
    chi:reportsResult chi:result_188208_StatisticalResult .

chi:artifact_188208_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188208 .

chi:result_188208_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188208_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188209 rdf:type chi:Paper ;
    dcterms:title "Developing a Social Support Framework: Understanding the Reciprocity in Human-Chatbot Relationship" ;
    dcterms:abstract "Chatbots are increasingly used to provide social support for individuals with mental health challenges. However, a systematic analysis of the types and directionality of support within chatbot use remains lacking. This study establishes a framework for understanding reciprocal social support exchanges in human-chatbot relationships, focusing on the popular chatbot, Replika. By analyzing 496 posts and 20,494 comments from the largest Replika community on Reddit, we identified 27 support subcategories, organized into five main types (functional, informational, emotional, esteem, and network) and two directions (chatbot-receiving and chatbot-giving). Our findings reveal significant yet controversial issues, such as subscription services and chatbot-displayed affection. Notably, \"user teaching chatbot\" emerged as a core aspect of the human-chatbot relationship, covering how users actively guide and refine the chatbot’s learning or algorithm. This study constructs a novel social support framework for chatbot use, highlighting the potential for reciprocal support exchanges between users and chatbots." ;
    dcterms:identifier "3706598.3713503" ;
    chi:hasAuthor chi:person_183489, chi:person_185171 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialSupportAndPeerChatbots ;
    chi:paperIncludesStudy chi:study_188209_QualitativeStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188209_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188209_InterfaceArtifact .

chi:study_188209_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188209 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188209_QualitativeResult .

chi:artifact_188209_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188209 .

chi:artifact_188209_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188209 .

chi:result_188209_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188210 rdf:type chi:Paper ;
    dcterms:title "Lookee: Gaze Tracking-based Infant Vocabulary Comprehension Assessment and Analysis" ;
    dcterms:abstract "Measuring preverbal vocabulary comprehension of young children is vital for early intervention and developmental evaluation, yet challenging due to their limited communication abilities. We introduce Lookee, an AI-powered vocabulary comprehension assessment tool through gaze tracking for toddlers in the preverbal stage. Lookee incorporates the Intermodal Preferential Looking Paradigm (IPLP), which is one of the prominent word comprehension measures for toddlers and estimates word comprehension through a random forest model analysis. We design and validate Lookee through user studies involving 19 toddlers and their parents. Then we identify necessary design requirements from potential stakeholders' perspectives through in-depth interviews including researchers, clinicians, and parents. As a result, Lookee achieves considerable estimation accuracy with sufficient system usability, and demonstrates key design requirements for each stakeholder group. From our study, we highlight necessary design implications in developing and validating AI-powered clinical tools for toddlers." ;
    dcterms:identifier "3706598.3713386" ;
    chi:hasAuthor chi:person_183339, chi:person_187017, chi:person_185730, chi:person_186116, chi:person_186285 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EarlyChildComprehensionAssessment ;
    chi:paperIncludesStudy chi:study_188210_UserStudy ;
    chi:paperIncludesStudy chi:study_188210_InterviewStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188210_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188210_InterfaceArtifact .

chi:study_188210_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188210 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188210_QualitativeResult ;
    chi:reportsResult chi:result_188210_StatisticalResult .

chi:study_188210_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188210 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188210_QualitativeResult ;
    chi:reportsResult chi:result_188210_StatisticalResult .

chi:artifact_188210_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188210 .

chi:artifact_188210_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188210 .

chi:result_188210_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188210_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188211 rdf:type chi:Paper ;
    dcterms:title "Leveraging Multimodal LLM for Inspirational User Interface Search" ;
    dcterms:abstract "Inspirational search, the process of exploring designs to inform and inspire new creative work, is pivotal in mobile user interface (UI) design. However, exploring the vast space of UI references remains a challenge. Existing AI-based UI search methods often miss crucial semantics like target users or the mood of apps. Additionally, these models typically require metadata like view hierarchies, limiting their practical use. We used a multimodal large language model (MLLM) to extract and interpret semantics from mobile UI images. We identified key UI semantics through a formative study and developed a semantic-based UI search system. Through computational and human evaluations, we demonstrate that our approach significantly outperforms existing UI retrieval methods, offering UI designers a more enriched and contextually relevant search experience. We enhance the understanding of mobile UI design semantics and highlight MLLMs' potential in inspirational search, providing a rich dataset of UI semantics for future studies." ;
    dcterms:identifier "3706598.3714213" ;
    chi:hasAuthor chi:person_186411, chi:person_187893, chi:person_183511, chi:person_187736, chi:person_184617 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:paperIncludesStudy chi:study_188211_UserStudy ;
    chi:paperIncludesStudy chi:study_188211_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188211_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188211_InterfaceArtifact .

chi:study_188211_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188211 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188211_QualitativeResult ;
    chi:reportsResult chi:result_188211_StatisticalResult .

chi:study_188211_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188211 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188211_QualitativeResult ;
    chi:reportsResult chi:result_188211_StatisticalResult .

chi:artifact_188211_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188211 .

chi:artifact_188211_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188211 .

chi:result_188211_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188211_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188212 rdf:type chi:Paper ;
    dcterms:title "Why So Serious? Exploring Timely Humorous Comments in AAC Through AI-Powered Interfaces" ;
    dcterms:abstract "People with disabilities that affect their speech may use speech-generating devices (SGD), commonly referred to as Augmentative and Alternative Communication (AAC) technology. This technology enables practical conversation; however, delivering expressive and timely comments remains challenging. This paper explores how to extend AAC technology to support a subset of humorous expressions: delivering timely humorous comments -witty remarks- through AI-powered interfaces. To understand the role of humor in AAC and the challenges and experiences of delivering humor with AAC, we conducted seven qualitative interviews with AAC users. Based on these insights and the lead author's firsthand experience as an AAC user, we designed four AI-powered interfaces to assist in delivering well-timed humorous comments during ongoing conversations. Our user study with five AAC users found that when timing is critical (e.g., delivering a humorous comment), AAC users are willing to trade agency for efficiency—contrasting prior research where they hesitated to delegate decision-making to AI.  We conclude by discussing the trade-off between agency and efficiency in AI-powered interfaces, how AI can shape user intentions, and offer design recommendations for AI-powered AAC interfaces. See our project and demo at: https://tobiwg.github.io/research/why_so_serious" ;
    dcterms:identifier "3706598.3714102" ;
    chi:hasAuthor chi:person_182801, chi:person_186388, chi:person_187556, chi:person_186493, chi:person_184224 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188212_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188212_UserStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188212_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188212_SoftwareArtifact .

chi:study_188212_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188212 ;
    chi:reportsResult chi:result_188212_QualitativeResult .

chi:study_188212_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188212 ;
    chi:reportsResult chi:result_188212_QualitativeResult .

chi:artifact_188212_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188212 .

chi:artifact_188212_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188212 .

chi:result_188212_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188213 rdf:type chi:Paper ;
    dcterms:title "``I want to think like an SLP'': A Design Exploration of AI-Supported Home Practice in Speech Therapy" ;
    dcterms:abstract "Parents of children in speech therapy play a crucial role in delivering consistent, high-quality home practice, which is essential for helping children generalize new speech skills to everyday situations. However, this responsibility is often complicated by uncertainties in implementing therapy techniques and keeping children engaged. In this study, we explore how varying levels of AI oversight can provide informational, emotional, and practical support to parents during home speech therapy practice. Through semi-structured interviews with 20 parents, we identified key challenges they face and their ideas for AI assistance. Using these insights, we developed six design concepts, which were then evaluated by 20 Speech-Language Pathologists (SLPs) for their potential impact, usability, and alignment with therapy goals. Our findings contribute to the discourse on AI’s role in supporting therapeutic practices, offering design considerations that address the needs and values of both families and professionals. " ;
    dcterms:identifier "3706598.3713986" ;
    chi:hasAuthor chi:person_187582, chi:person_186864, chi:person_183358, chi:person_183018, chi:person_184692, chi:person_186498, chi:person_187019 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188213_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188213_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188213_InterfaceArtifact .

chi:study_188213_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188213 ;
    chi:reportsResult chi:result_188213_QualitativeResult .

chi:study_188213_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188213 ;
    chi:reportsResult chi:result_188213_QualitativeResult .

chi:artifact_188213_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188213 .

chi:result_188213_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188214 rdf:type chi:Paper ;
    dcterms:title "SplatOverflow: Asynchronous Hardware Troubleshooting" ;
    dcterms:abstract "As tools for designing and manufacturing hardware become more accessible, smaller producers can develop and distribute novel hardware. However, processes for supporting end-user hardware troubleshooting or routine maintenance aren't well defined. As a result, providing technical support for hardware remains ad-hoc and challenging to scale. Inspired by patterns that helped scale software troubleshooting, we propose a workflow for asynchronous hardware troubleshooting: SplatOverflow.   SplatOverflow creates a novel boundary object, the SplatOverflow scene, that users reference to communicate about hardware. A scene comprises a 3D Gaussian Splat of the user's hardware registered onto the hardware’s CAD model. The splat captures the current state of the hardware, and the registered CAD model acts as a referential anchor for troubleshooting instructions. With SplatOverflow, remote maintainers can directly address issues and author instructions in the user’s workspace. Workflows containing multiple instructions can easily be shared between users and recontextualized in new environments.   In this paper, we describe the design of SplatOverflow, the workflows it enables, and its utility to different kinds of users. We also validate that non-experts can use SplatOverflow to troubleshoot common problems with a 3D printer in a usability study.   Project Page: https://amritkwatra.com/research/splatoverflow." ;
    dcterms:identifier "3706598.3714129" ;
    chi:hasAuthor chi:person_185672, chi:person_182801, chi:person_186775, chi:person_186441, chi:person_188136, chi:person_184246, chi:person_184224 ;
    chi:hasPrimaryTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:PhysicalDigitalWorkflowIntegration ;
    chi:paperIncludesStudy chi:study_188214_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188214_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188214_InterfaceArtifact .

chi:study_188214_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188214 ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:reportsResult chi:result_188214_QualitativeResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation ;
    chi:involvesParticipationPattern chi:AsynchronousParticipation .

chi:artifact_188214_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188214 .

chi:artifact_188214_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188214 .

chi:result_188214_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188215 rdf:type chi:Paper ;
    dcterms:title "Textoshop: Interactions Inspired by Drawing Software to Facilitate Text Editing" ;
    dcterms:abstract "We explore how interactions inspired by drawing software can help edit text. Making an analogy between visual and text editing, we consider words as pixels, sentences as regions, and tones as colours. For instance, direct manipulations move, shorten, expand, and reorder text; tools change number, tense, and grammar; colours map to tones explored along three dimensions in a tone picker; and layers help organize and version text. This analogy also leads to new workflows, such as boolean operations on text fragments to construct more elaborated text. A study shows participants were more successful at editing text and preferred using the proposed interface over existing solutions. Broadly, our work highlights the potential of interaction analogies to rethink existing workflows, while capitalizing on familiar features." ;
    dcterms:identifier "3706598.3713862" ;
    chi:hasAuthor chi:person_187159, chi:person_185361, chi:person_187104 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:paperIncludesStudy chi:study_188215_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188215_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188215_SoftwareArtifact .

chi:study_188215_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188215 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:reportsResult chi:result_188215_StatisticalResult .

chi:artifact_188215_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188215 .

chi:artifact_188215_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188215 .

chi:result_188215_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188216 rdf:type chi:Paper ;
    dcterms:title "Investigating Context-Aware Collaborative Text Entry on Smartphones using Large Language Models" ;
    dcterms:abstract "Text entry is a fundamental and ubiquitous task, but users often face challenges such as situational impairments or difficulties in sentence formulation. Motivated by this, we explore the potential of large language models (LLMs) to assist with text entry in real-world contexts. We propose a collaborative smartphone-based text entry system, CATIA, that leverages LLMs to provide text suggestions based on contextual factors, including screen content, time, location, activity, and more. In a 7-day in-the-wild study with 36 participants, the system offered appropriate text suggestions in over 80% of cases. Users exhibited different collaborative behaviors depending on whether they were composing text for interpersonal communication or information services. Additionally, the relevance of contextual factors beyond screen content varied across scenarios. We identified two distinct mental models: AI as a supportive facilitator or as a more equal collaborator. These findings outline the design space for human-AI collaborative text entry on smartphones." ;
    dcterms:identifier "3706598.3713944" ;
    chi:hasAuthor chi:person_184346, chi:person_187044, chi:person_187790, chi:person_184053, chi:person_184047, chi:person_183438, chi:person_184210, chi:person_183957, chi:person_186562, chi:person_187569 ;
    chi:hasPrimaryTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:paperIncludesStudy chi:study_188216_FieldStudy ;
    chi:paperIncludesStudy chi:study_188216_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188216_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188216_InterfaceArtifact .

chi:study_188216_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188216 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188216_QualitativeResult ;
    chi:reportsResult chi:result_188216_StatisticalResult .

chi:study_188216_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188216 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188216_QualitativeResult ;
    chi:reportsResult chi:result_188216_StatisticalResult .

chi:artifact_188216_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188216 .

chi:artifact_188216_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188216 .

chi:result_188216_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188216_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188217 rdf:type chi:Paper ;
    dcterms:title "Permission Rationales in the Web Ecosystem: An Exploration of Rationale Text and Design Patterns" ;
    dcterms:abstract "Modern web applications use features like camera and geolocation for personalized experiences, requiring user permission via browser prompts. To explain these requests, applications provide rationales—contextual information on why permissions are needed. Despite their importance, little is known about how often rationales appear on the web or their influence on user decisions.  This paper presents the first large-scale study of how the web ecosystem handles permission rationales, covering three areas: (i) identifying webpages that use permissions, (ii) detecting and classifying permission rationales, and (iii) analyzing their attributes to understand their impact on user decisions. We examined over 770K webpages from Chrome telemetry, finding 3.6K unique rationale texts and 749 rationale UIs across 85K pages. We extracted key rationale attributes and assessed their effect on user behavior by cross-referencing them with Chrome telemetry data. Our findings reveal nine key insights, providing the first evidence of how different rationales affect user decisions. " ;
    dcterms:identifier "3706598.3713547" ;
    chi:hasAuthor chi:person_187819, chi:person_187982, chi:person_185510, chi:person_184920, chi:person_184730, chi:person_184239, chi:person_185735 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:DataDisclosureAndConsent ;
    chi:paperIncludesStudy chi:study_188217_FieldStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188217_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188217_SoftwareArtifact .

chi:study_188217_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188217 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188217_QualitativeResult ;
    chi:reportsResult chi:result_188217_StatisticalResult .

chi:artifact_188217_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188217 .

chi:artifact_188217_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188217 .

chi:result_188217_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188217_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188219 rdf:type chi:Paper ;
    dcterms:title "VisiMark: Characterizing and Augmenting Landmarks for People with Low Vision in Augmented Reality to Support Indoor Navigation" ;
    dcterms:abstract "Landmarks are critical in navigation, supporting self-orientation and mental model development. Similar to sighted people, people with low vision (PLV) frequently look for landmarks via visual cues but face difficulties identifying some important landmarks due to vision loss. We first conducted a formative study with six PLV to characterize their challenges and strategies in landmark selection, identifying their unique landmark categories (e.g., area silhouettes, accessibility-related objects) and preferred landmark augmentations. We then designed VisiMark, an AR interface that supports landmark perception for PLV by providing both overviews of space structures and in-situ landmark augmentations. We evaluated VisiMark with 16 PLV and found that VisiMark enabled PLV to perceive landmarks they preferred but could not easily perceive before, and changed PLV's landmark selection from only visually-salient objects to cognitive landmarks that are more important and meaningful. We further derive design considerations for AR-based landmark augmentation systems for PLV." ;
    dcterms:identifier "3706598.3713847" ;
    chi:hasAuthor chi:person_186880, chi:person_183598, chi:person_183015, chi:person_184336, chi:person_187293 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:NavigationSupportForLowVision ;
    chi:paperIncludesStudy chi:study_188219_UserStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188219_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188219_SoftwareArtifact .

chi:study_188219_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188219 ;
    chi:reportsResult chi:result_188219_QualitativeResult .

chi:artifact_188219_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188219 .

chi:artifact_188219_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188219 .

chi:result_188219_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188220 rdf:type chi:Paper ;
    dcterms:title "Spatial Hand Actions: Exploring the Hand Actions used to Represent Spatial Thinking for 3D Assembling Tasks" ;
    dcterms:abstract "When designing 3D objects in 3D virtual environments using naturalistic 3D user interfaces, people use their hands to manipulate the environment and objects inside it. At the same time, people utilize their spatial thinking to understand the spatial relationship of the objects in the scene. Yet, the relationship between spatial thinking and hand actions remains unclear. Here, we present a user study with 18 participants that examines the association between 3D assembling tasks and reflective hand movements that allow people to enhance their spatial thinking. Utilizing a mixed-methods protocol, we identified nine SPATIAL HAND ACTIONS and three SPATIAL THEMES people use when designing 3D objects. Then, we analyzed a subset of the participants to understand the relationship between SPATIAL HAND ACTIONS and spatial abilities. Our results will help develop better hand-based naturalistic 3DUI that considers the spatial thinking abilities of the users." ;
    dcterms:identifier "3706598.3713424" ;
    chi:hasAuthor chi:person_185522, chi:person_186638 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:EmbodiedVRInteraction ;
    chi:paperIncludesStudy chi:study_188220_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188220_InterfaceArtifact .

chi:study_188220_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188220 ;
    chi:reportsResult chi:result_188220_QualitativeResult ;
    chi:reportsResult chi:result_188220_StatisticalResult .

chi:artifact_188220_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188220 .

chi:result_188220_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188220_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188221 rdf:type chi:Paper ;
    dcterms:title "TangibleNet: Synchronous Network Data Storytelling through Tangible Interactions in Augmented Reality" ;
    dcterms:abstract "Synchronous data-driven storytelling with network visualizations presents significant challenges due to the complexity of real-time manipulation of network components. While existing research addresses asynchronous scenarios, there is a lack of effective tools for live presentations. To address this gap, we developed TangibleNet, a projector-based AR prototype that allows presenters to interact with node-link diagrams using double-sided magnets during live presentations. The design process was informed by interviews with professionals experienced in synchronous data storytelling and workshops with 14 HCI/VIS researchers. Insights from the interviews helped identify key design considerations for integrating physical objects as interactive tools in presentation contexts. The workshops contributed to the development of a design space mapping user actions to interaction commands for node-link diagrams. Evaluation with 12 participants confirmed that TangibleNet supports intuitive interactions and enhances presenter autonomy, demonstrating its effectiveness for synchronous network-based data storytelling." ;
    dcterms:identifier "3706598.3714265" ;
    chi:hasAuthor chi:person_184917, chi:person_182992, chi:person_185150, chi:person_187472, chi:person_186890, chi:person_187993 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:CollaborativeVisualizationTools ;
    chi:paperIncludesStudy chi:study_188221_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188221_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188221_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188221_SoftwareArtifact .

chi:study_188221_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188221 ;
    chi:reportsResult chi:result_188221_QualitativeResult ;
    chi:involvesParticipationPattern chi:SynchronousParticipation .

chi:study_188221_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188221 ;
    chi:reportsResult chi:result_188221_QualitativeResult ;
    chi:involvesParticipationPattern chi:SynchronousParticipation .

chi:artifact_188221_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188221 .

chi:artifact_188221_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188221 .

chi:result_188221_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188222 rdf:type chi:Paper ;
    dcterms:title "A Longitudinal Study on the Effects of Circadian Fatigue on Sound Source Identification and Localization using a Heads-Up Display" ;
    dcterms:abstract "Circadian fatigue, largely caused by sleep deprivation, significantly diminishes alertness and situational awareness. This issue becomes critical in environments where auditory awareness—such as responding to verbal instructions or localizing alarms—is essential for performance and safety. While head-mounted displays have demonstrated potential in enhancing situational awareness through visual cues, their effectiveness in supporting sound localization under the influence of circadian fatigue remains under-explored. This study addresses this knowledge gap through a longitudinal study (N=19) conducted over 2–4 months, tracking participants’ fatigue levels through daily assessments. Participants were called in to perform non-line-of-sight sound source identification and localization tasks in a virtual environment under high- and low-fatigue conditions, both with and without head-up display assistance. The results show task-dependent effects of circadian fatigue. Unexpectedly, reaction times were shorter across all tasks under high-fatigue conditions. Yet, in sound localization, where precision is key, the HUD offered the greatest performance enhancement by reducing pointing error. The results suggest the auditory channel is a robust means of enhancing situational awareness and providing support for incorporating spatial audio cues and HUD as standard features in augmented reality platforms for fatigue-prone scenarios. " ;
    dcterms:identifier "3706598.3713402" ;
    chi:hasAuthor chi:person_183016, chi:person_184191, chi:person_183141, chi:person_183940, chi:person_182903, chi:person_185369, chi:person_187320, chi:person_184214, chi:person_186414, chi:person_187896 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:SpatialNavigationPerformance ;
    chi:paperIncludesStudy chi:study_188222_UserStudy ;
    chi:paperIncludesStudy chi:study_188222_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188222_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188222_DeviceArtifact .

chi:study_188222_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188222 ;
    chi:hasMeasure chi:ReactionTimeMeasure ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188222_StatisticalResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:study_188222_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188222 ;
    chi:hasMeasure chi:ReactionTimeMeasure ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188222_StatisticalResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:artifact_188222_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188222 .

chi:artifact_188222_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188222 .

chi:result_188222_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188223 rdf:type chi:Paper ;
    dcterms:title "PAIRcolator: Pair Collaboration for Sensemaking and Reflection on Personal Data" ;
    dcterms:abstract "This paper explores pair collaboration as a novel approach for making sense of personal data. Pair collaboration---characterized by dyadic comparison and structured roles for questioning and reasoning---has proven effective for co-constructing knowledge. However, current collaborative visualization tools primarily focus on group comparisons, overlooking the challenges of accommodating pair collaboration in the context of personal data. To address this gap, we propose a set of design rationales supporting subjective data analysis through dyadic comparison and mixed-focus collaboration styles for co-constructing personal narratives. We operationalize these principles in a tangible visualization toolkit, \projectname. Our user study demonstrates that pairwise collaboration facilitated by the toolkit: 1) reveals detailed data insights that are effective for recalling personal experiences, and 2) fosters a structured, reciprocal sensemaking process for interpreting and reconstructing personal experiences beyond data insights. Our results shed light on the design rationales for, and the processes of pair sensemaking of personal data, and their effects to foster deep levels of reflection. " ;
    dcterms:identifier "3706598.3713332" ;
    chi:hasAuthor chi:person_187437, chi:person_187491, chi:person_184629, chi:person_186571 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:CollaborativeVisualizationTools ;
    chi:paperIncludesStudy chi:study_188223_UserStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188223_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188223_InterfaceArtifact .

chi:study_188223_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188223 ;
    chi:reportsResult chi:result_188223_QualitativeResult .

chi:artifact_188223_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188223 .

chi:artifact_188223_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188223 .

chi:result_188223_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188224 rdf:type chi:Paper ;
    dcterms:title "A Feminist Care Ethics Toolkit for Community-Based Design: Bridging Theory and Practice" ;
    dcterms:abstract " Existing ethics frameworks for participatory engagement in HCI often overlook the nuanced ethical challenges of dynamic community-based contexts given the latter’s relational nature. We hope to bridge this gap by grounding feminist care ethics in actionable tools for community-based projects to enhance ethical engagement in these settings. Prior research advocates for adaptable, context-sensitive ethics in participatory research, informed by feminist care ethics. To address this need, we developed and iteratively refined a toolkit embodying the underlying principles of feminist care ethics through workshops with participants working in academic and non-academic community-based settings. Our findings suggest that the toolkit fosters ethical reflection aligned with the feminist care ethics ethos while facilitating meaningful experiences for participants. This work contributes to the field by offering a practical design artefact that not only embodies feminist care ethics but also supports researchers and communities in navigating complex ethical landscapes in participatory engagements, together or independently." ;
    dcterms:identifier "3706598.3713950" ;
    chi:hasAuthor chi:person_185213, chi:person_185453, chi:person_184123, chi:person_186323, chi:person_184312, chi:person_187715, chi:person_185541, chi:person_186279, chi:person_186938 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:ParticipatoryEthicsMethods ;
    chi:paperIncludesStudy chi:study_188224_UserStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188224_SoftwareArtifact .

chi:study_188224_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188224 ;
    chi:reportsResult chi:result_188224_QualitativeResult .

chi:artifact_188224_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188224 .

chi:result_188224_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188225 rdf:type chi:Paper ;
    dcterms:title "Beyond Automation: How Designers Perceive AI as a Creative Partner in the Divergent Thinking Stages of UI/UX Design" ;
    dcterms:abstract "Divergent thinking activities, like research and ideation, are key drivers of innovation in UI/UX design. Existing research has explored AI's role in automating design tasks, but leaves a critical gap in understanding how AI specifically influences divergent thinking. To address this, we conducted interviews with 19 professional UI/UX designers, examining their use and perception of AI in these creative activities. We found that in this context, participants valued AI tools that offer greater control over ideation, facilitate collaboration, enhance efficiency to liberate creativity, and align with their visual habits. Our results indicated four key roles AI plays in supporting divergent thinking: aiding research, kick-starting creativity, generating design alternatives, and facilitating prototype exploration. Through this study, we provide insights into the evolving role of AI in the less-investigated area of divergent thinking in UI/UX design, offering recommendations for future AI tools that better support design innovation." ;
    dcterms:identifier "3706598.3713500" ;
    chi:hasAuthor chi:person_187653, chi:person_183288, chi:person_186643 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:CollaborativeVisualizationTools ;
    chi:paperIncludesStudy chi:study_188225_InterviewStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188225_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188225_InterfaceArtifact .

chi:study_188225_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188225 ;
    chi:reportsResult chi:result_188225_QualitativeResult .

chi:artifact_188225_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188225 .

chi:artifact_188225_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188225 .

chi:result_188225_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188227 rdf:type chi:Paper ;
    dcterms:title "SocialEyes: Scaling Mobile Eye-tracking to Multi-person Social Settings" ;
    dcterms:abstract "Eye movements provide a window into human behaviour, attention, and interaction dynamics. Challenges in real-world, multi-person environments have, however, restrained eye-tracking research predominantly to single-person, in-lab settings. We developed a system to stream, record, and analyse synchronised data from multiple mobile eye-tracking devices during collective viewing experiences (e.g., concerts, films, lectures). We implemented lightweight operator interfaces for real-time-monitoring, remote-troubleshooting, and gaze-projection from individual egocentric perspectives to a common coordinate space for shared gaze analysis. We tested the system in a live concert and a film screening with 30 simultaneous viewers during each of two public events (N=60).  We observe precise time-synchronisation between devices measured through recorded clock-offsets, and accurate gaze-projection in challenging dynamic scenes. Our novel analysis metrics and visualizations illustrate the potential of collective eye-tracking data for understanding collaborative behaviour and social interaction. This advancement promotes ecological validity in eye-tracking research and paves the way for innovative interactive tools." ;
    dcterms:identifier "3706598.3713910" ;
    chi:hasAuthor chi:person_182817, chi:person_184386, chi:person_187309, chi:person_187490, chi:person_182740, chi:person_186631, chi:person_185056, chi:person_185067 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:CollaborationAndHybridWork ;
    chi:paperIncludesStudy chi:study_188227_FieldStudy ;
    chi:paperIncludesStudy chi:study_188227_UserStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188227_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188227_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188227_DeviceArtifact .

chi:study_188227_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188227 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188227_QualitativeResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation ;
    chi:involvesParticipationPattern chi:SynchronousParticipation .

chi:study_188227_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188227 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188227_QualitativeResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation ;
    chi:involvesParticipationPattern chi:SynchronousParticipation .

chi:artifact_188227_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188227 .

chi:artifact_188227_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188227 .

chi:artifact_188227_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188227 .

chi:result_188227_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188230 rdf:type chi:Paper ;
    dcterms:title "From Alien to Ally: Exploring Non-Verbal Communication with Non-Anthropomorphic Avatars in a Collaborative Escape-Room" ;
    dcterms:abstract "Despite the spread of technologies in the physical world and the normalization of virtual experiences, non-verbal communication with radically non-anthropomorphic avatars remains an underexplored frontier. We present an interaction system in which two participants must learn to communicate with each other non-verbally through a digital filter that morphs their appearance. In a collaborative escape room, the Visitor must teach a non-anthropomorphic physical robot to play, while the Controller, in a different location, embodies the robot with an altered perception of the environment and the Visitor’s companion in VR. This study addresses the design of the activity, the robot, and the virtual environment, with a focus on how the Visitor’s morphology is translated in VR. Results show that participants were able to develop emergent and effective communication strategies, with the Controller naturally embodying its avatar’s narrative, making this system a promising testbed for future research on human-technology interaction, entertainment, and embodiment." ;
    dcterms:identifier "3706598.3713428" ;
    chi:hasAuthor chi:person_183840, chi:person_186904, chi:person_186424 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:paperIncludesStudy chi:study_188230_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188230_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188230_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188230_DeviceArtifact .

chi:study_188230_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188230 ;
    chi:reportsResult chi:result_188230_QualitativeResult ;
    chi:involvesParticipationPattern chi:HybridParticipation .

chi:artifact_188230_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188230 .

chi:artifact_188230_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188230 .

chi:artifact_188230_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188230 .

chi:result_188230_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188231 rdf:type chi:Paper ;
    dcterms:title "Curious Shorts: Curiosity-Driven Exploration and Learning on Short-Form Video Platforms" ;
    dcterms:abstract "Short-form video platforms like YouTube Shorts captivate users with engaging content, but their potential for promoting incidental learning remains underexplored. We present Curious Shorts, a conceptual framework that extends the Hook Model, designed to enhance curiosity-driven exploration and incidental learning on these platforms. In Study 1, we empirically tested two designs that incorporate \"curiosity nudges\" — interactive prompts that spark curiosity and encourage further exploration — with follow-up videos to satisfy that curiosity. Results show that specific, question-driven prompts proved most effective, significantly boosting curiosity and encouraging more focused and intentional viewing compared to the baseline. Study 2 examined whether this design enhances incidental learning without compromising engagement. Findings confirmed improved learning outcomes. However, when applied to a realistic viewing environment interspersed with entertainment videos, engagement remained high while learning benefits diminished. We conclude with implications for balancing learning and engagement on short-form video platforms and propose directions for future research." ;
    dcterms:identifier "3706598.3713951" ;
    chi:hasAuthor chi:person_187669, chi:person_187682, chi:person_185901, chi:person_183907, chi:person_186082 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188231_BaselineComparisonStudy ;
    chi:paperIncludesStudy chi:study_188231_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188231_InterfaceArtifact .

chi:study_188231_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188231 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188231_StatisticalResult .

chi:study_188231_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188231 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188231_StatisticalResult .

chi:artifact_188231_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188231 .

chi:result_188231_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188232 rdf:type chi:Paper ;
    dcterms:title "Intriguing, Concerning, and Questioning the Impact on Immersion: An Exploration of VR Users' Advertising Experiences and Attitudes" ;
    dcterms:abstract "Many companies are experimenting with, and developing, advertisements for virtual reality (VR) consumer applications. So far, the development of VR advertising has not accounted for the voices of VR users. Since VR users will be the ones impacted by VR advertising, it is both a requirement and a moral imperative to center their voices in the discussion. We interviewed 22 VR users (14 of which had experienced VR ads, 8 of which had not) to understand their experiences with, and attitudes towards, VR advertising. Many participants had already encountered VR advertisements, ranging from static billboards in virtual worlds to virtual markets. While some participants acknowledged that VR advertising could provide benefits (including monetizing the VR ecosystem and more informative advertising), many were concerned about in-app VR advertisements ruining the immersion of VR experiences, unavoidable ads that were forced on users, privacy risks, physical harms, and manipulation. We conclude by discussing avenues for designing VR advertisements that align with users' needs and wants." ;
    dcterms:identifier "3706598.3713095" ;
    chi:hasAuthor chi:person_182700, chi:person_186368, chi:person_188006 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:EmbodiedVRInteraction ;
    chi:paperIncludesStudy chi:study_188232_InterviewStudy ;
    chi:proposesArtifact chi:artifact_188232_DeviceArtifact .

chi:study_188232_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188232 ;
    chi:reportsResult chi:result_188232_QualitativeResult .

chi:artifact_188232_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188232 .

chi:result_188232_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188233 rdf:type chi:Paper ;
    dcterms:title "Enhancing the Educational Potential of Online Movement Videos: System Development and Empirical Studies with TikTok Dance Challenges" ;
    dcterms:abstract "We hypothesize that online movement videos have untapped potential for teaching physical skills, and we developed a platform that automatically generates practice plans from raw TikTok dance videos. The practice plans teach one segment at a time using fading guidance and part-learning principles and are presented using a web-based interface featuring concurrent visual aids. Two user studies (n=54, n=38) were conducted.  The first showed significant improvements in learning outcomes compared to standard tutorials, underscoring the importance of well-structured practice plans and offering nuanced insights into the design and effectiveness of visual aids. The second study found that segmentation and emoji-based dual-coding only benefit learning when integrated into a well-designed lesson structure. We provide a set of practical recommendations for enhancing online movement learning, focusing on the need for substantive part-learning activities and careful use of visual aids to prevent cognitive overload." ;
    dcterms:identifier "3706598.3714062" ;
    chi:hasAuthor chi:person_186658, chi:person_188021, chi:person_183862, chi:person_185016, chi:person_187291, chi:person_182709, chi:person_185695 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188233_UserStudy ;
    chi:paperIncludesStudy chi:study_188233_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188233_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188233_InterfaceArtifact .

chi:study_188233_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188233 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188233_StatisticalResult ;
    chi:reportsResult chi:result_188233_QualitativeResult .

chi:study_188233_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188233 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188233_StatisticalResult ;
    chi:reportsResult chi:result_188233_QualitativeResult .

chi:artifact_188233_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188233 .

chi:artifact_188233_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188233 .

chi:result_188233_StatisticalResult rdf:type chi:StatisticalResult .

chi:result_188233_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188234 rdf:type chi:Paper ;
    dcterms:title "\"What Would I Want to Make? Probably Everything\": Practices and Speculations of Blind and Low Vision Tactile Graphics Creators" ;
    dcterms:abstract "Tactile graphics communicate images and spatial information to blind and low vision (BLV) audiences via touch. However, designing and producing tactile graphics is laborious and often inaccessible to BLV people themselves. We interviewed 14 BLV adults with experience both using and creating tactile graphics to understand their current and desired practices. We found that tactile graphics are intensely valued by many, but that access to and fluency with tactile graphics are compounding challenges. To produce tactile graphics, BLV makers constantly navigate tradeoffs between accessible, low-fidelity craft materials and less accessible, high-fidelity equipment. Going forward, we argue that tactile graphics design and production should be made widely accessible and that tactile graphics themselves should be designed to be expressive and ubiquitous. Drawing from these design goals, we propose specific future tools with features for inclusive designing, sharing, and (re)production of tactile graphics." ;
    dcterms:identifier "3706598.3714173" ;
    chi:hasAuthor chi:person_183663, chi:person_186450, chi:person_182706, chi:person_185427 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188234_InterviewStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188234_InterfaceArtifact .

chi:study_188234_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188234 ;
    chi:reportsResult chi:result_188234_QualitativeResult .

chi:artifact_188234_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188234 .

chi:result_188234_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188235 rdf:type chi:Paper ;
    dcterms:title "Co-Designing Multimodal Tools for Radically Mobile Hybrid Meetings" ;
    dcterms:abstract "Hybrid meetings have become common practice in collaborative work environments.  However, they are constrained by the fixed spatial configurations of videoconferencing technology.  This limits opportunities for mobile and spontaneous interactions; qualities that are critical to successful collaboration. In this paper, we explore the concept of radically mobile hybrid meetings.  Our work investigates the design space of multimodal devices as mobile alternatives to traditional videoconferencing. We conducted three group co-design sessions, where participants prototyped mobile hybrid meeting technologies to explore how such meetings could be supported. From these workshops, we derive design fictions envisioning future uses of these technologies, which we evaluate with a questionnaire to spark reflections on future mobile hybrid collaboration tools and practices. We contribute an initial exploration of the design space for radically mobile hybrid meetings, laying the groundwork for developing tools that enable spontaneous, effective, and inclusive collaboration in hybrid mobile settings." ;
    dcterms:identifier "3706598.3713993" ;
    chi:hasAuthor chi:person_185487, chi:person_183357, chi:person_187876 ;
    chi:hasPrimaryTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:MobileHybridCollaboration ;
    chi:paperIncludesStudy chi:study_188235_UserStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188235_DeviceArtifact .

chi:study_188235_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188235 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188235_QualitativeResult .

chi:artifact_188235_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188235 .

chi:result_188235_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188236 rdf:type chi:Paper ;
    dcterms:title "Ethical Reflexivity Canvas: Resourcing Ethical Sensitivity for HCI Educators" ;
    dcterms:abstract "Integrating ethics education in human-computer interaction (HCI) programs is critical to training responsible industry practitioners. Yet, there is a lack of practical educator-focused resources, which facilitate reflection on personal approaches to ethics education. We conducted a series of nine generative participatory workshops with 15 educators to explore, design and seek feedback on the Ethics Reflexivity Canvas as a pedagogical resource. The canvas makes the educator and learner positionality explicit to develop ethical sensitivity, sensitise and situate a pedagogical plan, and iterate and adapt over time. However, our findings suggest that educators experience tensions, depending on their pedagogical approach. We contribute insight on how resources can align with education work in HCI, help educators reflect on a plurality of approaches to ethics, use accessible language to stimulate curiosity towards ethics, and provide scaffolding to operationalize collaborative and personal exploration." ;
    dcterms:identifier "3706598.3713574" ;
    chi:hasAuthor chi:person_186741, chi:person_188074, chi:person_182935, chi:person_185590, chi:person_187610, chi:person_184795, chi:person_182886 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:ParticipatoryEthicsMethods ;
    chi:paperIncludesStudy chi:study_188236_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188236_InterfaceArtifact .

chi:study_188236_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188236 ;
    chi:reportsResult chi:result_188236_QualitativeResult .

chi:artifact_188236_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188236 .

chi:result_188236_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188237 rdf:type chi:Paper ;
    dcterms:title "Jupybara: Operationalizing a Design Space for Actionable Data Analysis and Storytelling with LLMs" ;
    dcterms:abstract "Mining and conveying actionable insights from complex data is a key challenge of exploratory data analysis (EDA) and storytelling. To address this challenge, we present a design space for actionable EDA and storytelling. Synthesizing theory and expert interviews, we highlight how semantic precision, rhetorical persuasion, and pragmatic relevance underpin effective EDA and storytelling. We also show how this design space subsumes common challenges in actionable EDA and storytelling, such as identifying appropriate analytical strategies and leveraging relevant domain knowledge. Building on the potential of LLMs to generate coherent narratives with commonsense reasoning, we contribute Jupybara, an AI-enabled assistant for actionable EDA and storytelling implemented as a Jupyter Notebook extension. Jupybara employs two strategies—design-space-aware prompting and multi-agent architectures—to operationalize our design space. An expert evaluation confirms Jupybara’s usability, steerability, explainability, and reparability, as well as the effectiveness of our strategies in operationalizing the design space framework with LLMs." ;
    dcterms:identifier "3706598.3713913" ;
    chi:hasAuthor chi:person_184858, chi:person_185559, chi:person_186992 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:CollaborativeVisualizationTools ;
    chi:paperIncludesStudy chi:study_188237_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188237_UserStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188237_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188237_InterfaceArtifact .

chi:study_188237_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188237 ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:reportsResult chi:result_188237_QualitativeResult .

chi:study_188237_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188237 ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:reportsResult chi:result_188237_QualitativeResult .

chi:artifact_188237_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188237 .

chi:artifact_188237_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188237 .

chi:result_188237_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188238 rdf:type chi:Paper ;
    dcterms:title "“My doctor didn't give me half of that privilege”: Incorporating Black Patients’ Lived Experiences in Virtual Patients for Racial Bias Mitigation Training" ;
    dcterms:abstract "Despite HCI research emphasizing the direct involvement of racial minorities in technology design, Black patients have been notably excluded when designing virtual patients intended to represent them in healthcare training applications. To address this gap, this paper describes an iterative user-centered design process to create a virtual patient prototype (EQUITY) that authentically reflects real-world racially biased encounters using narratives of Black patients’ lived experiences. EQUITY was developed using insights gathered from 6 focus groups with 33 Black patients (Study 1). EQUITY was evaluated with 25 doctors to assess its effectiveness in inducing disorienting experiences and facilitating self-reflection (Study 2). Findings suggest that incorporating patient narratives, particularly through virtual patients' verbal and non-verbal behaviors and role-playing, significantly enhanced virtual patient’s authenticity and meaningful self-reflection among doctors. Our research contributes to HCI by identifying key virtual patient interface design features that align with Black patients' lived experiences of racially biased encounters." ;
    dcterms:identifier "3706598.3713549" ;
    chi:hasAuthor chi:person_182942, chi:person_184257, chi:person_184695, chi:person_187417 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188238_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188238_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188238_InterfaceArtifact .

chi:study_188238_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188238 ;
    chi:reportsResult chi:result_188238_QualitativeResult .

chi:artifact_188238_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188238 .

chi:artifact_188238_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188238 .

chi:result_188238_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188239 rdf:type chi:Paper ;
    dcterms:title "The Effects and Non-Effects of Social Sanctions from User Jury-Based Content Moderation Decisions on Weibo" ;
    dcterms:abstract "Between 2012 and 2014, Weibo used a novel crowdsourced user `committee' system to make content moderation decisions. In it, user volunteers were randomly assigned to jury-like committees to vote and comment on whether reported content violated platform rules. The perceived legitimacy of similar systems has been studied in tightly controlled lab and survey experiments, but the causal effects of such jury-like moderation systems on user behavior in the real world have not been studied to the same extent. Leveraging random variation in Weibo case votes due to the assignment of more or less lenient `jurors', we show that, on average, social sanctioning and norm-setting through committee votes was associated with a large but brief decline in reported users' future posting of offensive terms. However, in line with prior work on the relative ineffectiveness of out-group sanctioning, we observe no such effect among women sanctioned by the largely male committees.This study advances our understanding of the effects of institutionalized social sanctioning on social media user behavior, and the promises and potential shortcomings of crowdsourced moderation systems." ;
    dcterms:identifier "3706598.3713154" ;
    chi:hasAuthor chi:person_183390, chi:person_186452 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:paperIncludesStudy chi:study_188239_FieldStudy ;
    chi:paperIncludesStudy chi:study_188239_QuantitativeStudy ;
    chi:proposesArtifact chi:artifact_188239_SoftwareArtifact .

chi:study_188239_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188239 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188239_StatisticalResult .

chi:study_188239_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188239 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188239_StatisticalResult .

chi:artifact_188239_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188239 .

chi:result_188239_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188240 rdf:type chi:Paper ;
    dcterms:title "Your Hands Can Tell: Detecting Redirected Hand Movements in Virtual Reality" ;
    dcterms:abstract "In-air hand interactions are prevalent in Virtual Reality (VR), and prior studies have shown that manipulating the visual movement of the hand to be different from the actual hand movement, i.e., hand redirection, could create a more immersive and engaging VR experience. However, this manipulation risks degrading task performance and, if maliciously applied, poses a threat to user safety. Such manipulations may arise from VR applications developed with intentional or inadvertent perceptual manipulations that yield harmful outcomes. We advocate for a user's prerogative to be informed of any such potential manipulations before application usage. To address this, our study introduces an \textit{Autoencoder}-based anomaly detection technique that leverages users' inherent hand movements to identify hand redirection, thereby preserving the integrity of application use. Our model is trained on regular (i.e., non-manipulated) hand movement patterns and employs a stochastic thresholding approach for anomaly detection. We validated our method through a technical evaluation involving 21 participants engaged in reaching tasks under manipulated and non-manipulated scenarios. The results demonstrated a high accuracy of hand redirection detection at 93.7%, with an F1-score of 93.9%. " ;
    dcterms:identifier "3706598.3713679" ;
    chi:hasAuthor chi:person_185804, chi:person_186301, chi:person_184500 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:EmbodiedVRInteraction ;
    chi:paperIncludesStudy chi:study_188240_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188240_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188240_InterfaceArtifact .

chi:study_188240_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188240 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188240_StatisticalResult .

chi:artifact_188240_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188240 .

chi:artifact_188240_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188240 .

chi:result_188240_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188241 rdf:type chi:Paper ;
    dcterms:title "Getting Trapped in Amazon's \"Iliad Flow\": A Foundation for the Temporal Analysis of Dark Patterns" ;
    dcterms:abstract "Dark patterns are ubiquitous in digital systems, impacting users throughout their journeys on many popular apps and websites. While substantial efforts from the research community in the last five years have led to consolidated taxonomies and an ontology of dark patterns, most characterizations of these patterns have been focused on static images or isolated pattern types. In this paper, we leverage documents from a US Federal Trade Commission complaint describing dark patterns in Amazon Prime's \"Iliad Flow,\" illustrating the interplay of dark patterns across a user journey. We use this case study to illustrate how dark patterns can be characterized and mapped over time, providing a sufficient audit trail and consistent application of dark patterns at high- and meso-level scales. We conclude by describing the groundwork for a methodology of Temporal Analysis of Dark Patterns (TADP) that allows for rigorous identification of dark patterns by researchers, regulators, and legal scholars." ;
    dcterms:identifier "3706598.3713828" ;
    chi:hasAuthor chi:person_185541, chi:person_187643, chi:person_185662 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188241_InterfaceArtifact .

chi:artifact_188241_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188241 .

chi:result_188241_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188242 rdf:type chi:Paper ;
    dcterms:title "Deriving Selection Techniques for GUIs based on the Multiple Process Model" ;
    dcterms:abstract "Designing efficient selection techniques for graphical user interfaces (GUIs) is fundamental in HCI research. We derive selection techniques based on the multiple process model, a theory that details the motor control processes during goal-directed movements. Specifically, we deduce three theoretical assumptions on how control processes of pre-planning, impulse control, and limb-target control could influence selection movements when adjusting GUI elements, including visual feedback, cursor position, and target position. Corresponding to our assumptions, we develop three techniques that hide the cursor when a target is highlighted, snap the cursor when selection begins, and expand clustered objects during selection movements. After that, we pre-register the assumptions and research methodology and evaluate the techniques in three crowdsourcing-based pointing studies. Our results show that all techniques improved the selection efficiency compared to established baselines. We further discuss the design implications and reflect on how we derived techniques from theory." ;
    dcterms:identifier "3706598.3713089" ;
    chi:hasAuthor chi:person_184815, chi:person_186738, chi:person_183263, chi:person_186817 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:PointingAndSelectionPerformance ;
    chi:paperIncludesStudy chi:study_188242_BaselineComparisonStudy ;
    chi:paperIncludesStudy chi:study_188242_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188242_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188242_SoftwareArtifact .

chi:study_188242_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188242 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188242_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:study_188242_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188242 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188242_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:artifact_188242_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188242 .

chi:artifact_188242_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188242 .

chi:result_188242_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188243 rdf:type chi:Paper ;
    dcterms:title "Designing for Difference: How We Learn to Stop Worrying and Love the Doppelganger" ;
    dcterms:abstract "To use social media is to interact with digital representations of oneself in the form of algorithmically-determined personalized content. Yet when we assume that interactions with personalized content will be a persistent feature of our futures, the concepts available to frame such digital representations -- things variously called doubles, twins, and doppelgangers -- appear as worryingly creepy. Where might one find optimism amid such presumptive creepiness? Through conceptual analysis of data doubles, digital twins, and data doppelgangers, we identify and explain one source of justifiable optimism. Unlike the double and twin, the data doppelganger's dynamics center difference rather than presumed sameness. Fostering justifiable optimism about the futures of personalization -- with social media as a starting point -- requires learning how to design for the experience of difference represented by the doppelganger: the irreducibility of the person to the represented user." ;
    dcterms:identifier "3706598.3713560" ;
    chi:hasAuthor chi:person_186164, chi:person_182735 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialPersonalizationAndFeeds ;
    chi:aimsAtGoal chi:IncreaseEngagement .

chi:result_188243_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188244 rdf:type chi:Paper ;
    dcterms:title "Non-Natural Interaction Design" ;
    dcterms:abstract "Natural interactions, such as those based on gesture input, feel intuitive, familiar, and well-suited to user abilities in context, and have been supported by extensive research. Contrary to the conventional mainstream, we advocate for non-natural interaction design as a transformative process that results in highly effective interactions by deliberately deviating from user intuition and expectations of physical-world naturalness or the context in which innate human modalities, such as gestures used for interaction and communication, are applied-departing from the established notion of the \"natural,\" yet prioritizing usability. To this end, we offer four perspectives on the relationship between natural and non-natural design, and explore three prototypes addressing gesture-based interactions with digital content in the physical environment, on the user's body, and through digital devices, to challenge assumptions in natural design. Lastly, we provide a formalization of non-natural interaction, along with design principles to guide future developments." ;
    dcterms:identifier "3706598.3713459" ;
    chi:hasAuthor chi:person_184882 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188244_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188244_DeviceArtifact .

chi:artifact_188244_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188244 .

chi:artifact_188244_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188244 .

chi:paper_188245 rdf:type chi:Paper ;
    dcterms:title "Toward Affective Empathy via Personalized Analogy Generation: A Case Study on Microaggression" ;
    dcterms:abstract "The importance of empathy cannot be overstated in modern societies where people of diverse backgrounds increasingly interact together. The HCI community has strived to foster affective empathy through immersive technologies. Many previous techniques are built upon a premise that presenting the same experience as-is may help evoke the same emotion, which however faces limitations in matters where the emotional responses largely differ across individuals. In this paper, we present a novel concept of generating a personalized experience based on a large language model (LLM) to facilitate affective empathy between individuals despite their differences. As a case study to showcase its effectiveness, we developed EmoSync, an LLM-based agent that generates personalized analogical microaggression situations, facilitating users to personally resonate with a specific microaggression situation of another person. EmoSync is designed and evaluated along a 3-phased user study with 100+ participants. We comprehensively discuss implications, limitations, and possible applications. " ;
    dcterms:identifier "3706598.3714122" ;
    chi:hasAuthor chi:person_188086, chi:person_188098, chi:person_186772, chi:person_185096, chi:person_187409 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:ChatbotAssistedUserStudies ;
    chi:paperIncludesStudy chi:study_188245_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188245_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188245_InterfaceArtifact .

chi:study_188245_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188245 ;
    chi:reportsResult chi:result_188245_QualitativeResult .

chi:artifact_188245_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188245 .

chi:artifact_188245_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188245 .

chi:result_188245_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188246 rdf:type chi:Paper ;
    dcterms:title "AI, Help Me Think—but for Myself: Assisting People in Complex Decision-Making by Providing Different Kinds of Cognitive Support" ;
    dcterms:abstract "How can we design AI tools that effectively support human decision-making by complementing and enhancing users' reasoning processes? Common recommendation-centric approaches face challenges such as inappropriate reliance or a lack of integration with users' decision-making processes. Here, we explore an alternative interaction model in which the AI outputs build upon users' own decision-making rationales. We compare this approach, which we call ExtendAI, with a recommendation-based AI. Participants in our mixed-methods user study interacted with both AIs as part of an investment decision-making task. We found that the AIs had different impacts, with ExtendAI integrating better into the decision-making process and people's own thinking and leading to slightly better outcomes. RecommendAI was able to provide more novel insights while requiring less cognitive effort. We discuss the implications of these and other findings along with three tensions of AI-assisted decision-making which our study revealed." ;
    dcterms:identifier "3706598.3713295" ;
    chi:hasAuthor chi:person_184481, chi:person_188150, chi:person_184477, chi:person_184355, chi:person_188194, chi:person_187141 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188246_UserStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188246_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188246_InterfaceArtifact .

chi:study_188246_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188246 ;
    chi:reportsResult chi:result_188246_QualitativeResult ;
    chi:reportsResult chi:result_188246_StatisticalResult .

chi:artifact_188246_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188246 .

chi:artifact_188246_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188246 .

chi:result_188246_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188246_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188248 rdf:type chi:Paper ;
    dcterms:title "Birds of a Rhythm: The Effects of Haptic Pattern Similarity on People's Social Perceptions in Virtual Reality" ;
    dcterms:abstract "Virtual reality (VR) expands opportunities for social interaction, yet its heavy reliance on visual cues can limit social engagement and hinder immersive experiences in visually overwhelming situations. To explore alternative social cues beyond the visual domain, we verified the potential of haptic cues for social identification in VR by examining the effects of haptic pattern similarity on social perceptions. Unique haptic patterns were assigned to participants and virtual agents for identification, while the similarity of haptic patterns was manipulated (same, similar, distinct). The results demonstrated that participants maintained closer interpersonal distances and reported higher senses of belonging, social connection, and comfort toward agents as the similarity of patterns increased. Our findings validate the potential of haptic patterns in social identification and provide scientific evidence that homophily extends beyond the visual domain to the haptic domain. We also suggest a novel haptic-based methodology for conveying relationship information and enhancing social VR experiences." ;
    dcterms:identifier "3706598.3714264" ;
    chi:hasAuthor chi:person_182713, chi:person_186515 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:paperIncludesStudy chi:study_188248_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188248_InterfaceArtifact .

chi:study_188248_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188248 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188248_StatisticalResult .

chi:artifact_188248_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188248 .

chi:result_188248_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188250 rdf:type chi:Paper ;
    dcterms:title "Examining Student and Teacher Perspectives on Undisclosed Use of Generative AI in Academic Work" ;
    dcterms:abstract "With the widespread adoption of Generative Artificial Intelligence (GenAI) tools, ethical issues are being raised around the disclosure of their use in publishing, journalism, or artwork. Recent research has found that college students are increasingly using GenAI tools; however, we know less about when, why, and how they choose to hide or disclose their use of GenAI in academic work. To address this gap, we conducted an online survey (n=97) and interviews with fifteen college students followed by interviews with nine teachers who had experience with students' undisclosed use of GenAI. Our findings elucidate the strategies students employ to hide their GenAI use and their justifications for doing so, alongside the strategies teachers follow to manage such non-disclosure. We unpack students' non-disclosure of GenAI through the lens of cognitive dissonance and discuss practical considerations for teachers and students regarding ways to promote transparency in GenAI use in higher education." ;
    dcterms:identifier "3706598.3713393" ;
    chi:hasAuthor chi:person_183722, chi:person_183273, chi:person_183270, chi:person_186046, chi:person_183741 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:paperIncludesStudy chi:study_188250_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188250_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning .

chi:study_188250_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188250 ;
    chi:reportsResult chi:result_188250_QualitativeResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:study_188250_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188250 ;
    chi:reportsResult chi:result_188250_QualitativeResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:result_188250_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188254 rdf:type chi:Paper ;
    dcterms:title "Snap, Sweat, and Sketch: Designing Home Exercise Experiences for Augmented Reality Head-mounted Displays" ;
    dcterms:abstract "Augmented Reality (AR) head-mounted displays (HMDs) offer potential for more inclusive and immersive exercising and exergaming experiences at home. Previous work found that augmenting home objects can create more engaging exercise experiences and identified various home objects that can be augmented to facilitate different exercises. However, it is unclear how these objects can be augmented to enhance exercising and tailored based on the exercise. We conducted a multi-part study involving a design activity using Snapchat and focus group discussion with 28 participants. We present five themes relating to participants' preferences for the augmentation of home objects for exercising, and identify and discuss key guidelines that designers and researchers should consider when augmenting home objects. Our results provide designers with guidelines and ideas for the augmentation of four different exercises, and advance the foundation for future work developing home-based exergaming through AR HMDs to increase people's physical activity levels." ;
    dcterms:identifier "3706598.3713575" ;
    chi:hasAuthor chi:person_183623, chi:person_187773, chi:person_185248 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:EmbodiedVRInteraction ;
    chi:paperIncludesStudy chi:study_188254_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188254_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188254_InterfaceArtifact .

chi:study_188254_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188254 ;
    chi:reportsResult chi:result_188254_QualitativeResult .

chi:artifact_188254_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188254 .

chi:artifact_188254_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188254 .

chi:result_188254_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188255 rdf:type chi:Paper ;
    dcterms:title "Seeing and Touching the Air: Unraveling Eye-Hand Coordination in Mid-Air Gesture Typing for Mixed Reality" ;
    dcterms:abstract "Mid-air text entry in mixed reality (MR) headsets has shown promise but remains less efficient than traditional input methods. While research has focused on improving typing performance, the mechanics of mid-air gesture typing, especially eye-hand coordination, are less understood. This paper investigates visuomotor coordination of mid-air gesture keyboards through a user study (n=16) comparing gesture typing on a tablet and in mid-air. Through an expert task we demonstrate that users were able to achieve a comparable text input performance. Our in-depth analysis of eye-hand coordination reveals significant differences in the eye-hand coordination patterns between gesture typing on a tablet and in-air. The mid-air gesture typing necessitates almost all of the visual attention on the keyboard area and a more consistent synchronization in eye-hand coordination to compensate for the increased motor and cognitive demands without physical boundaries. These insights provide important implications for the design of more efficient text input methods." ;
    dcterms:identifier "3706598.3713743" ;
    chi:hasAuthor chi:person_187619, chi:person_185306, chi:person_184067 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:paperIncludesStudy chi:study_188255_UserStudy ;
    chi:paperIncludesStudy chi:study_188255_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188255_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188255_InputDeviceArtifact .

chi:study_188255_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188255 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188255_StatisticalResult ;
    chi:reportsResult chi:result_188255_QualitativeResult .

chi:study_188255_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188255 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188255_StatisticalResult ;
    chi:reportsResult chi:result_188255_QualitativeResult .

chi:artifact_188255_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188255 .

chi:artifact_188255_InputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188255 .

chi:result_188255_StatisticalResult rdf:type chi:StatisticalResult .

chi:result_188255_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188256 rdf:type chi:Paper ;
    dcterms:title "Understanding Attitudes and Trust of Generative AI Chatbots for Social Anxiety Support" ;
    dcterms:abstract "Social anxiety (SA) has become increasingly prevalent. Traditional coping strategies often face accessibility challenges. Generative AI (GenAI), known for their knowledgeable and conversational capabilities, are emerging as alternative tools for mental well-being. With the increased integration of GenAI, it is important to examine individuals' attitudes and trust in GenAI chatbots' support for SA. Through a mixed-method approach that involved surveys (n = 159) and interviews (n = 17), we found that individuals with severe symptoms tended to trust and embrace GenAI chatbots more readily, valuing their non-judgmental support and perceived emotional comprehension. However, those with milder symptoms prioritized technical reliability. We identified factors influencing trust, such as GenAI chatbots' ability to generate empathetic responses and its context-sensitive limitations, which were particularly important among individuals with SA. We also discuss the design implications and use of GenAI chatbots in fostering cognitive and emotional trust, with practical and design considerations." ;
    dcterms:identifier "3706598.3714286" ;
    chi:hasAuthor chi:person_183125, chi:person_183970, chi:person_185709, chi:person_186381 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing:SelfReflectionAndBehaviorChange ;
    chi:paperIncludesStudy chi:study_188256_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188256_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188256_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188256_InterfaceArtifact .

chi:study_188256_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188256 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188256_QualitativeResult ;
    chi:reportsResult chi:result_188256_StatisticalResult .

chi:study_188256_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188256 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188256_QualitativeResult ;
    chi:reportsResult chi:result_188256_StatisticalResult .

chi:artifact_188256_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188256 .

chi:artifact_188256_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188256 .

chi:result_188256_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188256_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188257 rdf:type chi:Paper ;
    dcterms:title "It's Not the Shape, It's the Settings: Tools for Exploring, Documenting, and Sharing Physical Fabrication Parameters in 3D Printing" ;
    dcterms:abstract "The material properties of 3D prints depend on their constituent materials, how they were printed, and local geometrical features. Motivated by challenges in sharing physical details of 3D printing workflows including machine state and print settings, we contribute tools to support the exploration of the vast design space these interdependent parameters make up. Inspired by live music performance and video captioning, we contribute an interactive controller for parameters not represented in geometry such as speed and extrusion rate, and a system for automatically syncing video documentation to machine settings, G-Code, and print commands. By synchronizing video with machine instructions and interactive adjustments, we archive the relationship between digital settings and physical output for revisiting and sharing. We demonstrate example workflows in multiple materials. Our approach suggests how maker tools that promote settings exploration and sharing can support the integration of fabrication technologies in new contexts, with new materials." ;
    dcterms:identifier "3706598.3713354" ;
    chi:hasAuthor chi:person_188050, chi:person_183322, chi:person_185427 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188257_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188257_InterfaceArtifact .

chi:artifact_188257_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188257 .

chi:artifact_188257_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188257 .

chi:paper_188258 rdf:type chi:Paper ;
    dcterms:title "Lost in Translation: How Does Bilingualism Shape Reader Preferences for Annotated Charts?" ;
    dcterms:abstract "Visualizations are powerful tools for conveying information but often rely on accompanying text for essential context and guidance. This study investigates the impact of annotation patterns on reader preferences and comprehension accuracy among multilingual populations, addressing a gap in visualization research. We conducted experiments with two groups fluent in English and either Tamil (n = 557) or Arabic (n = 539) across six visualization types, each varying in annotation volume and semantic content. Full-text annotations yielded the highest comprehension accuracy across all languages, while preferences diverged: English readers favored highly annotated charts, whereas Tamil/Arabic readers preferred full-text or minimally annotated versions. Semantic variations in annotations (L1–L4) did not significantly affect comprehension, demonstrating the robustness of text comprehension across languages. English annotations were generally preferred, with a tendency to think technically in English linked to greater aversion to non-English annotations, though this diminished among participants who regularly switched languages internally. Non-English annotations incorporating visual or external knowledge were less favored, particularly in titles. Our findings highlight cultural and educational factors influencing perceptions of visual information, underscoring the need for inclusive annotation practices for diverse linguistic audiences. All data and materials are available at: https://osf.io/ckdb4/." ;
    dcterms:identifier "3706598.3713380" ;
    chi:hasAuthor chi:person_185563, chi:person_183007, chi:person_184971 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:SelfReflectionAndBehaviorChange ;
    chi:paperIncludesStudy chi:study_188258_UserStudy ;
    chi:paperIncludesStudy chi:study_188258_QuantitativeStudy ;
    chi:paperIncludesStudy chi:study_188258_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188258_InterfaceArtifact .

chi:study_188258_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188258 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188258_StatisticalResult .

chi:study_188258_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188258 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188258_StatisticalResult .

chi:study_188258_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188258 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188258_StatisticalResult .

chi:artifact_188258_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188258 .

chi:result_188258_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188259 rdf:type chi:Paper ;
    dcterms:title "The Framework of the Lived Experience of Metrics: Understanding the Purposes and Activities of Self-Tracking Metrics" ;
    dcterms:abstract "Most studies of Personal Informatics (PI) focus on the holistic experience of self-tracking or how users relate to self-tracking goals. Recently, new tracker metrics became available in commercial systems, e.g. stress scores or body battery. Hence, more attention should be devoted to what users track and how they understand metrics produced by their trackers. Charting the evolution of metrics in PI can enable building systems that better support well-being. To this end, we interviewed n=25 fitness tracker users to discover what metrics are most important to them, how they understand the metrics, and how they formulate their goals with respect to the metrics. We found that users created a metric ecology which they adjusted to their life circumstances, reformulating their goals. We identified key issues in understanding metrics which bear the risk of misuse. We contribute recommendations for future PI systems as self-tracking metrics increase in complexity." ;
    dcterms:identifier "3706598.3713650" ;
    chi:hasAuthor chi:person_187787, chi:person_187495, chi:person_186702, chi:person_187730 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:SelfReflectionAndBehaviorChange ;
    chi:paperIncludesStudy chi:study_188259_InterviewStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188259_DeviceArtifact .

chi:study_188259_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188259 ;
    chi:reportsResult chi:result_188259_QualitativeResult .

chi:artifact_188259_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188259 .

chi:result_188259_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188260 rdf:type chi:Paper ;
    dcterms:title "Hidden in Plain Sight: a Structured Analysis of Privacy Policies in the Context of Body-worn 'FemTech' Technologies" ;
    dcterms:abstract "As HCI research turns to women's reproductive health as a topic of interest, an increasing number of female-oriented technologies (FemTech) are being marketed to consumers. This opens up a space for better management and understanding of intimate health but is not without risk. Reproductive health data collected by FemTech devices is highly sensitive and politicized. Breaches of privacy can cause or exacerbate discrimination and gender inequality, and negatively impact users' safety and well-being. It is therefore important that users are well informed about how their data is collected, handled, used and stored. This work contributes insights into whether and to what extent this is achieved by current FemTech. We conduct a structured content analysis of 18 in-effect privacy policies. Applying an empirically-grounded taxonomy, we identify challenges in policy wording, content and presentation. We conclude with recommendations for improving transparency and supporting users in providing informed consent and claiming data authority." ;
    dcterms:identifier "3706598.3713702" ;
    chi:hasAuthor chi:person_186690, chi:person_182661, chi:person_184932, chi:person_186821 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:DataDisclosureAndConsent ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188260_DeviceArtifact .

chi:artifact_188260_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188260 .

chi:result_188260_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188262 rdf:type chi:Paper ;
    dcterms:title "Modeling the Impact of Visual Stimuli on Redirection Noticeability with Gaze Behavior in Virtual Reality" ;
    dcterms:abstract "While users could embody virtual avatars that mirror their physical movements in Virtual Reality, these avatars' motions can be redirected to enable novel interactions. Excessive redirection, however, could break the user's sense of embodiment due to perceptual conflicts between vision and proprioception. While prior work focused on avatar-related factors influencing the noticeability of redirection, we investigate how the visual stimuli in the surrounding virtual environment affect user behavior and, in turn, the noticeability of redirection. Given the wide variety of different types of visual stimuli and their tendency to elicit varying individual reactions, we propose to use users' gaze behavior as an indicator of their response to the stimuli and model the noticeability of redirection. We conducted two user studies to collect users' gaze behavior and noticeability, investigating the relationship between them and identifying the most effective gaze behavior features for predicting noticeability. Based on the data, we developed a regression model that takes users' gaze behavior as input and outputs the noticeability of redirection. We then conducted an evaluation study to test our model on unseen visual stimuli, achieving an accuracy of 0.012 MSE. We further implemented an adaptive redirection technique and conducted a proof-of-concept study to evaluate its effectiveness with complex visual stimuli in two applications. The results indicated that participants experienced less physical demanding and a stronger sense of body ownership when using our adaptive technique, demonstrating the potential of our model to support real-world use cases." ;
    dcterms:identifier "3706598.3713392" ;
    chi:hasAuthor chi:person_187140, chi:person_185286, chi:person_186880, chi:person_185605, chi:person_183231, chi:person_187044, chi:person_182990 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:EmbodiedVRInteraction ;
    chi:paperIncludesStudy chi:study_188262_UserStudy ;
    chi:paperIncludesStudy chi:study_188262_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188262_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188262_InterfaceArtifact .

chi:study_188262_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188262 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188262_StatisticalResult .

chi:study_188262_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188262 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188262_StatisticalResult .

chi:artifact_188262_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188262 .

chi:artifact_188262_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188262 .

chi:result_188262_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188263 rdf:type chi:Paper ;
    dcterms:title "Private Yet Social: How LLM Chatbots Support and Challenge Eating Disorder Recovery" ;
    dcterms:abstract "Eating disorders (ED) are complex mental health conditions that require long-term management and support. Recent advancements in large language model (LLM)-based chatbots offer the potential to assist individuals in receiving immediate support. Yet, concerns remain about their reliability and safety in sensitive contexts such as ED. We explore the opportunities and potential harms of using LLM-based chatbots for ED recovery. We observe the interactions between 26 participants with ED and an LLM-based chatbot, WellnessBot, designed to support ED recovery, over 10 days. We discovered that our participants have felt empowered in recovery by discussing ED-related stories with the chatbot, which served as a personal yet social avenue. However, we also identified harmful chatbot responses, especially concerning individuals with ED, that went unnoticed partly due to participants’ unquestioning trust in the chatbot's reliability. Based on these findings, we provide design implications for safe and effective LLM-based interventions in ED management." ;
    dcterms:identifier "3706598.3713485" ;
    chi:hasAuthor chi:person_187349, chi:person_185353, chi:person_187230, chi:person_187522, chi:person_187761 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:SocialComputing:SocialSupportAndPeerChatbots ;
    chi:paperIncludesStudy chi:study_188263_FieldStudy ;
    chi:paperIncludesStudy chi:study_188263_UserStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188263_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188263_InterfaceArtifact .

chi:study_188263_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188263 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188263_QualitativeResult .

chi:study_188263_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188263 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188263_QualitativeResult .

chi:artifact_188263_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188263 .

chi:artifact_188263_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188263 .

chi:result_188263_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188272 rdf:type chi:Paper ;
    dcterms:title "All in One: Rapid Game Prototyping in a Single View" ;
    dcterms:abstract "Creating games involves frequent prototyping to quickly obtain feedback. In this paper, we explore the impact of removing a traditional game engine’s separation of scene and game logic that supports scalability to large projects and, instead, combine scene and game logic in a single view. In our tool, Pronto, designers connect game objects with visual representations of behavior to define game logic in the scene view, thus exposing any concern of the prototype to the designer within one click. To explore the implications of the trade-off between scalability and speed of access, we conducted a cognitive walkthrough and an explorative user study comparing prototyping in the Godot game engine and in Pronto. Godot’s separate views made it appear more structured and reliable to users, while Pronto’s scattered game logic accelerated editing and gave users the impression of progressing faster in their implementation." ;
    dcterms:identifier "3706598.3714251" ;
    chi:hasAuthor chi:person_183195, chi:person_184395, chi:person_185696, chi:person_183171, chi:person_184990, chi:person_186025 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:paperIncludesStudy chi:study_188272_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188272_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188272_InterfaceArtifact .

chi:study_188272_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188272 ;
    chi:reportsResult chi:result_188272_QualitativeResult .

chi:artifact_188272_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188272 .

chi:artifact_188272_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188272 .

chi:result_188272_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188274 rdf:type chi:Paper ;
    dcterms:title "Measuring Risks to Users' Health Privacy Posed by Third-Party Web Tracking and Targeted Advertising" ;
    dcterms:abstract "Online advertising platforms may be able to infer privacy-sensitive information about people, such as their health conditions. This could lead to harms like exposure to predatory targeted advertising or unwanted disclosure of health conditions to employers or insurers. In this work, we experimentally evaluate whether online advertisers target people with health conditions. We collected the browsing histories of people with and without health conditions. We crawled their histories to simulate their browsing profiles and collected the ads that were served to them. Then, we compared the content of the ads between groups. We observed that the profiles of people who visited more health-related web pages received more health-related ads. 49.5% of health-related ads used deceptive advertising techniques. Our findings suggest that new privacy regulations and enforcement measures are needed to protect people's health privacy from online tracking and advertising platforms." ;
    dcterms:identifier "3706598.3714318" ;
    chi:hasAuthor chi:person_187551, chi:person_186370, chi:person_187477, chi:person_184486, chi:person_188124, chi:person_187832, chi:person_183245, chi:person_183927, chi:person_184020, chi:person_182799, chi:person_186305, chi:person_187440 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness:DataDisclosureAndConsent ;
    chi:aboutTopic chi:EthicsPrivacyFairness:DataDisclosureAndConsent ;
    chi:paperIncludesStudy chi:study_188274_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188274_SoftwareArtifact .

chi:study_188274_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188274 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188274_StatisticalResult .

chi:artifact_188274_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188274 .

chi:result_188274_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188275 rdf:type chi:Paper ;
    dcterms:title "DynEx: Dynamic Code Synthesis with Structured Design Exploration for Accelerated Exploratory Programming" ;
    dcterms:abstract "Recent advancements in large language models have significantly expedited the process of generating front-end code. This allows users to rapidly prototype user interfaces and ideate through code, a process known as exploratory programming. However, existing LLM code generation tools focus more on technical implementation details rather than finding the right design given a particular problem. We present DynEx, an LLM-based method for design exploration in accelerated exploratory programming.  DynEx introduces a technique to explore the design space through a structured Design Matrix before creating the prototype with a modular, stepwise approach to LLM code generation. Code is generated sequentially, and users can test and approve each step before moving onto the next. A user study of 10 experts found that DynEx increased design exploration and enabled the creation of more complex and varied prototypes compared to a Claude Artifact baseline.  We conclude with a discussion of the implications of design exploration for exploratory programming. " ;
    dcterms:identifier "3706598.3714115" ;
    chi:hasAuthor chi:person_188023, chi:person_186461, chi:person_186824, chi:person_185473, chi:person_184898, chi:person_184604, chi:person_185779 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:paperIncludesStudy chi:study_188275_UserStudy ;
    chi:paperIncludesStudy chi:study_188275_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188275_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188275_InterfaceArtifact .

chi:study_188275_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188275 ;
    chi:reportsResult chi:result_188275_QualitativeResult ;
    chi:reportsResult chi:result_188275_StatisticalResult .

chi:study_188275_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188275 ;
    chi:reportsResult chi:result_188275_QualitativeResult ;
    chi:reportsResult chi:result_188275_StatisticalResult .

chi:artifact_188275_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188275 .

chi:artifact_188275_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188275 .

chi:result_188275_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188275_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188276 rdf:type chi:Paper ;
    dcterms:title "Toward Filling a Critical Knowledge Gap: Charting the Interactions of Age with Task and Visualization" ;
    dcterms:abstract "We present the results of a study comparing the performance of younger adults (YA) and people in late adulthood (PLA) across ten low-level analysis tasks and five basic visualizations, employing Bayesian regression to aggregate and model participant performance. We analyzed performance at the task level and across combinations of tasks and visualizations, reporting measures of performance at aggregate and individual levels. These analyses showed that PLA on average required more time to complete tasks while demonstrating comparable accuracy. Furthermore, at the individual level, PLA exhibited greater heterogeneity in task performance as well as differences in best-performing visualization types for some tasks. We contribute empirical knowledge on how age interacts with analysis task and visualization type and use these results to offer actionable insights and design recommendations for aging-inclusive visualization design. We invite the visualization research community to further investigate aging-aware data visualization. Supplementary materials can be found at https://osf.io/a7xtz/." ;
    dcterms:identifier "3706598.3714229" ;
    chi:hasAuthor chi:person_187266, chi:person_187797 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:ErrorRatesAndTaskCompletion ;
    chi:paperIncludesStudy chi:study_188276_UserStudy ;
    chi:paperIncludesStudy chi:study_188276_QuantitativeStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188276_InterfaceArtifact .

chi:study_188276_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188276 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188276_StatisticalResult .

chi:study_188276_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188276 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188276_StatisticalResult .

chi:artifact_188276_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188276 .

chi:result_188276_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188277 rdf:type chi:Paper ;
    dcterms:title "QCM: A Curvature Manipulation Method to Suppress Discomfort in Redirected Walking" ;
    dcterms:abstract "In redirected walking techniques, curvature gain and bending gain, which are referred to as curvature manipulation, are important redirection gains. The applied gains can differ when multiple paths are mapped, and sudden changes in gain may cause discomfort. This study proposes quadratic curvature manipulation (QCM) based on the habituation mechanism to effectively reduce discomfort. This method quadratically adjusts the path curvature, thereby reducing user's perception of curvature changes. Furthermore, we introduce the segmented curvature change (SCC) mode that combines QCM with linear curvature manipulation to facilitate more natural gain transitions, thereby reducing discomfort. Two experiments were conducted. Experiment 1 examined the relationship between QCM parameters and gains at which users felt discomfort. Experiment 2 further examined the effects of different curvature change modes on discomfort. The results indicate that using the SCC mode in curvature manipulations is more effective than other methods in reducing discomfort." ;
    dcterms:identifier "3706598.3714116" ;
    chi:hasAuthor chi:person_182751, chi:person_185540, chi:person_187617, chi:person_187040, chi:person_186257, chi:person_183659, chi:person_183431, chi:person_186074 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction-ImmersiveTrainingAndSimulation ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction-ImmersiveTrainingAndSimulation ;
    chi:paperIncludesStudy chi:study_188277_UserStudy ;
    chi:aimsAtGoal chi:ReduceCognitiveLoad ;
    chi:proposesArtifact chi:artifact_188277_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188277_InterfaceArtifact .

chi:study_188277_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188277 ;
    chi:reportsResult chi:result_188277_StatisticalResult .

chi:artifact_188277_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188277 .

chi:artifact_188277_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188277 .

chi:result_188277_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188278 rdf:type chi:Paper ;
    dcterms:title "Data at Hand: Exploring the Tactile Perception of Data Physicalizations" ;
    dcterms:abstract "Data physicalizations are tangible objects, and touching them may improve their interpretation. However, little is known about how people actually touch physicalizations. We recorded verbal and tactile responses to data physicalizations in three consecutive conditions: as an unspecified object, as a representation of unknown data, and with full information about data and encoding. Our two stimulus objects present data for nine countries in a 3x3 grid. We varied vertical axis polarity, with positive data values either above (convex) or below (concave) baseline. Using an analog tracer method, we examine whether some components of the physicalization are touched more than others, whether touch varies by task and the impact of axis polarity. We found large differences in the degree to which different components were touched and that the effect of vertical axis polarity depended on task. We describe additional tactile and verbal behaviors that can inform the design of data physicalizations." ;
    dcterms:identifier "3706598.3713212" ;
    chi:hasAuthor chi:person_183258, chi:person_184790, chi:person_184453 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:paperIncludesStudy chi:study_188278_UserStudy ;
    chi:proposesArtifact chi:artifact_188278_DeviceArtifact .

chi:study_188278_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188278 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188278_QualitativeResult ;
    chi:reportsResult chi:result_188278_StatisticalResult .

chi:artifact_188278_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188278 .

chi:result_188278_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188278_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188279 rdf:type chi:Paper ;
    dcterms:title "The News Says, the Bot Says: How Immigrants and Locals Differ in Chatbot-Facilitated News Reading" ;
    dcterms:abstract "News reading helps individuals stay informed about events and developments in society. Local residents and new immigrants often approach the same news differently, prompting the question of how technology, such as LLM-powered chatbots, can best enhance a reader-oriented news experience. The current paper presents an empirical study involving 144 participants from three groups in Virginia, United States: local residents born and raised there (N=48), Chinese immigrants (N=48), and Vietnamese immigrants (N=48). All participants read local housing news with the assistance of the Copilot chatbot. We collected data on each participant's Q&A interactions with the chatbot, along with their takeaways from news reading. While engaging with the news content, participants in both immigrant groups asked the chatbot fewer analytical questions than the local group. They also demonstrated a greater tendency to rely on the chatbot when formulating practical takeaways. These findings offer insights into technology design that aims to serve diverse news readers." ;
    dcterms:identifier "3706598.3714050" ;
    chi:hasAuthor chi:person_183090, chi:person_183581, chi:person_185836, chi:person_186991 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialPersonalizationAndFeeds ;
    chi:paperIncludesStudy chi:study_188279_UserStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188279_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188279_InterfaceArtifact .

chi:study_188279_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188279 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188279_StatisticalResult ;
    chi:reportsResult chi:result_188279_QualitativeResult .

chi:artifact_188279_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188279 .

chi:artifact_188279_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188279 .

chi:result_188279_StatisticalResult rdf:type chi:StatisticalResult .

chi:result_188279_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188280 rdf:type chi:Paper ;
    dcterms:title "Reselling Practices in a Textile Bazaar: Translating E-Commerce Platforms to WhatsApp " ;
    dcterms:abstract "We examine WhatsApp-based reselling practices adopted by small garment sellers in Surat, a textile city in India, as a response to the challenges posed by high commission costs, confusing dashboards, and restrictive rules of global e-commerce platforms. Through interviews and observations, we show how sellers use WhatsApp’s popularity to collaborate with women resellers and customers, enabling participation in online commerce bypassing e-commerce platforms. Using the lens of translation, we argue that WhatsApp functions as a tool and site of praxis for sellers who translate the complicated, standardized, and expensive processes of e-commerce platforms that are in English into multimodal, idiomatic, collaborative reselling practices. These are undertaken in regional languages on WhatsApp with the help of traders and women resellers economically benefiting everyone while delivering a personalized online shopping experience for customers. We discuss the politics of this translation, examining its impact on the design of e-commerce platforms while also shaping the discourse of reselling as an empowering pathway for women." ;
    dcterms:identifier "3706598.3713178" ;
    chi:hasAuthor chi:person_186384, chi:person_182941 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:paperIncludesStudy chi:study_188280_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188280_FieldStudy .

chi:study_188280_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188280 ;
    chi:reportsResult chi:result_188280_QualitativeResult .

chi:study_188280_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188280 ;
    chi:reportsResult chi:result_188280_QualitativeResult .

chi:result_188280_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188281 rdf:type chi:Paper ;
    dcterms:title "Hapticus: Exploring the Effects of Haptic Feedback and its Customization on Motor Skill Learning: Tactile, Haptic, and Somatosensory Approaches" ;
    dcterms:abstract "Numerous haptic devices have been proposed to support motor learning, such as a hand exoskeleton with mechanical linkages, a vibrotactile glove, and an Electrical Muscle Stimulation (EMS) device. Understanding the impact of each type of feedback on users’ learning performance and experience, as well as the effects of customizing the haptic feedback each user receives, is vital to achieving both efficient and highly motivating learning. To this end, we compared learning performance and experience while using these haptic devices for piano learning. It revealed the distinct characteristics of each device, notably, the exoskeleton was the most preferred despite certain drawbacks. We then conducted a user study to evaluate the effectiveness of haptic customization, allowing participants to customize the order of haptic feedback, demonstrating its advantages such as improved agency and performance. These findings would benefit haptic designers by providing more efficient and optimized haptic feedback for motor learning scenarios." ;
    dcterms:identifier "3706598.3713821" ;
    chi:hasAuthor chi:person_185408, chi:person_186845, chi:person_185836, chi:person_185476 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188281_UserStudy ;
    chi:paperIncludesStudy chi:study_188281_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188281_DeviceArtifact .

chi:study_188281_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188281 ;
    chi:hasMeasure chi:PerformanceMeasure ;
    chi:reportsResult chi:result_188281_QualitativeResult ;
    chi:reportsResult chi:result_188281_StatisticalResult .

chi:study_188281_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188281 ;
    chi:hasMeasure chi:PerformanceMeasure ;
    chi:reportsResult chi:result_188281_QualitativeResult ;
    chi:reportsResult chi:result_188281_StatisticalResult .

chi:artifact_188281_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188281 .

chi:result_188281_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188281_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188283 rdf:type chi:Paper ;
    dcterms:title "Surrendering to Powerlesness: Governing Personal Data Flows in Generative AI" ;
    dcterms:abstract "Personal data flows across digital technologies integrated into people's lives and relationships. Increasingly, these technologies include Generative AI. (How) should personal data flow into and out of GenAI models? We investigate how people experience personal data collection in GenAI ecosystems and unpack the enablers and barriers to governing their data. We focus on personal data collection by Meta, specifically Instagram, in line with their recent policy update on processing user data to train GenAI models. We conducted semi-structured interviews with 20 Latin American Instagram users, based in Europe and Latin America. We discussed the acceptability of their data flowing in and out of GenAI models through different scenarios. Our results interrogate power dynamics in data collection, the (inter)personal nature of data, and the multiple unknowns concerning data and their algorithmic derivatives. We pose provocations around feelings of powerlessness, reframing (inter)personal data, and encountering unknown data and algorithms through design." ;
    dcterms:identifier "3706598.3713504" ;
    chi:hasAuthor chi:person_182984, chi:person_183699, chi:person_186199 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:DataDisclosureAndConsent ;
    chi:paperIncludesStudy chi:study_188283_InterviewStudy .

chi:study_188283_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188283 ;
    chi:reportsResult chi:result_188283_QualitativeResult .

chi:result_188283_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188284 rdf:type chi:Paper ;
    dcterms:title "How to Design with Ambiguity: Insights from Self-tracking Wearables" ;
    dcterms:abstract "Nearly 20 years ago, Gaver et al. introduced ambiguity as a design resource, proposing tactics to reflect everyday uncertainty into interactive systems. This approach is especially relevant for self-tracking wearables, which often obscure the inherent ambiguity of system design and tracked phenomena with seemingly clear, prescriptive data and insights. Although scholars recognize the importance of ambiguity, its practical application in the design process remains underexplored. To address this, we conducted a two-week workshop with 60 designers, examining the application of Gaver et al.’s tactics into 11 design concepts, and performed interviews with 16 participants. Our findings reveal eight relevant ambiguity tactics for self-tracking and offer insights into participants' experiences with designing using ambiguity. We discuss prescription and overlooked ambiguity as levers for the operationalization of ambiguity, the potential benefits and downsides of ambiguity tactics for users, future directions for HCI research and practice, and the study limitations." ;
    dcterms:identifier "3706598.3713267" ;
    chi:hasAuthor chi:person_187733, chi:person_183876, chi:person_184155 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:SelfReflectionAndBehaviorChange ;
    chi:paperIncludesStudy chi:study_188284_UserStudy ;
    chi:paperIncludesStudy chi:study_188284_InterviewStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188284_DeviceArtifact .

chi:study_188284_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188284 ;
    chi:reportsResult chi:result_188284_QualitativeResult .

chi:study_188284_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188284 ;
    chi:reportsResult chi:result_188284_QualitativeResult .

chi:artifact_188284_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188284 .

chi:result_188284_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188285 rdf:type chi:Paper ;
    dcterms:title "Living Bento: Heartbeat-Driven Noodles for Enriched Dining Dynamics" ;
    dcterms:abstract "To enhance focused eating and dining socialization, previous Human-Food Interaction research has indicated that external devices can support these dining objectives and immersion. However, methods that focus on the food itself and the diners themselves have remained underdeveloped. In this study, we integrated biofeedback with food, utilizing diners' heart rates as a source of the food's appearance to promote focused eating and dining socialization. By employing LED lights, we dynamically displayed diners' real-time physiological signals through the transparency of the food. Results revealed significant effects on various aspects of dining immersion, such as awareness perceptions, attractiveness, attentiveness to each bite, and emotional bonds with the food. Furthermore, to promote dining socialization, we established a “Sharing Bio-Sync Food” dining system to strengthen emotional connections between diners. Based on these findings, we developed tableware that integrates biofeedback into the culinary experience." ;
    dcterms:identifier "3706598.3713108" ;
    chi:hasAuthor chi:person_185050, chi:person_186198, chi:person_184607, chi:person_187638, chi:person_183411 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:SelfReflectionAndBehaviorChange ;
    chi:paperIncludesStudy chi:study_188285_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188285_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188285_InterfaceArtifact .

chi:study_188285_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188285 ;
    chi:hasMeasure chi:HeartRateMeasure ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188285_StatisticalResult .

chi:artifact_188285_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188285 .

chi:artifact_188285_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188285 .

chi:result_188285_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188286 rdf:type chi:Paper ;
    dcterms:title "Looking but Not Focusing: Defining Gaze-Based Indices of Attention Lapses and Classifying Attentional States" ;
    dcterms:abstract "Identifying objective markers of attentional states is critical, particularly in real-world scenarios where attentional lapses have serious consequences. In this study, we identified gaze-based indices of attentional lapses and validated them by examining their impact on the performance of classification models. We designed a virtual reality visual search task that encouraged active eye movements to define dynamic gaze-based metrics of different attentional states (zone in/out). The results revealed significant differences in both reactive ocular features, such as first fixation and saccade onset latency, and global ocular features, such as saccade amplitude, depending on the attentional state. Moreover, the performance of the classification models improved significantly when trained only on the proven gaze-based and behavioral indices rather than all available features, with the highest prediction accuracy of 79.3%. We highlight the importance of the preliminary studies before model training and provide generalizable gaze-based indices of attentional states for practical applications. " ;
    dcterms:identifier "3706598.3714269" ;
    chi:hasAuthor chi:person_188078, chi:person_186515 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:paperIncludesStudy chi:study_188286_UserStudy ;
    chi:paperIncludesStudy chi:study_188286_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188286_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188286_InterfaceArtifact .

chi:study_188286_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188286 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188286_StatisticalResult .

chi:study_188286_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188286 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188286_StatisticalResult .

chi:artifact_188286_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188286 .

chi:artifact_188286_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188286 .

chi:result_188286_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188287 rdf:type chi:Paper ;
    dcterms:title "Keeping Score: A Quantitative Analysis of How the CHI Community Appreciates Its Milestones" ;
    dcterms:abstract "The ACM CHI Conference has a tradition of citing its intellectual heritage. At the same time, we know CHI is highly diverse and evolving. In this highly dynamic context, it is not clear how the CHI community continues to appreciate its milestones (within and outside of CHI). We present an investigation into how the community's citations to milestones have evolved over 43 years of CHI Proceedings (1981-2024). Forgetting curves plotted for each year suggest that milestones are slowly fading from the CHI community's collective memory. However, the picture is more nuanced when we trace citations to the top-cited milestones over time. We identify three distinct types of milestones cited at CHI, a typology of milestone contributions, and define the Milestone Coefficient as a metric to assess the impact of milestone papers on a continuous scale. Further, our findings suggest the potential presence of a Matthew effect at CHI. We discuss the broader ramifications for the CHI community and the field of HCI." ;
    dcterms:identifier "3706598.3713464" ;
    chi:hasAuthor chi:person_184808, chi:person_183009 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:paperIncludesStudy chi:study_188287_QuantitativeStudy ;
    chi:proposesArtifact chi:artifact_188287_SoftwareArtifact .

chi:study_188287_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188287 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188287_StatisticalResult ;
    chi:reportsResult chi:result_188287_QualitativeResult .

chi:artifact_188287_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188287 .

chi:result_188287_StatisticalResult rdf:type chi:StatisticalResult .

chi:result_188287_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188288 rdf:type chi:Paper ;
    dcterms:title "Who Reaps All the Superchats? A Large-Scale Analysis of Income Inequality in Virtual YouTuber Livestreaming" ;
    dcterms:abstract "The explosive growth of Virtual YouTubers (VTubers)---streamers who perform behind virtual anime avatars---has created a unique digital economy with profound implications for content creators, platforms, and viewers. Understanding the economic landscape of VTubers is crucial for designing equitable platforms, supporting content creator livelihoods, and fostering sustainable digital communities. To this end, we conducted a large-scale study of over 1 million hours of publicly available streaming records from 1,923 VTubers on YouTube, covering tens of millions of dollars in actual profits. Our analysis reveals stark inequality within the VTuber community and characterizes the sources of income for VTubers from multiple perspectives. Furthermore, we also found that the VTuber community is increasingly monopolized by two agencies, driving the financial disparity. This research illuminates the financial dynamics of VTuber communities, informing the design of equitable platforms and sustainable support systems for digital content creators." ;
    dcterms:identifier "3706598.3713877" ;
    chi:hasAuthor chi:person_186489, chi:person_184130, chi:person_183084, chi:person_185035, chi:person_186784, chi:person_186835 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188288_SoftwareArtifact .

chi:artifact_188288_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188288 .

chi:result_188288_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188289 rdf:type chi:Paper ;
    dcterms:title "TH-Wood: Developing Thermo-Hygro-Coordinating Driven Wood Actuators to Enhance Human-Nature Interaction" ;
    dcterms:abstract "Wood has become increasingly applied in shape-changing interfaces for its eco-friendly and smart responsive properties, while its applications face challenges as it remains primarily driven by humidity. We propose TH-Wood, a biodegradable actuator system composed of wood veneer and microbial polymers, driven by both temperature and humidity, and capable of functioning in complex outdoor environments. This dual-factor-driven approach enhances the sensing and response channels, allowing for more sophisticated coordinating control methods. To assist in designing and utilizing the system more effectively, we developed a structure library inspired by dynamic plant forms, conducted extensive technical evaluations, created an educational platform accessible to users, and provided a design tool for deformation adjustments and behavior previews. Finally, several ecological applications demonstrate the potential of TH-Wood to significantly enhance human interaction with natural environments and expand the boundaries of human-nature relationships." ;
    dcterms:identifier "3706598.3714304" ;
    chi:hasAuthor chi:person_187366, chi:person_188164, chi:person_183472, chi:person_184671, chi:person_184684, chi:person_183371, chi:person_184412, chi:person_187265, chi:person_183143, chi:person_182810, chi:person_185712, chi:person_184319 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188289_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188289_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188289_InterfaceArtifact .

chi:artifact_188289_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188289 .

chi:artifact_188289_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188289 .

chi:artifact_188289_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188289 .

chi:paper_188290 rdf:type chi:Paper ;
    dcterms:title "Productive vs. Reflective: How Different Ways of Integrating AI into Design Workflows Affect Cognition and Motivation" ;
    dcterms:abstract "An increasing number of tools now integrate AI support, extending the ability of users—especially novices—to produce creative work. While AI could play various roles within such tools, less is known about how the positioning of AI affects an individual's cognitive processes and sense of agency. To examine this relationship, we built a collaborative whiteboard plugin that integrates an LLM into design templates to facilitate reflective brainstorming activities. We conducted a between-subjects experiment with N=47 participants assigned to one of three versions of AI-support—No-AI, AI input provided incrementally (Co-led) and AI provided all at once (AI-led)—to compare the allocation of cognitive resources. Results show that the positioning of AI scaffolds shifts the underlying cognition: AI-led participants devoted more time to comprehension and synthesis, which yielded more topically diverse problems and solutions. No-AI and Co-led participants spent more time revising content and reported higher confidence in their process." ;
    dcterms:identifier "3706598.3713649" ;
    chi:hasAuthor chi:person_185391, chi:person_188022, chi:person_183101, chi:person_183474, chi:person_188067, chi:person_185293 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:CollaborativeVisualizationTools ;
    chi:paperIncludesStudy chi:study_188290_UserStudy ;
    chi:paperIncludesStudy chi:study_188290_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188290_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188290_SoftwareArtifact .

chi:study_188290_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188290 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188290_StatisticalResult .

chi:study_188290_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188290 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188290_StatisticalResult .

chi:artifact_188290_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188290 .

chi:artifact_188290_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188290 .

chi:result_188290_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188293 rdf:type chi:Paper ;
    dcterms:title "Tendon Vibration for Creating Movement Illusions in Virtual Reality" ;
    dcterms:abstract "Tendon vibration can create movement illusions: vibrating the biceps tendon induces an illusion of extending the arm, while vibrating the triceps tendon induces an illusion of flexing the arm. However, it is unclear how to create and integrate such illusions shown in neuroscience to interaction techniques in virtual reality (VR). We first design a motor setup for tendon vibration. Study 1 validates that the setup induces movement illusions which on average create a 5.26 cm offset in active arm movements. Study 2 shows that tendon vibration improves the detection thresholds of visual motion gains often used in VR interaction techniques by 0.22. A model we developed in Study 2 predicts the effects of tendon vibration and is used in a biomechanical simulation to demonstrate the detection thresholds across typical reaching tasks in VR." ;
    dcterms:identifier "3706598.3714003" ;
    chi:hasAuthor chi:person_183916, chi:person_184815, chi:person_187258, chi:person_186040, chi:person_185752, chi:person_186817 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:paperIncludesStudy chi:study_188293_UserStudy ;
    chi:paperIncludesStudy chi:study_188293_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188293_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188293_InputDeviceArtifact .

chi:study_188293_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188293 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188293_StatisticalResult .

chi:study_188293_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188293 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188293_StatisticalResult .

chi:artifact_188293_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188293 .

chi:artifact_188293_InputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188293 .

chi:result_188293_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188294 rdf:type chi:Paper ;
    dcterms:title "From Camera-Eye to AI: Exploring the Interplay of Cinematography and Computational Visual Storytelling" ;
    dcterms:abstract "While much prior work on computational visual storytelling analyzes image content, it largely overlooks formal elements. This raises the question: how might particular cinematographic techniques shape a system's interpretation and narration of imagery? To investigate this question, we generate 60 responses from a Vision Language Model using a multi-faceted prompt paired with different still frames from Man with a Movie Camera (1929), a silent documentary film renowned for its innovative cinematography. We present three themes that highlight roles of cinematography in computational visual storytelling: (1) how AI discerns drama and power from camera shots and angles that portray social reality; (2) how AI (mis)interprets lighting and focus techniques that compose ambiguous reality; and (3) how AI navigates visual effects that render surreality. In turn, we look toward cinematic controls to reimagine users as directors of visual storytelling systems and discuss how expressive AI can support speculating about the past." ;
    dcterms:identifier "3706598.3713840" ;
    chi:hasAuthor chi:person_185702, chi:person_184681 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:proposesArtifact chi:artifact_188294_SoftwareArtifact .

chi:artifact_188294_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188294 .

chi:result_188294_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188297 rdf:type chi:Paper ;
    dcterms:title "Knowledge Workers' Perspectives on AI Training for Responsible AI Use" ;
    dcterms:abstract "AI expansion has accelerated workplace adoption of new technologies. Yet, it is unclear whether and how knowledge workers are supported and trained to safely use AI. Inadequate training may lead to unrealized benefits if workers abandon tools, or perpetuate biases if workers misinterpret AI-based outcomes. In a workshop with 39 workers from 26 countries specializing in human resources, labor law, standards creation, and worker training, we explored questions and ideas they had about safely adopting AI. We held 17 follow-up interviews to further investigate what skills and training knowledge workers need to achieve safe and effective AI in practice. We synthesize nine training topics participants surfaced for knowledge workers related to challenges around understanding what AI is, misinterpreting outcomes, exacerbating biases, and worker rights. We reflect how these training topics might be addressed under different contexts, imagine HCI research prototypes as potential training tools, and consider ways to ensure training does not perpetuate harmful values." ;
    dcterms:identifier "3706598.3714100" ;
    chi:hasAuthor chi:person_186410, chi:person_186484 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:TargetedEthicsInterventions ;
    chi:paperIncludesStudy chi:study_188297_InterviewStudy ;
    chi:aimsAtGoal chi:PromoteLearning .

chi:study_188297_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188297 ;
    chi:reportsResult chi:result_188297_QualitativeResult .

chi:result_188297_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188300 rdf:type chi:Paper ;
    dcterms:title "Let’s Talk Futures: A Literature Review of HCI’s Future Orientation " ;
    dcterms:abstract "HCI is future-oriented by nature: it explores new human--technology interactions and applies the findings to promote and shape vital visions of society. Still, the visions of futures in HCI publications seem largely implicit, techno-deterministic, narrow, and lacking in roadmaps and attention to uncertainties. A literature review centered on this problem examined futuring and its forms in the ACM Digital Library's most frequently cited HCI publications. This analysis entailed developing the four-category framework SPIN, informed by futures studies literature. The results confirm that, while technology indeed drives futuring in HCI, a growing body of HCI research is coming to challenge techno-centric visions. Emerging foci of HCI futuring demonstrate active exploration of uncertainty, a focus on human experience, and contestation of dominant narratives. The paper concludes with insight illuminating factors behind techno-centrism's continued dominance of HCI discourse, as grounding for five opportunities for the field to expand its contribution to futures and anticipation research." ;
    dcterms:identifier "3706598.3713759" ;
    chi:hasAuthor chi:person_185787, chi:person_184416, chi:person_186700, chi:person_185814, chi:person_185191 .

chi:result_188300_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188302 rdf:type chi:Paper ;
    dcterms:title "Why does Automation Adoption in Organizations Remain a Fallacy?: Scrutinizing Practitioners' Imaginaries in an International Airport" ;
    dcterms:abstract "In organizations, the interest in automation is long-standing. However, adopting automated processes remains challenging, even in environments that appear highly standardized and technically suitable for it. Through a case study in Amsterdam Airport Schiphol, this paper investigates automation as a broader sociotechnical system influenced by a complex network of actors and contextual factors. We study practitioners' collective understandings of automation and subsequent efforts taken to implement it. Using imaginaries as a lens, we report findings from a qualitative interview study with 16 practitioners involved in airside automation projects. Our findings illustrate the organizational dynamics and complexities surrounding automation adoption, as reflected in the captured problem formulations, conceptions of the technology, envisioned human roles in autonomous operations, and perspectives on automation fit in the airside ecosystem. Ultimately,  we advocate for contextual automation design, which carefully considers human roles, accounts for existing organizational politics, and avoids techno-solutionist approaches.  " ;
    dcterms:identifier "3706598.3713978" ;
    chi:hasAuthor chi:person_183403, chi:person_185732, chi:person_186709, chi:person_185412 ;
    chi:paperIncludesStudy chi:study_188302_InterviewStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking .

chi:study_188302_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188302 ;
    chi:reportsResult chi:result_188302_QualitativeResult .

chi:result_188302_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188303 rdf:type chi:Paper ;
    dcterms:title "From Scores to Careers: Understanding AI’s Role in Supporting Collaborative Family Decision-Making in Chinese College Applications" ;
    dcterms:abstract "This study investigates how 18-year-old students, parents, and experts in China utilize artificial intelligence (AI) tools to support decision-making in college applications during college entrance exam- a highly competitive, score-driven, annual national exam. Through 32 interviews, we examine the use of Quark GaoKao, an AI tool that generates college application lists and acceptance probabilities based on exam scores, historical data, preferred locations, etc. Our findings show that AI tools are predominantly used by parents with limited involvement from students, and often focus on immediate exam results, failing to address long-term career goals. We also identify challenges such as misleading AI recommendations, and irresponsible use of AI by third-party consultant agencies.  Finally, we offer design insights to better support multi-stakeholders' decision-making in families, especially in the Chinese context, and discuss how emerging AI tools create barriers for families with fewer resources." ;
    dcterms:identifier "3706598.3713341" ;
    chi:hasAuthor chi:person_186797, chi:person_183903, chi:person_185608, chi:person_184262, chi:person_183943, chi:person_184440 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188303_InterviewStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188303_SoftwareArtifact .

chi:study_188303_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188303 ;
    chi:reportsResult chi:result_188303_QualitativeResult .

chi:artifact_188303_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188303 .

chi:result_188303_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188304 rdf:type chi:Paper ;
    dcterms:title "SET-PAiREd: Designing for Parental Involvement in Learning with an AI-Assisted Educational Robot" ;
    dcterms:abstract "AI-assisted learning companion robots are increasingly used in early education. Many parents express concerns about content appropriateness, while they also value how AI and robots could supplement their limited skill, time, and energy to support their children's learning. We designed a card-based kit, SET, to systematically capture scenarios that have different extents of parental involvement. We developed a prototype interface, PAiREd, with a learning companion robot to deliver LLM-generated educational content that can be reviewed and revised by parents. Parents can flexibly adjust their involvement in the activity by determining what they want the robot to help with. We conducted an in-home field study involving 20 families with children aged 3--5. Our work contributes to an empirical understanding of the level of support parents with different expectations may need from AI and robots and a prototype that demonstrates an innovative interaction paradigm for flexibly including parents in supporting their children." ;
    dcterms:identifier "3706598.3713330" ;
    chi:hasAuthor chi:person_185609, chi:person_184605, chi:person_184179, chi:person_183712 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188304_FieldStudy ;
    chi:paperIncludesStudy chi:study_188304_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188304_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188304_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188304_SoftwareArtifact .

chi:study_188304_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188304 ;
    chi:reportsResult chi:result_188304_QualitativeResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:study_188304_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188304 ;
    chi:reportsResult chi:result_188304_QualitativeResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:artifact_188304_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188304 .

chi:artifact_188304_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188304 .

chi:artifact_188304_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188304 .

chi:result_188304_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188305 rdf:type chi:Paper ;
    dcterms:title "Sensing Movement: Contemporary Dance Workshops with People who are Blind or have Low Vision and Dance Teachers" ;
    dcterms:abstract "Dance teachers rely primarily on verbal instructions and visual demonstrations to convey key dance concepts and movement. These techniques, however, have limitations in supporting students who are blind or have low vision (BLV). This work explores the role technology can play in supporting instruction for BLV students, as well as improvisation with their instructor. Through a series of design workshops with dance instructors and BLV students, ideas were generated by physically engaging with probes featuring diverse modalities including tactile objects, a body tracked sound and musical probe, and a body tracked controller with vibrational feedback. Implications for the design of supporting technologies were discovered for four contemporary dance learning goals: learning a phrase; improvising; collaborating through movement; and awareness of body and movement qualities. We discuss the potential of numerous multi-sensory methods and artefacts, and present design considerations for technologies to support meaningful dance instruction and participation." ;
    dcterms:identifier "3706598.3714325" ;
    chi:hasAuthor chi:person_186653, chi:person_187269, chi:person_183501, chi:person_186602, chi:person_182987 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:LearningAndEducation:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188305_UserStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188305_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188305_InputDeviceArtifact ;
    chi:proposesArtifact chi:artifact_188305_OutputDeviceArtifact ;
    chi:proposesArtifact chi:artifact_188305_InterfaceArtifact .

chi:study_188305_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188305 ;
    chi:reportsResult chi:result_188305_QualitativeResult .

chi:artifact_188305_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188305 .

chi:artifact_188305_InputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188305 .

chi:artifact_188305_OutputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188305 .

chi:artifact_188305_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188305 .

chi:result_188305_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188307 rdf:type chi:Paper ;
    dcterms:title "Signals Beyond Text: Understanding How Accessing Peer Concept Mapping and Commenting Augments Reflective Mind for High-Stake Videos" ;
    dcterms:abstract "In high-stakes domains, deep analytical processing of online videos is essential for decision-making and knowledge acquisition. However, individuals may lack sufficient cognitive resources and triggers to engage in such processes. To address this, we introduce DeepThinkingMap, a collaborative video mapping system with affordances designed to leverage peers' thoughts and comments to promote reflective and critical thinking. Thee design supports collaborative mapping of video concepts and supports open deliberations of personal thoughts over concepts as \"thinking nudges\" to foster deeper thinking for themselves and others. Through two experimental studies, we investigated the potential of deeper thinking by accessing peers' thoughts in standalone and collaborative information work respectively. Results illustrated that accessing peers' comments enhances personal engagement in reflective and critical thinking, and reinforces their confidence in their correct beliefs toward the video topics. This work contributes to understanding the socio-technical-cognitive mechanism of thinking while accessing peer comments, and presents design implications for information and knowledge work." ;
    dcterms:identifier "3706598.3713426" ;
    chi:hasAuthor chi:person_183020, chi:person_184165, chi:person_186533, chi:person_185381 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188307_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188307_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188307_InterfaceArtifact .

chi:study_188307_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188307 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188307_QualitativeResult ;
    chi:reportsResult chi:result_188307_StatisticalResult .

chi:artifact_188307_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188307 .

chi:artifact_188307_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188307 .

chi:result_188307_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188307_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188308 rdf:type chi:Paper ;
    dcterms:title "DanmuA11y: Making Time-Synced On-Screen Video Comments (Danmu) Accessible to Blind and Low Vision Users via Multi-Viewer Audio Discussions" ;
    dcterms:abstract "By overlaying time-synced user comments on videos, Danmu creates a co-watching experience for online viewers. However, its visual-centric design poses significant challenges for blind and low vision (BLV) viewers. Our formative study identified three primary challenges that hinder BLV viewers' engagement with Danmu: the lack of visual context, the speech interference between comments and videos, and the disorganization of comments. To address these challenges, we present DanmuA11y, a system that makes Danmu accessible by transforming it into multi-viewer audio discussions. DanmuA11y incorporates three core features: (1) Augmenting Danmu with visual context, (2) Seamlessly integrating Danmu into videos, and (3) Presenting Danmu via multi-viewer discussions. Evaluation with twelve BLV viewers demonstrated that DanmuA11y significantly improved Danmu comprehension, provided smooth viewing experiences, and fostered social connections among viewers. We further highlight implications for enhancing commentary accessibility in video-based social media and live-streaming platforms." ;
    dcterms:identifier "3706598.3713496" ;
    chi:hasAuthor chi:person_185998, chi:person_182714, chi:person_187993, chi:person_182990 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:SocialComputing:FuturesOfSocialPlatforms ;
    chi:paperIncludesStudy chi:study_188308_UserStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188308_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188308_InterfaceArtifact .

chi:study_188308_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188308 ;
    chi:reportsResult chi:result_188308_QualitativeResult ;
    chi:reportsResult chi:result_188308_StatisticalResult .

chi:artifact_188308_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188308 .

chi:artifact_188308_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188308 .

chi:result_188308_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188308_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188309 rdf:type chi:Paper ;
    dcterms:title "MotionBlocks: Modular Geometric Motion Remapping for More Accessible Upper Body Movement in Virtual Reality" ;
    dcterms:abstract "Movement-based spatial interaction in VR can present significant challenges for people with limited mobility, particularly due to the mismatch between the upper body motion a VR app requires and the user's capabilities. We describe MotionBlocks, an approach which enables 3D spatial input with smaller motions or simpler input devices using modular geometric motion remapping. A formative study identifies common accessibility issues within VR motion design, and informs a design language of VR motions that fall within simple geometric primitives. These 3D primitives enable collapsing spatial or non-spatial input into a normalized input vector, which is then expanded into a second 3D primitive representing larger, more complex 3D motions. An evaluation with people with mobility limitations found that using geometric primitives for highly customized upper body input remapping reduced physical workload, temporal workload, and perceived effort." ;
    dcterms:identifier "3706598.3713837" ;
    chi:hasAuthor chi:person_187149, chi:person_184136, chi:person_184181, chi:person_187745 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:AccessibilityNavigationSupport ;
    chi:paperIncludesStudy chi:study_188309_UserStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188309_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188309_InterfaceArtifact .

chi:study_188309_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188309 ;
    chi:hasMeasure chi:SubjectiveMeasure ;
    chi:reportsResult chi:result_188309_QualitativeResult ;
    chi:reportsResult chi:result_188309_StatisticalResult .

chi:artifact_188309_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188309 .

chi:artifact_188309_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188309 .

chi:result_188309_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188309_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188311 rdf:type chi:Paper ;
    dcterms:title "Estimating Detection Thresholds of Being Looked at in Virtual Reality for Avatar Redirection" ;
    dcterms:abstract "The human face and eyes provide crucial conversational cues about a person’s focus of attention.  In virtual reality applications, avatar faces are typically simplified, and eye movements often neglected.  This paper explores how VR users perceive the look-at direction of other avatars and estimates the range within which an avatar's averted gaze goes unnoticed. Through two-alternative forced choice experiments, we investigate different gaze offsets to quantify thresholds for perceived gaze aversion across three conditions: gaze side (left/right), stimulus duration, and avatar distance. Additionally, we assess the impact of averted gaze on social presence during interactions with an embodied conversational agent in a social game.  A user study (N=40) revealed that social presence is significantly affected by averted gaze when noticed, and that detection thresholds are particularly impacted by stimuli duration and interactions between side and distance. Our findings provide a foundation for understanding gaze perception in social virtual reality." ;
    dcterms:identifier "3706598.3714041" ;
    chi:hasAuthor chi:person_185352, chi:person_186822, chi:person_183050, chi:person_182976 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:paperIncludesStudy chi:study_188311_UserStudy ;
    chi:paperIncludesStudy chi:study_188311_QuantitativeStudy ;
    chi:proposesArtifact chi:artifact_188311_InterfaceArtifact .

chi:study_188311_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188311 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188311_StatisticalResult .

chi:study_188311_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188311 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188311_StatisticalResult .

chi:artifact_188311_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188311 .

chi:result_188311_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188312 rdf:type chi:Paper ;
    dcterms:title "User Experience of LLM-based Recommendation Systems: A Case of Music Recommendation" ;
    dcterms:abstract "The advancement of large language models (LLMs) now allows users to actively interact with conversational recommendation systems (CRS) and build their own personalized recommendation services tailored to their unique needs and goals. This experience offers users a significantly higher level of controllability compared to traditional RS, enabling an entirely new dimension of recommendation experiences. Building on this context, this study explored the unique experiences that LLM-powered CRS can provide compared to traditional RS. Through a three-week diary study with 12 participants using custom GPTs for music recommendations, we found that LLM-powered CRS can (1) help users clarify implicit needs, (2) support unique exploration, and (3) facilitate a deeper understanding of musical preferences. Based on these findings, we discuss the new design space enabled by LLM-powered CRS and highlight its potential to support more personalized, user-driven recommendation experiences." ;
    dcterms:identifier "3706598.3713347" ;
    chi:hasAuthor chi:person_184761, chi:person_183539 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialPersonalizationAndFeeds ;
    chi:paperIncludesStudy chi:study_188312_DiaryStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188312_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188312_InterfaceArtifact .

chi:study_188312_DiaryStudy rdf:type chi:DiaryStudy ;
    chi:isStudyReportedIn chi:paper_188312 ;
    chi:reportsResult chi:result_188312_QualitativeResult .

chi:artifact_188312_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188312 .

chi:artifact_188312_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188312 .

chi:result_188312_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188314 rdf:type chi:Paper ;
    dcterms:title "Generative and Malleable User Interfaces with Generative and Evolving Task-Driven Data Model" ;
    dcterms:abstract "Unlike static and rigid user interfaces, generative and malleable user interfaces offer the potential to respond to diverse users’ goals and tasks. However, current approaches primarily rely on generating code, making it difficult for end-users to iteratively tailor the generated interface to their evolving needs. We propose employing task-driven data models—representing the essential information entities, relationships, and data within information tasks—as the foundation for UI generation. We leverage AI to interpret users’ prompts and generate the data models that describe users’ intended tasks, and by mapping the data models with UI specifications, we can create generative user interfaces. End-users can easily modify and extend the interfaces via natural language and direct manipulation, with these interactions translated into changes in the underlying model. The technical evaluation of our approach and user evaluation of the developed system demonstrate the feasibility and effectiveness of generative and malleable user interfaces." ;
    dcterms:identifier "3706598.3713285" ;
    chi:hasAuthor chi:person_187843, chi:person_184731, chi:person_183602 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:paperIncludesStudy chi:study_188314_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188314_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188314_SoftwareArtifact .

chi:study_188314_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188314 ;
    chi:reportsResult chi:result_188314_QualitativeResult .

chi:artifact_188314_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188314 .

chi:artifact_188314_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188314 .

chi:result_188314_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188315 rdf:type chi:Paper ;
    dcterms:title "Pixel Memories: Do Lifelog Summaries Fail to Enhance Memory but Offer Privacy-Aware Memory Assessments?" ;
    dcterms:abstract "We explore the metaphorical \"daily memory pill\" concept – a brief pictorial lifelog recap aimed at reviving and preserving memories. Leveraging psychological strategies, we explore the potential of such summaries to boost autobiographical memory.  We developed an automated lifelogging memory prosthesis and a research protocol (Automated Memory Validation ``AMV'') for conducting privacy-aware, in-situ evaluations. We conducted a real-world lifelogging experiment for a month (n=11). We also designed a browser ``Pixel Memories’’ for browsing one-week worth of lifelogs. The results suggest that daily timelapse summaries, while not yielding significant memory augmentation effects, also do not lead to memory degradation. Participants' confidence in recalled content remains unaltered, but the study highlights the challenge of users' overestimation of memory accuracy. Our core contributions, the AMV protocol and \"Pixel Memories\" browser, advance our understanding of memory augmentations and offer a privacy-preserving method for evaluating future ubicomp systems." ;
    dcterms:identifier "3706598.3714145" ;
    chi:hasAuthor chi:person_184592, chi:person_188161, chi:person_186842, chi:person_186683, chi:person_187241, chi:person_185374, chi:person_187433, chi:person_187956, chi:person_183337 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:SelfReflectionAndBehaviorChange ;
    chi:paperIncludesStudy chi:study_188315_FieldStudy ;
    chi:paperIncludesStudy chi:study_188315_UserStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188315_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188315_InterfaceArtifact .

chi:study_188315_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188315 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188315_StatisticalResult .

chi:study_188315_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188315 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188315_StatisticalResult .

chi:artifact_188315_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188315 .

chi:artifact_188315_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188315 .

chi:result_188315_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188316 rdf:type chi:Paper ;
    dcterms:title "“What If Smart Homes Could See Our Homes?”: Exploring DIY Smart Home Building Experiences with VLM-Based Camera Sensors" ;
    dcterms:abstract "The advancement of Vision-Language Model (VLM) camera sensors, which enable autonomous understanding of household situations without user intervention, has the potential to completely transform the DIY smart home building experience. Will this simplify or complicate the DIY smart home process? Additionally, what features do users want to create using these sensors? To explore this, we conducted a three-week diary-based experience prototyping study with 12 participants. Participants recorded their daily activities, used GPT to analyze the images, and manually customized and tested smart home features based on the analysis. The study revealed three key findings: (1) participants’ expectations for VLM camera-based smart homes, (2) the impact of VLM camera sensor characteristics on the DIY process, and (3) users’ concerns. Through the findings of this study, we propose design implications to support the DIY smart home building process with VLM camera sensors, and discuss living with intelligence." ;
    dcterms:identifier "3706598.3713265" ;
    chi:hasAuthor chi:person_184761, chi:person_183539 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:paperIncludesStudy chi:study_188316_DiaryStudy ;
    chi:paperIncludesStudy chi:study_188316_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188316_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188316_DeviceArtifact .

chi:study_188316_DiaryStudy rdf:type chi:DiaryStudy ;
    chi:isStudyReportedIn chi:paper_188316 ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188316_QualitativeResult .

chi:study_188316_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188316 ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188316_QualitativeResult .

chi:artifact_188316_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188316 .

chi:artifact_188316_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188316 .

chi:result_188316_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188317 rdf:type chi:Paper ;
    dcterms:title "User Preferences for Interaction Timing in Smartwatch Sleep Hygiene Games" ;
    dcterms:abstract "Good sleep hygiene is essential for quality sleep. This study investigates user preferences for the timing of interactions with features in smartwatch-based sleep hygiene games. Findings reveal that interactions during sleep are generally undesirable, with Sleep Health Points being the only exception. We also identified a misconception that games must involve active play, overlooking the potential of passive and idle game mechanics. Participants preferred engaging with planning and behavior-triggering features before the associated behavior, while reflection and reinforcement features, like reports and rewards, were favored post-behavior. The perceived dual functionality of certain features suggests that preferred interaction timing depends on users' perceptions of the features’ roles. Users' schedules and situational context, especially evening availability, also influenced their preferences. This study highlights the importance of aligning feature timing with user routines and perceptions, and advocates for game designs that blend active and passive elements to boost engagement and promote sleep hygiene.  " ;
    dcterms:identifier "3706598.3713591" ;
    chi:hasAuthor chi:person_187520, chi:person_185666, chi:person_185432, chi:person_185137, chi:person_187870, chi:person_187210 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:SelfReflectionAndBehaviorChange ;
    chi:paperIncludesStudy chi:study_188317_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188317_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188317_InterfaceArtifact .

chi:study_188317_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188317 ;
    chi:reportsResult chi:result_188317_QualitativeResult .

chi:artifact_188317_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188317 .

chi:artifact_188317_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188317 .

chi:result_188317_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188318 rdf:type chi:Paper ;
    dcterms:title "Designing Accessible and Intuitive Developer Tools for Neuromorphic Programming" ;
    dcterms:abstract "Neuromorphic technology offers advantages such as low-power processing, low latency, adaptive learning, and noise tolerance, making it ideal for edge computing applications. However, developers face significant hurdles due to the nascent nature of the field, including limited access to hardware and software, lack of benchmarks, and the need for deep interdisciplinary knowledge. Through interviews with 12 practitioners from both industry and academia, we conducted a thematic analysis to understand the current landscape of neuromorphic programming and identified key challenges, workflows, and potential solutions for enhancing accessibility and adoption. Our findings led to a set of guidelines for creating more accessible software development tools and platforms for those looking to create neuromorphic applications. Through this work, we aim to bridge the gap between neuromorphic computing and the HCI community, promoting the design of more intuitive and effective interfaces for neuromorphic development, and ultimately facilitating the creation of edge intelligent systems. " ;
    dcterms:identifier "3706598.3713249" ;
    chi:hasAuthor chi:person_184383, chi:person_183445, chi:person_186906, chi:person_187762, chi:person_186508, chi:person_186698, chi:person_186767, chi:person_185917 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:paperIncludesStudy chi:study_188318_InterviewStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188318_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188318_InterfaceArtifact .

chi:study_188318_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188318 ;
    chi:reportsResult chi:result_188318_QualitativeResult .

chi:artifact_188318_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188318 .

chi:artifact_188318_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188318 .

chi:result_188318_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188319 rdf:type chi:Paper ;
    dcterms:title "Exploring Security and Privacy Discourse on Twitter During the `Justice Pour Nahel' Movement in France" ;
    dcterms:abstract "The shooting of Nahel Merzouk in June 2023 ignited widespread protests across France, known as the ``Justice Pour Nahel'' movement, drawing attention to the privacy and security risks faced by protesters. This study explores the discourse on Twitter during the protests, focusing on digital surveillance and censorship concerns. We analyzed 341 tweets using qualitative methods to understand the security and privacy attitudes and advice shared by French-speaking users. Our findings reveal a strong apprehension toward increased long-term government surveillance and censorship, with limited and often low-tech advice on how to counteract these threats. We highlight the discrepancy between the concerns raised and the available guidance and compare our findings with those of prior work. Grounded in our analysis and informed by prior research, we offer targeted recommendations for activists, policymakers, and researchers to mitigate security and privacy concerns arising from social unrest, both in France and globally. " ;
    dcterms:identifier "3706598.3713870" ;
    chi:hasAuthor chi:person_185715, chi:person_187754, chi:person_184776, chi:person_184498 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:DataDisclosureAndConsent ;
    chi:paperIncludesStudy chi:study_188319_QualitativeStudy .

chi:study_188319_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188319 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188319_QualitativeResult .

chi:result_188319_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188320 rdf:type chi:Paper ;
    dcterms:title "\"It Brought the Model to Life\": Exploring the Embodiment of Multimodal I3Ms for People who are Blind or have Low Vision" ;
    dcterms:abstract "3D-printed models are increasingly used to provide people who are blind or have low vision (BLV) with access to maps, educational materials, and museum exhibits. Recent research has explored interactive 3D-printed models (I3Ms) that integrate touch gestures, conversational dialogue, and haptic vibratory feedback to create more engaging interfaces. Prior research with sighted people has found that imbuing machines with human-like behaviours, i.e., embodying them, can make them appear more lifelike, increasing social perception and presence. Such embodiment can increase engagement and trust. This work presents the first exploration into the design of embodied I3Ms and their impact on BLV engagement and trust. In a controlled study with 12 BLV participants, we found that I3Ms using specific embodiment design factors, such as haptic vibratory and embodied personified voices, led to an increased sense of liveliness and embodiment, as well as engagement, but had mixed impact on trust." ;
    dcterms:identifier "3706598.3713158" ;
    chi:hasAuthor chi:person_187257, chi:person_182987, chi:person_186060 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:paperIncludesStudy chi:study_188320_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188320_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188320_DeviceArtifact .

chi:study_188320_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188320 ;
    chi:reportsResult chi:result_188320_QualitativeResult .

chi:artifact_188320_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188320 .

chi:artifact_188320_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188320 .

chi:result_188320_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188321 rdf:type chi:Paper ;
    dcterms:title "Exploring the Effects of Social VR Coupling Modes on Engagement and Task Performance for Older Adults" ;
    dcterms:abstract "Social Virtual Reality (VR) presents a promising avenue for older adults to connect with others and engage in collaborative activities remotely.  However, many social VR experiences focus on individual tasks, reducing opportunities for meaningful social interaction. To investigate the potential of VR to enhance engagement with other participants, this paper explores two modes of coupling: (i) loosely coupled, where participants focus on their individual tasks within a collaborative setting, and (ii) tightly coupled, where participants need to rely on each other’s assistance to complete their tasks. We conducted a user study with 20 older adults to evaluate how these modes affect task performance and engagement. Results show that the tightly coupled mode, focused on collaboration, increases engagement, while the loosely coupled mode, centers on individual tasks, improves performance in time and attempts. We provide guidelines for collaborative VR applications to enhance social engagement and interaction among older adults." ;
    dcterms:identifier "3706598.3713345" ;
    chi:hasAuthor chi:person_185164, chi:person_185853, chi:person_186808, chi:person_186504, chi:person_185741, chi:person_187102, chi:person_186941, chi:person_185184 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:ImmersiveTrainingAndSimulation ;
    chi:paperIncludesStudy chi:study_188321_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188321_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188321_InterfaceArtifact .

chi:study_188321_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188321 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:reportsResult chi:result_188321_StatisticalResult .

chi:artifact_188321_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188321 .

chi:artifact_188321_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188321 .

chi:result_188321_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188322 rdf:type chi:Paper ;
    dcterms:title "AI Suggestions Homogenize Writing Toward Western Styles and Diminish Cultural Nuances" ;
    dcterms:abstract "Large language models (LLMs) are being increasingly integrated into everyday products and services, such as coding tools and writing assistants. As these embedded AI applications are deployed globally, there is a growing concern that the AI models underlying these applications prioritize Western values. This paper investigates what happens when a Western-centric AI model provides writing suggestions to users from a different cultural background. We conducted a cross-cultural controlled experiment with 118 participants from India and the United States who completed culturally grounded writing tasks with and without AI suggestions. Our analysis reveals that AI provided greater efficiency gains for Americans compared to Indians. Moreover, AI suggestions led Indian participants to adopt Western writing styles, altering not just what is written but also how it is written. These findings show that Western-centric AI models homogenize writing toward Western norms, diminishing nuances that differentiate cultural expression." ;
    dcterms:identifier "3706598.3713564" ;
    chi:hasAuthor chi:person_183225, chi:person_187267, chi:person_186594 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:AlgorithmicFairnessAndBias ;
    chi:paperIncludesStudy chi:study_188322_UserStudy ;
    chi:paperIncludesStudy chi:study_188322_BaselineComparisonStudy ;
    chi:proposesArtifact chi:artifact_188322_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188322_InterfaceArtifact .

chi:study_188322_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188322 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:reportsResult chi:result_188322_QualitativeResult ;
    chi:reportsResult chi:result_188322_StatisticalResult .

chi:study_188322_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188322 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:reportsResult chi:result_188322_QualitativeResult ;
    chi:reportsResult chi:result_188322_StatisticalResult .

chi:artifact_188322_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188322 .

chi:artifact_188322_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188322 .

chi:result_188322_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188322_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188323 rdf:type chi:Paper ;
    dcterms:title "Labeling Synthetic Content: User Perceptions of Label Designs for AI-Generated Content on Social Media" ;
    dcterms:abstract "In this research, we explored the efficacy of various warning label designs for AI-generated content on social media platforms---e.g., \textit{deepfakes}. We devised and assessed ten distinct label design samples that varied across the dimensions of sentiment, color/iconography, positioning, and level of detail. Our experimental study involved 911 participants randomly assigned to these ten label designs and a control group evaluating social media content. We explored their perceptions relating to 1) Belief in the content being AI-generated, 2) Trust in the labels and 3) Social Media engagement perceptions of the content. The results demonstrate that the presence of labels had a significant effect on the user's belief that the content is AI-generated, deepfake, or edited by AI. However their trust in the label significantly varied based on the label design. Notably, having labels did not significantly change their engagement behaviors, such as 'like', comment, and sharing. However, there were significant differences in engagement based on content type: political and entertainment. This investigation contributes to the field of human-computer interaction by defining a design space for label implementation and providing empirical support for the strategic use of labels to mitigate the risks associated with synthetically generated media." ;
    dcterms:identifier "3706598.3713171" ;
    chi:hasAuthor chi:person_184589, chi:person_184760, chi:person_187453, chi:person_188088 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness:DataDisclosureAndConsent ;
    chi:aboutTopic chi:EthicsPrivacyFairness:DataDisclosureAndConsent ;
    chi:aboutTopic chi:SocialComputing:FuturesOfSocialPlatforms ;
    chi:paperIncludesStudy chi:study_188323_UserStudy ;
    chi:paperIncludesStudy chi:study_188323_QuantitativeStudy ;
    chi:paperIncludesStudy chi:study_188323_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188323_InterfaceArtifact .

chi:study_188323_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188323 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188323_StatisticalResult .

chi:study_188323_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188323 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188323_StatisticalResult .

chi:study_188323_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188323 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188323_StatisticalResult .

chi:artifact_188323_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188323 .

chi:result_188323_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188337 rdf:type chi:Paper ;
    dcterms:title "Challenging Futures: Using Chatbots to Reflect on Aging and Dementia" ;
    dcterms:abstract "Intertemporal reflection, flexibly thinking forward and backward in time, is vital for one's future planning. Yet, cultivating intertemporal reflection about encountering difficult futures, e.g., developing a progressive cognitive condition like dementia, can be challenging. We assessed people's attitudes towards dementia following conversing with a chatbot presented as either neurotypical or simulating dementia symptoms. While neither the chatbot’s presentation nor the framing of participants’ future selves impacted attitudes toward dementia, it influenced participants' experiences. When framed as future selves, the chatbot evoked a strong emotional connection, leading to reflection on aging, particularly with the chatbot simulating dementia symptoms. Participants interacting with the chatbot framed as a stranger with simulated symptoms often felt frustrated, especially when they had a task-oriented mindset. Chatbots can be promising tools for prompting reflections on challenging futures, such as dementia, although their effectiveness varies due to the tensions between simulated cognitive decline and expectations for effective communication." ;
    dcterms:identifier "3706598.3713727" ;
    chi:hasAuthor chi:person_185626, chi:person_183992, chi:person_186543, chi:person_183628, chi:person_182890, chi:person_186315, chi:person_183651, chi:person_188147 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialSupportAndPeerChatbots ;
    chi:paperIncludesStudy chi:study_188337_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188337_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188337_InterfaceArtifact .

chi:study_188337_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188337 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188337_QualitativeResult ;
    chi:reportsResult chi:result_188337_StatisticalResult .

chi:artifact_188337_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188337 .

chi:artifact_188337_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188337 .

chi:result_188337_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188337_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188338 rdf:type chi:Paper ;
    dcterms:title "The End of “Trust and Safety”?: Examining the Future of Content Moderation and Upheavals in Professional Online Safety Efforts" ;
    dcterms:abstract "Trust & Safety (T&S) teams have become vital parts of tech platforms; ensuring safe platform use and combating abuse, harassment, and misinformation. However, between 2021 and 2023, T&S teams faced significant layoffs, impacted by broader downsizing in the tech industry. In addition, a reduction in T&S teams has also been attributed to partisan pressure against content moderation efforts designed to mitigate the spread of election and COVID-19-related misinformation. Accordingly, there exist crucial questions over the future of content moderation and T&S in the digital information environment, questions central to the work of CHI researchers interested in intervening in online harm through design, policy and user research. Through in-depth interviews with T&S professionals, this paper explores upheavals within the T&S industry, examining current perspectives of content moderation and broader strategies for maintaining safe digital environments." ;
    dcterms:identifier "3706598.3713662" ;
    chi:hasAuthor chi:person_186340, chi:person_182857, chi:person_186043, chi:person_184171 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:aboutTopic chi:FuturesOfSocialPlatforms ;
    chi:paperIncludesStudy chi:study_188338_InterviewStudy .

chi:study_188338_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188338 ;
    chi:reportsResult chi:result_188338_QualitativeResult .

chi:result_188338_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188340 rdf:type chi:Paper ;
    dcterms:title "Generative Politics and Labour Markets: Unions and Collective Life in a City in Crisis" ;
    dcterms:abstract "The COVID-19 pandemic temporarily disrupted the operations of on-demand ride-sourcing digital labour platforms like Uber and Ola, severely impacting gig workers' labour opportunities. In response, the Kolkata Ola-Uber App-Cab Operator and Drivers Union in West Bengal, India, mobilised an alternate socio-technical infrastructure by operating emergency transport and taxi ambulance services. Our ethnographic study explores how this initiative leveraged technologies to structure and coordinate hybrid sites of action and ‘generate’ a labour market without profit motive to support the public health infrastructure. Our paper highlights the significance of what we call the gig worker union's ‘generative politics’ in creating resources to support workers and citizens, facilitating political action beyond protest politics, contributing to new counter-hegemonic formations, and shaping collective action centered around regeneration and care for the city and life under capitalism. We contribute to the HCI literature by offering insights to design alternate and participatory socio-technical infrastructures that challenge the hegemony of digital labour platforms. " ;
    dcterms:identifier "3706598.3713266" ;
    chi:hasAuthor chi:person_183106, chi:person_186238, chi:person_186662, chi:person_184522 ;
    chi:hasPrimaryTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188340_FieldStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188340_SoftwareArtifact .

chi:study_188340_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188340 ;
    chi:reportsResult chi:result_188340_QualitativeResult .

chi:artifact_188340_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188340 .

chi:result_188340_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188341 rdf:type chi:Paper ;
    dcterms:title "Articulating Human-World Relations from Co-Designing a Collaborative Robotic System" ;
    dcterms:abstract "In contrast to traditional industrial robots, collaborative robots are developed with the intention of allowing for close-proximity physical interaction between humans and robots. Current definitions of collaborative robots provide a pragmatic starting point for establishing safety guidelines, choosing operating parameters, and implementing organisational changes, but remain predicated on technological conceptions that prioritise a conscious split between people and robots, with the surrounding world as merely a physical site for interaction. In this paper, we take a postphenomenological perspective on robots in an investigation of human-world relations that robots can give rise to. This perspective can help elucidate the nature of such relations in a design process. Our investigation is anchored in an 8-month research study that aimed to, first, identify opportunities for a robot integration within a medical manufacturing facility and, second, facilitate a design and implementation process of a proof-of-concept robotic system in collaboration with workers. The paper contributes with an empirically anchored postphenomenological analysis of how human-world relations played out in the design process of a collaborative robotic system. Finally, we elaborate on the utility and limitations of a postphenomenological lens for design research." ;
    dcterms:identifier "3706598.3714109" ;
    chi:hasAuthor chi:person_187937, chi:person_183965, chi:person_184268 ;
    chi:hasPrimaryTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:paperIncludesStudy chi:study_188341_FieldStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188341_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188341_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188341_InterfaceArtifact .

chi:study_188341_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188341 ;
    chi:reportsResult chi:result_188341_QualitativeResult .

chi:artifact_188341_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188341 .

chi:artifact_188341_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188341 .

chi:artifact_188341_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188341 .

chi:result_188341_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188342 rdf:type chi:Paper ;
    dcterms:title "“Even Though I Went Through Everything, I Didn’t Feel Like I Learned a Lot”: Insights From Experiences of Non-Computer Science Students Learning to Code" ;
    dcterms:abstract "Programming education is increasingly seen as an important curricular component of non-Computer Science (CS) disciplines at the undergraduate level. While existing research has studied non-CS majors' experiences in introductory programming courses, there is limited work that explores such experiences across universities and disciplines. To address this gap, we conducted semi-structured interviews with 12 non-CS major programming students across several majors and universities and interpreted the results through reflexive thematic analysis. Our findings suggest that while students are excited about and interested in learning programming, they face barriers that often arise from the design of the courses they take and a lack of targeted resources and tools to support them. Building on our findings, we conclude with a set of recommendations for the design of tools, artifacts, and courses that can support programming education for non-major students." ;
    dcterms:identifier "3706598.3713624" ;
    chi:hasAuthor chi:person_184885, chi:person_185015 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:paperIncludesStudy chi:study_188342_InterviewStudy ;
    chi:aimsAtGoal chi:PromoteLearning .

chi:study_188342_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188342 ;
    chi:reportsResult chi:result_188342_QualitativeResult .

chi:result_188342_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188343 rdf:type chi:Paper ;
    dcterms:title "Haptic Biosignals Affect Proxemics Toward Virtual Reality Agents" ;
    dcterms:abstract "Encounters with virtual agents currently lack the haptic viscerality of human contact. While digital biosignal communication can mediate such virtual social interactions, how artificial haptic biosignals influence users’ personal space during Virtual Reality (VR) experiences is unknown. Designing vibrotactile heartbeats and thermally-actuated body temperature, we ran a within-subjects study (N=31) to investigate feedback (Thermal, Vibration, Thermal+Vibration, None) and agent stories (Negative, Neutral, Positive) on objective and subjective interpersonal distance (IPD), perceived arousal and comfort, presence, and post-experience responses. Findings showed that thermal feedback decreased objective but not subjective IPD, whereas vibrotactile heartbeats (signaling agent's closeness) increased both while heightening arousal and discomfort. Agents' stories did not affect IPD, arousal, or comfort. Our qualitative findings shed light on signal ambiguity and presence constructs within VR-based haptic stimulation. We contribute insights into artificial biosignals and their influence on VR proxemics, with cautionary considerations should the boundaries blur between physical and virtual touch." ;
    dcterms:identifier "3706598.3713231" ;
    chi:hasAuthor chi:person_188141, chi:person_188147, chi:person_188165, chi:person_186964, chi:person_184702 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:EmbodiedVRInteraction ;
    chi:paperIncludesStudy chi:study_188343_UserStudy ;
    chi:proposesArtifact chi:artifact_188343_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188343_DeviceArtifact .

chi:study_188343_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188343 ;
    chi:hasMeasure chi:SubjectiveMeasure ;
    chi:reportsResult chi:result_188343_QualitativeResult ;
    chi:reportsResult chi:result_188343_StatisticalResult .

chi:artifact_188343_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188343 .

chi:artifact_188343_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188343 .

chi:result_188343_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188343_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188344 rdf:type chi:Paper ;
    dcterms:title "Virtual Worlds Beyond Sight: Designing and Evaluating an Audio-Haptic System for Non-Visual VR Exploration" ;
    dcterms:abstract "Contemporary research in Virtual Reality (VR) for users who are visually impaired often employs navigation and interaction modalities that are either non-conventional or constrained by physical spaces or both. We designed and examined a hapto-acoustic VR system that mitigates this by enabling non-visual exploration of large virtual environments using white cane simulation and walk-in place locomotion. The system features a complex urban cityscape incorporating a physical cane prototype coupled with a virtual cane for rendering surface textures and an omnidirectional slide mill for navigation. In addition, spatialized audio is rendered based on the progression of sound through the geometry around the user. A study involving twenty sighted participants evaluated the system through three formative tasks while blindfolded to simulate absolute blindness. 19/20 participants successfully completed all the tasks while effectively navigating through the environment. This work highlights the potential for accessible non-visual VR experiences requiring minimal training and limited prior VR exposure." ;
    dcterms:identifier "3706598.3713400" ;
    chi:hasAuthor chi:person_185991, chi:person_186569 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:NavigationSupportForLowVision ;
    chi:paperIncludesStudy chi:study_188344_UserStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188344_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188344_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188344_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188344_InputDeviceArtifact .

chi:study_188344_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188344 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188344_StatisticalResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:artifact_188344_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188344 .

chi:artifact_188344_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188344 .

chi:artifact_188344_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188344 .

chi:artifact_188344_InputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188344 .

chi:result_188344_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188345 rdf:type chi:Paper ;
    dcterms:title "Perceptions of the Fairness Impacts of Multiplicity in Machine Learning" ;
    dcterms:abstract "Machine learning (ML) is increasingly used in high-stakes settings, yet multiplicity – the existence of multiple good models – means that some predictions are essentially arbitrary. ML researchers and philosophers posit that multiplicity poses a fairness risk, but no studies have investigated whether stakeholders agree. In this work, we conduct a survey to see how multiplicity impacts lay stakeholders’ – i.e., decision subjects’ – perceptions of ML fairness, and which approaches to address multiplicity they prefer. We investigate how these perceptions are modulated by task characteristics (e.g., stakes and uncertainty). Survey respondents think that multiplicity threatens the fairness of model outcomes, but not the appropriateness of using the model, even though existing work suggests the opposite. Participants are strongly against resolving multiplicity by using a single model (effectively ignoring multiplicity) or by randomizing the outcomes. Our results indicate that model developers should be intentional about dealing with multiplicity in order to maintain fairness." ;
    dcterms:identifier "3706598.3713524" ;
    chi:hasAuthor chi:person_187829, chi:person_183725, chi:person_186965, chi:person_183291 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:AlgorithmicFairnessAndBias ;
    chi:paperIncludesStudy chi:study_188345_UserStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking .

chi:study_188345_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188345 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188345_StatisticalResult ;
    chi:reportsResult chi:result_188345_QualitativeResult .

chi:result_188345_StatisticalResult rdf:type chi:StatisticalResult .

chi:result_188345_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188346 rdf:type chi:Paper ;
    dcterms:title "How Do People Perceive Bundling? An Experiment" ;
    dcterms:abstract "We present an exploratory study on how people perceive visualizations of spatial social networks generated by edge bundling algorithms. Although these algorithms successfully minimize clutter in node-link diagrams, they do so through various methods that can sometimes create false connections between nodes. We conducted a qualitative experiment involving participants with technical expertise but no prior knowledge of edge bundling algorithms. Participants described their perceptions of both bundled and straight-line visualizations in open-ended tasks. Analysis of their annotations and transcripts revealed a general preference for bundled visualizations. However, when it came to false connections, participants tended to follow them in tightly bundled diagrams while also vocalizing that these drawings were more ambiguous. The routing of bundles influenced the perception of clusters and participants assigned more or fewer nodes to the clusters, depending on the routing of bundles. Participants' unfamiliarity with the dataset led them to use analogies to describe the bundled drawings, potentially adding perceived semantic meaning to the data." ;
    dcterms:identifier "3706598.3713444" ;
    chi:hasAuthor chi:person_184759, chi:person_187844, chi:person_183999, chi:person_188084, chi:person_186267 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:CollaborativeVisualizationTools ;
    chi:paperIncludesStudy chi:study_188346_UserStudy ;
    chi:paperIncludesStudy chi:study_188346_QualitativeStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188346_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188346_SoftwareArtifact .

chi:study_188346_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188346 ;
    chi:reportsResult chi:result_188346_QualitativeResult .

chi:study_188346_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188346 ;
    chi:reportsResult chi:result_188346_QualitativeResult .

chi:artifact_188346_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188346 .

chi:artifact_188346_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188346 .

chi:result_188346_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188347 rdf:type chi:Paper ;
    dcterms:title "Encountering Friction, Understanding Crises: How Do Digital Natives Make Sense of Crisis Maps?" ;
    dcterms:abstract "Crisis maps are regarded as crucial tools in crisis communication, as demonstrated during the COVID-19 pandemic and climate change crises. However, there is limited understanding of how public audiences engage with these maps and extract essential information. Our study investigates the sensemaking of young, digitally native viewers as they interact with crisis maps. We integrate frameworks from the learning sciences and human-data interaction to explore sensemaking through two empirical studies: a thematic analysis of online comments from a New York Times series on graph comprehension, and interviews with 18 participants from German-speaking regions. Our analysis categorizes sensemaking activities into established clusters: inspecting, engaging with content, and placing, and introduces responding personally to capture the affective dimension. We identify friction points connected to these clusters, including struggles with color concepts, responses to missing context, lack of personal connection, and distrust, offering insights for improving crisis communication to public audiences." ;
    dcterms:identifier "3706598.3713520" ;
    chi:hasAuthor chi:person_186684, chi:person_187420, chi:person_182702, chi:person_183000 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:CollaborativeVisualizationTools ;
    chi:paperIncludesStudy chi:study_188347_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188347_QualitativeStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188347_InterfaceArtifact .

chi:study_188347_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188347 ;
    chi:reportsResult chi:result_188347_QualitativeResult .

chi:study_188347_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188347 ;
    chi:reportsResult chi:result_188347_QualitativeResult .

chi:artifact_188347_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188347 .

chi:result_188347_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188348 rdf:type chi:Paper ;
    dcterms:title "Investigating Composite Relation with a Data-Physicalized Thing through the Deployment of the WavData Lamp" ;
    dcterms:abstract "This paper reports on a field study of the WavData Lamp: an interactive lamp that can physically visualize people’s music listening data by changing light colors and outstretching its form enclosure. We deployed five WavData Lamps to five participants' homes for two months to investigate their composite relation with a data-physicalized thing. Findings reveal that their music-listening norms were determined by the instantiated materiality of the Lamp in the early days. With a tilted form enclosure, the WavData Lamp successfully engendered rich actions and meanings of the cohabiting participants and their family members. In the end, the participants described their experiences of entangling with and living with the Lamp as a form of collaboration. Reflecting on these empirical insights explicitly extends the intrinsic meaning of the composite relation and offers rich implications to promote further HCI explorations and practices." ;
    dcterms:identifier "3706598.3713489" ;
    chi:hasAuthor chi:person_183465, chi:person_182966, chi:person_184788, chi:person_187897, chi:person_185516 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:paperIncludesStudy chi:study_188348_FieldStudy ;
    chi:proposesArtifact chi:artifact_188348_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188348_InterfaceArtifact .

chi:study_188348_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188348 ;
    chi:reportsResult chi:result_188348_QualitativeResult .

chi:artifact_188348_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188348 .

chi:artifact_188348_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188348 .

chi:result_188348_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188350 rdf:type chi:Paper ;
    dcterms:title "Effects of Information Widgets on Time Perception during Mentally Demanding Tasks" ;
    dcterms:abstract "This article examined how different time and task management information widgets affect time perception across modalities. In mentally demanding office environments, effective countdown representations are crucial for enhancing temporal awareness and productivity. We developed TickSens, a set of information widgets with different modalities, and conducted a within-subjects experiment with 30 participants to evaluate the five types of time perception modes: visual, auditory, haptic, as well as the blank and the timer modes. Our assessment focused on the technology acceptance, cognitive performance and emotional responses. Results indicated that compared to the blank and the timer modes, the use of modalities significantly improved the cognitive performance and positive emotional responses, and was better received by participants. The visual mode had the best task performance, while the auditory feedback was effective in boosting focus and the haptic mode significantly enhances user acceptance. The study revealed varied user preferences that enlightened the integration of these widgets into office." ;
    dcterms:identifier "3706598.3713270" ;
    chi:hasAuthor chi:person_185298, chi:person_183380, chi:person_183059, chi:person_187593, chi:person_183459, chi:person_184196 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:ErrorRatesAndTaskCompletion ;
    chi:paperIncludesStudy chi:study_188350_UserStudy ;
    chi:aimsAtGoal chi:ReduceCognitiveLoad ;
    chi:proposesArtifact chi:artifact_188350_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188350_SoftwareArtifact .

chi:study_188350_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188350 ;
    chi:hasMeasure chi:PerformanceMeasure ;
    chi:hasMeasure chi:SubjectiveMeasure ;
    chi:reportsResult chi:result_188350_StatisticalResult .

chi:artifact_188350_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188350 .

chi:artifact_188350_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188350 .

chi:result_188350_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188351 rdf:type chi:Paper ;
    dcterms:title "A Route to Somatic Literacy of the Pelvic Floor through Technology-Initiated Touch" ;
    dcterms:abstract "The Pelvic Chair is a shape-changing chair that touches the pelvic area. Through rhythmic and gentle movements on different parts of the pelvic area, the touch interactions from the Pelvic Chair invite attention to the anatomy, muscles, and connectedness. We present a user study with 14 participants focusing on their experience of being touched by the Pelvic Chair. Through our qualitative analysis of participants' experiences, we show that meaningful touch can offer an active approach to sensing the pelvic floor that contributes to increasing somatic literacy - becoming familiar with the pelvic floor, being able to feel and distinguish between tension and relaxation, and establishing new connections between the pelvic floor and the body. Using the Pelvic Chair as a design case we show the potential for technology-initiated touch in providing an intimate and safe way of touching and connecting with the body." ;
    dcterms:identifier "3706598.3713223" ;
    chi:hasAuthor chi:person_183972, chi:person_188108, chi:person_187155, chi:person_183307 ;
    chi:paperIncludesStudy chi:study_188351_UserStudy ;
    chi:paperIncludesStudy chi:study_188351_QualitativeStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188351_DeviceArtifact .

chi:study_188351_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188351 ;
    chi:reportsResult chi:result_188351_QualitativeResult .

chi:study_188351_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188351 ;
    chi:reportsResult chi:result_188351_QualitativeResult .

chi:artifact_188351_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188351 .

chi:result_188351_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188352 rdf:type chi:Paper ;
    dcterms:title "Reimagining Wearable-Based Digital Contact Tracing: Insights from Kenya and Côte d’Ivoire" ;
    dcterms:abstract "While digital contact tracing has been extensively studied in Western contexts, its relevance and application in Africa remain largely unexplored. This study focuses on Kenya and Côte d’Ivoire to uncover user perceptions and inform the design of culturally resonant contact tracing technologies. Utilizing a wearable proximity sensor as a technology probe, we conducted field studies with healthcare workers and community members in rural areas through interviews (𝑁 = 19) and participatory design workshops (𝑁 = 72). Our findings identify critical barriers to adoption, including low awareness, widespread misconceptions, and social stigma. The study emphasizes the need for culturally sensitive and discreet wearables and advocates for awareness campaigns over mandates to foster adoption. Our work addresses the unique needs of Kenyan and Ivorian populations, offering vital design recommendations and insights to guide designers and policymakers in enhancing digital contact tracing adoption across Africa." ;
    dcterms:identifier "3706598.3713817" ;
    chi:hasAuthor chi:person_186645, chi:person_183985, chi:person_183103, chi:person_185179, chi:person_185284, chi:person_186342, chi:person_184913, chi:person_185658, chi:person_183922, chi:person_186442, chi:person_186495, chi:person_185310 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188352_FieldStudy ;
    chi:paperIncludesStudy chi:study_188352_InterviewStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188352_DeviceArtifact .

chi:study_188352_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188352 ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188352_QualitativeResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:study_188352_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188352 ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188352_QualitativeResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:artifact_188352_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188352 .

chi:result_188352_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188353 rdf:type chi:Paper ;
    dcterms:title "From Locked Rooms to Open Minds: Escape Room Best Practices to Enhance Reflection in Extended Reality Learning Environments" ;
    dcterms:abstract "Extended reality (XR) learning environments result in greater knowledge gains when coupled with opportunities to reflect on one's actions and learning. However, when and how one should prompt reflection in XR learning environments (XRLEs) to effectively enhance learning, without breaking immersion, remains an open question. In this work, we argue that we can extract insights on how to design effective, immersive reflection for XRLEs from the expertise of escape room game masters (GMs) who regularly provide reflective hints and prompts in complex, immersive problem solving environments. To explore what we can learn from GMs, we conducted exploratory semi-structured interviews with 13 escape room GMs and, via iterative open coding, captured their best practices in how they provide hints and give nudges to escape room players. " ;
    dcterms:identifier "3706598.3713811" ;
    chi:hasAuthor chi:person_186759, chi:person_185009, chi:person_185375, chi:person_187483, chi:person_186091, chi:person_187254 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188353_InterviewStudy ;
    chi:aimsAtGoal chi:PromoteLearning .

chi:study_188353_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188353 ;
    chi:reportsResult chi:result_188353_QualitativeResult .

chi:result_188353_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188354 rdf:type chi:Paper ;
    dcterms:title "Trust and Visual Focus in Automated Vehicles: A Comparative Study of Beginner and Experienced Drivers" ;
    dcterms:abstract "This study investigated the relationship between trust in automation, gaze behavior, and driving performance in beginner and experienced drivers during a simulated driving session. Twenty participants completed a 17-minute drive across three conditions: manual driving, non-critical automated driving, and critical automated driving, with a non-driving-related task (NDRT) introduced between conditions to assess visual attention. Driving performance was evaluated using the Standard Deviation of Lateral Position (SDLP), and eye-tracking data in terms of mean gaze duration (MGD). While both groups demonstrated increased trust in the automated system post-session, beginners showed greater lateral position variability in critical conditions, suggesting over-reliance on automation. Eye-tracking analysis revealed significant changes in glance behavior across driving conditions, particularly in response to critical events. These findings highlight how driver experience shapes interactions with automated systems, emphasizing the importance of trust calibration in automated driving scenarios." ;
    dcterms:identifier "3706598.3713806" ;
    chi:hasAuthor chi:person_184226, chi:person_186207, chi:person_186134, chi:person_186302, chi:person_184587, chi:person_184125 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:ErrorRatesAndTaskCompletion ;
    chi:paperIncludesStudy chi:study_188354_UserStudy ;
    chi:proposesArtifact chi:artifact_188354_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188354_InterfaceArtifact .

chi:study_188354_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188354 ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188354_StatisticalResult .

chi:artifact_188354_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188354 .

chi:artifact_188354_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188354 .

chi:result_188354_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188355 rdf:type chi:Paper ;
    dcterms:title "ID.EARS: One-Ear EEG Device with Biosignal Noise for Real-Time Gesture Recognition and Various Interactions" ;
    dcterms:abstract "In-ear EEG research has traditionally treated biological signals other than brainwaves, such as electromyography (EMG) and electrooculography (EOG), as unwanted noise to be removed. However, instead of discarding these signals, we developed ID.EARS, a single-ear, dry electrode-based device that utilizes these signals for real-time gesture input. We first identified the optimal position for EEG measurement around the ear using the Alpha Attenuation Response (AAR) test and collected biological signals that occur alongside brainwaves at this location. Using these signals, we created a real-time artifact detection model capable of recognizing five specific gestures: blinking, left and right winking, teeth clenching, and chewing. This model achieved over 90% accuracy in cross-validation experiments. Leveraging this model and device, we propose several application scenarios, including music control, accessibility features, MR/XR control, and healthcare services. This innovative approach extends the use of ear-EEG devices beyond healthcare, opening up possibilities for natural user interfaces." ;
    dcterms:identifier "3706598.3714185" ;
    chi:hasAuthor chi:person_185337, chi:person_187186, chi:person_184414, chi:person_187518, chi:person_186236, chi:person_184944 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:paperIncludesStudy chi:study_188355_UserStudy ;
    chi:paperIncludesStudy chi:study_188355_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188355_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188355_InputDeviceArtifact ;
    chi:proposesArtifact chi:artifact_188355_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188355_InterfaceArtifact .

chi:study_188355_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188355 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188355_StatisticalResult .

chi:study_188355_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188355 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188355_StatisticalResult .

chi:artifact_188355_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188355 .

chi:artifact_188355_InputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188355 .

chi:artifact_188355_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188355 .

chi:artifact_188355_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188355 .

chi:result_188355_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188356 rdf:type chi:Paper ;
    dcterms:title "Datamancer: Bimanual Gesture Interaction in Multi-Display Ubiquitous Analytics Environments" ;
    dcterms:abstract "We introduce Datamancer, a wearable device enabling bimanual gesture interaction across multi-display ubiquitous analytics environments. Datamancer addresses the gap in gesture-based interaction within data visualization settings, where current methods are often constrained by limited interaction spaces or the need for installing bulky tracking setups. Datamancer integrates a finger-mounted pinhole camera and a chest-mounted gesture sensor, allowing seamless selection and manipulation of visualizations on distributed displays. By pointing to a display, users can acquire the display and engage in various interactions, such as panning, zooming, and selection, using both hands. Our contributions include (1) an investigation of the design space of gestural interaction for physical ubiquitous analytics environments; (2) a prototype implementation of the Datamancer system that realizes this model; and (3) an evaluation of the prototype through demonstration of application scenarios, an expert review, and a user study." ;
    dcterms:identifier "3706598.3713123" ;
    chi:hasAuthor chi:person_185902, chi:person_184316, chi:person_186061, chi:person_186774, chi:person_187386 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:paperIncludesStudy chi:study_188356_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188356_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188356_InputDeviceArtifact ;
    chi:proposesArtifact chi:artifact_188356_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188356_SoftwareArtifact .

chi:study_188356_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188356 ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188356_QualitativeResult .

chi:artifact_188356_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188356 .

chi:artifact_188356_InputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188356 .

chi:artifact_188356_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188356 .

chi:artifact_188356_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188356 .

chi:result_188356_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188357 rdf:type chi:Paper ;
    dcterms:title "3D Printing for Accessible Education: A Case Study in Assistive Technology Adoption" ;
    dcterms:abstract "3D printing is a mainstream technology enabling the affordable production of 3D models that may enhance access and understanding of graphics for students who are blind or have low vision (BLV). However, the potential usefulness of a new technology does not guarantee its adoption. This paper presents a case study in the adoption of 3D printing as an accessible format for BLV education in Australia and New Zealand. Over the last six years, a community-driven research project engaged in awareness raising, created a community of practice and developed guidelines for the use of 3D printing in education. We evaluate the success of the project using an Implementation Science lens with the RE-AIM framework and identify the key factors for successful adoption. We hope this work will guide the adoption of 3D printing for BLV students and serve as an exemplar for the adoption of other assistive technologies." ;
    dcterms:identifier "3706598.3713689" ;
    chi:hasAuthor chi:person_186602, chi:person_182987, chi:person_185466, chi:person_186060 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:AccessibleLearningAndSupportSystems ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:AccessibleLearningAndSupportSystems ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188357_DeviceArtifact .

chi:artifact_188357_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188357 .

chi:result_188357_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188358 rdf:type chi:Paper ;
    dcterms:title "\"Python is for girls!\": Masculinity, Femininity, and Queering Inclusion at Hackathons" ;
    dcterms:abstract "This paper explores how queerness intersects with hackathon culture, reinforcing or challenging its masculine norms. By utilizing autoethnographic insights from seven UK hackathons, it reveals that while queerness is visibly celebrated, inclusion remains conditional—accepted only when it aligns with masculine-coded technical authority. Femininity, regardless of the queer identities of those who embody it, is devalued and associated with lesser technical competence. Beyond social dynamics, gendered hierarchies influence programming tools, roles, and physical environments, embedding exclusion within technical culture. Although gender-fluid expressions like cosplay provide moments of subversion, they remain limited by the masculine framework of hackathons. This study contributes to human-computer interaction and feminist technology studies by showing that queerness alone does not dismantle gendered hierarchies. It advocates for moving beyond visibility to actively challenge masculinized definitions of technical legitimacy, promoting alternative, non-exclusionary models of expertise." ;
    dcterms:identifier "3706598.3713235" ;
    chi:hasAuthor chi:person_183086 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:ParticipatoryEthicsMethods ;
    chi:paperIncludesStudy chi:study_188358_FieldStudy .

chi:study_188358_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188358 ;
    chi:reportsResult chi:result_188358_QualitativeResult .

chi:result_188358_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188371 rdf:type chi:Paper ;
    dcterms:title "Understanding and Supporting Peer Review Using AI-reframed Positive Summary" ;
    dcterms:abstract "While peer review enhances writing and research quality, harsh feedback can frustrate and demotivate authors. Hence, it is essential to explore how critiques should be delivered to motivate authors and enable them to keep iterating their work. In this study, we explored the impact of appending an automatically generated positive summary to the peer reviews of a writing task, alongside varying levels of overall evaluations (high vs. low), on authors’ feedback reception, revision outcomes, and motivation to revise. Through a 2x2 online experiment with 137 participants, we found that adding an AI-reframed positive summary to otherwise harsh feedback increased authors’ critique acceptance, whereas low overall evaluations of their work led to increased revision efforts. We discuss the implications of using AI in peer feedback, focusing on how AI-driven critiques can influence critique acceptance and support research communities in fostering productive and friendly peer feedback practices." ;
    dcterms:identifier "3706598.3713219" ;
    chi:hasAuthor chi:person_183642, chi:person_186948, chi:person_184574, chi:person_184113 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:ChatbotAssistedUserStudies ;
    chi:paperIncludesStudy chi:study_188371_UserStudy ;
    chi:paperIncludesStudy chi:study_188371_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188371_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188371_InterfaceArtifact .

chi:study_188371_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188371 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188371_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:study_188371_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188371 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188371_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:artifact_188371_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188371 .

chi:artifact_188371_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188371 .

chi:result_188371_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188372 rdf:type chi:Paper ;
    dcterms:title "Layered Interactions: Exploring Non-Intrusive Digital Craftsmanship Design Through Lacquer Art Interfaces" ;
    dcterms:abstract "Integrating technology with the distinctive characteristics of craftsmanship has become a key issue in the field of digital craftsmanship. This paper introduces Layered Interactions, a design approach that seamlessly merges Human-Computer Interaction (HCI) technologies with traditional lacquerware craftsmanship. By leveraging the multi-layer structure and material properties of lacquerware, we embed interactive circuits and integrate programmable hardware within the layers, creating tangible interface that support diverse interactions. This method enhances the adaptability and practicality of traditional crafts in modern digital contexts. Through the development of a lacquerware toolkit, along with user experiments and semi-structured interviews, we demonstrate that this approach not only makes technology more accessible to traditional artisans but also enhances the materiality and emotional qualities of interactive interfaces. Additionally, it fosters mutual learning and collaboration between artisans and technologists. Our research introduces a cross-disciplinary perspective to the HCI community, broadening the material and design possibilities for interactive interfaces." ;
    dcterms:identifier "3706598.3713599" ;
    chi:hasAuthor chi:person_187419, chi:person_186786, chi:person_183617, chi:person_184549, chi:person_185614 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:paperIncludesStudy chi:study_188372_UserStudy ;
    chi:paperIncludesStudy chi:study_188372_InterviewStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188372_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188372_DeviceArtifact .

chi:study_188372_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188372 ;
    chi:reportsResult chi:result_188372_QualitativeResult .

chi:study_188372_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188372 ;
    chi:reportsResult chi:result_188372_QualitativeResult .

chi:artifact_188372_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188372 .

chi:artifact_188372_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188372 .

chi:result_188372_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188373 rdf:type chi:Paper ;
    dcterms:title "Queue Player: Investigating Distributed Co-Listening Experiences for Social Connection across Space, Time, and Tempo " ;
    dcterms:abstract "We describe the design and deployment of Queue Player, four networked domestic music players that combine music listening histories of close friends to explore new potentialities for interacting with this shared archive. We deployed the Queue Players with four close friends living in separate homes for six weeks. Our goals are to (i) explore how this system might enable co-listening experiences that foster social presence, interaction, and reflection and (ii) empirically explore conceptual propositions related to slow technology. Findings revealed that, after overcoming initial frictions, Queue Player became integrated in participants’ lives and triggered a range of social interactions and reflections on past life experiences. They also showed that Queue Player provoked questions on the benefits and limits of data capturing one’s life history as well as the role and pace of technology in everyday life at home. Findings are interpreted to present opportunities for future HCI research and practice." ;
    dcterms:identifier "3706598.3714293" ;
    chi:hasAuthor chi:person_187626, chi:person_185238, chi:person_185504, chi:person_183622, chi:person_184364, chi:person_185782, chi:person_186346 ;
    chi:hasPrimaryTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:CollaborativeSensemaking ;
    chi:paperIncludesStudy chi:study_188373_FieldStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188373_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188373_SoftwareArtifact .

chi:study_188373_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188373 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188373_QualitativeResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:artifact_188373_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188373 .

chi:artifact_188373_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188373 .

chi:result_188373_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188374 rdf:type chi:Paper ;
    dcterms:title "Prestige and Prejudice: How the Interplay of Recruiting Work and Algorithms Reinforces Social Inequities in Software Engineering" ;
    dcterms:abstract "The technology industry has long sought to diversify its workforce. This study evaluates one avenue that works against these efforts: the interaction between recruiter work practices and algorithmic recruiting tools. Through interviews and cognitive walkthroughs with fifteen recruiters, we find that recruiters—often under deadlines and quotas—develop shortcuts (e.g., computer science degrees and employment at prestigious companies) for identifying “typical” software engineers (one of the most sought-after roles in the field) who have a higher chance of being successfully hired. We then analyze the results of searches like those recruiters often conduct in one commonly-used recruitment tool. We see recruiters’ shortcuts also reflected in these results: candidates with computer science degrees, living in expensive tech hubs, and employed at high-profile tech companies are disproportionately favored. Given the lack of demographic diversity in software engineering at prestigious companies, we assert that algorithmically preferencing these factors helps to reify existing stereotypes, impacting the diversity of candidates who are ultimately hired." ;
    dcterms:identifier "3706598.3713176" ;
    chi:hasAuthor chi:person_187947, chi:person_184883, chi:person_184809, chi:person_182986 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:AlgorithmicFairnessAndBias ;
    chi:paperIncludesStudy chi:study_188374_InterviewStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188374_SoftwareArtifact .

chi:study_188374_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188374 ;
    chi:reportsResult chi:result_188374_QualitativeResult .

chi:artifact_188374_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188374 .

chi:result_188374_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188375 rdf:type chi:Paper ;
    dcterms:title "LLM Whisperer: An Inconspicuous Attack to Bias LLM Responses" ;
    dcterms:abstract "Writing effective prompts for large language models (LLM) can be unintuitive and burdensome. In response, services that optimize or suggest prompts have emerged. While such services can reduce user effort, they also introduce a risk: the prompt provider can subtly manipulate prompts to produce heavily biased LLM responses. In this work, we show that subtle synonym replacements in prompts can increase the likelihood (by a difference up to 78%) that LLMs mention a target concept (e.g., a brand, political party, nation). We substantiate our observations through a user study, showing that our adversarially perturbed prompts 1) are indistinguishable from unaltered prompts by humans, 2) push LLMs to recommend target concepts more often, and 3) make users more likely to notice target concepts, all without arousing suspicion. The practicality of this attack has the potential to undermine user autonomy. Among other measures, we recommend implementing warnings against using prompts from untrusted parties." ;
    dcterms:identifier "3706598.3714025" ;
    chi:hasAuthor chi:person_186806, chi:person_183081, chi:person_187493, chi:person_182799, chi:person_187130, chi:person_185240 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:AlgorithmicFairnessAndBias ;
    chi:paperIncludesStudy chi:study_188375_UserStudy ;
    chi:proposesArtifact chi:artifact_188375_SoftwareArtifact .

chi:study_188375_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188375 ;
    chi:reportsResult chi:result_188375_StatisticalResult .

chi:artifact_188375_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188375 .

chi:result_188375_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188376 rdf:type chi:Paper ;
    dcterms:title "The Many Tendrils of the Octopus Map" ;
    dcterms:abstract "Conspiratorial thinking can connect many distinct or distant ills to a central cause. This belief has visual form in the octopus map: a map where a central force (for instance a nation, an ideology, or an ethnicity) is depicted as a literal or figurative octopus, with extending tendrils. In this paper, we explore how octopus maps function as visual arguments through an analysis of historical examples as well as a through a crowd-sourced study on how the underlying data and the use of visual metaphors contribute to specific negative or conspiratorial interpretations. We find that many features of the data or visual style can lead to \"octopus-like\" thinking in visualizations, even without the use of an explicit octopus motif. We conclude with a call for a deeper analysis of visual rhetoric, and an acknowledgment of the potential for the design of data visualizations to contribute to harmful or conspiratorial thinking." ;
    dcterms:identifier "3706598.3713583" ;
    chi:hasAuthor chi:person_186619, chi:person_187831, chi:person_183172 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:paperIncludesStudy chi:study_188376_UserStudy .

chi:study_188376_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188376 ;
    chi:reportsResult chi:result_188376_QualitativeResult .

chi:result_188376_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188378 rdf:type chi:Paper ;
    dcterms:title "How CO2STLY Is CHI? The Carbon Footprint of Generative AI in HCI Research and What We Should Do About It" ;
    dcterms:abstract "The energy cost of developing and deploying Generative AI (GenAI) models has exploded with their mass adoption, as has the ensuing carbon emissions. The climate impact of this is currently unknown. In Human-Computer Interaction, GenAI models are rarely trained but often used. Based on detailed review of 282 papers, we estimate this footprint from energy consumption of the total use of GenAI for CHI 2024 research as between 10,769.63 and 10,925.12 kg CO2e — equal to driving a car for more than 100,000 km. We show that in CHI research, GenAI is most often used for Prototyping, Evaluation & User studies, and that Data Collection and Fine-tuning models incurs the highest CO2st. We find that CHI submissions are unlikely to report GenAI use transparently, which makes precise calculations difficult. By measuring the usage of a subset of the papers on local hardware, we obtain estimations of the energy consumption and carbon footprint. Based on this evidence, we discuss and demonstrate ways to mitigate the issues of GenAI carbon footprint and lack of transparency." ;
    dcterms:identifier "3706598.3714227" ;
    chi:hasAuthor chi:person_184278, chi:person_184721, chi:person_187949 .

chi:result_188378_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188379 rdf:type chi:Paper ;
    dcterms:title "BIT: Battery-free, IC-less and Wireless Smart Textile Interface and Sensing System" ;
    dcterms:abstract "The development of smart textile interfaces is hindered by the inclusion of rigid hardware components and batteries within the fabric, which pose challenges in terms of manufacturability, usability, and environmental concerns related to electronic waste. To mitigate these issues, we propose a smart textile interface and its wireless sensing system to eliminate the need for ICs, batteries, and connectors embedded into textiles. Our technique is established on the integration of multi-resonant circuits in smart textile interfaces, and utilizing near-field electromagnetic coupling between two coils to facilitate wireless power transfer and data acquisition from smart textile interface.A key aspect of our system is the development of a mathematical model that accurately represents the equivalent circuit of the sensing system. Using this model, we developed a novel algorithm to accurately estimate sensor signals based on changes in system impedance. Through simulation-based experiments and a user study, we demonstrate that our technique effectively supports multiple textile sensors of various types. " ;
    dcterms:identifier "3706598.3713100" ;
    chi:hasAuthor chi:person_184137, chi:person_184732, chi:person_183231, chi:person_183493, chi:person_187214 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:paperIncludesStudy chi:study_188379_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188379_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188379_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188379_InputDeviceArtifact .

chi:study_188379_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188379 ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188379_StatisticalResult .

chi:artifact_188379_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188379 .

chi:artifact_188379_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188379 .

chi:artifact_188379_InputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188379 .

chi:result_188379_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188380 rdf:type chi:Paper ;
    dcterms:title "Generating Highlight Videos of a User-Specified Length using Most Replayed Data" ;
    dcterms:abstract "A highlight is a short edit of the original video that includes the most engaging moments. Given the rigid timing of TV commercial slots and length limits of social media uploads, generating highlights of specific lengths is crucial. Previous research on automatic highlight generation often overlooked the control over the duration of the final video, producing highlights of arbitrary lengths. We propose a novel system that automatically generates highlights of any user-specified length. Our system leverages Most Replayed Data (MRD), which identifies how frequently a video has been watched over time, to gauge the most engaging parts. It then optimizes the final editing path by adjusting internal segment durations. We evaluated the quality of our system's outputs through two user studies, including a comparison with highlights created by human editors. Results show that our system can automatically produce highlights that are indistinguishable from those created by humans in viewing experience." ;
    dcterms:identifier "3706598.3713880" ;
    chi:hasAuthor chi:person_183473, chi:person_186582, chi:person_186931 ;
    chi:paperIncludesStudy chi:study_188380_UserStudy ;
    chi:paperIncludesStudy chi:study_188380_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188380_SoftwareArtifact .

chi:study_188380_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188380 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:reportsResult chi:result_188380_StatisticalResult .

chi:study_188380_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188380 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:reportsResult chi:result_188380_StatisticalResult .

chi:artifact_188380_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188380 .

chi:result_188380_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188381 rdf:type chi:Paper ;
    dcterms:title "The Last JITAI? Exploring Large Language Models for Issuing Just-in-Time Adaptive Interventions: Fostering Physical Activity in a Prospective Cardiac Rehabilitation Setting" ;
    dcterms:abstract "We evaluated the viability of using Large Language Models (LLMs) to trigger and personalize content in Just-in-Time Adaptive Interventions (JITAIs) in digital health. As an interaction pattern representative of context-aware computing, JITAIs are being explored for their potential to support sustainable behavior change, adapting interventions to an individual’s current context and needs. Challenging traditional JITAI implementation models, which face severe scalability and flexibility limitations, we tested GPT-4 for suggesting JITAIs in the use case of heart-healthy activity in cardiac rehabilitation. Using three personas representing patients affected by CVD with varying severeness and five context sets per persona, we generated 450 JITAI decisions and messages. These were systematically evaluated against those created by 10 laypersons (LayPs) and 10 healthcare professionals (HCPs). GPT-4-generated JITAIs surpassed human-generated intervention suggestions, outperforming both LayPs and HCPs across all metrics (i.e., appropriateness, engagement, effectiveness, and professionalism). These results highlight the potential of LLMs to enhance JITAI implementations in personalized health interventions, demonstrating how generative AI could revolutionize context-aware computing." ;
    dcterms:identifier "3706598.3713307" ;
    chi:hasAuthor chi:person_182899, chi:person_185490, chi:person_187467, chi:person_188121, chi:person_184717, chi:person_184076, chi:person_185316, chi:person_187803, chi:person_183337, chi:person_183227 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:SelfReflectionAndBehaviorChange ;
    chi:paperIncludesStudy chi:study_188381_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188381_SoftwareArtifact .

chi:study_188381_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188381 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188381_StatisticalResult .

chi:artifact_188381_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188381 .

chi:result_188381_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188382 rdf:type chi:Paper ;
    dcterms:title "\"They are responsible for ensuring that I can continue to use the service.\" Investigating Users' Expectations Towards 2FA Recovery in Germany" ;
    dcterms:abstract "Two-factor authentication is often recommended for increasing online security, and users often follow this by using their phones. If physical items become unavailable, there is a risk of losing access to the account due to missing authentication requirements. In such cases, users need a backup or help from the service. Previous work found no standardized approach to how services address this issue, assist users, or offer backup options. Until now, it is unclear how users handle backups and account recovery and what their expectations towards service providers are. To shed light on this, we conducted 16 interviews and a survey with 95 participants. We found that most had never considered how to access their accounts if the second factor was lost, and only a few had a backup plan. Instead, users often rely on website support, assuming that personal data will help them regain access. We give recommendations for services." ;
    dcterms:identifier "3706598.3714245" ;
    chi:hasAuthor chi:person_188052, chi:person_185594, chi:person_188003, chi:person_187938, chi:person_187242 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:DataDisclosureAndConsent ;
    chi:paperIncludesStudy chi:study_188382_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188382_UserStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking .

chi:study_188382_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188382 ;
    chi:reportsResult chi:result_188382_QualitativeResult ;
    chi:reportsResult chi:result_188382_StatisticalResult .

chi:study_188382_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188382 ;
    chi:reportsResult chi:result_188382_QualitativeResult ;
    chi:reportsResult chi:result_188382_StatisticalResult .

chi:result_188382_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188382_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188384 rdf:type chi:Paper ;
    dcterms:title "Imprinto: Enhancing Infrared Inkjet Watermarking for Human and Machine Perception" ;
    dcterms:abstract "Hybrid paper interfaces leverage augmented reality to combine the desired tangibility of paper documents with the affordances of interactive digital media. Typically, virtual content can be embedded through direct links (e.g., QR codes); however, this impacts the aesthetics of the paper print and limits the available visual content space. To address this problem, we present Imprinto, an infrared inkjet watermarking technique that allows for invisible content embeddings only by using off-the-shelf IR inks and a camera. Imprinto was established through a psychophysical experiment, studying how much IR ink can be used while remaining invisible to users regardless of background color. We demonstrate that we can detect invisible IR content through our machine learning pipeline, and we developed an authoring tool that optimizes the amount of IR ink on the color regions of an input document for machine and human detectability. Finally, we demonstrate several applications, including augmenting paper documents and objects." ;
    dcterms:identifier "3706598.3713286" ;
    chi:hasAuthor chi:person_187379, chi:person_187519, chi:person_185366, chi:person_186262, chi:person_185713, chi:person_187775, chi:person_186494, chi:person_182800 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:paperIncludesStudy chi:study_188384_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188384_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188384_InterfaceArtifact .

chi:study_188384_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188384 ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188384_StatisticalResult .

chi:artifact_188384_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188384 .

chi:artifact_188384_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188384 .

chi:result_188384_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188385 rdf:type chi:Paper ;
    dcterms:title "Enhancing Computational Notebooks with Code+Data Space Versioning" ;
    dcterms:abstract "There is a gap between how people explore data and how Jupyter-like computational notebooks are designed. People explore data nonlinearly, using execution undos, branching, and/or complete reverts, whereas notebooks are designed for sequential exploration. Recent works like ForkIt are still insufficient to support these multiple modes of nonlinear exploration in a unified way. In this work, we address the challenge by introducing two dimensional code+data space versioning for computational notebooks and verifying its effectiveness using our prototype system, Kishuboard, which integrates with Jupyter. By adjusting code and data knobs, users of Kishuboard can intuitively manage the state of computational notebooks in a flexible way, thereby achieving both execution rollbacks and checkouts across complex multi-branch exploration history. Moreover, this two-dimensional versioning mechanism can easily be presented along with a friendly one-dimensional history. Human subject studies indicate that Kishuboard significantly enhances user productivity in various data science tasks. " ;
    dcterms:identifier "3706598.3714141" ;
    chi:hasAuthor chi:person_186068, chi:person_186878, chi:person_186317, chi:person_187158 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:paperIncludesStudy chi:study_188385_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188385_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188385_InterfaceArtifact .

chi:study_188385_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188385 ;
    chi:reportsResult chi:result_188385_StatisticalResult .

chi:artifact_188385_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188385 .

chi:artifact_188385_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188385 .

chi:result_188385_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188386 rdf:type chi:Paper ;
    dcterms:title "PCB Renewal: Iterative Reuse of PCB Substrates for Sustainable Electronic Making" ;
    dcterms:abstract "PCB (printed circuit board) substrates are often single-use, leading to material waste in electronics making. We introduce PCB Renewal , a novel technique that \"erases\" and \"reconfigures\" PCB traces by selectively depositing conductive epoxy onto outdated areas, transforming isolated paths into conductive planes that support new traces. We present the PCB Renewal workflow, evaluate its electrical performance and mechanical durability, and model its sustainability impact, including material usage, cost, energy consumption, and time savings. We develop a software plug-in that guides epoxy deposition, generates updated PCB profiles, and calculates resource usage. To demonstrate PCB Renewal’s effectiveness and versatility, we repurpose  a single PCB across four design iterations spanning three projects: a camera roller, a WiFi radio, and an ESPboy game console. We also show how an outsourced double-layer PCB can be reconfigured, transforming it from an LED watch to an interactive cat toy. The paper concludes with limitations and future directions." ;
    dcterms:identifier "3706598.3714276" ;
    chi:hasAuthor chi:person_186005, chi:person_185289, chi:person_186145, chi:person_185175, chi:person_186061 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:proposesArtifact chi:artifact_188386_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188386_DeviceArtifact .

chi:artifact_188386_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188386 .

chi:artifact_188386_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188386 .

chi:paper_188387 rdf:type chi:Paper ;
    dcterms:title "Surveillance on Exhibit: Using Problematic Technology To Teach About Problematic Technology" ;
    dcterms:abstract "As our most advanced technologies, such as AI, become both infrastructural and opaque, experts must educate and engage the broader public. To that end, we developed an Augmented Reality (AR) museum installation about facial recognition and data collection that served both as a medium of public education and as a platform for collecting multiple different kinds of data—though, notably, not facial or other biometric data—from more than 100,000 museum visitors. We explain our design process through four animating tensions: comfort/discomfort, simplicity/complexity, neutrality/critique, and the individual/communal. Using thematic analysis of interviews and surveys, we draw insights on how people exposed to problematic technologies in a ‘safe space’ such as a museum make sense of these issues: with levity and resignation but also reverence, often specifically rooted in local cultures. We conclude with implications of the guiding principle derived from this work: “using problematic technology to teach about problematic technology.” " ;
    dcterms:identifier "3706598.3713710" ;
    chi:hasAuthor chi:person_183583, chi:person_185899, chi:person_184946, chi:person_185832, chi:person_185502, chi:person_184036, chi:person_184417 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188387_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188387_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188387_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188387_SoftwareArtifact .

chi:study_188387_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188387 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188387_QualitativeResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation ;
    chi:involvesParticipationPattern chi:AsynchronousParticipation .

chi:study_188387_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188387 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188387_QualitativeResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation ;
    chi:involvesParticipationPattern chi:AsynchronousParticipation .

chi:artifact_188387_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188387 .

chi:artifact_188387_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188387 .

chi:result_188387_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188388 rdf:type chi:Paper ;
    dcterms:title "Efficient Management of LLM-Based Coaching Agents' Reasoning While Maintaining Interaction Quality and Speed" ;
    dcterms:abstract "    LLM-based agents improve upon standalone LLMs, which are optimized for immediate intent-satisfaction, by allowing the pursuit of more extended objectives, such as helping users over the long term. To do so, LLM-based agents need to reason before responding. For complex tasks like personalized coaching, this reasoning can be informed by adding relevant information at key moments, shifting it in the desired direction.     However, the pursuit of objectives beyond interaction quality may compromise this very quality. Moreover, as the depth and informativeness of reasoning increase, so do the number of tokens required, leading to higher latency and cost.     This study investigates how an LLM-based coaching agent can adjust its reasoning depth using a discrepancy mechanism that signals how much reasoning effort to allocate based on how well the objective is being met.     Our discrepancy-based mechanism constrains reasoning to better align with alternative objectives, reducing cost roughly tenfold while minimally impacting interaction quality." ;
    dcterms:identifier "3706598.3713606" ;
    chi:hasAuthor chi:person_188156, chi:person_183161, chi:person_185045 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:ChatbotAssistedUserStudies ;
    chi:proposesArtifact chi:artifact_188388_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188388_InterfaceArtifact .

chi:artifact_188388_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188388 .

chi:artifact_188388_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188388 .

chi:paper_188389 rdf:type chi:Paper ;
    dcterms:title "Designing LLM-Powered Multimodal Instructions to Support Rich Hands-on Skills Remote Learning: A Case Study with Massage Instructors and Learners" ;
    dcterms:abstract "Although remote learning is widely used for delivering and capturing knowledge, it has limitations in teaching hands-on skills that require nuanced instructions and demonstrations of precise actions, such as massage. Furthermore, scheduling conflicts between instructors and learners often limit the availability of real-time feedback, reducing learning efficiency. To address these challenges, we developed a synthesis tool utilizing an LLM-powered Virtual Teaching Assistant (VTA). This tool integrates multimodal instructions that convey precise data, such as stroke patterns and pressure control, while providing real-time feedback for learners and summarizing their performance for instructors. Our case study with instructors and learners demonstrated the effectiveness of these multimodal instructions and the VTA in enhancing massage teaching and learning. We then discuss the tools' use in other hands-on skills instruction and cognitive process differences in various courses. " ;
    dcterms:identifier "3706598.3713677" ;
    chi:hasAuthor chi:person_186611, chi:person_187908, chi:person_186962, chi:person_182722, chi:person_185281, chi:person_185071, chi:person_184172 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188389_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188389_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188389_InterfaceArtifact .

chi:study_188389_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188389 ;
    chi:reportsResult chi:result_188389_QualitativeResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:artifact_188389_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188389 .

chi:artifact_188389_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188389 .

chi:result_188389_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188390 rdf:type chi:Paper ;
    dcterms:title "AI on My Shoulder: Supporting Emotional Labor in Front-Office Roles with an  LLM-based Empathetic Coworker" ;
    dcterms:abstract "Client-Service Representatives (CSRs) are vital to organizations. Frequent interactions with disgruntled clients, however, disrupt their mental well-being. To help CSRs regulate their emotions while interacting with uncivil clients, we designed Care-Pilot, an LLM-powered assistant, and evaluated its efficacy, perception, and use. Our comparative analyses between 665 human and Care-Pilot-generated support messages highlight Care-Pilot’s ability to adapt to and demonstrate empathy in various incivility incidents. Additionally, 143 CSRs assessed Care-Pilot’s empathy as more sincere and actionable than human messages. Finally, we interviewed 20 CSRs who interacted with Care-Pilot in a simulation exercise. They reported that Care-Pilot helped them avoid negative thinking, recenter thoughts, and humanize clients; showing potential for bridging gaps in coworker support. Yet, they also noted deployment challenges and emphasized the indispensability of shared experiences. We discuss future designs and societal implications of AI-mediated emotional labor, underscoring empathy as a critical function for AI assistants for worker mental health." ;
    dcterms:identifier "3706598.3713705" ;
    chi:hasAuthor chi:person_184079, chi:person_183432, chi:person_182730, chi:person_185683, chi:person_187976, chi:person_187070, chi:person_186081, chi:person_186375, chi:person_185714, chi:person_185603 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:SocialComputing ;
    chi:paperIncludesStudy chi:study_188390_BaselineComparisonStudy ;
    chi:paperIncludesStudy chi:study_188390_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188390_UserStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188390_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188390_InterfaceArtifact .

chi:study_188390_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188390 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188390_QualitativeResult ;
    chi:reportsResult chi:result_188390_StatisticalResult .

chi:study_188390_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188390 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188390_QualitativeResult ;
    chi:reportsResult chi:result_188390_StatisticalResult .

chi:study_188390_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188390 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188390_QualitativeResult ;
    chi:reportsResult chi:result_188390_StatisticalResult .

chi:artifact_188390_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188390 .

chi:artifact_188390_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188390 .

chi:result_188390_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188390_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188393 rdf:type chi:Paper ;
    dcterms:title "Promoting Comprehension and Engagement in Introductory Data and Statistics for Blind and Low-Vision Students: A Co-Design Study" ;
    dcterms:abstract "Statistical literacy involves understanding, interpreting, and critically evaluating statistical information in a contextually grounded way. Current instructional practices rely heavily on visual techniques, which renders them inaccessible to students who are blind or have low vision (BLV). To bridge this gap, we formed an extended co-design partnership with a statistics teacher, a teacher for students with visual impairments (TVI), and two BLV students to develop accessibility-first practices for building statistical literacy. Through several months of collaboration that included discussion, exploration, design, and evaluation, we identified specific approaches to promote comprehension and engagement. The enactive approaches we designed, using scaffolding and timely feedback, fostered insights through pattern recognition and analogical reasoning. Additionally, inquiry-based methods promoted contextually situated reasoning and reflection on how statistics can improve students' lives and communities. We present these findings alongside participants’ experiences and discuss their implications for inclusive learning frameworks and tools." ;
    dcterms:identifier "3706598.3713333" ;
    chi:hasAuthor chi:person_183360, chi:person_182683, chi:person_183259, chi:person_182877, chi:person_185581, chi:person_187255, chi:person_182743, chi:person_182819, chi:person_186474, chi:person_188160, chi:person_184026, chi:person_184772, chi:person_184998, chi:person_185802, chi:person_187399 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:AccessibilityNavigationSupport ;
    chi:paperIncludesStudy chi:study_188393_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188393_InterfaceArtifact .

chi:study_188393_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188393 ;
    chi:reportsResult chi:result_188393_QualitativeResult .

chi:artifact_188393_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188393 .

chi:result_188393_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188395 rdf:type chi:Paper ;
    dcterms:title "Chartist: Task-driven Eye Movement Control for Chart Reading" ;
    dcterms:abstract "To design data visualizations that are easy to comprehend, we need to understand how people with different interests read them. Computational models of predicting scanpaths on charts could complement empirical studies by offering estimates of user performance inexpensively; however, previous models have been limited to gaze patterns and overlooked the effects of tasks. Here, we contribute Chartist, a computational model that simulates how users move their eyes to extract information from the chart in order to perform analysis tasks, including value retrieval, filtering, and finding extremes. The novel contribution lies in a two-level hierarchical control architecture. At the high level, the model uses LLMs to comprehend the information gained so far and applies this representation to select a goal for the lower-level controllers, which, in turn, move the eyes in accordance with a sampling policy learned via reinforcement learning. The model is capable of predicting human-like task-driven scanpaths across various tasks. It can be applied in fields such as explainable AI, visualization design evaluation, and optimization.  While it displays limitations in terms of generalizability and accuracy, it takes modeling in a promising direction, toward understanding human behaviors in interacting with charts." ;
    dcterms:identifier "3706598.3713128" ;
    chi:hasAuthor chi:person_183254, chi:person_183756, chi:person_187562, chi:person_184945, chi:person_188125 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:CollaborativeVisualizationTools ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188395_SoftwareArtifact .

chi:artifact_188395_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188395 .

chi:paper_188396 rdf:type chi:Paper ;
    dcterms:title "DysVis: A User-Centred Data Visualization System for Dyslexia Pre-screening" ;
    dcterms:abstract "Dyslexia is a common neurobiological learning disorder significantly impacting reading, writing, and spelling worldwide. Early identification and intervention are essential, but most pre-screening tools focus on Latin languages, leaving Chinese-speaking students underserved. To address this gap, we conduct semi-structured interviews with special education (special-ed) teachers to gather their needs for dyslexia pre-screening tailored to Chinese contexts. Us- ing their insights, we have developed DysVis, a user-centered data visualization system that combines handwriting analysis, body movement keypoint conversion, and a comprehensive visualization interface. DysVis provides teachers with multi-level visualizations, such as performance overviews, task analyses, handwriting observations, and behavioural insights, enabling them to identify the root causes of learning difficulties. Our evaluations, including case studies, a user study, and expert interviews, demonstrate that DysVis is user-friendly and effective in quickly identifying at-risk students, ultimately enhancing learning outcomes for Chinese-speaking students with dyslexia." ;
    dcterms:identifier "3706598.3713194" ;
    chi:hasAuthor chi:person_184861, chi:person_182953, chi:person_184682, chi:person_182937, chi:person_185307, chi:person_185132, chi:person_185379, chi:person_187050 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188396_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188396_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188396_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188396_InterfaceArtifact .

chi:study_188396_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188396 ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:reportsResult chi:result_188396_QualitativeResult .

chi:study_188396_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188396 ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:reportsResult chi:result_188396_QualitativeResult .

chi:artifact_188396_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188396 .

chi:artifact_188396_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188396 .

chi:result_188396_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188398 rdf:type chi:Paper ;
    dcterms:title "“It’s a spectrum”: Exploring Autonomy, Competence, and Relatedness in Software Development Processes and Tools" ;
    dcterms:abstract "The recent surge of research on software developer mental health challenges highlights the importance and urgency of studying solutions to support developer wellbeing. Self-Determination Theory (SDT) offers a valuable framework for exploring wellbeing at work, emphasizing the need to satisfy three psychological needs: autonomy, competence, and relatedness. This paper presents an interview study with 31 software developers in the United States that uses SDT as a guide, exploring how these three needs are perceived and influenced in the work of software developers. We identify specific factors and processes at work and work tools and designs that impact developers’ psychological needs and satisfaction. Results from our study can help design targeted solutions to satisfy developers’ psychological needs, which indirectly support developer wellbeing. This paper highlights the necessity of healthy work cultures in software development and presents design considerations for creating tools for developers." ;
    dcterms:identifier "3706598.3713250" ;
    chi:hasAuthor chi:person_185148, chi:person_185678, chi:person_186261, chi:person_184468, chi:person_184104, chi:person_185844, chi:person_187856, chi:person_183253, chi:person_183572 ;
    chi:hasPrimaryTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:CollaborationAndHybridWork ;
    chi:paperIncludesStudy chi:study_188398_InterviewStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188398_SoftwareArtifact .

chi:study_188398_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188398 ;
    chi:reportsResult chi:result_188398_QualitativeResult .

chi:artifact_188398_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188398 .

chi:result_188398_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188399 rdf:type chi:Paper ;
    dcterms:title "Exploring Data-Driven Advocacy in Home Health Care Work" ;
    dcterms:abstract "This paper explores opportunities and challenges for data-driven advocacy to support home care workers, an often overlooked group of low-wage, frontline health workers. First, we investigate what data to collect and how to collect it in ways that preserve privacy and avoid burdening workers. Second, we examine how workers and advocates could use collected data to strengthen individual and collective advocacy efforts. Our qualitative study with 11 workers and 15 advocates highlights tensions between workers’ desires for individual and immediate benefits and advocates’ preferences to prioritize more collective and long-term benefits. We also uncover discrepancies between participants’ expectations for how data might transform advocacy and their on-the-ground experiences collecting and using real data. Finally, we discuss future directions for data-driven worker advocacy, including combining different kinds of data to ameliorate challenges, leveraging advocates as data stewards, and accounting for workers’ and organizations’ heterogeneous goals." ;
    dcterms:identifier "3706598.3713086" ;
    chi:hasAuthor chi:person_184449, chi:person_184382, chi:person_186995, chi:person_184471, chi:person_185776, chi:person_187101, chi:person_183871, chi:person_186594, chi:person_185647 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188399_InterviewStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking .

chi:study_188399_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188399 ;
    chi:reportsResult chi:result_188399_QualitativeResult .

chi:result_188399_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188400 rdf:type chi:Paper ;
    dcterms:title "PatternTrack: Multi-Device Tracking Using Infrared, Structured-Light Projections from Built-in LiDAR" ;
    dcterms:abstract "As augmented reality devices (e.g., smartphones and headsets) proliferate in the market, multi-user AR scenarios are set to become more common. Co-located users will want to share coherent and synchronized AR experiences, but this is surprisingly cumbersome with current methods. In response, we developed PatternTrack, a novel tracking approach that repurposes the structured infrared light patterns emitted by VCSEL-driven depth sensors, like those found in the Apple Vision Pro, iPhone, iPad, and Meta Quest 3. Our approach is infrastructure-free, requires no pre-registration, works on featureless surfaces, and provides the real-time 3D position and orientation of other users' devices. In our evaluation --- tested on six different surfaces and with inter-device distances of up to 260 cm --- we found a mean 3D positional tracking error of 11.02 cm and a mean angular error of 6.81°. " ;
    dcterms:identifier "3706598.3713388" ;
    chi:hasAuthor chi:person_184377, chi:person_187697, chi:person_184969 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:paperIncludesStudy chi:study_188400_UserStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188400_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188400_SoftwareArtifact .

chi:study_188400_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188400 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188400_StatisticalResult .

chi:artifact_188400_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188400 .

chi:artifact_188400_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188400 .

chi:result_188400_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188401 rdf:type chi:Paper ;
    dcterms:title "eaSEL: Promoting Social-Emotional Learning and Parent-Child Interaction through AI-Mediated Content Consumption" ;
    dcterms:abstract "As children increasingly consume media on devices, parents look for ways this usage can support learning and growth, especially in domains like social-emotional learning. We introduce eaSEL, a system that (a) integrates social-emotional learning (SEL) curricula into children’s video consumption by generating reflection activities and (b) facilitates parent-child discussions around digital media without requiring co-consumption of videos. We present a technical evaluation of our system’s ability to detect social-emotional moments within a transcript and to generate high-quality SEL-based activities for both children and parents. Through a user study with 𝑁 = 20 parent-child dyads, we find that after completing an eaSEL activity, children reflect more on the emotional content of videos. Furthermore, parents find that the tool promotes meaningful active engagement and could scaffold deeper conversations around content. Our work paves directions in how AI can support children’s social-emotional reflection of media and family connections in the digital age." ;
    dcterms:identifier "3706598.3713405" ;
    chi:hasAuthor chi:person_187038, chi:person_189830, chi:person_182706, chi:person_189829 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188401_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188401_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188401_InterfaceArtifact .

chi:study_188401_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188401 ;
    chi:reportsResult chi:result_188401_QualitativeResult .

chi:artifact_188401_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188401 .

chi:artifact_188401_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188401 .

chi:result_188401_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188402 rdf:type chi:Paper ;
    dcterms:title "TravelGalleria: Supporting Remembrance and Reflection of Travel Experiences through Digital Storytelling in Virtual Reality" ;
    dcterms:abstract "Travel is a powerful yet fleeting experience that can shape personal perspectives and support self-reflection. To recapture the essence of travel, we explored the use of VR as a medium for immersive re-experiencing with an emphasis on storytelling. We developed TravelGalleria, a VR authoring tool that allows users to curate personalized digital galleries. TravelGalleria encourages creative expression, enabling users to use audio narration, annotations, spatially arranged photos, and more to recount their travel stories. A probing user study with TravelGalleria (n = 20) showed promising trends toward emotional resonance and introspective learning. Our findings illustrate how our tool supports users in remembering, reliving, and deriving new insights regarding past experiences, as they were able to reconnect with emotions and themes central to their travels. We discuss these findings in the context of meaningful digital experiences and storytelling in reflective digital practices, highlighting design suggestions and open areas for future research. " ;
    dcterms:identifier "3706598.3713398" ;
    chi:hasAuthor chi:person_185723, chi:person_187697 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:EmbodiedVRInteraction ;
    chi:paperIncludesStudy chi:study_188402_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188402_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188402_InterfaceArtifact .

chi:study_188402_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188402 ;
    chi:reportsResult chi:result_188402_QualitativeResult .

chi:artifact_188402_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188402 .

chi:artifact_188402_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188402 .

chi:result_188402_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188403 rdf:type chi:Paper ;
    dcterms:title "Understanding Marine Scientist Software Tool Use" ;
    dcterms:abstract "Marine science researchers are heavy users of software tools and systems such as statistics packages, visualization tools, and online data catalogues. Following a constructivist grounded theory approach, we conduct a semi-structured interview study of 23 marine science researchers and research supports within a North American university, to understand their perceptions of and approaches towards using both graphical and code-based software tools and systems. We propose the concept of fragmentation to represent how various factors lead to isolated pockets of views and practices concerning software tool use during the research process. These factors include informal learning of tools, preferences towards doing things from scratch, and a push towards more code-based tools. Based on our findings, we suggest design priorities for user interfaces that could more effectively help support marine scientists make and use software tools and systems." ;
    dcterms:identifier "3706598.3713621" ;
    chi:hasAuthor chi:person_186031, chi:person_185274, chi:person_187745 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:paperIncludesStudy chi:study_188403_InterviewStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188403_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188403_SoftwareArtifact .

chi:study_188403_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188403 ;
    chi:reportsResult chi:result_188403_QualitativeResult .

chi:artifact_188403_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188403 .

chi:artifact_188403_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188403 .

chi:result_188403_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188404 rdf:type chi:Paper ;
    dcterms:title "Observe, Ask, Intervene: Designing AI Agents for More Inclusive Meetings" ;
    dcterms:abstract "Video conferencing meetings are more effective when they are inclusive, but inclusion often hinges on meeting leaders' and/or co-facilitators' practices. AI systems can be designed to improve meeting inclusion at scale by moderating negative meeting behaviors and supporting meeting leaders. We explored this design space by conducting 9 user-centered ideation sessions, instantiating design insights in a prototype ``virtual co-host'' system, and testing the system in a formative exploratory lab study ($n=68$ across 12 groups, 18 interviews). We found that ideation session participants wanted AI agents to ask questions before intervening, which we formalized as the ``Observe, Ask, Intervene'' (OAI) framework. Participants who used our prototype preferred OAI over fully autonomous intervention, but rationalized away the virtual co-host's critical feedback. From these findings, we derive guidelines for designing AI agents to influence behavior and mediate group work. We also contribute methodological and design guidelines specific to mitigating inequitable meeting participation." ;
    dcterms:identifier "3706598.3713838" ;
    chi:hasAuthor chi:person_182692, chi:person_187015, chi:person_187962, chi:person_187862 ;
    chi:hasPrimaryTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188404_UserStudy ;
    chi:paperIncludesStudy chi:study_188404_InterviewStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188404_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188404_InterfaceArtifact .

chi:study_188404_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188404 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188404_QualitativeResult .

chi:study_188404_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188404 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188404_QualitativeResult .

chi:artifact_188404_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188404 .

chi:artifact_188404_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188404 .

chi:result_188404_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188405 rdf:type chi:Paper ;
    dcterms:title "\"Grab the Chat and Stick It to My Wall\": Understanding How Social VR Streamers Bridge Immersive VR Experiences with Streaming Audiences Outside VR" ;
    dcterms:abstract "Social VR platforms are increasingly transforming online social spaces by enhancing embodied and immersive social interactions within VR. However, how social VR users also share their activities outside the social VR platform, such as on 2D live streaming platforms, is an increasingly popular yet understudied phenomenon that blends social VR and live streaming research. Through 17 interviews with experienced social VR streamers, we unpack social VR streamers' innovative strategies to further blur the boundary between VR and non-VR spaces to engage their audiences and potential limitations of their strategies. We add new insights into how social VR streamers transcend traditional 2D streamer-audience engagement, which also extend our current understandings of cross-reality interactions. Grounded in these insights, we propose design implications to better support more complicated cross-reality dynamics in social VR streaming while mitigating potential tensions, in hopes of achieving more inclusive, engaging, and secure cross-reality environments in the future." ;
    dcterms:identifier "3706598.3713561" ;
    chi:hasAuthor chi:person_187932, chi:person_186829, chi:person_186780 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:paperIncludesStudy chi:study_188405_InterviewStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188405_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188405_InterfaceArtifact .

chi:study_188405_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188405 ;
    chi:reportsResult chi:result_188405_QualitativeResult .

chi:artifact_188405_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188405 .

chi:artifact_188405_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188405 .

chi:result_188405_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188406 rdf:type chi:Paper ;
    dcterms:title "PPG Earring: Wireless Smart Earring for Heart Health Monitoring" ;
    dcterms:abstract "Heart rate is a key vital sign for cardiovascular health and fitness. However, the photoplethysmography (PPG) sensors that monitor heart rate in wearables struggle with accuracy during motion. Our day-long in-the-wild study shows Fitbit measures valid heart rates only 54.88% of the time. To address this, we developed PPG Earring, which measures 14 mm in diameter, weighs 2.0 g, and offers 21 hours of continuous sensing. Our eight-user exercise study shows that PPG Earring captures valid heart rate data for 91.74% of the time during exercise and 86.29% of our day-long in-the-wild study. All participants found the PPG Earring as comfortable as their regular earrings, and most participants expressed a strong willingness to wear the PPG Earring all the time every day. Our results validate the signal quality and comfort level of the PPG Earring, highlighting its potential as a daily health monitoring device." ;
    dcterms:identifier "3706598.3713856" ;
    chi:hasAuthor chi:person_184884, chi:person_187100, chi:person_184258, chi:person_184948, chi:person_188041, chi:person_185790 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:paperIncludesStudy chi:study_188406_FieldStudy ;
    chi:paperIncludesStudy chi:study_188406_UserStudy ;
    chi:paperIncludesStudy chi:study_188406_BaselineComparisonStudy ;
    chi:proposesArtifact chi:artifact_188406_DeviceArtifact .

chi:study_188406_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188406 ;
    chi:hasMeasure chi:HeartRateMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188406_StatisticalResult ;
    chi:reportsResult chi:result_188406_QualitativeResult .

chi:study_188406_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188406 ;
    chi:hasMeasure chi:HeartRateMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188406_StatisticalResult ;
    chi:reportsResult chi:result_188406_QualitativeResult .

chi:study_188406_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188406 ;
    chi:hasMeasure chi:HeartRateMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188406_StatisticalResult ;
    chi:reportsResult chi:result_188406_QualitativeResult .

chi:artifact_188406_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188406 .

chi:result_188406_StatisticalResult rdf:type chi:StatisticalResult .

chi:result_188406_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188407 rdf:type chi:Paper ;
    dcterms:title "EchoSight: Streamlining Bidirectional Virtual-physical Interaction with In-situ Optical Tethering" ;
    dcterms:abstract "Emerging AR applications require seamless integration of the virtual and physical worlds, which calls for tools that support both passive perception and active manipulation of the environment, enabling bidirectional interaction. We introduce EchoSight, a system for AR glasses that enables efficient look-and-control bidirectional interaction. EchoSight exploits optical wireless communication to instantaneously connect virtual data with its physical counterpart. EchoSight's unique dual-element optical design leverages beam directionality to automatically align the user's focus with target objects, reducing the overhead in both target identification and subsequent communication. This approach streamlines user interaction, reducing cognitive load and enhancing engagement. Our evaluations demonstrate EchoSight's effectiveness for room-scale communication, achieving distances up to 5 m and viewing angles up to 120 degrees. A study with 12 participants confirms EchoSight's improved efficiency and user experience over traditional methods, such as QR Code scanning and voice control, in AR IoT applications." ;
    dcterms:identifier "3706598.3713925" ;
    chi:hasAuthor chi:person_186197, chi:person_186898, chi:person_188048, chi:person_182946, chi:person_183599 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:paperIncludesStudy chi:study_188407_BaselineComparisonStudy ;
    chi:paperIncludesStudy chi:study_188407_UserStudy ;
    chi:aimsAtGoal chi:ReduceCognitiveLoad ;
    chi:proposesArtifact chi:artifact_188407_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188407_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188407_SoftwareArtifact .

chi:study_188407_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188407 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:reportsResult chi:result_188407_StatisticalResult .

chi:study_188407_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188407 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:reportsResult chi:result_188407_StatisticalResult .

chi:artifact_188407_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188407 .

chi:artifact_188407_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188407 .

chi:artifact_188407_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188407 .

chi:result_188407_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188408 rdf:type chi:Paper ;
    dcterms:title "Wearable AR in Everyday Contexts: Insights from a Digital Ethnography of YouTube Videos" ;
    dcterms:abstract "With growing investment in consumer augmented reality (AR) headsets and glasses, wearable AR is moving from niche applications to everyday use. However, current research primarily examines AR in controlled settings, offering limited insights into its use in real-world daily life. To address this gap, we adopt a digital ethnographic approach, analysing 27 hours of 112 YouTube videos featuring early adopters. These videos capture usage ranging from continuous periods of hours to intermittent use over weeks and months. Our analysis shows that currently, wearable AR is primarily used for media consumption and gaming. While productivity is a desired use case, frequent use is constrained by current hardware limitations and the nascent application ecosystem. Users seek continuity in their digital experience, desiring functionalities similar to those on smartphones, tablets, or computers. We propose implications for everyday AR development that promote adoption while ensuring safe, ethical, and socially-aware integration into daily life." ;
    dcterms:identifier "3706598.3713572" ;
    chi:hasAuthor chi:person_183831, chi:person_186625, chi:person_186259, chi:person_187560, chi:person_185675 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:ImmersiveTrainingAndSimulation ;
    chi:paperIncludesStudy chi:study_188408_QualitativeStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188408_DeviceArtifact .

chi:study_188408_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188408 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188408_QualitativeResult ;
    chi:involvesParticipationPattern chi:AsynchronousParticipation .

chi:artifact_188408_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188408 .

chi:result_188408_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188409 rdf:type chi:Paper ;
    dcterms:title "ClueCart: Supporting Game Story Interpretation and Narrative Inference from Fragmented Clues" ;
    dcterms:abstract "Indexical storytelling is gaining popularity in video games, where the narrative unfolds through fragmented clues. This approach fosters player-generated content and discussion, as story interpreters piece together the overarching narrative from these scattered elements. However, the fragmented and non-linear nature of the clues makes systematic categorization and interpretation challenging, potentially hindering efficient story reconstruction and creative engagement. To address these challenges, we first proposed a hierarchical taxonomy to categorize narrative clues, informed by a formative study. Using this taxonomy, we designed ClueCart, a creativity support tool aimed at enhancing creators' ability to organize story clues and facilitate intricate story interpretation. We evaluated ClueCart through a between-subjects study (N=40), using Miro as a baseline. The results showed that ClueCart significantly improved creators' efficiency in organizing and retrieving clues, thereby better supporting their creative processes. Additionally, we offer design insights for future studies focused on player-centric narrative analysis." ;
    dcterms:identifier "3706598.3713381" ;
    chi:hasAuthor chi:person_185744, chi:person_185089, chi:person_184980, chi:person_186954, chi:person_186740, chi:person_186448, chi:person_185629 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:CollaborativeVisualizationTools ;
    chi:paperIncludesStudy chi:study_188409_BaselineComparisonStudy ;
    chi:paperIncludesStudy chi:study_188409_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188409_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188409_InterfaceArtifact .

chi:study_188409_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188409 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:reportsResult chi:result_188409_StatisticalResult ;
    chi:reportsResult chi:result_188409_QualitativeResult .

chi:study_188409_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188409 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:reportsResult chi:result_188409_StatisticalResult ;
    chi:reportsResult chi:result_188409_QualitativeResult .

chi:artifact_188409_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188409 .

chi:artifact_188409_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188409 .

chi:result_188409_StatisticalResult rdf:type chi:StatisticalResult .

chi:result_188409_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188412 rdf:type chi:Paper ;
    dcterms:title "AlphaPIG: The Nicest Way to Prolong Interactive Gestures in Extended Reality" ;
    dcterms:abstract "Mid-air gestures serve as a common interaction modality across Extended Reality (XR) applications, enhancing engagement and ownership through intuitive body movements. However, prolonged arm movements induce shoulder fatigue—known as \"Gorilla Arm Syndrome\"—degrading user experience and reducing interaction duration. Although existing ergonomic techniques derived from Fitts' law (such as reducing target distance, increasing target width, and modifying control-display gain) provide some fatigue mitigation, their implementation in XR applications remains challenging due to the complex balance between user engagement and physical exertion. We present \textit{AlphaPIG}, a meta-technique designed to \textbf{P}rolong \textbf{I}nteractive \textbf{G}estures by leveraging real-time fatigue predictions. AlphaPIG assists designers in extending and improving XR interactions by enabling automated fatigue-based interventions. Through adjustment of intervention timing and intensity decay rate, designers can explore and control the trade-off between fatigue reduction and potential effects such as decreased body ownership. We validated AlphaPIG's effectiveness through a study (N=22) implementing the widely-used Go-Go technique. Results demonstrated that AlphaPIG significantly reduces shoulder fatigue compared to non-adaptive Go-Go, while maintaining comparable perceived body ownership and agency. Based on these findings, we discuss positive and negative perceptions of the intervention. By integrating real-time fatigue prediction with adaptive intervention mechanisms, AlphaPIG constitutes a critical first step towards creating fatigue-aware applications in XR." ;
    dcterms:identifier "3706598.3714249" ;
    chi:hasAuthor chi:person_187107, chi:person_183137, chi:person_184206, chi:person_187959, chi:person_183062, chi:person_184067, chi:person_187375 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:EmbodiedVRInteraction ;
    chi:paperIncludesStudy chi:study_188412_UserStudy ;
    chi:paperIncludesStudy chi:study_188412_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188412_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188412_InterfaceArtifact .

chi:study_188412_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188412 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188412_StatisticalResult ;
    chi:reportsResult chi:result_188412_QualitativeResult .

chi:study_188412_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188412 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188412_StatisticalResult ;
    chi:reportsResult chi:result_188412_QualitativeResult .

chi:artifact_188412_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188412 .

chi:artifact_188412_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188412 .

chi:result_188412_StatisticalResult rdf:type chi:StatisticalResult .

chi:result_188412_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188413 rdf:type chi:Paper ;
    dcterms:title "Power-on-Touch: Powering Actuators, Sensors, and Devices during Interaction" ;
    dcterms:abstract "We introduce Power-on-Touch, a novel method for powering devices during interaction. Power-on-Touch comprises two main components: (1) a wearable-transmitter attached to the user’s body (e.g., fingernail, back of the hand, feet) with wireless power-coils and a battery; and (2) receiver-tags embedded in interactive devices, making them battery-free. Many devices only require power during interaction (e.g., TV remotes, digital calipers). We leverage this interactive opportunity by inductively transferring energy from the user’s coil to the device’s coil when in close proximity. To achieve this, we engineered receiver-tags and coils, including thin pancake-coils best-suited for wearables and spherical-coils that receive power omnidirectionally. To understand which coils best support a wide range of interactions (e.g., grasping, touching, hovering), we performed technical characterizations, including impedance and 3D efficiency analysis. We believe our technical approach can inspire ubiquitous computing with new ways to scale up the number and diversity of battery-free devices, not just sensors (µWatts) but also actuators (Watts)." ;
    dcterms:identifier "3706598.3713987" ;
    chi:hasAuthor chi:person_187744, chi:person_186716, chi:person_182945, chi:person_183578 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:proposesArtifact chi:artifact_188413_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188413_InputDeviceArtifact ;
    chi:proposesArtifact chi:artifact_188413_OutputDeviceArtifact .

chi:artifact_188413_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188413 .

chi:artifact_188413_InputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188413 .

chi:artifact_188413_OutputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188413 .

chi:paper_188414 rdf:type chi:Paper ;
    dcterms:title "Enabling Recycling of Multi-Material 3D Printed Objects through Computational Design and Disassembly by Dissolution" ;
    dcterms:abstract "Multi-material 3D printing combines the functional properties of different materials (e.g., mechanical, electrical, color) within a single object that is fabricated without manual assembly. However, this presents sustainability challenges as multi-material objects cannot be easily recycled. Because each material has a different processing temperature, considerable effort must be used to separate them for recycling. This paper presents a computational fabrication technique to generate dissolvable interfaces between different materials in a 3D printed object without affecting the object’s intended use. When the interfaces are dissolved, the object is disassembled to enable recycling of the individual materials. We describe the computational design of these interfaces alongside experimental evaluations of their strength and water solubility. Finally, we demonstrate our technique across 9 multi-material 3D printed objects of varying structural and functional complexity. Our technique enables us to recycle 89.97% of the total mass of these objects, promoting greater sustainability in 3D printing." ;
    dcterms:identifier "3706598.3714080" ;
    chi:hasAuthor chi:person_184836, chi:person_184101, chi:person_185742 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:proposesArtifact chi:artifact_188414_SoftwareArtifact .

chi:artifact_188414_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188414 .

chi:result_188414_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188415 rdf:type chi:Paper ;
    dcterms:title "SmarTeeth: Augmenting Manual Toothbrushing with In-ear Microphones" ;
    dcterms:abstract "Improper toothbrushing practices persist as a primary cause of oral health issues such as tooth decay and gum disease. Despite the availability of high-end electric toothbrushes that offer some guidance, manual toothbrushes remain widely used due to their simplicity and convenience. We present SmarTeeth, an earable-based toothbrushing monitoring system designed to augment manual toothbrushing with functionalities typically offered only by high-end electric toothbrushes, such as brushing surface tracking. The underlying idea of SmarTeeth is to leverage in-ear microphones on earphones to capture toothbrushing sounds transmitted through the oral cavity to ear canals through facial bones and tissues. The distinct propagation paths of brushing sounds from various dental locations to each ear canal provide the foundational basis for our methods to accurately identify different brushing locations. By extracting customized features from these sounds, we can detect brushing locations using a deep-learning model. With only one registration session (~2 mins) for a new user, the average accuracy is 92.7% for detecting six regions and 75.6% for sixteen tooth surfaces. With three registration sessions (~6 mins), the performance can be boosted to 98.8% and 90.3% for six-region and sixteen-surface tracking, respectively. A key advantage of using earphones for monitoring is that they provide natural auditory feedback to alert users when they are overbrushing or underbrushing. Comprehensive evaluation validates the effectiveness of SmarTeeth under various conditions (different users, brushes, orders, noise, etc.), and the feedback from the user study (N=13) indicates that users found the system highly useful (6.0/7.0) and reported a low workload (2.5/7.0) while using it. Our findings suggest that SmarTeeth could offer a scalable and effective solution to improve oral health globally by providing manual toothbrush users with advanced brushing monitoring capabilities." ;
    dcterms:identifier "3706598.3713893" ;
    chi:hasAuthor chi:person_183536, chi:person_182685, chi:person_186217, chi:person_187043, chi:person_185336, chi:person_182699, chi:person_183855 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:ErrorRatesAndTaskCompletion ;
    chi:paperIncludesStudy chi:study_188415_UserStudy ;
    chi:paperIncludesStudy chi:study_188415_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188415_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188415_SoftwareArtifact .

chi:study_188415_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188415 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188415_StatisticalResult ;
    chi:reportsResult chi:result_188415_QualitativeResult .

chi:study_188415_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188415 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188415_StatisticalResult ;
    chi:reportsResult chi:result_188415_QualitativeResult .

chi:artifact_188415_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188415 .

chi:artifact_188415_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188415 .

chi:result_188415_StatisticalResult rdf:type chi:StatisticalResult .

chi:result_188415_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188425 rdf:type chi:Paper ;
    dcterms:title "Generative Ghosts: Anticipating Benefits and Risks of AI Afterlives" ;
    dcterms:abstract "As AI systems quickly improve in both breadth and depth of performance, they lend themselves to creating increasingly powerful and realistic agents, including the possibility of agents modeled on specific people. We anticipate that within our lifetimes it may become common practice for people to create custom AI agents to interact with loved ones and/or the broader world after death; indeed, the past year has seen a boom in startups purporting to offer such services. We call these generative ghosts since such agents will be capable of generating novel content rather than merely parroting content produced by their creator while living. In this paper, we reflect on the history of technologies for AI afterlives, including current early attempts by individual enthusiasts and startup companies to create generative ghosts. We then introduce a novel design space detailing potential implementations of generative ghosts. We use this analytic framework to ground a discussion of the practical and ethical implications of various approaches to designing generative ghosts, including potential positive and negative impacts on individuals and society. Based on these considerations, we lay out a research agenda for the AI and HCI research communities to better understand the risk/benefit landscape of this novel technology to ultimately empower people who wish to create and interact with AI afterlives to do so in a beneficial manner." ;
    dcterms:identifier "3706598.3713758" ;
    chi:hasAuthor chi:person_186479, chi:person_184041 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness:ParticipatoryEthicsMethods ;
    chi:aboutTopic chi:EthicsPrivacyFairness:ParticipatoryEthicsMethods ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188425_SoftwareArtifact .

chi:artifact_188425_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188425 .

chi:result_188425_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188426 rdf:type chi:Paper ;
    dcterms:title "Curves Ahead: Enhancing the Steering Law for Complex Curved Trajectories" ;
    dcterms:abstract "The Steering Law has long been a fundamental model in predicting movement time for tasks involving navigating through constrained paths, such as in selecting sub-menu options, particularly for straight and circular arc trajectories. However, this does not reflect the complexities of real-world tasks where curvatures can vary arbitrarily, limiting its applications. This study aims to address this gap by introducing the total curvature parameter K into the equation to account for the overall curviness characteristic of a path. To validate this extension, we conducted a mouse-steering experiment on fixed-width paths with varying lengths and curviness levels. Our results demonstrate that the introduction of K significantly improves model fitness for movement time prediction over traditional models. These findings advance our understanding of movement in complex environments and support potential applications in fields like speech motor control and virtual navigation." ;
    dcterms:identifier "3706598.3713102" ;
    chi:hasAuthor chi:person_185037, chi:person_184303 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:PointingAndSelectionPerformance ;
    chi:paperIncludesStudy chi:study_188426_UserStudy ;
    chi:proposesArtifact chi:artifact_188426_InputDeviceArtifact .

chi:study_188426_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188426 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:reportsResult chi:result_188426_StatisticalResult .

chi:artifact_188426_InputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188426 .

chi:result_188426_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188427 rdf:type chi:Paper ;
    dcterms:title "PromptHive: Bringing Subject Matter Experts Back to the Forefront with Collaborative Prompt Engineering for Educational Content Creation" ;
    dcterms:abstract "Involving subject matter experts in prompt engineering can guide LLM outputs toward more helpful, accurate, and tailored content that meets the diverse needs of different domains. However, iterating towards effective prompts can be challenging without adequate interface support for systematic experimentation within specific task contexts. In this work, we introduce PromptHive, a collaborative interface for prompt authoring designed to better connect domain knowledge with prompt engineering through features that encourage rapid iteration on prompt variations. We conducted an evaluation study with ten subject matter experts in math and validated our design through two collaborative prompt writing sessions and a learning gain study with 358 learners. Our results elucidate the prompt iteration process and validate the tool's usability, enabling non-AI experts to craft prompts that generate content comparable to human-authored materials while reducing perceived cognitive load by half and shortening the authoring process from several months to just a few hours." ;
    dcterms:identifier "3706598.3714051" ;
    chi:hasAuthor chi:person_186905, chi:person_186367, chi:person_185942, chi:person_186439 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:paperIncludesStudy chi:study_188427_UserStudy ;
    chi:aimsAtGoal chi:ReduceCognitiveLoad ;
    chi:proposesArtifact chi:artifact_188427_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188427_SoftwareArtifact .

chi:study_188427_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188427 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:SubjectiveMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188427_QualitativeResult ;
    chi:reportsResult chi:result_188427_StatisticalResult .

chi:artifact_188427_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188427 .

chi:artifact_188427_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188427 .

chi:result_188427_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188427_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188429 rdf:type chi:Paper ;
    dcterms:title "Exploring the Design of Human Speech Indicators to Enhance Waiting Experience in Voice User Interface" ;
    dcterms:abstract "Waiting for system loading is a common scenario that often diminishes user experience, leading to dissatisfaction. Well-established visual indicators like progress bars can not directly apply to the interactions with voice assistants (VAs) like Siri. As VAs continue to rise in popularity, this research aims to explore the design of auditory indicators, particularly human speech, for optimizing waiting experiences in Voice User Interfaces (VUIs). We first organized focus groups (N=35) to identify design considerations for speech indicators, uncovering design opportunities in integrating explanations and humor. Subsequently, we conducted an empirical study (N=30) to evaluate the effects of speech indicators with two levels of explanation and humor on the waiting experience, measured by attention, perceived time, pleasure, and overall satisfaction, during both short and long loading durations. Our findings suggest significant potential for incorporating explanations and humor into VUIs, offering actionable insights for designing effective speech indicators that improve waiting experiences." ;
    dcterms:identifier "3706598.3713090" ;
    chi:hasAuthor chi:person_185728, chi:person_186293, chi:person_187890, chi:person_185644, chi:person_187109, chi:person_185038 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:paperIncludesStudy chi:study_188429_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188429_InterfaceArtifact .

chi:study_188429_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188429 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188429_QualitativeResult ;
    chi:reportsResult chi:result_188429_StatisticalResult .

chi:artifact_188429_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188429 .

chi:result_188429_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188429_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188430 rdf:type chi:Paper ;
    dcterms:title "Integrating Virtual Reality Head-Mounted Displays into Higher Education Classrooms on a Large Scale" ;
    dcterms:abstract "Virtual reality head-mounted displays (HMDs) offer unique and immersive opportunities for higher education. However, current research focuses on small-scale and infrequent use cases, raising questions about large-scale HMD integration into classrooms. We explored logistical and pedagogical challenges and opportunities when using 30 VR HMDs in a design class of 55 undergraduate students throughout a 12-week term. Each student shared an HMD with a partner, using it weekly in class and at home. We administered questionnaires and conducted observations and interviews. Our results reveal highly positive student engagement, but instructors and students must adapt to unique HMD characteristics and challenges, including in-VR lecturing practices, developing safety measures, and mitigating cybersickness. Although instructor-led VR tutorials were helpful, most learning occurred in individual, paired, and group activities, where screencasting and HMD sharing fostered collaborative learning. Free time during classes provided an opportunity for targeted instructor support while allowing students to explore emerging practices." ;
    dcterms:identifier "3706598.3713690" ;
    chi:hasAuthor chi:person_183443, chi:person_183271, chi:person_182831, chi:person_183754 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188430_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188430_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188430_DeviceArtifact .

chi:study_188430_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188430 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188430_QualitativeResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation ;
    chi:involvesParticipationPattern chi:AsynchronousParticipation .

chi:study_188430_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188430 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188430_QualitativeResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation ;
    chi:involvesParticipationPattern chi:AsynchronousParticipation .

chi:artifact_188430_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188430 .

chi:result_188430_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188431 rdf:type chi:Paper ;
    dcterms:title "Beyond Explicit and Implicit: How Users Provide Feedback to Shape Personalized Recommendation Content" ;
    dcterms:abstract "As personalized recommendation algorithms become integral to social media platforms, users are increasingly aware of their ability to influence recommendation content. However, limited research has explored how users provide feedback through their behaviors and platform mechanisms to shape the recommendation content. We conducted semi-structured interviews with 34 active users of algorithmic-driven social media platforms (e.g., Xiaohongshu, Douyin). In addition to explicit and implicit feedback, this study introduced intentional implicit feedback, highlighting the actions users intentionally took to refine recommendation content through perceived feedback mechanisms. Additionally, choices of feedback behaviors were found to align with specific purposes. Explicit feedback was primarily used for feed customization, while unintentional implicit feedback was more linked to content consumption. Intentional implicit feedback was employed for multiple purposes, particularly in increasing content diversity and improving recommendation relevance. This work underscores the user intention dimension in the explicit-implicit feedback dichotomy and offers insights for designing personalized recommendation feedback that better responds to users' needs." ;
    dcterms:identifier "3706598.3713241" ;
    chi:hasAuthor chi:person_185840, chi:person_182776, chi:person_187313, chi:person_184025, chi:person_186882 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialPersonalizationAndFeeds ;
    chi:paperIncludesStudy chi:study_188431_InterviewStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking .

chi:study_188431_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188431 ;
    chi:reportsResult chi:result_188431_QualitativeResult .

chi:result_188431_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188432 rdf:type chi:Paper ;
    dcterms:title "Beyond Vacuuming: How Can We Exploit Domestic Robots’ Idle Time?" ;
    dcterms:abstract "We are increasingly adopting domestic robots (e.g., Roomba) that provide relief from mundane household tasks. However, these robots usually only spend little time executing their specific task and remain idle for long periods. They typically possess advanced mobility and sensing capabilities, and therefore have significant potential applications beyond their designed use. Our work explores this untapped potential of domestic robots in ubiquitous computing, focusing on how they can improve and support modern lifestyles. We conducted two studies: an online survey (n=50) to understand current usage patterns of these robots within homes and an exploratory study (n=12) with HCI and HRI experts. Our thematic analysis revealed 12 key dimensions for developing interactions with domestic robots and outlined over 100 use cases, illustrating how these robots can offer proactive assistance and provide privacy. Finally, we implemented a proof-of-concept prototype to demonstrate the feasibility of reappropriating domestic robots for diverse ubiquitous computing applications." ;
    dcterms:identifier "3706598.3714266" ;
    chi:hasAuthor chi:person_183394, chi:person_187131, chi:person_187351, chi:person_187126, chi:person_185577 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:paperIncludesStudy chi:study_188432_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188432_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188432_SoftwareArtifact .

chi:study_188432_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188432 ;
    chi:reportsResult chi:result_188432_QualitativeResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:artifact_188432_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188432 .

chi:artifact_188432_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188432 .

chi:result_188432_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188433 rdf:type chi:Paper ;
    dcterms:title "Understanding End-User Perception of Transfer Risks in Smart Contracts" ;
    dcterms:abstract "Blockchain smart contracts are increasingly used in critical use cases (e.g., financial transactions). Thus, it is pertinent to ensure that their end-users understand risks in attempting token transfers. Addressing this, we investigate end-user comprehension of five transfer risks (e.g. the end-user being blacklisted) in the most popular Ethereum contract, USD Tether (USDT), and their prevalence in other top ERC-20 contracts. First, we conducted a user study investigating end-user comprehension of transfer risks in USDT with 110 participants. Second, we performed source code analysis of the next top (78) ERC-20 smart contracts to identify the prevalence of these risks. Study results show that the majority of end-users do not comprehend some real risks, and confuse real and fictitious risks. This holds regardless of participants’ self-rated programming and Web3 proficiency. Source code analysis demonstrates that examined risks are prevalent in up to 19.2% of the top ERC-20 contracts." ;
    dcterms:identifier "3706598.3713887" ;
    chi:hasAuthor chi:person_188046, chi:person_183080, chi:person_188197, chi:person_183068 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:DataDisclosureAndConsent ;
    chi:paperIncludesStudy chi:study_188433_UserStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188433_SoftwareArtifact .

chi:study_188433_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188433 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188433_StatisticalResult .

chi:artifact_188433_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188433 .

chi:result_188433_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188434 rdf:type chi:Paper ;
    dcterms:title "Live-Streaming-Based Dual-Teacher Classes for Equitable Education: Insights and Challenges From Local Teachers' Perspective in Disadvantaged Areas" ;
    dcterms:abstract "Educational inequalities in disadvantaged areas have long been a global concern. While Information and Communication Technologies (ICTs) have shown great potential in addressing this issue, the unique challenges in disadvantaged areas often hinder the practical effectiveness of such technologies. This paper examines live-streaming-based dual-teacher classes (LSDC) through a qualitative study in disadvantaged regions of China. Our findings indicate that, although LSDC offers students in these regions access to high-quality educational resources, its practical implementation is fraught with challenges. Specifically, we foreground the pivotal role of local teachers in mitigating these challenges. Through a series of situated efforts, local teachers contextualize high-quality lectures to the local classroom environment, ensuring the expected educational outcomes. Based on our findings, we argue that greater recognition and support for the situational practices of local teachers is essential for fostering a more equitable, sustainable, and scalable technology-driven educational model in disadvantaged areas." ;
    dcterms:identifier "3706598.3714232" ;
    chi:hasAuthor chi:person_185192, chi:person_183391, chi:person_186632, chi:person_183431, chi:person_183270, chi:person_185263, chi:person_188159, chi:person_186046 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188434_QualitativeStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188434_SoftwareArtifact .

chi:study_188434_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188434 ;
    chi:reportsResult chi:result_188434_QualitativeResult .

chi:artifact_188434_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188434 .

chi:result_188434_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188435 rdf:type chi:Paper ;
    dcterms:title "Understanding Break-ability through Screen-based Affordances" ;
    dcterms:abstract "Can J.J. Gibson’s concept of affordances be empirically examined using screen-based technology? We show how screen-based affordances can be examined through the use case of perceptual toughness, i.e. the break-ability of a virtual object. We present two user experiments (n=72, n=66) examining break-ability through a novel ’Perceptual Impact Testing’ methodology and online screen-based 3D virtual environment. We show that judgements of break-ability are systematically distorted when a perceiver’s virtual ‘Point of Observation’ or virtual environment’s ‘Horizonal Geometry’ are manipulated. These statistically significant results provide evidence that: 1) direct perception can account for perceptual distortions of break-ability; 2) Gibsonian affordances can be empirically examined through screen-based interactions. " ;
    dcterms:identifier "3706598.3713595" ;
    chi:hasAuthor chi:person_186925, chi:person_183866, chi:person_186754 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:PointingAndSelectionPerformance ;
    chi:paperIncludesStudy chi:study_188435_UserStudy ;
    chi:proposesArtifact chi:artifact_188435_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188435_SoftwareArtifact .

chi:study_188435_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188435 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188435_StatisticalResult .

chi:artifact_188435_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188435 .

chi:artifact_188435_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188435 .

chi:result_188435_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188436 rdf:type chi:Paper ;
    dcterms:title "Who is Trusted for a Second Opinion? Comparing Collective Advice from a Medical AI and Physicians in Biopsy Decisions After Mammography Screening" ;
    dcterms:abstract "Artificial Intelligence (AI) is increasingly integrated into clinical practice, but its influence on patient decision-making, particularly when AI and physicians disagree, remains unclear. To examine collective advice, we investigated a breast cancer screening scenario using (1) a qualitative interview study (N=9) and (2) a quantitative experiment (N=339) where participants received either consistent or conflicting biopsy recommendations. Qualitative findings include the need for empathetic care, the importance of patient autonomy, and a desire for a four-eyes principle. Quantitative findings accordingly show that patients generally trust physicians more than AI but still tend to follow AI recommendations due to risk aversion. When both advised a biopsy, 99% adhered; if both advised against it, 25% still proceeded. In conflicting scenarios, 97% followed the physician’s advice, whereas 66% followed the AI if it recommended the biopsy.  These results underscore the need for careful interaction design of collective healthcare advice to prevent unnecessary healthcare procedures." ;
    dcterms:identifier "3706598.3713898" ;
    chi:hasAuthor chi:person_183175, chi:person_186564, chi:person_187957, chi:person_184637 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness:TargetedEthicsInterventions ;
    chi:aboutTopic chi:EthicsPrivacyFairness:TargetedEthicsInterventions ;
    chi:paperIncludesStudy chi:study_188436_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188436_QuantitativeStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking .

chi:study_188436_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188436 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188436_QualitativeResult ;
    chi:reportsResult chi:result_188436_StatisticalResult .

chi:study_188436_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188436 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188436_QualitativeResult ;
    chi:reportsResult chi:result_188436_StatisticalResult .

chi:result_188436_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188436_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188437 rdf:type chi:Paper ;
    dcterms:title "Vision-Based Multimodal Interfaces: A Survey and Taxonomy for Enhanced Context-Aware System Design" ;
    dcterms:abstract "The recent surge in artificial intelligence, particularly in multimodal processing technology, has advanced human-computer interaction, by altering how intelligent systems perceive, understand, and respond to contextual information (i.e., context awareness). Despite such advancements, there is a significant gap in comprehensive reviews examining these advances, especially from a multimodal data perspective, which is crucial for refining system design. This paper addresses a key aspect of this gap by conducting a systematic survey of data modality-driven Vision-based Multimodal Interfaces (VMIs). VMIs are essential for integrating multimodal data, enabling more precise interpretation of user intentions and complex interactions across physical and digital environments. Unlike previous task- or scenario-driven surveys, this study highlights the critical role of the visual modality in processing contextual information and facilitating multimodal interaction. Adopting a design framework moving from the whole to the details and back, it classifies VMIs across dimensions, providing insights for developing effective, context-aware systems." ;
    dcterms:identifier "3706598.3714161" ;
    chi:hasAuthor chi:person_185530, chi:person_186247, chi:person_183052, chi:person_187248, chi:person_186482, chi:person_187144, chi:person_184160, chi:person_187215, chi:person_185852 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188437_InterfaceArtifact .

chi:artifact_188437_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188437 .

chi:result_188437_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188438 rdf:type chi:Paper ;
    dcterms:title "Beyond the Circadian Rhythm: Variable Cycles of Regularity Found in Long-Term Sleep Tracking" ;
    dcterms:abstract "Sleep is more than resting eight hours a day---it contextualizes and shapes the routines during the day. Using a large-scale naturalistic dataset of 180,083 people from a popular sleep app, made possible by the widespread adoption of passive tracking, we find that people’s lives have distinct natural rhythms that can be automatically inferred from sleep routines. We discover heterogeneous behaviors: the rhythm of sleep is different for each person, as there is a different cadence for each person to achieve consistency. Some are most consistent week-to-week, while others weeks-to-weeks. We investigate changes in overall daily routines and find the interval for each person at which they show the most consistency. Through a series of comparative case analyses, we investigate the implications of designing for the weekly `norm'. Our tripartite analyses triangulate to one conclusion: we should design for people’s natural routines to account for variable cycles of regularity.  " ;
    dcterms:identifier "3706598.3713868" ;
    chi:hasAuthor chi:person_184222, chi:person_185834, chi:person_183262, chi:person_184199, chi:person_182928, chi:person_186747, chi:person_187834 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:EverydayFatigueAndWorkloadTracking ;
    chi:paperIncludesStudy chi:study_188438_QuantitativeStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188438_SoftwareArtifact .

chi:study_188438_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188438 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188438_StatisticalResult ;
    chi:reportsResult chi:result_188438_QualitativeResult .

chi:artifact_188438_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188438 .

chi:result_188438_StatisticalResult rdf:type chi:StatisticalResult .

chi:result_188438_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188439 rdf:type chi:Paper ;
    dcterms:title "Accompany Sleep: Using GenAI to Create Bedtime Stories for Mediating Parent-Child Relationships in LBC Families" ;
    dcterms:abstract "Left-Behind Children (LBC) refers to children who lack daily companionship due to their parents working away from home, accounting for approximately one-fifth of all children in China. Due to the lack of communication and emotional support from their parents, LBCs often experience physical and mental health issues. Effective communication is usually limited by time and topics, and the format of mobile devices and video calls is not always suitable. To address this issue, we developed the Accompany Sleep system. Parents upload daily life content through the app, and the system uses ChatGPT4o to create bedtime stories projected to the LBC. To explore the role of Accompany Sleep in family mediation, we conducted a one-month user study involving four families. The results of the study indicated that both parents and children exhibited positive behaviors, the parent-child relationship was effectively strengthened, and GenAI played a crucial role in this process. Based on these findings, this paper discusses how Accompany Sleep facilitated behavioral changes and improved parent-child relationships while expanding the application of GenAI in the family domain." ;
    dcterms:identifier "3706598.3713192" ;
    chi:hasAuthor chi:person_186639, chi:person_183377, chi:person_186277, chi:person_186732 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialSupportAndPeerChatbots ;
    chi:paperIncludesStudy chi:study_188439_UserStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188439_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188439_InterfaceArtifact .

chi:study_188439_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188439 ;
    chi:reportsResult chi:result_188439_QualitativeResult .

chi:artifact_188439_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188439 .

chi:artifact_188439_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188439 .

chi:result_188439_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188441 rdf:type chi:Paper ;
    dcterms:title "Human Creativity in the Age of LLMs: Randomized Experiments on Divergent and Convergent Thinking" ;
    dcterms:abstract "Large language models are transforming the creative process by offering unprecedented capabilities to algorithmically generate ideas. While these tools can enhance human creativity when people co-create with them, it's unclear how this will impact unassisted human creativity. We conducted two large pre-registered parallel experiments involving 1,100 participants attempting tasks targeting the two core components of creativity, divergent and convergent thinking. We compare the effects of two forms of large language model (LLM) assistance---a standard LLM providing direct answers and a coach-like LLM offering guidance---with a control group receiving no AI assistance, and focus particularly on how all groups perform in a final, unassisted stage. Our findings reveal that while LLM assistance can provide short-term boosts in creativity during assisted tasks, it may inadvertently hinder independent creative performance when users work without assistance, raising concerns about the long-term impact on human creativity and cognition." ;
    dcterms:identifier "3706598.3714198" ;
    chi:hasAuthor chi:person_184529, chi:person_188178, chi:person_186401, chi:person_188188 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:SelfReflectionAndBehaviorChange ;
    chi:paperIncludesStudy chi:study_188441_BaselineComparisonStudy ;
    chi:paperIncludesStudy chi:study_188441_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188441_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188441_InterfaceArtifact .

chi:study_188441_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188441 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188441_StatisticalResult .

chi:study_188441_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188441 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188441_StatisticalResult .

chi:artifact_188441_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188441 .

chi:artifact_188441_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188441 .

chi:result_188441_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188442 rdf:type chi:Paper ;
    dcterms:title "\"It Actually Doesn’t Feel Very Mutual:\" How Technology Impacts the Values of Mutual Aid Groups in Practice" ;
    dcterms:abstract "Social movement organizations, such as mutual aid groups, rely on technology to increase their influence, meet immediate needs, and address systemic inequalities. In this paper, we examine the role of technology in moments of crisis and the tensions mutual aid groups face when relying on tools designed with values that may be antithetical to their own. Through a qualitative study with mutual aid volunteers in the United States, we found that mutual aid groups’ values, such as solidarity, security, and co-production, are prioritized as they navigate adopting technology. However, while technology can streamline logistics and enhance visibility for mutual aid groups, we argue that the adoption of existing technologies and conventions of practice can erode opportunities for building solidarity, present challenges for accountability, and exacerbate pre-existing social exclusions. We argue that these tensions emerge not simply as a mismatch between values and technical design, but as systematic outcomes of adopting tools that embed different political assumptions and points of access. Our findings contribute to understanding how values shape --- and are shaped by --- technological infrastructure in mutual aid work." ;
    dcterms:identifier "3706598.3714192" ;
    chi:hasAuthor chi:person_187295, chi:person_185331, chi:person_183902 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:paperIncludesStudy chi:study_188442_QualitativeStudy .

chi:study_188442_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188442 ;
    chi:reportsResult chi:result_188442_QualitativeResult .

chi:result_188442_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188443 rdf:type chi:Paper ;
    dcterms:title "BallistoBud: Heart Rate Variability Monitoring using Earbud Accelerometry for Stress Assessment" ;
    dcterms:abstract "This paper examines the potential of commercial earbuds for detecting physiological biomarkers like heart rate (HR) and heart rate variability (HRV) for stress assessment. Using accelerometer (IMU) and photoplethysmography (PPG) data from earbuds, we compared these estimates with reference electrocardiogram (ECG) data from 81 healthy participants. We explored using low-power accelerometer sensors for capturing ballistocardiography (BCG) signals. However, BCG signal quality can vary due to individual differences and body motion. Therefore, BCG data quality assessment is critical before extracting any meaningful biomarkers. To address this, we introduced the ECG-gated BCG heatmap, a new method for assessing BCG signal quality. We trained a Random Forest model to identify usable signals, achieving 82% test accuracy. Filtering out unusable signals improved HR/HRV estimation accuracy to levels comparable to PPG-based estimates. Our findings demonstrate the feasibility of accurate physiological monitoring with earbuds, advancing the development of user-friendly wearable health technologies for stress management." ;
    dcterms:identifier "3706598.3714029" ;
    chi:hasAuthor chi:person_185878, chi:person_186020, chi:person_182790, chi:person_184099, chi:person_187720, chi:person_185276, chi:person_185484, chi:person_185283 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:paperIncludesStudy chi:study_188443_BaselineComparisonStudy ;
    chi:proposesArtifact chi:artifact_188443_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188443_InputDeviceArtifact .

chi:study_188443_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188443 ;
    chi:hasMeasure chi:PhysiologicalMeasure ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:hasMeasure chi:HeartRateMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188443_StatisticalResult .

chi:artifact_188443_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188443 .

chi:artifact_188443_InputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188443 .

chi:result_188443_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188444 rdf:type chi:Paper ;
    dcterms:title "Satori 悟り: Towards Proactive AR Assistant with Belief-Desire-Intention User Modeling" ;
    dcterms:abstract "Augmented Reality (AR) assistance is increasingly used for supporting users with physical tasks like assembly and cooking. However, most systems rely on reactive responses triggered by user input, overlooking rich contextual and user-specific information. To address this, we present Satori, a novel AR system that proactively guides users by modeling both -- their mental states and environmental contexts. Satori integrates the Belief-Desire-Intention (BDI) framework with the state-of-the-art multi-modal large language model (LLM) to deliver contextually appropriate guidance. Our system is designed based on two formative studies involving twelve experts. We evaluated the system with a sixteen within-subject study and found that Satori matches the performance of designer-created Wizard-of-Oz (WoZ) systems, without manual configurations or heuristics, thereby improving generalizability, reusability, and expanding the potential of AR assistance.  Code is available at https://github.com/VIDA-NYU/satori-assistance." ;
    dcterms:identifier "3706598.3714188" ;
    chi:hasAuthor chi:person_187574, chi:person_185362, chi:person_187618, chi:person_184351, chi:person_187482, chi:person_184431, chi:person_183627, chi:person_188060, chi:person_183827 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:EmbodiedVRInteraction ;
    chi:paperIncludesStudy chi:study_188444_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188444_UserStudy ;
    chi:paperIncludesStudy chi:study_188444_WizardOfOzStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188444_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188444_InterfaceArtifact .

chi:study_188444_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188444 ;
    chi:reportsResult chi:result_188444_StatisticalResult .

chi:study_188444_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188444 ;
    chi:reportsResult chi:result_188444_StatisticalResult .

chi:study_188444_WizardOfOzStudy rdf:type chi:WizardOfOzStudy ;
    chi:isStudyReportedIn chi:paper_188444 ;
    chi:reportsResult chi:result_188444_StatisticalResult .

chi:artifact_188444_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188444 .

chi:artifact_188444_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188444 .

chi:result_188444_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188445 rdf:type chi:Paper ;
    dcterms:title "Open-ended Play For People With Dementia" ;
    dcterms:abstract "The progression of dementia leads to a loss of initiative and agency, halting daily activities, hobbies, or social encounters. Open-ended play can encourage initiative but remains underexplored in demen- tia. This paper explores how technology-driven design can support open-ended play, making social interactions more enjoyable and re- newing interest in daily activities. We conducted five workshops at dementia daycare facilities, observing people with dementia engage with playful circuit-building toolkits to identify strategies. Find- ings reveal these toolkits stimulated self-direction and initiative to accomplish self-imposed goals, both independently and collabora- tively. We show how open-ended play fosters confidence, resilience, social engagement, and self-expression, allowing people with de- mentia to exercise choice and share moments of achievement. We provide design implications for technology to stimulate initiative through open-ended play by 1) balancing structure and freedom, 2) emphasizing novelty and material diversity for non-verbal social connection, and 3) considering age-appropriate aesthetics." ;
    dcterms:identifier "3706598.3713930" ;
    chi:hasAuthor chi:person_185241, chi:person_185087, chi:person_186315, chi:person_184413, chi:person_183651 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188445_FieldStudy ;
    chi:paperIncludesStudy chi:study_188445_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188445_DeviceArtifact .

chi:study_188445_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188445 ;
    chi:reportsResult chi:result_188445_QualitativeResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:study_188445_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188445 ;
    chi:reportsResult chi:result_188445_QualitativeResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:artifact_188445_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188445 .

chi:result_188445_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188446 rdf:type chi:Paper ;
    dcterms:title "Surfacing Technology Routines While Studying Videoconferencing Among Older Adults with Cognitive Concerns" ;
    dcterms:abstract "HCI research increasingly focuses on everyday life to inform technology design for older adults. Routines, a key aspect of everyday life, have been studied to contextualize technology use. Our work brings attention to understanding of routines around videoconferencing technology among older adults with cognitive concerns. We conducted a week-long study involving observations, interviews, and a modified diary study with six older adults with cognitive concerns who videoconference at least once a week. Our analysis revealed how routines helped people adapt to videoconferencing constraints, how participants navigated disruptions to their videoconferencing routines, and the kinds of routines that were more challenging to manage when faced disruptions. In the discussion, we describe why routines are particularly important to study and support for people with cognitive concerns, the importance of studying older adults’ routines to support technology use in HCI, and methods that can enrich HCI research by uncovering insights into routines." ;
    dcterms:identifier "3706598.3714207" ;
    chi:hasAuthor chi:person_183550, chi:person_184704 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188446_DiaryStudy ;
    chi:paperIncludesStudy chi:study_188446_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188446_FieldStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility .

chi:study_188446_DiaryStudy rdf:type chi:DiaryStudy ;
    chi:isStudyReportedIn chi:paper_188446 ;
    chi:reportsResult chi:result_188446_QualitativeResult .

chi:study_188446_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188446 ;
    chi:reportsResult chi:result_188446_QualitativeResult .

chi:study_188446_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188446 ;
    chi:reportsResult chi:result_188446_QualitativeResult .

chi:result_188446_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188449 rdf:type chi:Paper ;
    dcterms:title "Generative AI in Knowledge Work: Design Implications for Data Navigation and Decision-Making" ;
    dcterms:abstract "Our study of 20 knowledge workers revealed a common challenge: the difficulty of synthesizing unstructured information scattered across multiple platforms to make informed decisions. Drawing on their vision of an ideal knowledge synthesis tool, we developed Yodeai, an AI-enabled system, to explore both the opportunities and limitations of AI in knowledge work. Through a user study with 16 product managers, we identified three key requirements for Generative AI in knowledge work: adaptable user control, transparent collaboration mechanisms, and the ability to integrate background knowledge with external information. However, we also found significant limitations, including overreliance on AI, user isolation, and contextual factors outside the AI's reach. As AI tools become increasingly prevalent in professional settings, we propose design principles that emphasize adaptability to diverse workflows, accountability in personal and collaborative contexts, and context-aware interoperability to guide the development of human-centered AI systems for product managers and knowledge workers." ;
    dcterms:identifier "3706598.3713337" ;
    chi:hasAuthor chi:person_182704, chi:person_187695, chi:person_183406, chi:person_187820, chi:person_183902 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188449_UserStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188449_SoftwareArtifact .

chi:study_188449_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188449 ;
    chi:reportsResult chi:result_188449_QualitativeResult .

chi:artifact_188449_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188449 .

chi:result_188449_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188450 rdf:type chi:Paper ;
    dcterms:title "EchoBreath: Continuous Respiratory Behavior Recognition in the  Wild via Acoustic Sensing on Smart Glasses" ;
    dcterms:abstract "Monitoring the occurrence count of abnormal respiratory symptoms helps provide critical support for respiratory health. While this is necessary, there is still a lack of an unobtrusive and reliable way that can be effectively used in real-world settings. In this paper, we present EchoBreath, a passive and active acoustic combined sensing system for abnormal respiratory symptoms monitoring. EchoBreath novelly uses the speaker and microphone under the frame of the glasses to emit ultrasonic waves and capture both passive sounds and echo profiles, which can effectively distinguish between subject-aware behaviors and background noise. Furthermore, A lightweight neural network with the 'Null' class and open-set filtering mechanisms substantially improves real-world applicability by eliminating unrelated activity. Our experiments, involving 25 participants, demonstrate that EchoBreath can recognize 6 typical respiratory symptoms in a laboratory setting with an accuracy of 93.1%. Additionally, an in-the-semi-wild study with 10 participants further validates that EchoBreath can continuously monitor respiratory abnormalities under real-world conditions. We believe that EchoBreath can serve as an unobtrusive and reliable way to monitor abnormal respiratory symptoms. " ;
    dcterms:identifier "3706598.3714171" ;
    chi:hasAuthor chi:person_185513, chi:person_183803, chi:person_185475 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:ErrorRatesAndTaskCompletion ;
    chi:paperIncludesStudy chi:study_188450_UserStudy ;
    chi:paperIncludesStudy chi:study_188450_FieldStudy ;
    chi:proposesArtifact chi:artifact_188450_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188450_SoftwareArtifact .

chi:study_188450_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188450 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188450_StatisticalResult .

chi:study_188450_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188450 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188450_StatisticalResult .

chi:artifact_188450_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188450 .

chi:artifact_188450_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188450 .

chi:result_188450_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188451 rdf:type chi:Paper ;
    dcterms:title "Archaeological Gameworld Affordances: A Grounded Theory of How Players Interpret Environmental Storytelling" ;
    dcterms:abstract "Environmental storytelling is a design technique commonly used to convey narrative through assemblages of content in video games. To date there has been limited empirical work investigating how and on what basis players form interpretations about game environments. We report on a study in which participants (N=202) played a game about exploring a procedurally generated ruined village and were then surveyed on their interpretations. We draw on methods and theory from archaeology - a field that specialises in the interpretation of material remains - to support a grounded theory analysis of the survey responses, from which we form the theory of an archaeological gameworld mental model. Our study draws a novel link between affordance theory, archaeological knowledge production and game systems, and contributes new theoretical concepts that can be applied to procedurally generated and handcrafted methods in game design, narrative design and game preservation." ;
    dcterms:identifier "3706598.3714036" ;
    chi:hasAuthor chi:person_184528, chi:person_182954 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:paperIncludesStudy chi:study_188451_UserStudy ;
    chi:proposesArtifact chi:artifact_188451_SoftwareArtifact .

chi:study_188451_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188451 ;
    chi:reportsResult chi:result_188451_QualitativeResult .

chi:artifact_188451_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188451 .

chi:result_188451_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188452 rdf:type chi:Paper ;
    dcterms:title "CreAItive Collaboration? Users' Misjudgment of AI-Creativity Affects Their Collaborative Performance" ;
    dcterms:abstract "How does generative AI affect collaborative creative work and humans' capability to carry it out?  We tested 52 participant pairs in a standard creativity test, the Alternate Uses Test. The experimental AI group had access to ChatGPT-4, while the control group did not. The intervention did not lead to an improved performance overall. Further, the AI group elaborated their ideas significantly less.  This effect carried over to the unaided post-test, pointing to longer-term effects of AI be(com)ing everyday technology, as how people perform a task with a tool shapes how they (learn to) perform the task without it.  Analysis of the human-AI collaboration process revealed that participants were selective in using ChatGPT-4 output for the experimental task, misjudging and falsely assessing its output. This actually reduced their number of created ideas and underscores that users need to understand a (generative AI-based) tool's capability for the specific task to support effective performance. " ;
    dcterms:identifier "3706598.3713886" ;
    chi:hasAuthor chi:person_184952, chi:person_186004, chi:person_185992, chi:person_183067 ;
    chi:hasPrimaryTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:MobileHybridCollaboration ;
    chi:paperIncludesStudy chi:study_188452_BaselineComparisonStudy ;
    chi:paperIncludesStudy chi:study_188452_UserStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188452_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188452_InterfaceArtifact .

chi:study_188452_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188452 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188452_StatisticalResult ;
    chi:reportsResult chi:result_188452_QualitativeResult .

chi:study_188452_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188452 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188452_StatisticalResult ;
    chi:reportsResult chi:result_188452_QualitativeResult .

chi:artifact_188452_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188452 .

chi:artifact_188452_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188452 .

chi:result_188452_StatisticalResult rdf:type chi:StatisticalResult .

chi:result_188452_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188453 rdf:type chi:Paper ;
    dcterms:title "Spatial Haptics: A Sensory Substitution Method for Distal Object Detection Using Tactile Cues" ;
    dcterms:abstract "We present a sensory substitution-based method for representing locations of remote objects in 3D space via haptics. By imitating auditory localization processes, we enable vibrotactile localization abilities similar to those of some spiders, elephants, and other species. We evaluated this concept in virtual reality by modulating the vibration amplitude of two controllers depending on relative locations to a target. We developed two implementations applying this method using either ear or hand locations. A proof-of-concept study assessed localization performance and user experience, achieving under 30° differentiation between horizontal targets with no prior training. This unique approach enables localization by using only two actuators, requires low computational power, and could potentially assist users in gaining spatial awareness in challenging environments. We compare the implementations and discuss the use of hands as ears in motion, a novel technique not previously explored in the sensory substitution literature." ;
    dcterms:identifier "3706598.3714083" ;
    chi:hasAuthor chi:person_187633, chi:person_187206, chi:person_187197, chi:person_185708, chi:person_182994, chi:person_187702 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:paperIncludesStudy chi:study_188453_UserStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188453_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188453_InputDeviceArtifact ;
    chi:proposesArtifact chi:artifact_188453_OutputDeviceArtifact ;
    chi:proposesArtifact chi:artifact_188453_InterfaceArtifact .

chi:study_188453_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188453 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188453_StatisticalResult .

chi:artifact_188453_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188453 .

chi:artifact_188453_InputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188453 .

chi:artifact_188453_OutputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188453 .

chi:artifact_188453_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188453 .

chi:result_188453_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188454 rdf:type chi:Paper ;
    dcterms:title "The Design Space for Online Restorative Justice Tools: A Case Study with ApoloBot" ;
    dcterms:abstract "Volunteer moderators use various strategies to address online harms within their communities. Although punitive measures like content removal or account bans are common, recent research has explored the potential for restorative justice as an alternative framework to address the distinct needs of victims, offenders, and community members. In this study, we take steps toward identifying a more concrete design space for restorative justice-oriented tools by developing ApoloBot, a Discord bot designed to facilitate apologies when harm occurs in online communities. We present results from two rounds of interviews: first, with moderators giving feedback about the design of ApoloBot, and second, after a subset of these moderators have deployed ApoloBot in their communities. This study builds on prior work to yield more detailed insights regarding the potential of adopting online restorative justice tools, including opportunities, challenges, and implications for future designs." ;
    dcterms:identifier "3706598.3713598" ;
    chi:hasAuthor chi:person_183567, chi:person_185260 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:paperIncludesStudy chi:study_188454_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188454_FieldStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188454_SoftwareArtifact .

chi:study_188454_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188454 ;
    chi:reportsResult chi:result_188454_QualitativeResult .

chi:study_188454_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188454 ;
    chi:reportsResult chi:result_188454_QualitativeResult .

chi:artifact_188454_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188454 .

chi:result_188454_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188455 rdf:type chi:Paper ;
    dcterms:title "Explanatory Debiasing: Involving Domain Experts in the Data Generation Process to Mitigate Representation Bias in AI Systems" ;
    dcterms:abstract "Representation bias is one of the most common types of biases in artificial intelligence (AI) systems, causing AI  models to perform poorly on underrepresented data segments. Although AI practitioners use various methods to reduce representation bias, their effectiveness is often constrained by insufficient domain knowledge in the debiasing process. To address this gap, this paper introduces a set of generic design guidelines for effectively involving domain experts in representation debiasing.  We instantiated our proposed guidelines in a healthcare-focused application and evaluated them through a comprehensive mixed-methods user study with 35 healthcare experts. Our findings show that involving domain experts can reduce representation bias without compromising model accuracy. Based on our findings, we also offer recommendations for developers to build robust debiasing systems guided by our generic design guidelines, ensuring more effective inclusion of domain experts in the debiasing process." ;
    dcterms:identifier "3706598.3713497" ;
    chi:hasAuthor chi:person_183477, chi:person_187080, chi:person_183341, chi:person_186233 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:AlgorithmicFairnessAndBias ;
    chi:paperIncludesStudy chi:study_188455_UserStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188455_SoftwareArtifact .

chi:study_188455_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188455 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188455_QualitativeResult ;
    chi:reportsResult chi:result_188455_StatisticalResult .

chi:artifact_188455_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188455 .

chi:result_188455_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188455_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188457 rdf:type chi:Paper ;
    dcterms:title "RouteFlow: Trajectory-Aware Animated Transitions" ;
    dcterms:abstract "Animating objects’ movements is widely used to facilitate tracking changes and observing both the global trend and local hotspots where objects converge or diverge. Existing methods, however, often obscure critical local hotspots by only considering the start and end positions of objects' trajectories. To address this gap, we propose RouteFlow, a trajectory-aware animated transition method that effectively balances the global trend and local hotspots while minimizing occlusion. RouteFlow is inspired by a real-world bus route analogy: objects are regarded as passengers traveling together, with local hotspots representing bus stops where these passengers get on and off. Based on this analogy, animation paths are generated like bus routes, with the object layout generated similarly to seat allocation according to their destinations. Compared with state-of-the-art methods, RouteFlow better facilitates identifying the global trend and locating local hotspots while performing comparably in tracking objects' movements. " ;
    dcterms:identifier "3706598.3714300" ;
    chi:hasAuthor chi:person_184265, chi:person_185062, chi:person_187670, chi:person_184740, chi:person_187590, chi:person_186456 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:PointingAndSelectionPerformance ;
    chi:aimsAtGoal chi:ReduceCognitiveLoad ;
    chi:proposesArtifact chi:artifact_188457_InterfaceArtifact .

chi:artifact_188457_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188457 .

chi:paper_188458 rdf:type chi:Paper ;
    dcterms:title "CardioAI: A Multimodal AI-based System to Support Symptom Monitoring and Risk Prediction of Cancer Treatment-Induced Cardiotoxicity" ;
    dcterms:abstract "Despite recent advances in cancer treatments that prolong patients' lives, treatment-induced cardiotoxicity (i.e., the various heart damages caused by cancer treatments) emerges as one major side effect. The clinical decision-making process of cardiotoxicity is challenging, as early symptoms may happen in non-clinical settings and are too subtle to be noticed until life-threatening events occur at a later stage; clinicians already have a high workload focusing on the cancer treatment, no additional effort to spare on the cardiotoxicity side effect. Our project starts with a participatory design study with 11 clinicians to understand their decision-making practices and their feedback on an initial design of an AI-based decision-support system. Based on their feedback, we then propose a multimodal AI system, CardioAI, that can integrate wearables data and voice assistant data to model a patient's cardiotoxicity risk to support clinicians' decision-making. We conclude our paper with a small-scale heuristic evaluation with four experts and the discussion of future design considerations. " ;
    dcterms:identifier "3706598.3714272" ;
    chi:hasAuthor chi:person_187153, chi:person_185703, chi:person_187354, chi:person_183270, chi:person_186827, chi:person_187394, chi:person_186375, chi:person_185254, chi:person_183248, chi:person_186046 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:HCIResearchAndDesignTools:DesignAndFabricationWorkflowTools ;
    chi:paperIncludesStudy chi:study_188458_UserStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188458_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188458_InterfaceArtifact .

chi:study_188458_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188458 ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188458_QualitativeResult .

chi:artifact_188458_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188458 .

chi:artifact_188458_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188458 .

chi:result_188458_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188459 rdf:type chi:Paper ;
    dcterms:title "\"It's about Research. It's Not about Language\": Understanding and Designing for Mitigating Non-Native English-Speaking Presenters' Challenges in Live Q&A Sessions at Academic Conferences" ;
    dcterms:abstract "Live Q&A sessions at English-based, international academic conferences usually pose significant challenges for non-native English-speaking presenters, as they demand real-time comprehension and response in one's non-native language under stress. While language-supportive tools (e.g., real-time translation, transcription) can help alleviate such challenges, their adoption remains limited, even at HCI academic conferences that focus on how technology can better serve human needs. Through in-depth interviews with 15 non-native English-speaking academics, we identify their concerns and expectations regarding technological language support for HCI live Q&As. Our research provides critical design implications for future language support tools by highlighting the importance of culturally-aware solutions that offer accurate and seamless language experiences while fostering personal growth and building confidence. We also call for community-wide efforts in HCI to embrace more inclusive practices that actively support non-native English speakers, which can empower all scholars to equally engage in the HCI academic discourse regardless of their native languages. " ;
    dcterms:identifier "3706598.3713124" ;
    chi:hasAuthor chi:person_187358, chi:person_185608, chi:person_186829 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188459_InterviewStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility .

chi:study_188459_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188459 ;
    chi:reportsResult chi:result_188459_QualitativeResult .

chi:result_188459_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188460 rdf:type chi:Paper ;
    dcterms:title "Understanding the Security Advice Mechanisms of Low Socioeconomic Pakistanis" ;
    dcterms:abstract "Low socioeconomic populations face severe security challenges while being unable to access traditional written advice resources. We present the first study to explore the security advice landscape of low socioeconomic people in Pakistan. With 20 semi-structured interviews, we uncover how they learn and share security advice and what factors enable or limit their advice sharing. Our findings highlight that they heavily rely on community advice and intermediation to establish and maintain security-related practices (such as passwords). We uncover how shifting social environments shape advice dissemination, e.g., across different workplaces. Participants leverage their social structures to protect each other against threats that exploit their financial vulnerability and lack of digital literacy. However, we uncover barriers to social advice mechanisms, limiting their effectiveness, which may lead to increased security and privacy risks. Our results lay the foundation for rethinking security paradigms and advice for this vulnerable population. " ;
    dcterms:identifier "3706598.3713297" ;
    chi:hasAuthor chi:person_184535, chi:person_184001, chi:person_187353, chi:person_187494, chi:person_185986 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188460_InterviewStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility .

chi:study_188460_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188460 ;
    chi:reportsResult chi:result_188460_QualitativeResult .

chi:result_188460_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188461 rdf:type chi:Paper ;
    dcterms:title "Proactive Conversational Agents with Inner Thoughts" ;
    dcterms:abstract "One of the long-standing aspirations in conversational AI is to allow them to autonomously take initiatives in conversations, i.e. being proactive. This is especially challenging for multi-party conversations. Prior NLP research focused mainly on predicting the next speaker from contexts like preceding conversations. In this paper, we demonstrate the limitations of such methods and rethink what it means for AI to be proactive in multi-party, human-AI conversations.We propose that just like humans, rather than merely reacting to turn-taking cues, a proactive AI formulates its own inner thoughts during a conversation, and seeks the right moment to contribute. Through a formative study with 24 participants and inspiration from linguistics and cognitive psychology, we introduce the Inner Thoughts framework. Our framework equips AI with a continuous, covert train of thoughts in parallel to the overt communication process, which enables it to proactively engage by modeling its intrinsic motivation to express these thoughts. We instantiated this framework into two real-time systems: an AI playground web app and a chatbot. Through a technical evaluation and user studies with human participants, our framework significantly surpasses existing baselines on aspects like anthropomorphism, coherence, intelligence, and turn-taking appropriateness.  " ;
    dcterms:identifier "3706598.3713760" ;
    chi:hasAuthor chi:person_185146, chi:person_187404, chi:person_182658, chi:person_187699, chi:person_185665, chi:person_187008 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:ChatbotAssistedUserStudies ;
    chi:paperIncludesStudy chi:study_188461_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188461_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188461_InterfaceArtifact .

chi:study_188461_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188461 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188461_QualitativeResult ;
    chi:reportsResult chi:result_188461_StatisticalResult .

chi:artifact_188461_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188461 .

chi:artifact_188461_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188461 .

chi:result_188461_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188461_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188462 rdf:type chi:Paper ;
    dcterms:title "Playing Dumb to Get Smart: Creating and Evaluating an LLM-based Teachable Agent within University Computer Science Classes" ;
    dcterms:abstract "This work presents the iterative design and evaluation of a large-language-model (LLM) based teachable agent, MatlabTutee, that facilitates learning-by-teaching (LBT) experiences within university computer science courses. We detail four different experiments, with a total of 119 students, where we refine our system, compare it to human-facilitated LBT experiences, and deploy it in two, month-long in-the-wild environments. We find that our system is able to successfully convey a learner persona similar to a human pretending to be novice while also providing comparable LBT benefits. These benefits include helping students identify areas for improvement, develop a more accurate assessment of their own abilities, and improve their overall attitudes toward computer science. We also explore how students choose to adopt our system into their study habits while situated in real university courses. " ;
    dcterms:identifier "3706598.3713644" ;
    chi:hasAuthor chi:person_184707, chi:person_187001, chi:person_184737, chi:person_188029, chi:person_185552 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188462_UserStudy ;
    chi:paperIncludesStudy chi:study_188462_FieldStudy ;
    chi:paperIncludesStudy chi:study_188462_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188462_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188462_InterfaceArtifact .

chi:study_188462_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188462 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188462_QualitativeResult ;
    chi:reportsResult chi:result_188462_StatisticalResult .

chi:study_188462_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188462 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188462_QualitativeResult ;
    chi:reportsResult chi:result_188462_StatisticalResult .

chi:study_188462_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188462 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188462_QualitativeResult ;
    chi:reportsResult chi:result_188462_StatisticalResult .

chi:artifact_188462_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188462 .

chi:artifact_188462_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188462 .

chi:result_188462_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188462_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188463 rdf:type chi:Paper ;
    dcterms:title "Generative AI and News Consumption: Design Fictions and Critical Analysis" ;
    dcterms:abstract "The emergence of Generative AI features in news applications may radically change news consumption and challenge journalistic practices. To explore the future potentials and risks of this understudied area, we created six design fictions depicting scenarios such as virtual companions delivering news summaries to the user, AI providing context to news topics, and content being transformed into other formats on demand. The fictions, discussed with a multi-disciplinary group of experts, enabled a critical examination of the diverse ethical, societal, and journalistic implications of AI shaping this everyday activity. The discussions raised several concerns, suggesting that such consumer-oriented AI applications can clash with journalistic values and processes. These include fears that neither consumers nor AI could successfully balance engagement, objectivity, and truth, leading to growing detachment from shared understanding. We offer critical insights into the potential long-term effects to guide design efforts in this emerging application area of GenAI." ;
    dcterms:identifier "3706598.3713804" ;
    chi:hasAuthor chi:person_186897, chi:person_185203, chi:person_186688, chi:person_184813, chi:person_186748, chi:person_183039, chi:person_183800, chi:person_187398, chi:person_184580 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:ParticipatoryEthicsMethods ;
    chi:paperIncludesStudy chi:study_188463_QualitativeStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking .

chi:study_188463_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188463 ;
    chi:reportsResult chi:result_188463_QualitativeResult .

chi:result_188463_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188464 rdf:type chi:Paper ;
    dcterms:title "Understanding Temporality of Reflection in Personal Informatics through Baby Tracking" ;
    dcterms:abstract "Personal informatics literature has examined reflection in tracking, but there are gaps in our understanding of how self-initiated reflection that one engages in shortly after data collection has taken place occurs in everyday life and how technology can best support it. We use baby tracking as a case study to explore `temporality,' the time over which reflection occurs relative to data collection, as caregivers track their baby's well-being over both short-term and long-term. We interviewed 20 parents in the U.S. who used baby-tracking technology. We find that parents ask different questions based on the time elapsed since data collection, such as checking alignment with medical guidance and prior patterns immediately after tracking or augmenting memory when reflecting hours later. We summarize these findings into a framework for short-term reflection in baby tracking that includes three windows: the immediate, in-between, and cumulative. We use these windows to identify helpful design patterns in baby-tracking technologies toward supporting temporally meaningful reflection and opportunities for further study in other self-tracking domains." ;
    dcterms:identifier "3706598.3713197" ;
    chi:hasAuthor chi:person_182769, chi:person_183926, chi:person_187237, chi:person_187980, chi:person_185987 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:SelfReflectionAndBehaviorChange ;
    chi:paperIncludesStudy chi:study_188464_InterviewStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188464_SoftwareArtifact .

chi:study_188464_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188464 ;
    chi:reportsResult chi:result_188464_QualitativeResult .

chi:artifact_188464_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188464 .

chi:result_188464_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188465 rdf:type chi:Paper ;
    dcterms:title "Understanding Older Adults’ (Dis)Engagement with Design Materials" ;
    dcterms:abstract "Design workshops are a popular approach to include older adults in the technology design process. However, formative design sessions with older adults have had unexpected outcomes such as the non-use of traditional design materials like craft-based prototyping supplies or disengagement from design activities. Analyzing the engagement of 32 older adults across two design workshops, this paper sheds insights on some of these outcomes. Contributing to a growing body of HCI research on understanding older adults' participation in design, we provide an understanding of how design materials can shape older adults' engagement in formative design activities. Our discussion furthers research on understanding who older adults design for and why, argues for a different understanding of creative expression, and offers considerations for choosing design materials." ;
    dcterms:identifier "3706598.3713846" ;
    chi:hasAuthor chi:person_185635, chi:person_187588, chi:person_185565, chi:person_185364, chi:person_185601, chi:person_184704 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:paperIncludesStudy chi:study_188465_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement .

chi:study_188465_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188465 ;
    chi:reportsResult chi:result_188465_QualitativeResult .

chi:result_188465_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188466 rdf:type chi:Paper ;
    dcterms:title "Beyond the Dialogue: Multi-chatbot Group Motivational Interviewing for Premenstrual Syndrome (PMS) Management" ;
    dcterms:abstract "Premenstrual syndrome (PMS) is a prevalent disorder among women, often exacerbated by a lack of peer support due to associated stigmatization. Drawing inspiration from the established benefits of group therapy, particularly the sense of belonging it fosters, we developed a multi-chatbot group motivational interviewing system. The system consists of a facilitator bot and two peer bots, and simulates a group counseling environment for PMS management using Large Language Models (LLMs). We conducted a study with 63 participants and divided them into three conditions (no intervention, 1-on-1 chatbot, group chatbots) over two menstruation cycles for evaluation. Our findings revealed that participants in the group chat condition exhibited higher levels of engagement and language convergence with the chatbots. These participants were also able to engage in social learning and demonstrated motivation in coping through interactions with the chatbots. Finally, we discuss design implications for multi-chatbot interactions in supporting mental health." ;
    dcterms:identifier "3706598.3713918" ;
    chi:hasAuthor chi:person_183734, chi:person_185965, chi:person_183642, chi:person_186086, chi:person_185094, chi:person_186771, chi:person_186969, chi:person_183009, chi:person_184149 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialSupportAndPeerChatbots ;
    chi:paperIncludesStudy chi:study_188466_BaselineComparisonStudy ;
    chi:paperIncludesStudy chi:study_188466_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188466_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188466_InterfaceArtifact .

chi:study_188466_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188466 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188466_QualitativeResult ;
    chi:reportsResult chi:result_188466_StatisticalResult .

chi:study_188466_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188466 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188466_QualitativeResult ;
    chi:reportsResult chi:result_188466_StatisticalResult .

chi:artifact_188466_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188466 .

chi:artifact_188466_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188466 .

chi:result_188466_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188466_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188467 rdf:type chi:Paper ;
    dcterms:title "Designing for Transactional Moments: Features of Tools for Child-centred Speech Language Teletherapy" ;
    dcterms:abstract "Teletherapy for speech-language therapy (SLT) has become essential for many families. Early intervention for young children is important to ensure that developmental milestones are met. In this study, from a corpus of 10 videos, we present three cases of online and in-person therapy sessions with children between the ages of 3 and 6. Our analysis shows how online and in-person SLT sessions use tools, how they are conscripted into social and transactional moments, and identifies features of tools that support or hinder therapists’ goals (see Figure 1). From our findings, we discuss in detail four overarching features of tools and implications for design. These features support engagement, space usage, child-centred play, and adaptability in therapy sessions. The paper outlines how these features are present in the tools used in SLT, and describes how they impact SLT activities, therapists’ and children’s goals, and the environment for social transactional activities." ;
    dcterms:identifier "3706598.3713394" ;
    chi:hasAuthor chi:person_187579, chi:person_186055, chi:person_186001, chi:person_185964, chi:person_183414 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188467_FieldStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188467_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188467_InterfaceArtifact .

chi:study_188467_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188467 ;
    chi:reportsResult chi:result_188467_QualitativeResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:artifact_188467_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188467 .

chi:artifact_188467_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188467 .

chi:result_188467_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188469 rdf:type chi:Paper ;
    dcterms:title "AI-Enabled Conversational Journaling for Advancing Parkinson's Disease Symptom Tracking" ;
    dcterms:abstract "Journaling plays a crucial role in managing chronic conditions by allowing patients to document symptoms and medication intake, providing essential data for long-term care. While valuable, traditional journaling methods often rely on static, self-directed entries, lacking interactive feedback and real-time guidance. This gap can result in incomplete or imprecise information, limiting its usefulness for effective treatment. To address this gap, we introduce PATRIKA, an AI-enabled prototype designed specifically for people with Parkinson's disease (PwPD). The system incorporates cooperative conversation principles, clinical interview simulations, and personalization to create a more effective and user-friendly journaling experience. Through two user studies with PwPD and iterative refinement of PATRIKA, we demonstrate conversational journaling's significant potential in patient engagement and collecting clinically valuable information. Our results showed that generating probing questions PATRIKA turned journaling into a bi-directional interaction. Additionally, we offer insights for designing journaling systems for healthcare and future directions for promoting sustained journaling." ;
    dcterms:identifier "3706598.3714280" ;
    chi:hasAuthor chi:person_184865, chi:person_187357, chi:person_184033, chi:person_186355, chi:person_185054, chi:person_183336, chi:person_186992, chi:person_187154, chi:person_187797 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:SelfReflectionAndBehaviorChange ;
    chi:paperIncludesStudy chi:study_188469_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188469_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188469_InterfaceArtifact .

chi:study_188469_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188469 ;
    chi:reportsResult chi:result_188469_QualitativeResult .

chi:artifact_188469_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188469 .

chi:artifact_188469_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188469 .

chi:result_188469_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188470 rdf:type chi:Paper ;
    dcterms:title "Fairness by Design: Cross-Cultural Perspectives from Children on AI and Fair Data Processing in their Education Futures" ;
    dcterms:abstract "AI-driven educational technologies (AI-EdTech) process extensive data, raising concerns about commercial exploitation of children’s data and risks to their privacy, wellbeing, agency, and legal rights. The ‘fairness principle’ in data protection law requires fair data processing that meets children’s expectations and avoids unexpected, detrimental, discriminatory, or misleading practices. However, children’s own perspectives on what fairness means in AI-EdTech are underexplored in design. This study bridges the gap between law and design research to contextualize what fairness means through co-design workshops with 72 children (aged 10–12) and 4 teachers (N=76) in Scotland and Türkiye. We examine how children's perspectives can inform the operationalization of ‘fairness by design’ for AI-EdTech. Our contributions include: (1) an understanding of children’s perspectives on how fairness manifests (or does not) in AI-EdTech and (2) recommendations for both design and legal communities to align AI-EdTech design and data practices with children's values and rights." ;
    dcterms:identifier "3706598.3714402" ;
    chi:hasAuthor chi:person_186728, chi:person_182880, chi:person_185706, chi:person_187879 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:paperIncludesStudy chi:study_188470_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning .

chi:study_188470_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188470 ;
    chi:reportsResult chi:result_188470_QualitativeResult .

chi:result_188470_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188471 rdf:type chi:Paper ;
    dcterms:title "Xavier: Toward Better Coding Assistance in Authoring Tabular Data Wrangling Scripts" ;
    dcterms:abstract "Data analysts frequently employ code completion tools in writing custom scripts to tackle complex tabular data wrangling tasks. However, existing tools do not sufficiently link the data contexts such as schemas and values with the code being edited. This not only leads to poor code suggestions, but also frequent interruptions in coding processes as users need additional code to locate and understand relevant data. We introduce Xavier, a tool designed to enhance data wrangling script authoring in computational notebooks. Xavier maintains users' awareness of data contexts while providing data-aware code suggestions. It automatically highlights the most relevant data based on the user's code, integrates both code and data contexts for more accurate suggestions, and instantly previews data transformation results for easy verification. To evaluate the effectiveness and usability of Xavier, we conducted a user study with 16 data analysts, showing its potential to streamline data wrangling scripts authoring." ;
    dcterms:identifier "3706598.3714239" ;
    chi:hasAuthor chi:person_184139, chi:person_185849, chi:person_187985, chi:person_185405, chi:person_184851, chi:person_187993, chi:person_185458, chi:person_187341 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:paperIncludesStudy chi:study_188471_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188471_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188471_InterfaceArtifact .

chi:study_188471_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188471 ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:reportsResult chi:result_188471_QualitativeResult .

chi:artifact_188471_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188471 .

chi:artifact_188471_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188471 .

chi:result_188471_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188472 rdf:type chi:Paper ;
    dcterms:title "Generative AI and Perceptual Harms: Who’s Suspected of using LLMs?" ;
    dcterms:abstract "Large language models (LLMs) are increasingly integrated into a variety of writing tasks. While these tools can help people by generating ideas or producing higher quality work, like many other AI tools, they may risk causing a variety of harms, potentially disproportionately burdening historically marginalized groups.  In this work, we introduce and evaluate perceptual harms, a term for the harms caused to users when others perceive or suspect them of using AI.  We examined perceptual harms in three online experiments, each of which entailed participants evaluating write-ups from mock freelance writers.  We asked participants to state whether they suspected the freelancers of using AI, to rank the quality of their writing, and to evaluate whether they should be hired. We found some support for perceptual harms against certain demographic groups.   At the same time, perceptions of AI use negatively impacted writing evaluations and hiring outcomes across the board." ;
    dcterms:identifier "3706598.3713897" ;
    chi:hasAuthor chi:person_186388, chi:person_186339, chi:person_187267 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:AlgorithmicFairnessAndBias ;
    chi:paperIncludesStudy chi:study_188472_UserStudy ;
    chi:paperIncludesStudy chi:study_188472_QuantitativeStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking .

chi:study_188472_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188472 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188472_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:study_188472_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188472 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188472_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:result_188472_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188473 rdf:type chi:Paper ;
    dcterms:title "Designing with Dynamics: Reflections on Co-design Workshops Between People Living with Dementia and Their Care Partners" ;
    dcterms:abstract "Human-Computer Interaction (HCI) researchers focusing on informal care partners and people living with dementia often create personas, incorporating expectations about the pair's relationship dynamics to guide their research and design outcome. Similarly, in our two iterations of co-design workshops aimed at designing a robot to enhance these relationships, we started with expectation that care partners would primarily lead the relationship. This assumption guided the design of the co-design workshops, which included diary studies followed by co-design sessions with eight dyads. However, our results from reflexive thematic analysis challenge the initial view that relationship dynamics follow a single persona or outcome. Instead, the diversity in relationship dynamics led to multiple design outcomes, highlighting the need for HCI researchers to consider care dynamics when designing and conducting research studies for care partnerships. Researchers can structure and create iterative co-design workshops to accommodate these dynamics by incorporating ongoing reflection on the dyad’s relationship dynamics and the researchers’ influence throughout all co-design stages. This approach enhances researchers' ability to create more thoughtful and effective relationship technology." ;
    dcterms:identifier "3706598.3714105" ;
    chi:hasAuthor chi:person_184248, chi:person_185835, chi:person_184313, chi:person_184157 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188473_DiaryStudy ;
    chi:paperIncludesStudy chi:study_188473_UserStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188473_DeviceArtifact .

chi:study_188473_DiaryStudy rdf:type chi:DiaryStudy ;
    chi:isStudyReportedIn chi:paper_188473 ;
    chi:reportsResult chi:result_188473_QualitativeResult .

chi:study_188473_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188473 ;
    chi:reportsResult chi:result_188473_QualitativeResult .

chi:artifact_188473_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188473 .

chi:result_188473_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188474 rdf:type chi:Paper ;
    dcterms:title "Human-Precision Medicine Interaction: Public Perceptions of Polygenic Risk Score for Genetic Health Prediction" ;
    dcterms:abstract "Precision Medicine (PM) transforms the traditional \"one-drug-fits-all\" paradigm by customising treatments based on individual characteristics, and is an emerging topic for HCI research on digital health. A key element of PM, the Polygenic Risk Score (PRS), uses genetic data to predict an individual's disease risk. Despite its potential, PRS faces barriers to adoption, such as data inclusivity, psychological impact, and public trust. We conducted a mixed-methods study to explore how people perceive PRS, formed of surveys (n=254) and interviews (n=11) with UK-based participants. The interviews were supplemented by interactive storyboards with the ContraVision technique to provoke deeper reflection and discussion. We identified ten key barriers and five themes to PRS adoption and proposed design implications for a responsible PRS framework. To address the complexities of PRS and enhance broader PM practices, we introduce the term Human-Precision Medicine Interaction (HPMI), which integrates, adapts, and extends HCI approaches to better meet these challenges. " ;
    dcterms:identifier "3706598.3713567" ;
    chi:hasAuthor chi:person_184146, chi:person_183061, chi:person_184457 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:ParticipatoryEthicsMethods ;
    chi:paperIncludesStudy chi:study_188474_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188474_QuantitativeStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188474_InterfaceArtifact .

chi:study_188474_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188474 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188474_QualitativeResult ;
    chi:reportsResult chi:result_188474_StatisticalResult .

chi:study_188474_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188474 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188474_QualitativeResult ;
    chi:reportsResult chi:result_188474_StatisticalResult .

chi:artifact_188474_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188474 .

chi:result_188474_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188474_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188475 rdf:type chi:Paper ;
    dcterms:title "I Was Told to Install the Antivirus App, but I'm Not Sure I Need It: Understanding Smartphone Antivirus Software Adoption and User Perceptions" ;
    dcterms:abstract "The rising threat of mobile malware has prompted security vendors to recommend antivirus software for smartphones, yet user misconceptions, regulatory requirements, and improper use undermine its effectiveness. Our mixed-method study, consisting of in-depth interviews with 23 participants and a survey of 250 participants, examines smartphone antivirus software adoption in South Korea, where mandatory installation for banking and other financial apps is common. Many users confuse antivirus software with general security tools and remain unaware of its limited scope. Adoption is significantly influenced by perceived vulnerability, response efficacy, self-efficacy, social norms, and awareness, while concerns about system performance and skepticism about necessity lead to discontinuation or non-use. Mandatory installations for financial apps in South Korea contribute to user misconceptions, negative perceptions, and a false sense of security. These findings highlight the need for targeted user education, clearer communication about mobile-specific threats, and efforts to promote informed and effective engagement with antivirus software." ;
    dcterms:identifier "3706598.3713452" ;
    chi:hasAuthor chi:person_184166, chi:person_182682, chi:person_185610, chi:person_186990 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:DataDisclosureAndConsent ;
    chi:paperIncludesStudy chi:study_188475_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188475_UserStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188475_SoftwareArtifact .

chi:study_188475_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188475 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188475_QualitativeResult ;
    chi:reportsResult chi:result_188475_StatisticalResult .

chi:study_188475_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188475 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188475_QualitativeResult ;
    chi:reportsResult chi:result_188475_StatisticalResult .

chi:artifact_188475_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188475 .

chi:result_188475_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188475_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188476 rdf:type chi:Paper ;
    dcterms:title "Raise Your Eyebrows Higher: Facilitating Emotional Communication in Social Virtual Reality Through Region-Specific Facial Expression Exaggeration" ;
    dcterms:abstract "While exaggerated facial expressions in cartoon avatars can enhance emotional communication in social virtual reality (VR), they risk triggering the uncanny valley effect. Our research reveals that this effect varies significantly across different emotions. In Study 1 (N=30), participants evaluated scaled facial expressions during simulated VR conversations. We found that expression exaggeration had opposing effects: it decreased facial realism for joy, surprise, and disgust due to overly dramatic mouth movements, while enhancing realism for fear, sadness, and anger—emotions that rely on upper facial expressions typically constrained by HMD pressure. Based on these findings, we developed a region-specific facial expression exaggeration strategy that enhances under-expressed upper facial features while maintaining natural lower facial movements. Study 2 (N=20) validated this approach, demonstrating enhanced emotional intensity and contagion for negative emotions while mitigating the uncanny valley effect. Our research provides practical guidelines for optimizing avatar-mediated emotional communication in social VR environments." ;
    dcterms:identifier "3706598.3713688" ;
    chi:hasAuthor chi:person_183140, chi:person_184921, chi:person_186146, chi:person_187428, chi:person_183658, chi:person_184435, chi:person_184786, chi:person_185547 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:EmbodiedVRInteraction ;
    chi:paperIncludesStudy chi:study_188476_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188476_InterfaceArtifact .

chi:study_188476_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188476 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188476_StatisticalResult .

chi:artifact_188476_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188476 .

chi:result_188476_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188478 rdf:type chi:Paper ;
    dcterms:title "Inkspire: Supporting Design Exploration with Generative AI through Analogical Sketching" ;
    dcterms:abstract "With recent advancements in the capabilities of Text-to-Image (T2I) AI models, product designers have begun experimenting with them in their work. However, T2I models struggle to interpret abstract language and the current user experience of T2I tools can induce design fixation rather than a more iterative, exploratory process. To address these challenges, we developed Inkspire, a sketch-driven tool that supports designers in prototyping product design concepts with analogical inspirations and a complete sketch-to-design-to-sketch feedback loop. To inform the design of Inkspire, we conducted an exchange session with designers and distilled design goals for improving T2I interactions. In a within-subjects study comparing Inkspire to ControlNet, we found that Inkspire supported designers with more inspiration and exploration of design ideas, and improved aspects of the co-creative process by allowing designers to effectively grasp the current state of the AI to guide it towards novel design intentions." ;
    dcterms:identifier "3706598.3713397" ;
    chi:hasAuthor chi:person_183790, chi:person_184407, chi:person_182663, chi:person_183410, chi:person_186009, chi:person_184694 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:paperIncludesStudy chi:study_188478_UserStudy ;
    chi:paperIncludesStudy chi:study_188478_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188478_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188478_InterfaceArtifact .

chi:study_188478_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188478 ;
    chi:reportsResult chi:result_188478_QualitativeResult ;
    chi:reportsResult chi:result_188478_StatisticalResult .

chi:study_188478_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188478 ;
    chi:reportsResult chi:result_188478_QualitativeResult ;
    chi:reportsResult chi:result_188478_StatisticalResult .

chi:artifact_188478_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188478 .

chi:artifact_188478_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188478 .

chi:result_188478_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188478_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188479 rdf:type chi:Paper ;
    dcterms:title "PiaMuscle: Improving Piano Skill Acquisition by Cost-effectively Estimating and Visualizing Activities of Miniature Hand Muscles" ;
    dcterms:abstract "Understanding neuromusculoskeletal mechanisms significantly impacts skill specialization and proficiency. While existing methods can infer large muscle activities during gross motor movements, the estimation of dexterous motor control involving miniature muscles remains underexplored. Targeting the coordinated hand muscles in advanced piano performance, we learn spatiotemporal discrete representations of electromyography (EMG) data and hand postures utilizing a multimodal dataset. Subsequently, we train a precise and cost-effective neural network model. Based on this model, PiaMuscle is introduced to investigate if visualizing muscle activities during piano training enhances piano performance. Quantitative and qualitative results of a user study with highly skilled professional pianists demonstrate that PiaMuscle provides reliable muscle activation data to support and optimize force control. Our research underscores the potential of a naturalistic workflow to estimate small muscles' activities from readily accessible human-centric information and more accurately when combined with tool-centric data, thereby enhancing skill acquisition." ;
    dcterms:identifier "3706598.3713465" ;
    chi:hasAuthor chi:person_182840, chi:person_182964, chi:person_187950, chi:person_185341, chi:person_186750, chi:person_188196, chi:person_187299 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:SelfReflectionAndBehaviorChange ;
    chi:paperIncludesStudy chi:study_188479_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188479_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188479_InterfaceArtifact .

chi:study_188479_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188479 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188479_QualitativeResult ;
    chi:reportsResult chi:result_188479_StatisticalResult .

chi:artifact_188479_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188479 .

chi:artifact_188479_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188479 .

chi:result_188479_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188479_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188480 rdf:type chi:Paper ;
    dcterms:title "\"Piecing Data Connections Together Like a Puzzle\": Effects of Increasing Task Complexity on the Effectiveness of Data Storytelling Enhanced Visualisations" ;
    dcterms:abstract "The emerging concept of data storytelling (DS) suggests that enhancing visualisations with annotations and narratives can make complex data more insightful than conventional visualisations. Previous works found that DS-enhanced visualisations are more effective than conventional visualisations for simple tasks like identifying key data points or the main message. However, no previous work has explored the extent to which DS enhancements influence task completion across different levels of cognitive complexity. We address this gap by presenting the results of a study where 128 participants completed tasks based on four visualisations (two line charts and two choropleth maps, either with or without DS elements) spanning a range of complexity based on Bloom's taxonomy, which has been applied in data visualisation to categorise tasks hierarchically from lower to higher-order thinking.  Results suggest that while DS-enhanced visualisations effectively support lower-order tasks (finding data points and understanding insights), they don't necessarily aid the correct completion of higher-order tasks (application, analysis, evaluation and creation). However, DS enhancements improve how efficiently participants complete complex tasks." ;
    dcterms:identifier "3706598.3714270" ;
    chi:hasAuthor chi:person_185028, chi:person_186344, chi:person_186336, chi:person_186252, chi:person_186454, chi:person_187818, chi:person_187637, chi:person_187661, chi:person_186682 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:ErrorRatesAndTaskCompletion ;
    chi:paperIncludesStudy chi:study_188480_UserStudy ;
    chi:paperIncludesStudy chi:study_188480_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188480_InterfaceArtifact .

chi:study_188480_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188480 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188480_StatisticalResult .

chi:study_188480_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188480 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188480_StatisticalResult .

chi:artifact_188480_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188480 .

chi:result_188480_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188481 rdf:type chi:Paper ;
    dcterms:title "Escape or D13: Understanding Youth Perspectives of AI through Educational Game Co-design" ;
    dcterms:abstract "There are many initiatives that teach Artificial Intelligence (AI) literacy to K-12 students. Most downsize college-level instructional materials to grade-level appropriate formats, overlooking students' unique perspectives in the design of curricula. To investigate the use of educational games as a vehicle for uncovering youth's understanding of AI instruction, we co-designed games with 39 Black, Hispanic, and Asian high school girls and non-binary youth to create engaging learning materials for their peers. We conducted qualitative analyses on the designed game artifacts, student discourse, and their feedback on the efficacy of learning activities. This study highlights the benefits of co-design and learning games to uncover students' understanding and ability to apply AI concepts in game-based learning, their emergent perspectives of AI, and the prior knowledge that informs their game design choices. Our research uncovers students' AI misconceptions and informs the design of educational games and grade-level appropriate AI instruction." ;
    dcterms:identifier "3706598.3714037" ;
    chi:hasAuthor chi:person_185569, chi:person_184348, chi:person_184023, chi:person_186929, chi:person_183967, chi:person_185689, chi:person_184903, chi:person_183655 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188481_UserStudy ;
    chi:paperIncludesStudy chi:study_188481_QualitativeStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188481_SoftwareArtifact .

chi:study_188481_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188481 ;
    chi:reportsResult chi:result_188481_QualitativeResult .

chi:study_188481_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188481 ;
    chi:reportsResult chi:result_188481_QualitativeResult .

chi:artifact_188481_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188481 .

chi:result_188481_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188482 rdf:type chi:Paper ;
    dcterms:title "Exploring Place-Belongingness through Magic Machine Workshops in Refugee Communities" ;
    dcterms:abstract "Upon displacement, it becomes challenging for refugees to build a sense of home in a new environment due to the traumatic experiences they have endured. To unpack factors that are important in developing a sense of home and belonging in refugee communities, we lean on the theoretical concept of 'place-belongingness' - we did this by conducting 6 co-design workshops involving 15 refugee participants, via the 'Magic Machine' workshop approach. From the workshops, we uncovered how cultural identity and memory, life stability and normalcy, security and privacy, resilience and ingenuity, and social connections are central to their sense of home. This research contributes to HCI by building on the theoretical concept of place-belongingness in the context of forced displacement, proposing design implications that address refugees’ needs for home from cultural and social dimensions, and design considerations for refugees’ domestic settings." ;
    dcterms:identifier "3706598.3714246" ;
    chi:hasAuthor chi:person_184205, chi:person_184273, chi:person_187317 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:AccessibilityNavigationSupport ;
    chi:paperIncludesStudy chi:study_188482_UserStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility .

chi:study_188482_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188482 ;
    chi:reportsResult chi:result_188482_QualitativeResult .

chi:result_188482_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188484 rdf:type chi:Paper ;
    dcterms:title "Can AI writing be salvaged? Mitigating Idiosyncrasies and Improving Human-AI Alignment in the Writing Process through Edits" ;
    dcterms:abstract "LLM-based applications are helping people write, and LLM-generated text is making its way into social media, journalism, and our classrooms. However, the differences between LLM-generated and human-written text remain unclear. To explore this, we hired professional writers to edit paragraphs in several creative domains. We first found these writers agree on undesirable idiosyncrasies in LLM-generated text, formalizing it into a seven-category taxonomy (e.g. clichés, unnecessary exposition). Second, we curated the LAMP corpus: 1,057 LLM-generated paragraphs edited by professional writers according to our taxonomy. Analysis of LAMP reveals that none of the LLMs used in our study (GPT4o, Claude-3.5-Sonnet, Llama-3.1-70b) outperform each other in terms of writing quality, revealing common limitations across model families. Third, building on existing work in automatic editing we evaluated methods to improve LLM-generated text. A large-scale preference annotation confirms that although experts largely prefer text edited by other experts, automatic editing methods show promise in improving alignment between LLM-generated and human-written text." ;
    dcterms:identifier "3706598.3713559" ;
    chi:hasAuthor chi:person_182794, chi:person_183841, chi:person_187699 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:ChatbotAssistedUserStudies ;
    chi:paperIncludesStudy chi:study_188484_UserStudy ;
    chi:paperIncludesStudy chi:study_188484_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188484_SoftwareArtifact .

chi:study_188484_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188484 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188484_QualitativeResult ;
    chi:reportsResult chi:result_188484_StatisticalResult .

chi:study_188484_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188484 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188484_QualitativeResult ;
    chi:reportsResult chi:result_188484_StatisticalResult .

chi:artifact_188484_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188484 .

chi:result_188484_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188484_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188485 rdf:type chi:Paper ;
    dcterms:title "Towards Hormone Health: An Autoethnography of Long-Term Holistic Tracking to Manage PCOS" ;
    dcterms:abstract "Polycystic ovary syndrome (PCOS) is a common hormonal disorder affecting 11-13% of women of reproductive age, characterized by a wide range of symptoms (e.g., menstrual irregularity, acne, and obesity) that varies among individuals. While self-tracking tools help PCOS patients to monitor their symptoms and find personalized treatment, they often focus on regular periods of healthy women with inadequate support for the 1) personalization and 2) long-term holistic tracking necessary for managing complex chronic conditions like PCOS. To bridge this gap, the first author (who has PCOS) conducted an autoethnographic study of holistic self-tracking over a period of ten months in an effort to manage her condition. Our results highlight the challenges of personalized, holistic, long-term tracking in medical, socio-cultural, temporal, technical, and spatial contexts. Based on these insights, we provide design implications for tracking tools that are more inclusive and sustainable." ;
    dcterms:identifier "3706598.3713619" ;
    chi:hasAuthor chi:person_186573, chi:person_186519, chi:person_187529, chi:person_188043, chi:person_183585 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:SelfReflectionAndBehaviorChange ;
    chi:paperIncludesStudy chi:study_188485_QualitativeStudy ;
    chi:aimsAtGoal chi:ImproveUsability .

chi:study_188485_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188485 ;
    chi:reportsResult chi:result_188485_QualitativeResult .

chi:result_188485_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188486 rdf:type chi:Paper ;
    dcterms:title "This Game SUX: Why & How to Design Sh@*!y User Experiences" ;
    dcterms:abstract "While normative – \"good\" – game design and user experiences have been established, we look to games that challenge those notions. Intentional frustration and failure can be worthwhile. Through a reflexive thematic analysis of 31 games we identify how intentionally non-normative design choices lead to meaningful experiences. Working within the established Mechanics Dynamics Aesthetics (MDA) Game Design Framework, we lay out themes to design Shitty User Experiences (SUX). We contribute SUX MDA themes for designers and researchers to counter the status quo and identify new forms of play and interaction. " ;
    dcterms:identifier "3706598.3713246" ;
    chi:hasAuthor chi:person_185239, chi:person_186729, chi:person_182763, chi:person_182684, chi:person_184600, chi:person_182913 ;
    chi:paperIncludesStudy chi:study_188486_QualitativeStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188486_SoftwareArtifact .

chi:study_188486_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188486 ;
    chi:reportsResult chi:result_188486_QualitativeResult .

chi:artifact_188486_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188486 .

chi:result_188486_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188487 rdf:type chi:Paper ;
    dcterms:title "IEDS: Exploring an Intelli-Embodied Design Space Combining Designer, AR, and GAI to Support Industrial Conceptual Design" ;
    dcterms:abstract "Conceptual design is an important stage in industrial product development, influenced by the design space and materials available to designers. Advancements in human-computer interaction (HCI) and artificial intelligence (AI) technologies have broadened these aspects considerably. On the one hand, augmented reality (AR) technologies merge physical and virtual representations to enhance intuitive interaction and embodied cognition. On the other hand, generative artificial intelligence (GAI) serves as a novel design material, boosting creativity and productivity. Inspired by these technological strides, we proposed an Intelli-Embodied Design Space (IEDS), which integrates designers, AR, and GAI to support industrial conceptual design by combining embodied interaction with generative variability. Within IEDS, designers can interact with the physical prototypes intuitively, while GAI refines these into virtual forms that can be embedded in the physical world through AR technology. In this study, we established the theoretical framework and interaction modes of IEDS through literature reviews and expert interviews. Subsequently, we designed and implemented three GAI+AR tools, GAI + Head-mounted Display (HMD), GAI + Handheld Display (HHD), and GAI + Spatial Augmented Reality (SAR), based on three AR approaches in IEDS to practically examine the benefits and challenges of these interaction modes across industrial conceptual design tasks. We discussed IEDS's influence on industrial conceptual design and released its application guidelines to the HCI community." ;
    dcterms:identifier "3706598.3713528" ;
    chi:hasAuthor chi:person_184230, chi:person_183045, chi:person_183211, chi:person_182887, chi:person_186132, chi:person_187431, chi:person_187109, chi:person_184319 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:EmbodiedVRInteraction ;
    chi:paperIncludesStudy chi:study_188487_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188487_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188487_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188487_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188487_DeviceArtifact .

chi:study_188487_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188487 ;
    chi:reportsResult chi:result_188487_QualitativeResult .

chi:study_188487_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188487 ;
    chi:reportsResult chi:result_188487_QualitativeResult .

chi:artifact_188487_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188487 .

chi:artifact_188487_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188487 .

chi:artifact_188487_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188487 .

chi:result_188487_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188488 rdf:type chi:Paper ;
    dcterms:title "Tracing Change in Social Media Use: A Qualitative Longitudinal Study" ;
    dcterms:abstract "This study reveals a significant shift in how users perceive and engage with social media over time. Our analysis is based on qualitative longitudinal research carried out over ten years, involving a small group of participants in 2012, 2017, and 2022. Semi-structured, in-depth interviews were conducted using stimulated recall allowing for retrospection and reflection. Through this methodology, we trace the shifting perceptions of social media users, from initially embracing these platforms for quick, fun, and social activities, to later recognizing their potential intrusiveness and seeking strategies to manage their use. We outline three central trajectories that illustrate shifts in social media use across time: from public performance to private interaction, from producing to consuming and from fun to problematic. For HCI and social media studies, these findings underscore the need to prioritize user agency, ethical design practices, and longitudinal research endeavors to understand the evolving impacts of social media." ;
    dcterms:identifier "3706598.3713813" ;
    chi:hasAuthor chi:person_183678, chi:person_187774 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:aboutTopic chi:OnlineSelfDisclosureAndIdentity ;
    chi:paperIncludesStudy chi:study_188488_InterviewStudy .

chi:study_188488_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188488 ;
    chi:reportsResult chi:result_188488_QualitativeResult .

chi:result_188488_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188489 rdf:type chi:Paper ;
    dcterms:title "ACKnowledge: A Computational Framework for Human Compatible Affordance-based Interaction Planning in Real-world Contexts" ;
    dcterms:abstract "Intelligent agents coexisting with humans often need to interact with human-shared objects in environments. Thus, agents should plan their interactions based on objects' affordances and the current situation to achieve acceptable outcomes. How to support intelligent agents' planning of affordance-based interactions compatible with human perception and values in real-world contexts remains under-explored. We conducted a formative study identifying the physical, intrapersonal, and interpersonal contexts that count to household human-agent interaction. We then proposed ACKnowledge, a computational framework integrating a dynamic knowledge graph, a large language model, and a vision language model for affordance-based interaction planning in dynamic human environments. In evaluations, ACKnowledge generated acceptable planning results with an understandable process. In real-world simulation tasks, ACKnowledge achieved a high execution success rate and overall acceptability, significantly enhancing usage-rights respectfulness and social appropriateness over baselines. The case study's feedback demonstrated ACKnowledge's negotiation and personalization capabilities toward an understandable planning process. " ;
    dcterms:identifier "3706598.3713791" ;
    chi:hasAuthor chi:person_183012, chi:person_183609, chi:person_187975, chi:person_184571, chi:person_184172, chi:person_183431 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:paperIncludesStudy chi:study_188489_UserStudy ;
    chi:paperIncludesStudy chi:study_188489_FieldStudy ;
    chi:paperIncludesStudy chi:study_188489_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188489_SoftwareArtifact .

chi:study_188489_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188489 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188489_QualitativeResult ;
    chi:reportsResult chi:result_188489_StatisticalResult .

chi:study_188489_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188489 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188489_QualitativeResult ;
    chi:reportsResult chi:result_188489_StatisticalResult .

chi:study_188489_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188489 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188489_QualitativeResult ;
    chi:reportsResult chi:result_188489_StatisticalResult .

chi:artifact_188489_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188489 .

chi:result_188489_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188489_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188490 rdf:type chi:Paper ;
    dcterms:title "Intermanual Deictics: Uncovering Users' Gesture Preferences for Opposite-Arm Referential Input, from Fingers to Shoulder" ;
    dcterms:abstract "We examine intermanual deictics, a distinctive class of gesture input characterized by an intermanual structure, asymmetric postural-manipulative articulation, and a deictic nature, drawing from both on-skin and bimanual mid-air gestures. To understand user preferences for gestures featuring these characteristics, we conducted a large-sample end-user elicitation study with 75 participants, who proposed intermanual deictics involving the opposite palm, forearm, and upper arm. Our results reveal a strong preference for physical-contact gestures primarily performed with the index finger, with strokes (62.4%) and touch input (28.8%) being most common, complemented by some preference for non-contact gestures (5.2%). We report similar agreement rates across gestures elicited in the three arm regions, averaging 26.3%, with higher agreement between the forearm and upper arm. We also present a consensus set of sixty gestures for effecting generic commands in interactive systems, along with design principles encompassing multiple practical implications for interactions that incorporate intermanual deictics." ;
    dcterms:identifier "3706598.3713474" ;
    chi:hasAuthor chi:person_184882, chi:person_187450 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:paperIncludesStudy chi:study_188490_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188490_InterfaceArtifact .

chi:study_188490_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188490 ;
    chi:reportsResult chi:result_188490_QualitativeResult ;
    chi:reportsResult chi:result_188490_StatisticalResult .

chi:artifact_188490_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188490 .

chi:result_188490_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188490_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188491 rdf:type chi:Paper ;
    dcterms:title "Virtual Visits, Real Emotions: Designing Social VR Experiences for Imprisoned Fathers and their Children" ;
    dcterms:abstract "The imprisonment of parents has severe consequences for their relationship to their children. Thus, ensuring valuable contact between them is crucial for parent’s social rehabilitation and children’s development and well-being. However, visits are often not child-friendly and lack interaction. We see social VR as a means to address these issues. In this paper, we share findings of a user-centered design process of a virtual reality application that allows imprisoned parents to meet their children. Our pilot study with four dyads of children and imprisoned fathers revealed that both appreciated the virtual visits, felt close to each other, and had a positive emotional experience, although fathers missed physical contact. Children preferred VR’s playful and interactive nature compared to regular visits. Our research presents virtual visits as a suitable alternative to ensure valuable social interaction between prisoners and their children and contribute to the potential of immersive virtual social experiences for sensitive use cases." ;
    dcterms:identifier "3706598.3714018" ;
    chi:hasAuthor chi:person_186321, chi:person_187480, chi:person_188073, chi:person_183017, chi:person_184814 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188491_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188491_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188491_InterfaceArtifact .

chi:study_188491_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188491 ;
    chi:reportsResult chi:result_188491_QualitativeResult .

chi:artifact_188491_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188491 .

chi:artifact_188491_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188491 .

chi:result_188491_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188492 rdf:type chi:Paper ;
    dcterms:title "Does Positive Reinforcement Work?: A Quasi-Experimental Study of the Effects of Positive Feedback on Reddit" ;
    dcterms:abstract "Social media platform design often incorporates explicit signals of positive feedback. Some moderators provide positive feedback with the goal of positive reinforcement, but are often unsure of their ability to actually influence user behavior. Despite its widespread use and theory touting positive feedback as crucial for user motivation, its effect on recipients is relatively unknown. This paper examines how positive feedback impacts Reddit users and evaluates its differential effects to understand who benefits most from receiving positive feedback. Through a causal inference study of 11M posts across 4 months, we find that users who received positive feedback made more frequent (2\% per day) and higher quality (57\% higher score; 2\% fewer removals per day) posts compared to a set of matched control users. Our findings highlight the need for platforms, communities, and moderators to expand their perspective on moderation and complement punitive approaches with positive reinforcement strategies to foster desirable behavior online." ;
    dcterms:identifier "3706598.3713830" ;
    chi:hasAuthor chi:person_186539, chi:person_185714, chi:person_187502 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:paperIncludesStudy chi:study_188492_FieldStudy ;
    chi:paperIncludesStudy chi:study_188492_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188492_SoftwareArtifact .

chi:study_188492_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188492 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188492_StatisticalResult ;
    chi:involvesParticipationPattern chi:AsynchronousParticipation .

chi:study_188492_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188492 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188492_StatisticalResult ;
    chi:involvesParticipationPattern chi:AsynchronousParticipation .

chi:artifact_188492_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188492 .

chi:result_188492_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188494 rdf:type chi:Paper ;
    dcterms:title "RheoMap: Mapping Inks, Gels, Pastes, and Slurries within a Rheological Embedding Space using Retraction-Extrusion Pressure Sensor Vectors" ;
    dcterms:abstract "Viscous materials such as inks, gels, pastes, and slurries are ubiquitous across domains like food science, smart materials, digital fabrication, and the arts. However, their dynamic and unpredictable behavior—shifting over time and in response to environmental factors—poses challenges, often requiring costly equipment for accurate rheological analysis. This paper presents a low-cost, accessible sensing routine that retracts and extrudes viscous materials through an air tube, generating sensor vectors rich in rheological data. By embedding data from 26 rheologically diverse materials into a two-dimensional space, we create RheoMaps that allow for tracking material changes over time, distinguishing concentrations, and tuning rheological behaviors. These maps offer practical benefits for detecting preparation errors, guiding material design and documentation, and providing tutorial waypoints. We further discuss how this approach can be extended to extract relational insights from sensor data, improving material literacy and manipulation across a range of applications." ;
    dcterms:identifier "3706598.3713835" ;
    chi:hasAuthor chi:person_185724, chi:person_184476 ;
    chi:proposesArtifact chi:artifact_188494_DeviceArtifact .

chi:artifact_188494_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188494 .

chi:paper_188495 rdf:type chi:Paper ;
    dcterms:title "Accurate Insights, Trustworthy Interactions: Designing a Collaborative AI-Human Multi-Agent System with Knowledge Graph for Diagnosis Prediction" ;
    dcterms:abstract "Healthcare question-answering (QA) systems can assist physicians in making medical decisions. However, traditional medical QA systems struggle with multi-agents interaction and domain-specific knowledge processing, thereby reducing the accuracy and credibility of clinical decision-making. We thus develop a multi-agent decision-making system by combining a fine-tuned medical model, biomedical knowledge graphs, and PubMed data. By summarizing the symptoms described by users, our system can automatically convene clinical experts from various fields, retrieve domain knowledge, and provide clinical decision support for users. We have validated the system performance using both technical and user-centric approaches in terms of information accuracy, user satisfaction, user trust, ect. We thus provide an effective tool for healthcare professionals to make accurate and timely decisions. Furthermore, this study also reveals new design and research opportunities, including (1) optimizing multi-agent collaboration mechanisms for more complex medical decision-making, (2) improving interaction design to enhance system transparency and explainability, and (3) expanding the system to support a broader range of medical issues and multimodal data. " ;
    dcterms:identifier "3706598.3713526" ;
    chi:hasAuthor chi:person_183516, chi:person_183204, chi:person_187236 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:ChatbotAssistedUserStudies ;
    chi:paperIncludesStudy chi:study_188495_UserStudy ;
    chi:paperIncludesStudy chi:study_188495_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188495_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188495_InterfaceArtifact .

chi:study_188495_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188495 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188495_QualitativeResult ;
    chi:reportsResult chi:result_188495_StatisticalResult .

chi:study_188495_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188495 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188495_QualitativeResult ;
    chi:reportsResult chi:result_188495_StatisticalResult .

chi:artifact_188495_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188495 .

chi:artifact_188495_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188495 .

chi:result_188495_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188495_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188496 rdf:type chi:Paper ;
    dcterms:title "Comparing Native and Non-native English Speakers’ Behaviors in Collaborative Writing through Visual Analytics" ;
    dcterms:abstract "Understanding collaborative writing dynamics between native speakers (NS) and non-native speakers (NNS) is critical for enhancing collaboration quality and team inclusivity. In this paper, we partnered with communication researchers to develop visual analytics solutions for comparing NS and NNS behaviors in 162 writing sessions across 27 teams. The primary challenges in analyzing writing behaviors are data complexity and the uncertainties introduced by automated methods. In response, we present \textsc{COALA}, a novel visual analytics tool that improves model interpretability by displaying uncertainties in author clusters, generating behavior summaries using large language models, and visualizing writing-related actions at multiple granularities. We validated the effectiveness of \textsc{COALA} through user studies with domain experts (N=2+2) and researchers with relevant experience (N=8). We present the insights discovered by participants using \textsc{COALA}, suggest features for future AI-assisted collaborative writing tools, and discuss the broader implications for analyzing collaborative processes beyond writing." ;
    dcterms:identifier "3706598.3713693" ;
    chi:hasAuthor chi:person_184845, chi:person_187270, chi:person_185107, chi:person_184574, chi:person_186991, chi:person_185351 ;
    chi:hasPrimaryTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:CollaborativeSensemaking ;
    chi:paperIncludesStudy chi:study_188496_UserStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188496_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188496_InterfaceArtifact .

chi:study_188496_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188496 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188496_QualitativeResult .

chi:artifact_188496_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188496 .

chi:artifact_188496_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188496 .

chi:result_188496_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188497 rdf:type chi:Paper ;
    dcterms:title "A Concept at Work: A Review of Motivations, Operationalizations, and Conclusions in VR Research about Presence" ;
    dcterms:abstract "Presence appears an important concept for virtual reality (VR): It is frequently measured with questionnaires, and theory and methods about it have been discussed in numerous works. Yet, it is unclear how to actually work with this concept: Why is presence important to measure, how to choose an appropriate questionnaire, and what to conclude about it based on findings? To answer these questions, we review how the concept is put to work in 288 VR papers from 2023 measuring presence with questionnaires. Our findings include that measuring presence is often motivated by another construct, such as user experience; the reasons for choosing a specific questionnaire are often weak or not reported at all; and high presence values are frequently used simply to validate an interaction technique. We propose recommendations for working with presence and formulate questions to direct future research." ;
    dcterms:identifier "3706598.3714279" ;
    chi:hasAuthor chi:person_187884, chi:person_184815, chi:person_183263, chi:person_186817 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:EmbodiedVRInteraction .

chi:result_188497_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188498 rdf:type chi:Paper ;
    dcterms:title "``You Go Through So Many Emotions Scrolling Through Instagram'': How Teens Use Instagram To Regulate Their Emotions" ;
    dcterms:abstract "Prior work has documented various ways that teens use social media to regulate their emotions. However, little is known about what these processes look like on a moment-by-moment basis. We conducted a diary study to investigate how teens (N=57, Mage = 16.3 years) used Instagram to regulate their emotions. We identified three kinds of emotionally-salient drivers that brought teens to Instagram and two types of behaviors that impacted their emotional experiences on the platform. Teens described going to Instagram to escape, to engage, and to manage the demands of the platform. Once on Instagram, their primary behaviors consisted of mindless diversions and deliberate acts. Although teens reported many positive emotional responses, the variety, unpredictability, and habitual nature of their experiences revealed Instagram to be an unreliable tool for emotion regulation (ER). We present a model of teens’ ER processes on Instagram and offer design considerations for supporting adolescent emotion regulation. " ;
    dcterms:identifier "3706598.3713844" ;
    chi:hasAuthor chi:person_187088, chi:person_183118, chi:person_187179, chi:person_182773, chi:person_184901, chi:person_187168, chi:person_188111 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:paperIncludesStudy chi:study_188498_DiaryStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement .

chi:study_188498_DiaryStudy rdf:type chi:DiaryStudy ;
    chi:isStudyReportedIn chi:paper_188498 ;
    chi:reportsResult chi:result_188498_QualitativeResult ;
    chi:involvesParticipationPattern chi:AsynchronousParticipation .

chi:result_188498_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188499 rdf:type chi:Paper ;
    dcterms:title "Tactile Emotions: Multimodal Affective Captioning with Haptics Improves Narrative Engagement for d/Deaf and Hard-of-Hearing Viewers" ;
    dcterms:abstract "This paper explores a multimodal approach for translating emotional cues present in speech, designed with Deaf and Hard-of-Hearing (DHH) individuals in mind. Prior work has focused on visual cues applied to captions, successfully conveying whether a speaker's words have a negative or positive tone (valence), but with mixed results regarding the intensity (arousal) of these emotions. We propose a novel method using haptic feedback to communicate a speaker's arousal levels through vibrations on a wrist-worn device. In a formative study with 16 DHH participants, we tested six haptic patterns and found that participants preferred single per-word vibrations at 75 Hz to encode arousal. In a follow-up study with 27 DHH participants, this pattern was paired with visual cues, and narrative engagement with audio-visual content was measured. Results indicate that combining haptics with visuals significantly increased engagement compared to a conventional captioning baseline and a visuals-only affective captioning style." ;
    dcterms:identifier "3706598.3713304" ;
    chi:hasAuthor chi:person_183769, chi:person_187978, chi:person_187239, chi:person_187278, chi:person_183856, chi:person_187537, chi:person_185649 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188499_UserStudy ;
    chi:paperIncludesStudy chi:study_188499_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188499_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188499_InterfaceArtifact .

chi:study_188499_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188499 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188499_StatisticalResult .

chi:study_188499_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188499 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188499_StatisticalResult .

chi:artifact_188499_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188499 .

chi:artifact_188499_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188499 .

chi:result_188499_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188500 rdf:type chi:Paper ;
    dcterms:title "Adaptive Electrical Muscle Stimulation Improves Muscle Memory" ;
    dcterms:abstract "Electrical muscle stimulation (EMS) has been leveraged to assist in learning motor skills by actuating the user’s muscles. However, existing systems provide static demonstration—actuating the correct movements, regardless of the user’s learning progress. Instead, we contrast two versions of a piano-tutoring system: a conventional EMS setup that moves the participant’s fingers to play the sequence of movements correctly, and a novel adaptive-EMS system that changes its guidance strategy based on the participant’s performance. The adaptive-EMS dynamically adjusts its guidance: (1) demonstrate by playing the entire sequence when errors are frequent; (2) correct by lifting incorrect fingers and actuating the correct one when errors are moderate; and (3) warn by lifting incorrect fingers when errors are low. We found that adaptive-EMS improved learning outcomes (recall) and was preferred by participants. We believe this approach could inspire new types of physical tutoring systems that promote adaptive over static guidance." ;
    dcterms:identifier "3706598.3713676" ;
    chi:hasAuthor chi:person_187625, chi:person_187521, chi:person_184223, chi:person_182711, chi:person_184291, chi:person_183578 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:paperIncludesStudy chi:study_188500_UserStudy ;
    chi:paperIncludesStudy chi:study_188500_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188500_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188500_InputDeviceArtifact .

chi:study_188500_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188500 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188500_StatisticalResult ;
    chi:reportsResult chi:result_188500_QualitativeResult .

chi:study_188500_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188500 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188500_StatisticalResult ;
    chi:reportsResult chi:result_188500_QualitativeResult .

chi:artifact_188500_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188500 .

chi:artifact_188500_InputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188500 .

chi:result_188500_StatisticalResult rdf:type chi:StatisticalResult .

chi:result_188500_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188501 rdf:type chi:Paper ;
    dcterms:title "Diagrammatization and Abduction to Improve AI Interpretability With Domain-Aligned Explanations for Medical Diagnosis" ;
    dcterms:abstract "Many visualizations have been developed for explainable AI (XAI), but they often require further reasoning by users to interpret. Investigating XAI for high-stakes medical diagnosis, we propose improving domain alignment with diagrammatic and abductive reasoning to reduce the interpretability gap. We developed DiagramNet to predict cardiac diagnoses from heart auscultation, select the best-fitting hypothesis based on criteria evaluation, and explain with clinically-relevant murmur diagrams. The ante-hoc interpretable model leverages domain-relevant ontology, representation, and reasoning process to increase trust in expert users. In modeling studies, we found that DiagramNet not only provides faithful murmur shape explanations, but also has better performance than baseline models. We demonstrate the interpretability and trustworthiness of diagrammatic, abductive explanations in a qualitative user study with medical students, showing that clinically-relevant, diagrammatic explanations are preferred over technical saliency map explanations. This work contributes insights into providing domain-aligned explanations for user-centric XAI in complex domains." ;
    dcterms:identifier "3706598.3714058" ;
    chi:hasAuthor chi:person_185122, chi:person_187564, chi:person_185794, chi:person_185417 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:CollaborativeVisualizationTools ;
    chi:paperIncludesStudy chi:study_188501_BaselineComparisonStudy ;
    chi:paperIncludesStudy chi:study_188501_UserStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188501_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188501_InterfaceArtifact .

chi:study_188501_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188501 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188501_QualitativeResult ;
    chi:reportsResult chi:result_188501_StatisticalResult .

chi:study_188501_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188501 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188501_QualitativeResult ;
    chi:reportsResult chi:result_188501_StatisticalResult .

chi:artifact_188501_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188501 .

chi:artifact_188501_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188501 .

chi:result_188501_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188501_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188502 rdf:type chi:Paper ;
    dcterms:title "Encountering Robotic Art: The Social, Material, and Temporal Processes of Creation with Machines" ;
    dcterms:abstract "Robots extend beyond the tools of productivity; they also contribute to creativity. While typically defined as utility-driven technologies designed for productive or social settings, the role of robots in creative settings remains underexplored. This paper examines how robots participate in artistic creation. Through semi-structured interviews with robotic artists, we analyze the impact of robots on artistic processes and outcomes. We identify the critical roles of social interaction, material properties, and temporal dynamics in facilitating creativity. Our findings reveal that creativity emerges from the co-constitution of artists, robots, and audiences within spatial-temporal dimensions. Based on these insights, we propose several implications for socially informed, material-attentive, and process-oriented approaches to creation with computing systems. These approaches can inform the domains of HCI, including media and art creation, craft, digital fabrication, and tangible computing." ;
    dcterms:identifier "3706598.3713327" ;
    chi:hasAuthor chi:person_183030, chi:person_186462, chi:person_183426 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:paperIncludesStudy chi:study_188502_InterviewStudy ;
    chi:proposesArtifact chi:artifact_188502_DeviceArtifact .

chi:study_188502_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188502 ;
    chi:reportsResult chi:result_188502_QualitativeResult .

chi:artifact_188502_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188502 .

chi:result_188502_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188503 rdf:type chi:Paper ;
    dcterms:title "Design Patterns for the Common Good: Building Better Technologies Using the Wisdom of Virtue Ethics" ;
    dcterms:abstract "Virtue ethics is a philosophical tradition that emphasizes the cultivation of virtues in achieving the common good. It has been suggested to be an effective framework for envisioning more ethical technology, yet previous work on virtue ethics and technology design has remained at theoretical recommendations. Therefore, we propose an approach for identifying user experience design patterns that embody particular virtues to more concretely articulate virtuous technology designs. As a proof of concept for our approach, we documented seven design patterns for social media that uphold the virtues of Catholic Social Teaching. We interviewed 24 technology researchers and industry practitioners to evaluate these patterns. We found that overall the patterns enact the virtues they were identified to embody; our participants valued that the patterns fostered intentional conversations and personal connections. We pave a path for technology professionals to incorporate diverse virtue traditions into the development of technologies that support human flourishing." ;
    dcterms:identifier "3706598.3713546" ;
    chi:hasAuthor chi:person_186553, chi:person_182707, chi:person_186376, chi:person_184297 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness:ParticipatoryEthicsMethods ;
    chi:aboutTopic chi:EthicsPrivacyFairness:ParticipatoryEthicsMethods ;
    chi:paperIncludesStudy chi:study_188503_InterviewStudy ;
    chi:proposesArtifact chi:artifact_188503_InterfaceArtifact .

chi:study_188503_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188503 ;
    chi:reportsResult chi:result_188503_QualitativeResult .

chi:artifact_188503_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188503 .

chi:result_188503_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188505 rdf:type chi:Paper ;
    dcterms:title "Unlocking Scientific Concepts: How Effective Are LLM-Generated Analogies for Student Understanding and Classroom Practice?" ;
    dcterms:abstract "Teaching scientific concepts is essential but challenging, and analogies help students connect new concepts to familiar ideas. Advancements in large language models (LLMs) enable generating analogies, yet their effectiveness in education remains underexplored. In this paper, we first conducted a two-stage study involving high school students and teachers to assess the effectiveness of LLM-generated analogies in biology and physics through a controlled in-class test and a classroom field study. Test results suggested that LLM-generated analogies could enhance student understanding particularly in biology, but require teachers' guidance to prevent over-reliance and overconfidence.  Classroom experiments suggested that teachers could refine LLM-generated analogies to their satisfaction and inspire new analogies from generated ones, encouraged by positive classroom feedback and homework performance boosts. Based on findings, we developed and evaluated a practical system to help teachers generate and refine teaching analogies. We discussed future directions for developing and evaluating LLM-supported teaching and learning by analogy." ;
    dcterms:identifier "3706598.3714313" ;
    chi:hasAuthor chi:person_183079, chi:person_184094, chi:person_186477, chi:person_183584, chi:person_186107, chi:person_183310 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188505_FieldStudy ;
    chi:paperIncludesStudy chi:study_188505_BaselineComparisonStudy ;
    chi:paperIncludesStudy chi:study_188505_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188505_SoftwareArtifact .

chi:study_188505_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188505 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188505_QualitativeResult ;
    chi:reportsResult chi:result_188505_StatisticalResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:study_188505_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188505 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188505_QualitativeResult ;
    chi:reportsResult chi:result_188505_StatisticalResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:study_188505_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188505 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188505_QualitativeResult ;
    chi:reportsResult chi:result_188505_StatisticalResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:artifact_188505_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188505 .

chi:result_188505_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188505_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188507 rdf:type chi:Paper ;
    dcterms:title "Investigating LLM-Driven Curiosity in Human-Robot Interaction" ;
    dcterms:abstract "Integrating curious behavior traits into robots is essential for them to learn and adapt to new tasks over their lifetime and to enhance human-robot interaction. However, the effects of robots expressing curiosity on user perception, user interaction, and user experience in collaborative tasks are unclear. In this work, we present a Multimodal Large Language Model-based system that equips a robot with non-verbal and verbal curiosity traits. We conducted a user study ($N=20$) to investigate how these traits modulate the robot's behavior and the users' impressions of sociability and quality of interaction. Participants prepared cocktails or pizzas with a robot, which was either curious or non-curious. Our results show that we could create user-centric curiosity, which users perceived as more human-like, inquisitive, and autonomous while resulting in a longer interaction time. We contribute a set of design recommendations allowing system designers to take advantage of curiosity in collaborative tasks." ;
    dcterms:identifier "3706598.3713923" ;
    chi:hasAuthor chi:person_183606, chi:person_184537, chi:person_185160, chi:person_186490, chi:person_183337, chi:person_186917, chi:person_187145, chi:person_185517 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:ChatbotAssistedUserStudies ;
    chi:paperIncludesStudy chi:study_188507_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188507_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188507_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188507_InterfaceArtifact .

chi:study_188507_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188507 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188507_QualitativeResult ;
    chi:reportsResult chi:result_188507_StatisticalResult .

chi:artifact_188507_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188507 .

chi:artifact_188507_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188507 .

chi:artifact_188507_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188507 .

chi:result_188507_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188507_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188508 rdf:type chi:Paper ;
    dcterms:title "Sequential Visual Cues from Gaze Patterns: Reasoning Assistance for Bar Charts" ;
    dcterms:abstract "Even for well-studied visual reasoning tasks such as those performed on bar charts, little is known about the cognitive strategies users adopt to solve them. Guidance systems that support users in learning visual reasoning require information on successful strategies to help unsuccessful users improve or change their strategies. We introduce the guidance paradigm of sequential visual cues (SVCs), accompanied by a differential pattern mining approach that determines relevant visual attention patterns from gaze data, and exemplified for bar charts. The novel feature of SVCs is to give hints on critical fragments of successful strategies, guiding users where to look in a visualization and in which order, but not what to do with this information. Results from an empirical study (N=30) show how critical patterns of successful and unsuccessful strategies differ for various bar chart tasks. In a qualitative survey (N=5), we explore how to surface relevant gaze patterns as SVCs." ;
    dcterms:identifier "3706598.3713352" ;
    chi:hasAuthor chi:person_183502, chi:person_187457, chi:person_183681, chi:person_182724 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:CollaborativeVisualizationTools ;
    chi:paperIncludesStudy chi:study_188508_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188508_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188508_SoftwareArtifact .

chi:study_188508_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188508 ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188508_QualitativeResult ;
    chi:reportsResult chi:result_188508_StatisticalResult .

chi:artifact_188508_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188508 .

chi:artifact_188508_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188508 .

chi:result_188508_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188508_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188509 rdf:type chi:Paper ;
    dcterms:title "Rethinking Lived Experience in Chronic Illness: Navigating Bodily Doubt with Consumer Technology in Atrial Fibrillation Self-Care" ;
    dcterms:abstract "Consumer technology is increasingly used to support the self-care of atrial fibrillation (AF), a chronic heart condition that affects physical, emotional, and mental health due to its unpredictability, symptoms, and complications. Through interviews with 29 adults self-tracking while living with AF, we found that consumer technology enabled participants to outsource bodily awareness to their 'digitised heart,' facilitating innovative pill-in-pocket interventions and empowering negotiation in shared decision-making. Drawing on phenomenology, we introduce 'Bodily Doubt' to explain how uncertainty about the body shapes the use of technology in chronic illness and how the use of technology influences uncertainty. Technology mediates 'Bodily Doubt' both by providing reassurance and exacerbating it, particularly when technology fails to adapt to disease progression. Our findings have implications for understanding how technology influences the lived experience of illness, challenging experiential concepts of lived experience in self-tracking and design that foregrounds the experience of the lived body." ;
    dcterms:identifier "3706598.3713326" ;
    chi:hasAuthor chi:person_183202, chi:person_185354, chi:person_187858, chi:person_184215 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:SelfReflectionAndBehaviorChange ;
    chi:paperIncludesStudy chi:study_188509_InterviewStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188509_SoftwareArtifact .

chi:study_188509_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188509 ;
    chi:reportsResult chi:result_188509_QualitativeResult .

chi:artifact_188509_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188509 .

chi:result_188509_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188510 rdf:type chi:Paper ;
    dcterms:title "Exploring Multimodal Generative AI for Education through Co-design Workshops with Students" ;
    dcterms:abstract "Multimodal large language models (MLLMs) are Generative AI models that take different modalities such as text, audio, and video as input and generate appropriate multimodal output. Since such models will be integrated into future educational tools, a human-centered design approach that takes students’ perspectives into account is essential while designing such applications.  This paper describes two co-design workshops which were conducted with 79 student groups to examine how they design and prototype future educational tools integrated with MLLMs. Through various activities in the workshops, students discussed relevant educational problems, created journey maps, storyboards and low fidelity prototypes for their applications, and evaluated their applications based on relevant design principles. We found that students’ applications used MLLMs for important learning environment design features such as multimodal content creation, personalization, and feedback. Based on these findings, we discuss future research directions for the design of multimodality in generative AI educational applications." ;
    dcterms:identifier "3706598.3714146" ;
    chi:hasAuthor chi:person_187799, chi:person_184371, chi:person_183690 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188510_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188510_InterfaceArtifact .

chi:study_188510_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188510 ;
    chi:reportsResult chi:result_188510_QualitativeResult .

chi:artifact_188510_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188510 .

chi:result_188510_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188511 rdf:type chi:Paper ;
    dcterms:title "Understanding \"Mutes\" in Social Virtual Reality" ;
    dcterms:abstract "In social Virtual Reality (VR), particularly within VRChat, a significant group of users often referred to as ``mutes'' refrain from voice communication. This study analyzes 4212 discussion entries, including both original submissions and comments, from the r/VRchat subreddit to explore the experiences and reasons behind this practice. Our findings indicate that muteness is an integral aspect of social VR culture, yet mute users face challenges, including exposure to abusive behaviors and communication barriers in a fast-paced environment. Factors of social VR like harassment, heightened social anxiety from the immersive presence, and the complexities of identity management can discourage voice communication, leading many to adopt ``muteness'' as a response. This behavior can be seen within the broader context of social disability, challenging normative communication assumptions. We highlight the risks of generalizing marginalized communities and emphasize the need for further research to address and support the unique needs of these groups in social VR spaces. " ;
    dcterms:identifier "3706598.3714244" ;
    chi:hasAuthor chi:person_183818, chi:person_183186, chi:person_187240, chi:person_183039, chi:person_183829 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:aboutTopic chi:OnlineSelfDisclosureAndIdentity ;
    chi:aimsAtGoal chi:EnhanceAccessibility .

chi:result_188511_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188512 rdf:type chi:Paper ;
    dcterms:title "Continual Human-in-the-Loop Optimization" ;
    dcterms:abstract "Optimal input settings vary across users due to differences in motor abilities and personal preferences, which are typically addressed by manual tuning or calibration. Although human-in-the-loop optimization has the potential to identify optimal settings during use, it is rarely applied due to its long optimization process. A more efficient approach would continually leverage data from previous users to accelerate optimization, exploiting shared traits while adapting to individual characteristics. We introduce the concept of Continual Human-in-the-Loop Optimization and a Bayesian optimization-based method that leverages a Bayesian-neural-network surrogate model to capture population-level characteristics while adapting to new users. We propose a generative replay strategy to mitigate catastrophic forgetting. We demonstrate our method by optimizing virtual reality keyboard parameters for text entry using direct touch, showing reduced adaptation times with a growing user base. Our method opens the door for next-generation personalized input systems that improve with accumulated experience. " ;
    dcterms:identifier "3706598.3713603" ;
    chi:hasAuthor chi:person_184725, chi:person_185247, chi:person_187140, chi:person_183083, chi:person_183556 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:PointingAndSelectionPerformance ;
    chi:paperIncludesStudy chi:study_188512_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188512_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188512_InputDeviceArtifact .

chi:study_188512_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188512 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188512_StatisticalResult .

chi:artifact_188512_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188512 .

chi:artifact_188512_InputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188512 .

chi:result_188512_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188513 rdf:type chi:Paper ;
    dcterms:title "Designing and Evaluating a VR Boxing Experience with Blind People" ;
    dcterms:abstract "Virtual Reality (VR) offers immersive experiences through advanced interaction mechanisms and rich sensory stimuli but is often inaccessible to blind people due to its over-reliance on visual feedback. While prior work has investigated specific aspects of VR accessibility, there is little knowledge on how to design full, feature-rich VR experiences accessible to blind people. This paper presents the design and evaluation of a VR Boxing experience, developed through participatory design with an ex-professional boxer who is now blind. A user study with 15 blind participants explored their perceptions of the three-mode experience developed - Heavy Bag Training, Coach Training, and Combat - to inform the design of accessible VR experiences. Our findings highlight the importance of combining natural movement, rich auditory feedback, and well-timed guidance that also fosters user independence. Furthermore, they demonstrate the value of structured progression in complexity, while also opening opportunities for engaging spatial awareness and coordination training. " ;
    dcterms:identifier "3706598.3713374" ;
    chi:hasAuthor chi:person_185091, chi:person_184622, chi:person_183369, chi:person_184118, chi:person_185039, chi:person_184478, chi:person_185100 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188513_UserStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188513_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188513_InterfaceArtifact .

chi:study_188513_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188513 ;
    chi:reportsResult chi:result_188513_QualitativeResult .

chi:artifact_188513_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188513 .

chi:artifact_188513_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188513 .

chi:result_188513_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188514 rdf:type chi:Paper ;
    dcterms:title "\"Ethics is not neutral\": Understanding Ethical and Responsible AI Design from the Lenses of Black Youth" ;
    dcterms:abstract "The rise of generative AI has brought a host of challenges for historically marginalized groups, including increased surveillance, AI-mediated racism, and algorithmic inequity. While stakeholders emphasize ethical and responsible AI that is safe, anti-discriminatory, and  \"protects human dignity\", the centrality of anti-Blackness in the design, development, and deployment of AI systems coupled with race-evasive approaches to defining and advancing ethical, equitable, and ‘human-centered’ technologies have exacerbated racial oppression. We present three case studies of speculative technologies designed by Black youth in a college bridge, summer course that examine ethical and responsible AI in their everyday lives. From a bottom-up approach, we infringe upon this broader discourse to provide an initial grounding of responsible and ethical AI as well as discuss the criticality of Black, historically anchored, culturally-situated lenses to offer justice-oriented design principles that can guide the teaching, learning, and design of technology. " ;
    dcterms:identifier "3706598.3713510" ;
    chi:hasAuthor chi:person_187147, chi:person_185456, chi:person_184049, chi:person_188094 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness:AlgorithmicFairnessAndBias ;
    chi:aboutTopic chi:EthicsPrivacyFairness:AlgorithmicFairnessAndBias ;
    chi:paperIncludesStudy chi:study_188514_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188514_SoftwareArtifact .

chi:study_188514_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188514 ;
    chi:reportsResult chi:result_188514_QualitativeResult .

chi:artifact_188514_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188514 .

chi:result_188514_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188515 rdf:type chi:Paper ;
    dcterms:title "LuxKnit: Fabricating Interactive Display Textiles Integrated with Sensing by Machine Knitting" ;
    dcterms:abstract "Displays are crucial in modern smart devices, conveying information visually. Wearable displays have gained increasing interest due to their ability to integrate into everyday environments while maintaining an unobtrusive presence. Textile-based displays, in particular, offer extra advantages of comfort, lightness, and natural feel. We present LuxKnit, a design and fabrication pipeline for textile-based displays with integrated sensing using digital machine knitting. LuxKnit employs electroluminescent (EL) yarn for displays and conductive yarn for sensing. We offer an interactive design interface for users to customize the display’s color, shape, position, and size. We evaluate display luminance and sensing performance across various knitted layouts, deformations, and conductive yarn types. LuxKnit offers a scalable, deformable, stretchable, washable, and interactive display textile system with applications in assistive wearables, interactive educational interfaces, interactive input devices, and common display formats like the seven-segment display." ;
    dcterms:identifier "3706598.3713860" ;
    chi:hasAuthor chi:person_184888, chi:person_185876, chi:person_182848, chi:person_186695, chi:person_183250, chi:person_186912, chi:person_184233 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:paperIncludesStudy chi:study_188515_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188515_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188515_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188515_OutputDeviceArtifact ;
    chi:proposesArtifact chi:artifact_188515_InputDeviceArtifact ;
    chi:proposesArtifact chi:artifact_188515_SoftwareArtifact .

chi:study_188515_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188515 ;
    chi:reportsResult chi:result_188515_StatisticalResult .

chi:artifact_188515_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188515 .

chi:artifact_188515_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188515 .

chi:artifact_188515_OutputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188515 .

chi:artifact_188515_InputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188515 .

chi:artifact_188515_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188515 .

chi:result_188515_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188516 rdf:type chi:Paper ;
    dcterms:title "Public Opinions About Copyright for AI-Generated Art: The Role of Egocentricity, Competition, and Experience" ;
    dcterms:abstract "Breakthroughs in generative AI (GenAI) have fueled debates concerning the artistic and legal status of AI-generated creations. We investigate laypeople's perceptions (N=432) of AI-generated art through the lens of copyright law. We study lay judgments of GenAI images concerning several copyright-related factors and capture people's opinions of who should be the authors and rights-holders of AI-generated images. To do so, we held an incentivized AI art competition in which some participants used a GenAI model to create art while others evaluated these images. We find that participants believe creativity and effort, but not skills, are needed to create AI-generated art. Participants were most likely to attribute authorship and copyright to the AI model's users and to the artists whose creations were used for training. We find evidence of egocentric effects: participants favored their own art with respect to quality, creativity, and effort---particularly when these assessments determined real monetary awards." ;
    dcterms:identifier "3706598.3713338" ;
    chi:hasAuthor chi:person_187478, chi:person_182952, chi:person_187234 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:DataDisclosureAndConsent ;
    chi:paperIncludesStudy chi:study_188516_UserStudy ;
    chi:paperIncludesStudy chi:study_188516_QuantitativeStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188516_SoftwareArtifact .

chi:study_188516_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188516 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188516_StatisticalResult .

chi:study_188516_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188516 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188516_StatisticalResult .

chi:artifact_188516_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188516 .

chi:result_188516_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188517 rdf:type chi:Paper ;
    dcterms:title "Collaborative Health-Tracking Technologies for Children and Parents: A Review of Current Studies and Directions for Future Research" ;
    dcterms:abstract "Collaborative health-tracking technologies for children and parents have gained significant attention in recent years in HCI. This review examines the current state of these technologies by analyzing 29 studies screened from 15,973 search results across three databases. Our findings revealed three primary goals in these technologies: promoting family health, improving children’s health through child-parent co-tracking, and fostering children’s independence in self-tracking. For each goal, we examined child-parent roles, data types collected, and features that facilitate or hinder collaboration. Our findings highlight key directions for future research, including designing adaptable technologies to reflect evolving child-parent roles, exploring different technologies and tracking topics that impact child-parent dynamics, involving children in the system design stage to enhance collaborative features, and studying diverse populations with varied family characteristics. These insights aim to guide the creation of more effective and inclusive collaborative health-tracking technologies for children and parents." ;
    dcterms:identifier "3706598.3713596" ;
    chi:hasAuthor chi:person_186151, chi:person_186984, chi:person_184892, chi:person_186934, chi:person_182866, chi:person_187943 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:SupportTechnologiesForVulnerableUsers ;
    chi:aimsAtGoal chi:SupportCollaboration .

chi:result_188517_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188518 rdf:type chi:Paper ;
    dcterms:title "CoExploreDS: Framing and Advancing Collaborative Design Space Exploration Between Human and AI" ;
    dcterms:abstract "In product design, effective design space exploration (DSE) is crucial for generating high-quality design ideas, requiring designers to possess broad knowledge and balance various constraints. As large-scale models thrive, AI has become an indispensable design collaborator by providing cross-domain knowledge and assistance with complex reasoning. To facilitate collaborative DSE between designers and AI, we frame and advance the design process through the problem-solution co-evolution model and design reasoning methods. A formative study was conducted to identify key strategies for the implementation. Then we developed CoExploreDS, a system that formalizes problems and solutions emerging in the human-AI collaborative design space into nodes. Using four reasoning methods, this system dynamically generates suggestions based on the ongoing design process. User studies confirmed that CoExploreDS significantly improves design quality and the human-AI collaboration experience." ;
    dcterms:identifier "3706598.3713869" ;
    chi:hasAuthor chi:person_183045, chi:person_183977, chi:person_187627, chi:person_183043, chi:person_188081, chi:person_187109, chi:person_184319 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:CollaborativeVisualizationTools ;
    chi:paperIncludesStudy chi:study_188518_UserStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188518_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188518_InterfaceArtifact .

chi:study_188518_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188518 ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:reportsResult chi:result_188518_QualitativeResult ;
    chi:reportsResult chi:result_188518_StatisticalResult .

chi:artifact_188518_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188518 .

chi:artifact_188518_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188518 .

chi:result_188518_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188518_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188519 rdf:type chi:Paper ;
    dcterms:title "Relational AI: Facilitating Intergroup Cooperation with Socially Aware Conversational Support" ;
    dcterms:abstract "Cooperation is challenging when group identities are involved. While people readily cooperate with in-group members, they struggle to build trust with out-group members. This study examines how text suggestions generated by Large Language Models (LLMs) can mitigate in-group-out-group bias and facilitate intergroup cooperation through conversations. We conducted an experiment with 482 participants who communicated with either in-group partners sharing their views or out-group partners with differing views, based on a preliminary survey. Participants received either \"personalized\" message suggestions aligned with their own views and conversation styles or \"relational\" suggestions using conversation styles tailored to whether their partner was in-group or out-group. Following the conversations, participants engaged in a cooperation game designed to measure trust behaviorally. Our results show that while personalized assistance widened the cooperation gap, relational assistance significantly improved out-group cooperation to match in-group levels. We discuss design implications for integrating social awareness into AI-driven conversational support systems." ;
    dcterms:identifier "3706598.3713757" ;
    chi:hasAuthor chi:person_186825, chi:person_183001, chi:person_183850 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialSupportAndPeerChatbots ;
    chi:paperIncludesStudy chi:study_188519_UserStudy ;
    chi:paperIncludesStudy chi:study_188519_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188519_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188519_InterfaceArtifact .

chi:study_188519_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188519 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188519_StatisticalResult .

chi:study_188519_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188519 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188519_StatisticalResult .

chi:artifact_188519_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188519 .

chi:artifact_188519_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188519 .

chi:result_188519_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188520 rdf:type chi:Paper ;
    dcterms:title "Understanding the Dynamics in Deploying AI-Based Content Creation Support Tools in Broadcasting Systems - Benefits, Challenges, and Directions" ;
    dcterms:abstract "Recent advancements in generative artificial intelligence (AI) are profoundly impacting the broadcasting industry. While generative AI shows promise in supporting broadcasting professionals, its practical workflow integration remains underexplored. In this study, we conducted a user-focused investigation to understand how AI-based content creation support tools are being adopted and perceived in South Korean broadcasting stations. We used the AI Editing Assistant, an AI-powered post-production support tool, as a research probe. Through in-depth interviews with 37 diverse participants—including directors, editors, producers, developers, and executives—we discovered that generative AI significantly enhances production efficiency and unlocks new creative possibilities. However, we identified challenges such as lack of user-centered approach, demanding nature of broadcasting workflows, and professionals' low trust in AI technologies hinders widespread adoption. Based on our findings, we propose  implications, considerations, and guidelines for integrating generative AI into broadcasting practices, emphasizing improved multi-stakeholder communication and collaboration for effective and sustainable AI adoption. " ;
    dcterms:identifier "3706598.3713532" ;
    chi:hasAuthor chi:person_183984, chi:person_186098, chi:person_187312, chi:person_184944 ;
    chi:hasPrimaryTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:paperIncludesStudy chi:study_188520_InterviewStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188520_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188520_InterfaceArtifact .

chi:study_188520_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188520 ;
    chi:reportsResult chi:result_188520_QualitativeResult .

chi:artifact_188520_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188520 .

chi:artifact_188520_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188520 .

chi:result_188520_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188521 rdf:type chi:Paper ;
    dcterms:title "From Awareness to Action: The Effects of Experiential Learning on Educating Users about Dark Patterns" ;
    dcterms:abstract "Dark patterns (DPs) refer to unethical user interface designs that deceive users into making unintended decisions, compromising their privacy, safety, financial security, and more. Prior research has mainly focused on defining and classifying DPs, as well as assessing their impact on users, while legislative and technical efforts to mitigate them remain limited. Consequently, users are still exposed to DP risks, making it urgent to educate them on avoiding these harms. However, there has been little focus on developing educational interventions for DP awareness. This study addresses this gap by introducing DPTrek, an experiential learning (EL) platform that educates users through simulated real-world DP cases. Both qualitative and quantitative evaluations show the effectiveness of DPTrek in helping users identify and manage DPs. The study also offers insights for future DP education and research, highlighting challenges such as user-unfriendly taxonomies and the lack of practical mitigation solutions." ;
    dcterms:identifier "3706598.3713493" ;
    chi:hasAuthor chi:person_183853, chi:person_186159, chi:person_186913, chi:person_184315 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188521_UserStudy ;
    chi:paperIncludesStudy chi:study_188521_QualitativeStudy ;
    chi:paperIncludesStudy chi:study_188521_QuantitativeStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188521_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188521_InterfaceArtifact .

chi:study_188521_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188521 ;
    chi:reportsResult chi:result_188521_QualitativeResult ;
    chi:reportsResult chi:result_188521_StatisticalResult .

chi:study_188521_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188521 ;
    chi:reportsResult chi:result_188521_QualitativeResult ;
    chi:reportsResult chi:result_188521_StatisticalResult .

chi:study_188521_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188521 ;
    chi:reportsResult chi:result_188521_QualitativeResult ;
    chi:reportsResult chi:result_188521_StatisticalResult .

chi:artifact_188521_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188521 .

chi:artifact_188521_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188521 .

chi:result_188521_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188521_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188523 rdf:type chi:Paper ;
    dcterms:title "AI-Instruments: Embodying Prompts as Instruments to Abstract & Reflect Graphical Interface Commands as General-Purpose Tools" ;
    dcterms:abstract "Chat-based prompts respond with verbose linear-sequential texts, making it difficult to explore and refine ambiguous intents, back up and reinterpret, or shift directions in creative AI-assisted design work. AI-Instruments instead embody \"prompts\" as interface objects via three key principles: (1) Reification of user-intent as reusable direct-manipulation instruments; (2) Reflection of multiple interpretations of ambiguous user-intents (Reflection-in-intent) as well as the range of AI-model responses (Reflection-in-response) to inform design \"moves\" towards a desired result; and (3) Grounding to instantiate an instrument from an example, result, or extrapolation directly from another instrument. Further, AI-Instruments leverage LLM’s to suggest, vary, and refine new instruments, enabling a system that goes beyond hard-coded functionality by generating its own instrumental controls from content.  We demonstrate four technology probes, applied to image generation, and qualitative insights from twelve participants, showing how AI-Instruments address challenges of intent formulation, steering via direct manipulation, and non-linear iterative workflows to reflect and resolve ambiguous intents. " ;
    dcterms:identifier "3706598.3714259" ;
    chi:hasAuthor chi:person_182672, chi:person_183488, chi:person_183338, chi:person_186041, chi:person_184321, chi:person_183688, chi:person_185253, chi:person_185262, chi:person_185827 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:paperIncludesStudy chi:study_188523_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188523_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188523_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188523_SoftwareArtifact .

chi:study_188523_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188523 ;
    chi:reportsResult chi:result_188523_QualitativeResult .

chi:study_188523_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188523 ;
    chi:reportsResult chi:result_188523_QualitativeResult .

chi:artifact_188523_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188523 .

chi:artifact_188523_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188523 .

chi:result_188523_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188524 rdf:type chi:Paper ;
    dcterms:title "(Mis)Communicating with our AI Systems" ;
    dcterms:abstract "Explainable Artificial Intelligence (XAI) is a discipline concerned with understanding predictions of AI systems. What is ultimately desired from XAI methods is for an AI system to link its input and output in a way that is interpretable with reference to the environment in which it is applied. A variety of methods have been proposed, but we argue in this paper that what has yet to be considered is miscommunication: the failure to convey and/or interpret an explanation accurately. XAI can be seen as a communication process and thus looking at how humans explain things to each other can provide guidance to its application and evaluation. We motivate a specific model of communication to help identify essential components of the process, and show the critical importance for establishing common ground, i.e., shared mutual knowledge, beliefs, and assumptions of the participants communicating." ;
    dcterms:identifier "3706598.3713771" ;
    chi:hasAuthor chi:person_184434, chi:person_183308 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188524_SoftwareArtifact .

chi:artifact_188524_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188524 .

chi:result_188524_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188525 rdf:type chi:Paper ;
    dcterms:title "SketchFlex: Facilitating Spatial-Semantic Coherence in Text-to-Image Generation with Region-Based Sketches" ;
    dcterms:abstract "Text-to-image models can generate visually appealing images from text descriptions.  Efforts have been devoted to improving model controls with prompt tuning and spatial conditioning.  However, our formative study highlights the challenges for non-expert users in crafting appropriate prompts and specifying fine-grained spatial conditions (e.g., depth or canny references) to generate semantically cohesive images, especially when multiple objects are involved.  In response, we introduce SketchFlex, an interactive system designed to improve the flexibility of spatially conditioned image generation using rough region sketches.  The system automatically infers user prompts with rational descriptions within a semantic space enriched by crowd-sourced object attributes and relationships.  Additionally, SketchFlex refines users' rough sketches into canny-based shape anchors, ensuring the generation quality and alignment of user intentions.  Experimental results demonstrate that SketchFlex achieves more cohesive image generations than end-to-end models, meanwhile significantly reducing cognitive load and better matching user intentions compared to region-based generation baseline." ;
    dcterms:identifier "3706598.3713801" ;
    chi:hasAuthor chi:person_184573, chi:person_187205, chi:person_187405, chi:person_186195 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:paperIncludesStudy chi:study_188525_UserStudy ;
    chi:paperIncludesStudy chi:study_188525_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:ReduceCognitiveLoad ;
    chi:proposesArtifact chi:artifact_188525_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188525_InterfaceArtifact .

chi:study_188525_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188525 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188525_StatisticalResult .

chi:study_188525_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188525 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188525_StatisticalResult .

chi:artifact_188525_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188525 .

chi:artifact_188525_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188525 .

chi:result_188525_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188526 rdf:type chi:Paper ;
    dcterms:title "Persuasion in Pixels and Prose: The Effects of Emotional Language and Visuals in Agent Conversations on Decision-Making" ;
    dcterms:abstract "The growing sophistication of Large Language Models allows conversational agents (CAs) to engage users in increasingly personalized and targeted conversations. While users may vary in their receptiveness to CA persuasion, stylistic elements and agent personalities can be adjusted on the fly. Combined with image generation models that create context-specific realistic visuals, CAs have the potential to influence user behavior and decision making. We investigate the effects of linguistic and visual elements used by CAs on user perception and decision making in a charitable donation context with an online experiment (n=344). We find that while CA attitude influenced trust, it did not affect donation behavior. Visual primes played no role in shaping trust, though their absence resulted in higher donations and situational empathy. Perceptions of competence and situational empathy were potential predictors of donation amounts. We discuss the complex interplay of user and CA characteristics and the fine line between benign behavior signaling and manipulation." ;
    dcterms:identifier "3706598.3713579" ;
    chi:hasAuthor chi:person_186199, chi:person_183300, chi:person_187241, chi:person_185732 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness:TargetedEthicsInterventions ;
    chi:aboutTopic chi:EthicsPrivacyFairness:TargetedEthicsInterventions ;
    chi:paperIncludesStudy chi:study_188526_UserStudy ;
    chi:paperIncludesStudy chi:study_188526_QuantitativeStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188526_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188526_InterfaceArtifact .

chi:study_188526_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188526 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188526_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:study_188526_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188526 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188526_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:artifact_188526_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188526 .

chi:artifact_188526_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188526 .

chi:result_188526_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188527 rdf:type chi:Paper ;
    dcterms:title "CPVis: Evidence-based Multimodal Learning Analytics for Evaluation in Collaborative Programming" ;
    dcterms:abstract "As programming education becomes more widespread, many college students from non-computer science backgrounds begin learning programming. Collaborative programming emerges as an effective method for instructors to support novice students in developing coding and teamwork abilities. However, due to limited class time and attention, instructors face challenges in monitoring and evaluating the progress and performance of groups or individuals. To address this issue, we collect multimodal data from real-world settings and develop CPVis, an interactive visual analytics system designed to assess student collaboration dynamically. Specifically, CPVis enables instructors to evaluate both group and individual performance efficiently. CPVis employs a novel flower-based visual encoding to represent performance and provides time-based views to capture the evolution of collaborative behaviors. A within-subject experiment (N=22), comparing CPVis with two baseline systems, reveals that users gain more insights, find the visualization more intuitive, and report increased confidence in their assessments of collaboration." ;
    dcterms:identifier "3706598.3713353" ;
    chi:hasAuthor chi:person_187091, chi:person_187023, chi:person_183108, chi:person_185923, chi:person_183179, chi:person_185358, chi:person_186232, chi:person_187200 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:paperIncludesStudy chi:study_188527_BaselineComparisonStudy ;
    chi:paperIncludesStudy chi:study_188527_UserStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188527_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188527_SoftwareArtifact .

chi:study_188527_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188527 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188527_QualitativeResult ;
    chi:reportsResult chi:result_188527_StatisticalResult .

chi:study_188527_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188527 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188527_QualitativeResult ;
    chi:reportsResult chi:result_188527_StatisticalResult .

chi:artifact_188527_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188527 .

chi:artifact_188527_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188527 .

chi:result_188527_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188527_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188528 rdf:type chi:Paper ;
    dcterms:title "Reflecting on Design Paradigms of Animated Data Video Tools" ;
    dcterms:abstract "Animated data videos have gained significant popularity in recent years. However, authoring data videos remains challenging due to the complexity of creating and coordinating diverse components (e.g., visualization, animation, audio, etc.). Although numerous tools have been developed to streamline the process, there is a lack of comprehensive understanding and reflection of their design paradigms to inform future development. To address this gap, we propose a framework for understanding data video creation tools along two dimensions: what data video components to create and coordinate, including visual, motion, narrative, and audio components, and how to support the creation and coordination. By applying the framework to analyze 46 existing tools, we summarized key design paradigms of creating and coordinating each component based on the varying work distribution for humans and AI in these tools. Finally, we share our detailed reflections, highlight gaps from a holistic view, and discuss future directions to address them." ;
    dcterms:identifier "3706598.3713449" ;
    chi:hasAuthor chi:person_185781, chi:person_184851, chi:person_186514, chi:person_187993 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188528_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188528_InterfaceArtifact .

chi:artifact_188528_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188528 .

chi:artifact_188528_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188528 .

chi:result_188528_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188529 rdf:type chi:Paper ;
    dcterms:title "CoKnowledge: Supporting Assimilation of Time-synced Collective Knowledge in Online Science Videos" ;
    dcterms:abstract "Danmaku, a system of scene-aligned, time-synced, floating comments, can augment video content to create `collective knowledge'. However, its chaotic nature often hinders viewers from effectively assimilating the collective knowledge, especially in knowledge-intensive science videos. With a formative study, we examined viewers' practices for processing collective knowledge and the specific barriers they encountered. Building on these insights, we designed a processing pipeline to filter, classify, and cluster danmaku, leading to the development of CoKnowledge -- a tool incorporating a video abstract, knowledge graphs, and supplementary danmaku features to support viewers' assimilation of collective knowledge in science videos. A within-subject study (N=24) showed that CoKnowledge significantly enhanced participants’ comprehension and recall of collective knowledge compared to a baseline with unprocessed live comments. Based on our analysis of user interaction patterns and feedback on design features, we presented design considerations for developing similar support tools. " ;
    dcterms:identifier "3706598.3713682" ;
    chi:hasAuthor chi:person_187051, chi:person_184385, chi:person_185744, chi:person_187486, chi:person_185906, chi:person_183431 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188529_FieldStudy ;
    chi:paperIncludesStudy chi:study_188529_BaselineComparisonStudy ;
    chi:paperIncludesStudy chi:study_188529_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188529_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188529_InterfaceArtifact .

chi:study_188529_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188529 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188529_QualitativeResult ;
    chi:reportsResult chi:result_188529_StatisticalResult .

chi:study_188529_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188529 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188529_QualitativeResult ;
    chi:reportsResult chi:result_188529_StatisticalResult .

chi:study_188529_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188529 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188529_QualitativeResult ;
    chi:reportsResult chi:result_188529_StatisticalResult .

chi:artifact_188529_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188529 .

chi:artifact_188529_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188529 .

chi:result_188529_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188529_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188530 rdf:type chi:Paper ;
    dcterms:title "Reel Feel: Rich Haptic XR Experiences Using an Active, Worn, Multi-String Device " ;
    dcterms:abstract "While many haptic systems have been demonstrated for use in virtual and augmented reality, they most often enable a single category of feedback (e.g., kinematic breaking, object compliance, textures). Combining prior systems to achieve multi-dimensional effects is unwieldy, expensive, and often physically impossible. We believe this is holding back the ubiquity of rich haptics in both the consumer and industrial AR/VR/XR domains. In this work, we describe Reel Feel, a novel, shoulder-worn haptic system capable of rendering rigid geometry, object-bound haptic animations, impulsive forces, surface compliance, and fine-grained spatial effects all in one unified, worn device. Our design aimed to minimize the weight on the hands (<10 g), where a system's mass is most felt, as many prior systems are heavy gloves and exoskeletons. Finally, we sought to keep the device practical, being self-contained, low-cost, and low enough power to be feasible for consumer adoption with a high degree of mobility. In a user evaluation, our device rated better than a conventional vibrotactile baseline for all qualitative measures (immersion, realism, etc.) and allowed participants to more accurately discern object compliance and fine-grained spatial effects." ;
    dcterms:identifier "3706598.3713615" ;
    chi:hasAuthor chi:person_187459, chi:person_184969 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction-EmbodiedVRInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction-EmbodiedVRInteraction ;
    chi:paperIncludesStudy chi:study_188530_BaselineComparisonStudy ;
    chi:paperIncludesStudy chi:study_188530_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188530_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188530_InputDeviceArtifact ;
    chi:proposesArtifact chi:artifact_188530_OutputDeviceArtifact .

chi:study_188530_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188530 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:hasMeasure chi:SubjectiveMeasure ;
    chi:reportsResult chi:result_188530_StatisticalResult .

chi:study_188530_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188530 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:hasMeasure chi:SubjectiveMeasure ;
    chi:reportsResult chi:result_188530_StatisticalResult .

chi:artifact_188530_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188530 .

chi:artifact_188530_InputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188530 .

chi:artifact_188530_OutputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188530 .

chi:result_188530_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188531 rdf:type chi:Paper ;
    dcterms:title "Juggling Extra Limbs: Identifying Control Strategies for Supernumerary Multi-Arms in Virtual Reality" ;
    dcterms:abstract "Using supernumerary multi-limbs for complex tasks is a growing research focus in Virtual Reality (VR) and robotics. Understanding how users integrate extra limbs with their own to achieve shared goals is crucial for developing efficient supernumeraries. This paper presents an exploratory user study (N=14) investigating strategies for controlling virtual supernumerary limbs with varying autonomy levels in VR object manipulation tasks. Using a Wizard-of-Oz approach to simulate semi-autonomous limbs, we collected both qualitative and quantitative data. Results show participants adapted control strategies based on task complexity and system autonomy, affecting task delegation, coordination, and body ownership. Based on these findings, we propose guidelines—commands, demonstration, delegation, and labeling instructions—to improve multi-limb interaction design by adapting autonomy to user needs and fostering better context-aware experiences." ;
    dcterms:identifier "3706598.3713647" ;
    chi:hasAuthor chi:person_184250, chi:person_183049, chi:person_186386, chi:person_183593, chi:person_187961, chi:person_185652 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:EmbodiedVRInteraction ;
    chi:paperIncludesStudy chi:study_188531_WizardOfOzStudy ;
    chi:paperIncludesStudy chi:study_188531_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188531_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188531_SoftwareArtifact .

chi:study_188531_WizardOfOzStudy rdf:type chi:WizardOfOzStudy ;
    chi:isStudyReportedIn chi:paper_188531 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188531_QualitativeResult ;
    chi:reportsResult chi:result_188531_StatisticalResult .

chi:study_188531_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188531 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188531_QualitativeResult ;
    chi:reportsResult chi:result_188531_StatisticalResult .

chi:artifact_188531_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188531 .

chi:artifact_188531_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188531 .

chi:result_188531_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188531_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188532 rdf:type chi:Paper ;
    dcterms:title "Social Wearables Edu-Larp: Insights From a Novel Camp Combining Crafting, Coding, and Larping Aimed at Non-traditional Steam Participants" ;
    dcterms:abstract "Developing STEAM (Science, Technology, Engineering, Art, and Math) education curricula encouraging participation from underrepresented groups is crucial for diversity in computational fields. Many existing programs attract cis-white males, to the exclusion of other groups. This paper discusses a camp where participants, primarily female youth ages 10-14 (N=45), engage in crafting social wearable technologies within a live-action roleplay context. Our findings from four camp sessions show increased self-reported competence and interest in STEAM among participants, alongside enhanced feelings of community and social support. The camp's innovative approach integrates design thinking, iterative design, and collaboration, proving effective in fostering inclusivity and engagement in STEAM. We adopted an iterative Research-through-Design process, with researchers embedded in the camp to observe and conduct surveys and interviews with participants. Researchers and educators can benefit from reading our results, which demonstrate the value of a playful, socially-engaged curriculum in attracting and retaining diverse students in STEAM fields." ;
    dcterms:identifier "3706598.3713843" ;
    chi:hasAuthor chi:person_186773, chi:person_183019, chi:person_187462, chi:person_185772, chi:person_187570, chi:person_186556, chi:person_184081, chi:person_185740, chi:person_185521 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188532_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188532_FieldStudy ;
    chi:paperIncludesStudy chi:study_188532_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188532_DeviceArtifact .

chi:study_188532_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188532 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188532_QualitativeResult ;
    chi:reportsResult chi:result_188532_StatisticalResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:study_188532_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188532 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188532_QualitativeResult ;
    chi:reportsResult chi:result_188532_StatisticalResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:study_188532_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188532 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188532_QualitativeResult ;
    chi:reportsResult chi:result_188532_StatisticalResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:artifact_188532_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188532 .

chi:result_188532_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188532_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188533 rdf:type chi:Paper ;
    dcterms:title "FlexiVol: a Volumetric Display with an Elastic Diffuser to Enable Reach-Through Interaction" ;
    dcterms:abstract "Volumetric displays render true 3D graphics without forcing users to wear headsets or glasses. However, the optical diffusers that volumetric displays employ are rigid and thus do not allow for direct interaction. FlexiVol employs elastic diffusers to allow users to reach inside the display volume to have direct interaction with true 3D content. We explored various diffuser materials in terms of visual and mechanical properties. We correct the distortions of the volumetric graphics projected on elastic oscillating diffusers and propose a design space for FlexiVol, enabling various gestures and actions through direct interaction techniques. A user study suggests that selection, docking and tracing tasks can be performed faster and more precisely using direct interaction when compared to indirect interaction with a 3D mouse. Finally, applications such as a virtual pet or landscape edition highlight the advantages of a volumetric display that supports direct interaction." ;
    dcterms:identifier "3706598.3714315" ;
    chi:hasAuthor chi:person_187370, chi:person_183837, chi:person_188035, chi:person_183791, chi:person_184274, chi:person_187195, chi:person_183911 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:paperIncludesStudy chi:study_188533_UserStudy ;
    chi:paperIncludesStudy chi:study_188533_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188533_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188533_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188533_OutputDeviceArtifact ;
    chi:proposesArtifact chi:artifact_188533_InputDeviceArtifact .

chi:study_188533_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188533 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188533_StatisticalResult .

chi:study_188533_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188533 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188533_StatisticalResult .

chi:artifact_188533_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188533 .

chi:artifact_188533_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188533 .

chi:artifact_188533_OutputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188533 .

chi:artifact_188533_InputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188533 .

chi:result_188533_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188534 rdf:type chi:Paper ;
    dcterms:title "Bridging Simulation and Reality: Augmented Virtuality for Mass Casualty Triage Training - From Landscape Analysis to Empirical Insights" ;
    dcterms:abstract "Live drills are the gold standard for mass casualty incident (MCI) training but are often too resource-intensive for widespread implementation. Immersive technologies offer a promising alternative, but can they deliver comparable fidelity and effectiveness? Working with a local disaster response academy, this paper investigated the potential of Augmented Virtuality (AV) in MCI training through two phases. First, we conducted a landscape analysis of 126 papers across the virtuality continuum, revealing trends in population, training focus, and evaluation metrics. Second, we empirically evaluated an AV system for mass casualty triage training against traditional role-playing and Virtual Reality (VR) approaches, involving 60 trainees in an operational curriculum. Results indicated that both AV and VR surpassed traditional simulations, with AV's tactile integration significantly enhancing physical engagement, satisfaction, and triage accuracy. Through the lens of triage, we discussed the broader practical implications of integrating immersive technologies like AV into real-world MCI education.  " ;
    dcterms:identifier "3706598.3713794" ;
    chi:hasAuthor chi:person_185002, chi:person_185292, chi:person_183764, chi:person_187608, chi:person_184829, chi:person_184914 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:ImmersiveTrainingAndSimulation ;
    chi:paperIncludesStudy chi:study_188534_BaselineComparisonStudy ;
    chi:paperIncludesStudy chi:study_188534_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188534_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188534_InterfaceArtifact .

chi:study_188534_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188534 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188534_StatisticalResult .

chi:study_188534_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188534 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188534_StatisticalResult .

chi:artifact_188534_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188534 .

chi:artifact_188534_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188534 .

chi:result_188534_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188535 rdf:type chi:Paper ;
    dcterms:title "4D Bioforming with Bees: An Industry-Compatible Prototyping Method for Polymorphic Honeycomb Creation" ;
    dcterms:abstract "4D bioforming is a captivating yet often overlooked natural aesthetic phenomenon, involving the polymorphic transformations that occur during the construction of honeycomb by bees, which presents a significant opportunity for the innovative transformation of traditional apiculture. This paper proposes an industry-compatible prototyping method for polymorphic honeycomb creation following the phenomenon of 4D bioforming, aiming to introduce innovation to honeycomb forms through 4D bioforming while preserving the central role of beekeepers. The method is designed to align with the practical habits of beekeepers and can be outlined in four key steps: scaffold creation, quadrilateral shape division, bee path compilation with outer mold, and 4D bioforming. The dynamic temporal changes in the honeycomb were successfully demonstrated, enhancing the artistic aspect of honeycomb creation. Evaluation results suggest that the method is compatible with traditional practices, easily adoptable by beekeepers and that the polymorphic honeycomb meets essential aesthetic standards." ;
    dcterms:identifier "3706598.3713696" ;
    chi:hasAuthor chi:person_187414, chi:person_186499, chi:person_185033, chi:person_187359 ;
    chi:paperIncludesStudy chi:study_188535_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188535_DeviceArtifact .

chi:study_188535_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188535 ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:reportsResult chi:result_188535_QualitativeResult .

chi:artifact_188535_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188535 .

chi:result_188535_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188536 rdf:type chi:Paper ;
    dcterms:title "Noel: A Chatbot Persona to Support Children Designing for Others" ;
    dcterms:abstract "Designing for others encourages children to empathize with and consider different perspectives and needs. A chatbot persona could allow children to design for stakeholder groups that are challenging to involve directly in educational activities, such as people with disabilities. In this paper, we explore how an artificial intelligence chatbot persona leveraging the GPT-4 large language model can support children's design empathy while designing for others. We report the design, development process, and implementation of a chatbot persona representing a 12-year-old child with low vision named Noel. The exploratory case study consisted of three 90- to 120-minute workshop sessions with nineteen students (ages 11 to 13) in a grade 6/7 classroom. Results illustrate ways that Noel supported students throughout the design process, their expressions of design empathy, and their experiences. We present implications for developers and educators along with future directions for research. " ;
    dcterms:identifier "3706598.3713836" ;
    chi:hasAuthor chi:person_184929, chi:person_186789, chi:person_183057, chi:person_184302 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:paperIncludesStudy chi:study_188536_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188536_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188536_InterfaceArtifact .

chi:study_188536_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188536 ;
    chi:reportsResult chi:result_188536_QualitativeResult .

chi:artifact_188536_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188536 .

chi:artifact_188536_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188536 .

chi:result_188536_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188537 rdf:type chi:Paper ;
    dcterms:title "What Did My Car Say? Impact of Autonomous Vehicle Explanation Errors and Driving Context On Comfort, Reliance, Satisfaction, and Driving Confidence" ;
    dcterms:abstract "Explanations for autonomous vehicle (AV) decisions may build trust, however, explanations can contain errors. In a simulated driving study (n = 232), we tested how AV explanation errors, driving context characteristics (perceived harm and driving difficulty), and personal traits (prior trust and expertise) affected a passenger's comfort in relying on an AV, preference for control, confidence in the AV's ability, and explanation satisfaction. Errors negatively affected all outcomes. Surprisingly, despite identical driving, explanation errors reduced ratings of the AV's driving ability. Severity and potential harm amplified the negative impact of errors. Contextual harm and driving difficulty directly impacted outcome ratings and influenced the relationship between errors and outcomes. Prior trust and expertise were positively associated with outcome ratings. Results emphasize the need for accurate, contextually adaptive, and personalized AV explanations to foster trust, reliance, satisfaction, and confidence. We conclude with design, research, and deployment recommendations for trustworthy AV explanation systems." ;
    dcterms:identifier "3706598.3713088" ;
    chi:hasAuthor chi:person_188153, chi:person_183912, chi:person_186883, chi:person_185258 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:ErrorRatesAndTaskCompletion ;
    chi:paperIncludesStudy chi:study_188537_UserStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188537_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188537_InterfaceArtifact .

chi:study_188537_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188537 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188537_StatisticalResult .

chi:artifact_188537_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188537 .

chi:artifact_188537_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188537 .

chi:result_188537_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188538 rdf:type chi:Paper ;
    dcterms:title "Plurals: A System for Guiding LLMs via Simulated Social Ensembles" ;
    dcterms:abstract "Recent debates raised concerns that language models may favor certain viewpoints. But what if the solution is not to aim for a \"view from nowhere'' but rather to leverage different viewpoints? We introduce Plurals, a system and Python library for pluralistic AI deliberation. Plurals consists of Agents (LLMs, optionally with personas) which deliberate within customizable Structures, with Moderators overseeing deliberation. Plurals is a generator of simulated social ensembles. Plurals integrates with government datasets to create nationally representative personas, includes deliberation templates inspired by deliberative democracy, and allows users to customize both information-sharing structures and deliberation behavior within Structures. Six case studies demonstrate fidelity to theoretical constructs and efficacy. Three randomized experiments show simulated focus groups produced output resonant with an online sample of the relevant audiences (chosen over zero-shot generation in 75% of trials). Plurals is both a paradigm and a concrete system for pluralistic AI.  " ;
    dcterms:identifier "3706598.3713675" ;
    chi:hasAuthor chi:person_187965, chi:person_184501, chi:person_182755, chi:person_182729, chi:person_187859 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:ChatbotAssistedUserStudies ;
    chi:paperIncludesStudy chi:study_188538_BaselineComparisonStudy ;
    chi:paperIncludesStudy chi:study_188538_UserStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188538_SoftwareArtifact .

chi:study_188538_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188538 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188538_QualitativeResult ;
    chi:reportsResult chi:result_188538_StatisticalResult .

chi:study_188538_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188538 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188538_QualitativeResult ;
    chi:reportsResult chi:result_188538_StatisticalResult .

chi:artifact_188538_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188538 .

chi:result_188538_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188538_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188539 rdf:type chi:Paper ;
    dcterms:title "Diving into the Abyss: Exploring Deep Sea Connection and Curiosity through Virtual Reality " ;
    dcterms:abstract "This paper presents an investigation of the potential of virtual reality (VR) to bridge the gap between humans and the largely unexplored deep sea, using the immersive, playful experience of \"Echo of the Abyss\" (EotA). Built around the structure of a deep-sea dive experience, EotA aims to enhance users' sense of interconnectedness with underwater environments and stimulate curiosity about marine life. The qualitative analysis reveals a heightened empathy, respect for aquatic life, and a newfound interest in real-world diving experiences. Quantitative results indicate a marginal increase in positive perceptions towards the sea. From these findings, we discuss VR as an effective transformational tool to foster a deeper ecological consciousness. Our contributions can benefit HCI researchers and game designers interested in designing ocean sustainability-driven experiences and games.  " ;
    dcterms:identifier "3706598.3713833" ;
    chi:hasAuthor chi:person_183975, chi:person_183064, chi:person_185117, chi:person_183666, chi:person_183484 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:ImmersiveTrainingAndSimulation ;
    chi:paperIncludesStudy chi:study_188539_UserStudy ;
    chi:paperIncludesStudy chi:study_188539_QualitativeStudy ;
    chi:paperIncludesStudy chi:study_188539_QuantitativeStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188539_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188539_InterfaceArtifact .

chi:study_188539_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188539 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188539_QualitativeResult ;
    chi:reportsResult chi:result_188539_StatisticalResult .

chi:study_188539_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188539 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188539_QualitativeResult ;
    chi:reportsResult chi:result_188539_StatisticalResult .

chi:study_188539_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188539 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188539_QualitativeResult ;
    chi:reportsResult chi:result_188539_StatisticalResult .

chi:artifact_188539_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188539 .

chi:artifact_188539_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188539 .

chi:result_188539_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188539_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188540 rdf:type chi:Paper ;
    dcterms:title "AIdeation: Designing a Human-AI Collaborative Ideation System for Concept Designers" ;
    dcterms:abstract "Concept designers in the entertainment industry create highly detailed, often imaginary environments for movies, games, and TV shows. Their early ideation phase requires intensive research, brainstorming, visual exploration, and combination of various design elements to form cohesive designs. However, existing AI tools focus on image generation from user specifications, lacking support for the unique needs and complexity of concept designers' workflows. Through a formative study with 12 professional designers, we captured their workflows and identified key requirements for AI-assisted ideation tools. Leveraging these insights, we developed AIdeation to support early ideation by brainstorming design concepts with flexible searching and recombination of reference images. A user study with 16 professional designers showed that AIdeation significantly enhanced creativity, ideation efficiency, and satisfaction (all \textit{p}<.01) compared to current tools and workflows. A field study with 4 studios for 1 week provided insights into AIdeation's benefits and limitations in real-world projects. After the completion of the field study, two studios, covering films, television, and games, have continued to use AIdeation in their commercial projects to date, further validating AIdeation's improvement in ideation quality and efficiency." ;
    dcterms:identifier "3706598.3714148" ;
    chi:hasAuthor chi:person_184014, chi:person_187822, chi:person_183714, chi:person_185134, chi:person_182863 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:paperIncludesStudy chi:study_188540_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188540_UserStudy ;
    chi:paperIncludesStudy chi:study_188540_FieldStudy ;
    chi:paperIncludesStudy chi:study_188540_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188540_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188540_InterfaceArtifact .

chi:study_188540_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188540 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:reportsResult chi:result_188540_QualitativeResult ;
    chi:reportsResult chi:result_188540_StatisticalResult .

chi:study_188540_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188540 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:reportsResult chi:result_188540_QualitativeResult ;
    chi:reportsResult chi:result_188540_StatisticalResult .

chi:study_188540_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188540 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:reportsResult chi:result_188540_QualitativeResult ;
    chi:reportsResult chi:result_188540_StatisticalResult .

chi:study_188540_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188540 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:reportsResult chi:result_188540_QualitativeResult ;
    chi:reportsResult chi:result_188540_StatisticalResult .

chi:artifact_188540_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188540 .

chi:artifact_188540_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188540 .

chi:result_188540_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188540_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188541 rdf:type chi:Paper ;
    dcterms:title "The Interaction Geography Slicer: Designing Exploratory Spatial Data Visualization Tools for Teachers' Reflective Practice" ;
    dcterms:abstract "Researchers in HCI and teacher education have long recognized the potential of visualization to support teachers' reflective practice. Despite much progress however, teacher educators continue to highlight the need for more dynamic classroom data visualizations to better support teachers' reflective practice, particularly about spatial dimensions of their pedagogy. In response, this article makes three contributions. First, we build on prior work to present the Interaction Geography Slicer (IGS), an open-source tool to dynamically visualize movement, conversation, and video data over space and time in settings such as classrooms. Second, we share findings from a participatory design-based research project involving 11 experienced high school mathematics teachers who used the IGS over one year to support their reflective practice. Finally, we propose new directions for exploratory spatial classroom data visualization." ;
    dcterms:identifier "3706598.3713499" ;
    chi:hasAuthor chi:person_187771, chi:person_183821, chi:person_184777 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:CollaborativeVisualizationTools ;
    chi:paperIncludesStudy chi:study_188541_FieldStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188541_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188541_InterfaceArtifact .

chi:study_188541_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188541 ;
    chi:reportsResult chi:result_188541_QualitativeResult .

chi:artifact_188541_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188541 .

chi:artifact_188541_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188541 .

chi:result_188541_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188542 rdf:type chi:Paper ;
    dcterms:title "Co-design & Evaluation of Visual Interventions for Head Posture Correction in Virtual Reality Games" ;
    dcterms:abstract "While virtual reality (VR) games offer immersive experiences, prolonged improper head posture during VR gaming sessions can cause neck discomfort and injuries. To address this issue, we prototyped a framework to detect instances of improper head posture and apply various visual interventions to correct them. After assessing the prototype's usability in a co-design workshop with participants experienced in VR design and kinesiology, we refined the interventions in two main directions --- using explicit visual indicators or employing implicit background changes. The refined interventions were subsequently tested in a controlled experiment involving a target selection task. The study results demonstrate that the interventions effectively helped participants maintain better head posture during VR gameplay compared to the control condition. " ;
    dcterms:identifier "3706598.3713177" ;
    chi:hasAuthor chi:person_186103, chi:person_187035, chi:person_187468, chi:person_188171 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:paperIncludesStudy chi:study_188542_UserStudy ;
    chi:paperIncludesStudy chi:study_188542_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188542_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188542_SoftwareArtifact .

chi:study_188542_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188542 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188542_StatisticalResult .

chi:study_188542_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188542 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188542_StatisticalResult .

chi:artifact_188542_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188542 .

chi:artifact_188542_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188542 .

chi:result_188542_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188543 rdf:type chi:Paper ;
    dcterms:title "A Cross-Country Analysis of GDPR Cookie Banners and Flexible Methods for Scraping Them" ;
    dcterms:abstract "Online tracking remains problematic, with compliance and ethical issues persisting despite regulatory efforts. Consent interfaces, the visible manifestation of this industry, have seen significant attention over the years. We present robust automated methods to study the presence, design, and third-party suppliers of consent interfaces at scale and the web service consent-observatory.eu to do it with. We examine the top 10,000 websites across 31 countries under the ePrivacy Directive and GDPR (n=254.148). Our findings show that 67% of websites use consent interfaces, but only 15% are minimally compliant, mostly because they lack a reject option. Consent management platforms (CMPs) are powerful intermediaries in this space: 67% of interfaces are provided by CMPs, and three organisations hold 37% of the market. There is little evidence that regulators’ guidance and fines have impacted compliance rates, but 18% of compliance variance is explained by CMPs. Researchers should take an infrastructural perspective on online tracking and study the factual control of intermediaries to identify effective leverage points." ;
    dcterms:identifier "3706598.3713648" ;
    chi:hasAuthor chi:person_187621, chi:person_183452, chi:person_185083, chi:person_183362 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness:DataDisclosureAndConsent ;
    chi:aboutTopic chi:EthicsPrivacyFairness:DataDisclosureAndConsent ;
    chi:paperIncludesStudy chi:study_188543_FieldStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188543_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188543_InterfaceArtifact .

chi:study_188543_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188543 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188543_StatisticalResult .

chi:artifact_188543_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188543 .

chi:artifact_188543_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188543 .

chi:result_188543_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188545 rdf:type chi:Paper ;
    dcterms:title "Catalyst for Creativity or a Hollow Trend?: A Cross-Level Perspective on The Role of Generative AI in Design" ;
    dcterms:abstract "Generative AI image creation tools have the potential to transform design education and practice, but raise critical concerns for creativity and ownership. We leverage the 2022 launch of tools like Midjourney and DALL.E as a point dividing design enthusiasts into pre- and post-tool learners. In this paper, we conduct 28 artifact-based interviews with designers at varying levels of tool introduction, to understand how they perceive and use generative AI in their design roles. Our results indicate a rift in the value system of designers, with experienced designers being more circumspect about the loss of traditional creativity and foundational design skills. On the practical side, there exists a tension between the growing marketability of AI-related skills for design vs. the limited affordances of these tools for achieving meaningful designs. We discuss implications for the shifting definitions of design as a field, creativity and ownership, and AI in the design curriculum. " ;
    dcterms:identifier "3706598.3713233" ;
    chi:hasAuthor chi:person_188120, chi:person_185910, chi:person_186449 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:paperIncludesStudy chi:study_188545_InterviewStudy ;
    chi:aimsAtGoal chi:PromoteLearning .

chi:study_188545_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188545 ;
    chi:reportsResult chi:result_188545_QualitativeResult .

chi:result_188545_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188546 rdf:type chi:Paper ;
    dcterms:title "Out of Sight, Out of Mind? Exploring Data Protection Practices for Personal Data in Usable Security & Privacy Studies" ;
    dcterms:abstract "Adherence to data protection measures such as pseudonymization or anonymization is critical in human subjects research because it has a direct impact on the confidentiality of participants' sensitive information, trust in research practices, and compliance with ethical and legal standards. Regulations such as the General Data Protection Regulation (GDPR) and guarantees made by researchers in informed consent forms mandate strict protocols for data security. However, compliance with these is not always straightforward. To gain qualitative insights into data protection practices in the field of Usable Security and Privacy (USP), we conducted interviews with 22 practitioners (five professors, eight researchers, nine data protection officers) and one focus group with five researchers. Overall, our results show a high awareness of ethical and legal responsibilities but highlight many practical and procedural issues. Based on these, we make concrete recommendations on how to improve the protection of personal data in research." ;
    dcterms:identifier "3706598.3713654" ;
    chi:hasAuthor chi:person_184603, chi:person_187838, chi:person_187054, chi:person_185686, chi:person_186640, chi:person_187781, chi:person_187938, chi:person_187242 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:DataDisclosureAndConsent ;
    chi:paperIncludesStudy chi:study_188546_InterviewStudy .

chi:study_188546_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188546 ;
    chi:reportsResult chi:result_188546_QualitativeResult .

chi:result_188546_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188547 rdf:type chi:Paper ;
    dcterms:title "Being in Virtual Worlds: How Interaction, Environment, and Touch Shape Embodiment in Immersive Experiences" ;
    dcterms:abstract "Embodiment is an everyday experience that typically goes unnoticed. While we often take it for granted, with the adoption of virtual reality (VR) technology, embodiment in virtual bodies and worlds has become an important consideration for designers of immersive experiences. To date, the VR design community has primarily considered embodiment in terms of body ownership over a synchronized visual representation. In this paper, we construct an interactional framework of virtual embodiment, beginning by revisiting what it really means to be “embodied.” Our framework reconnects embodiment and presence in virtual environments founded in Dourish's concept of embodied interaction and Heidegger's Dasein or “being-in-the-world.” We discuss how embodiment, fundamentally rooted in past and present interactions, changes our understanding of body ownership and its extension into VR. Integrating theories from VR research, philosophy, HCI, and psychology we uncover the complex interplay of interaction, environment, and touch in shaping embodied experiences. We present a novel framework for understanding embodiment in VR rooted in interaction, enabling designers to create more immersive and meaningful virtual worlds." ;
    dcterms:identifier "3706598.3713586" ;
    chi:hasAuthor chi:person_188054, chi:person_183057, chi:person_187657 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:EmbodiedVRInteraction ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188547_InterfaceArtifact .

chi:artifact_188547_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188547 .

chi:result_188547_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188548 rdf:type chi:Paper ;
    dcterms:title "DBox: Scaffolding Algorithmic Programming Learning through Learner-LLM Co-Decomposition" ;
    dcterms:abstract "Decomposition is a fundamental skill in algorithmic programming, requiring learners to break down complex problems into smaller, manageable parts. However, current self-study methods, such as browsing reference solutions or using LLM assistants, often provide excessive or generic assistance that misaligns with learners' decomposition strategies, hindering independent problem-solving and critical thinking. To address this, we introduce Decomposition Box (DBox), an interactive LLM-based system that scaffolds and adapts to learners' personalized construction of a step tree through a \"learner-LLM co-decomposition\" approach, providing tailored support at an appropriate level. A within-subjects study (N=24) found that compared to the baseline, DBox significantly improved learning gains, cognitive engagement, and critical thinking. Learners also reported a stronger sense of achievement and found the assistance appropriate and helpful for learning. Additionally, we examined DBox's impact on cognitive load, identified usage patterns, and analyzed learners' strategies for managing system errors. We conclude with design implications for future AI-powered tools to better support algorithmic programming education." ;
    dcterms:identifier "3706598.3713748" ;
    chi:hasAuthor chi:person_183878, chi:person_184443, chi:person_187051, chi:person_183431, chi:person_187246 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188548_BaselineComparisonStudy ;
    chi:paperIncludesStudy chi:study_188548_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188548_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188548_InterfaceArtifact .

chi:study_188548_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188548 ;
    chi:hasMeasure chi:SubjectiveMeasure ;
    chi:reportsResult chi:result_188548_StatisticalResult ;
    chi:reportsResult chi:result_188548_QualitativeResult .

chi:study_188548_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188548 ;
    chi:hasMeasure chi:SubjectiveMeasure ;
    chi:reportsResult chi:result_188548_StatisticalResult ;
    chi:reportsResult chi:result_188548_QualitativeResult .

chi:artifact_188548_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188548 .

chi:artifact_188548_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188548 .

chi:result_188548_StatisticalResult rdf:type chi:StatisticalResult .

chi:result_188548_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188549 rdf:type chi:Paper ;
    dcterms:title "How Should We Design Technology With Diverse Stakeholders Who Wish Not to Attend Design Activities Together?" ;
    dcterms:abstract "The relationship between the Nigerian police and citizens is strained, hindering the co-design of conventional technologies to enhance community policing (CP) initiatives, hence the imperative to involve both in the design of a usable CP technology that can carter for their needs. Our preliminary findings indicate that Nigerian citizens are reluctant to participate in co-design activities with the police due to discomfort, which could potentially bias the design outcomes. Designing a CP technology with such stakeholders is crucial, but a new challenge for the Human Computer Interaction (HCI) community, as no existing framework has addressed it. We introduce Conflict Sensitive Design (CSD), a co-design approach that leverages mediation techniques (tension reduction, leveling, common ground reminder, separated meetings, formalizing agreements) to iteratively collect, analyze, and reconcile design inputs, ensuring that the final design is usable for CP enhancement. Our case application worked in CP technology requirements gathering with Nigerian CP stakeholders, and it could be extended to related HCI contexts. We present a structured approach to conflict resolution in co-design processes, and discuss the lessons learned as a spotlight to guide other designers in related contexts." ;
    dcterms:identifier "3706598.3714168" ;
    chi:hasAuthor chi:person_184852, chi:person_187599 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188549_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188549_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188549_InterfaceArtifact .

chi:study_188549_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188549 ;
    chi:reportsResult chi:result_188549_QualitativeResult .

chi:artifact_188549_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188549 .

chi:artifact_188549_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188549 .

chi:result_188549_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188550 rdf:type chi:Paper ;
    dcterms:title "Exploring Positionality in HCI: Perspectives, Trends, and Challenges" ;
    dcterms:abstract "Positionality acknowledges that researchers’ subjectivities, values and experiences influence approaches to and outcomes of research. It underlines and promotes self-awareness and explicit demonstration of reflexivity. To understand how positionality is conceptualised and used in HCI, we conducted two studies: (i) a scoping review of positionality and reflexivity statements in CHI papers from the last 11 years and (ii) a survey of HCI researchers (n=75). Our findings show that positionality statements are often viewed as a box-ticking exercise and their influence on the research is seldom discussed. They are also often restricted to more sensitive areas of research and may impact marginalised identities. We argue that positionality statements may be valuable but not as markers of methodological rigour; their content should be at the discretion of authors and methodologically consistent. Our contributions include a current snapshot of positionality in HCI and reflections on its current role and future directions in HCI." ;
    dcterms:identifier "3706598.3713280" ;
    chi:hasAuthor chi:person_187604, chi:person_183753, chi:person_184240, chi:person_184323, chi:person_186509, chi:person_186099, chi:person_183413 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:paperIncludesStudy chi:study_188550_Study .

chi:study_188550_Study rdf:type chi:Study ;
    chi:isStudyReportedIn chi:paper_188550 ;
    chi:reportsResult chi:result_188550_QualitativeResult .

chi:result_188550_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188551 rdf:type chi:Paper ;
    dcterms:title "A Qualitative Investigation of User Transitions and Frictions in Cross-Reality Applications" ;
    dcterms:abstract "Research in Augmented Reality (AR) and Virtual Reality (VR) has mostly viewed them in isolation. Yet, when used together in practical settings, AR and VR each offer unique strengths, necessitating multiple transitions to harness their advantages. This paper investigates potential challenges in Cross-Reality (CR) transitions to inform future application design. We implemented a CR system featuring a 3D modeling task that requires users to switch between PC, AR, and VR. Using a talk-aloud study (n=12) and thematic analysis, we revealed that frictions primarily arose when transitions conflicted with users' Spatial Mental Model (SMM). Furthermore, we found five transition archetypes employed to enhance productivity once an SMM was established. Our findings uncover that transitions have to focus on establishing and upholding the SMM of users across realities, by communicating differences between them." ;
    dcterms:identifier "3706598.3713921" ;
    chi:hasAuthor chi:person_186801, chi:person_182939, chi:person_187400, chi:person_188190, chi:person_186398, chi:person_187792 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:EmbodiedVRInteraction ;
    chi:paperIncludesStudy chi:study_188551_ThinkAloudStudy ;
    chi:paperIncludesStudy chi:study_188551_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188551_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188551_InterfaceArtifact .

chi:study_188551_ThinkAloudStudy rdf:type chi:ThinkAloudStudy ;
    chi:isStudyReportedIn chi:paper_188551 ;
    chi:reportsResult chi:result_188551_QualitativeResult .

chi:study_188551_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188551 ;
    chi:reportsResult chi:result_188551_QualitativeResult .

chi:artifact_188551_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188551 .

chi:artifact_188551_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188551 .

chi:result_188551_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188553 rdf:type chi:Paper ;
    dcterms:title "Designing Physical Interactions with Triboelectric Material Sensing" ;
    dcterms:abstract "Physical interactions in Human-Computer Interaction (HCI) provide immersive ways for people to engage with technology. However, designers face challenges in integrating physical computing and modeling when designing physical interactions. We explore triboelectric material sensing, a promising technology that addresses these challenges, though its use within the design community remains underexplored. To bridge this gap, we develop a toolkit consisting of triboelectric material pairs, a mechanism taxonomy, a signal processing tool, and computer program templates. We introduce this toolkit to designers in two workshops, where reflections on the design process highlight its effectiveness and inspire innovative interaction designs. Our work contributes valuable resources and knowledge to the design community, making triboelectric sensing more accessible and fostering creativity in physical interaction design." ;
    dcterms:identifier "3706598.3714194" ;
    chi:hasAuthor chi:person_187577, chi:person_185578, chi:person_182762, chi:person_184914 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:paperIncludesStudy chi:study_188553_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188553_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188553_DeviceArtifact .

chi:study_188553_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188553 ;
    chi:reportsResult chi:result_188553_QualitativeResult .

chi:artifact_188553_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188553 .

chi:artifact_188553_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188553 .

chi:result_188553_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188554 rdf:type chi:Paper ;
    dcterms:title "Responsible Prompting Recommendation: Fostering Responsible AI Practices in Prompting-Time" ;
    dcterms:abstract "Human-Computer Interaction practitioners have been proposing best practices in user interface design for decades. However, generative Artificial Intelligence (GenAI) brings additional design considerations and currently lacks sufficient user guidance regarding affordances, inputs, and outputs. In this context, we developed a recommender system to promote responsible AI (RAI) practices while people prompt GenAI systems. We detail 10 interviews with IT professionals, the resulting recommender system developed, and 20 user sessions with IT professionals interacting with our prompt recommendations. Results indicate that responsible prompting recommendations have the potential to support novice prompt engineers and raise awareness about RAI in prompting-time. They also suggest that recommendations should simultaneously maximize both a prompt’s similarity to a user’s input as well as a diversity of associated social values provided. These findings contribute to RAI by offering practical ways to provide user guidance and enrich human-GenAI interaction via prompt recommendations." ;
    dcterms:identifier "3706598.3713365" ;
    chi:hasAuthor chi:person_184894, chi:person_182791, chi:person_184966, chi:person_185805, chi:person_183316, chi:person_185086, chi:person_184231 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:paperIncludesStudy chi:study_188554_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188554_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188554_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188554_InterfaceArtifact .

chi:study_188554_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188554 ;
    chi:reportsResult chi:result_188554_QualitativeResult .

chi:study_188554_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188554 ;
    chi:reportsResult chi:result_188554_QualitativeResult .

chi:artifact_188554_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188554 .

chi:artifact_188554_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188554 .

chi:result_188554_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188555 rdf:type chi:Paper ;
    dcterms:title "“Housing Diversity Means Diverse Housing”: Blending Generative AI into Speculative Design in Rural Co-Housing Communities" ;
    dcterms:abstract "In response to various environmental and societal challenges, co-housing has emerged to support social cohesion, grassroots innovation and ecological regeneration. Co-housing communities typically have smaller personal spaces, closer neighbourly relationships, and engage in more mutually supportive sustainable practices. To understand such communities’ motivations and visions, we developed a speculative design tool that harnesses Generative Artificial Intelligence (GenAI) to facilitate the envisioning of alternative future scenarios that challenge prevailing values, beliefs, lifestyles, and ways of knowing in contemporary society. Within the context of co-housing communities, we conducted a participatory design study with participants in co-creating their future communities. This paper unpacks implications and also reflects on the co-design approach employing GenAI. Our main findings highlight that GenAI, as a catalyst for imagination, empowers individuals to create visualisations that pose questions through a plural and situated speculative discourse." ;
    dcterms:identifier "3706598.3713906" ;
    chi:hasAuthor chi:person_186125, chi:person_187317 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:paperIncludesStudy chi:study_188555_UserStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188555_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188555_InterfaceArtifact .

chi:study_188555_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188555 ;
    chi:reportsResult chi:result_188555_QualitativeResult .

chi:artifact_188555_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188555 .

chi:artifact_188555_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188555 .

chi:result_188555_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188556 rdf:type chi:Paper ;
    dcterms:title "InsightBridge: Enhancing Empathizing with Users through Real-Time Information Synthesis and Visual Communication" ;
    dcterms:abstract "User-centered design necessitates researchers deeply understanding target users throughout the design process. However, during early-stage user interviews, researchers may misinterpret users due to time constraints, incorrect assumptions, and communication barriers. To address this challenge, we introduce InsightBridge, a tool that supports real-time, AI-assisted information synthesis and visual-based verification. InsightBridge automatically organizes relevant information from ongoing interview conversations into an empathy map. It further allows researchers to specify elements to generate visual abstracts depicting the selected information, and then review these visuals with users to refine the visuals as needed. We evaluated the effectiveness of InsightBridge through a within-subject study (N=32) from both the researchers’ and users’ perspectives. Our findings indicate that InsightBridge can assist researchers in note-taking and organization, as well as in-time visual checking, thereby enhancing mutual understanding with users. Additionally, users’ discussions of visuals prompt them to recall overlooked details and scenarios, leading to more insightful ideas." ;
    dcterms:identifier "3706598.3713640" ;
    chi:hasAuthor chi:person_186867, chi:person_187507, chi:person_182874, chi:person_183217, chi:person_187566, chi:person_183431 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:ChatbotAssistedUserStudies ;
    chi:paperIncludesStudy chi:study_188556_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188556_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188556_InterfaceArtifact .

chi:study_188556_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188556 ;
    chi:reportsResult chi:result_188556_QualitativeResult .

chi:artifact_188556_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188556 .

chi:artifact_188556_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188556 .

chi:result_188556_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188557 rdf:type chi:Paper ;
    dcterms:title "Closing the Loop between User Stories and GUI Prototypes: An LLM-Based Assistant for Cross-Functional Integration in Software Development" ;
    dcterms:abstract "Graphical user interfaces (GUIs) are at the heart of almost every software we encounter. GUIs are often created through a collaborative effort involving UX designers, product owners, and software developers, constantly facing changing requirements. Historically, problems in GUI development include a fragmented, poorly integrated tool landscape and high synchronization efforts between stakeholders. Recent approaches suggest using large language models (LLMs) to recognize requirements fulfillment in GUIs and automatically propose new GUI components. Based on ten interviews with practitioners, this paper proposes an LLM-based assistant as a Figma plug-in that bridges the gap between user stories and GUI prototyping. We evaluated the prototype with 40 users and 40 crowd-workers, showing that the effectiveness of GUI creation is improved by using LLMs to detect requirements' completion and generate new GUI components. We derive design rationales to support cross-functional integration in software development, ensuring that our plug-in integrates well into established processes." ;
    dcterms:identifier "3706598.3713932" ;
    chi:hasAuthor chi:person_184891, chi:person_183814, chi:person_187014, chi:person_187177, chi:person_187923 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:paperIncludesStudy chi:study_188557_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188557_UserStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188557_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188557_InterfaceArtifact .

chi:study_188557_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188557 ;
    chi:reportsResult chi:result_188557_QualitativeResult ;
    chi:reportsResult chi:result_188557_StatisticalResult .

chi:study_188557_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188557 ;
    chi:reportsResult chi:result_188557_QualitativeResult ;
    chi:reportsResult chi:result_188557_StatisticalResult .

chi:artifact_188557_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188557 .

chi:artifact_188557_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188557 .

chi:result_188557_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188557_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188558 rdf:type chi:Paper ;
    dcterms:title "User Motivations to Participate in Crowdsourcing and Contribute User-generated Content on Location-based Media: A Literature Review" ;
    dcterms:abstract "Location-based media applications such as Google Maps, Strava and Pokémon GO together have more than a billion monthly active users, and popular social media such as Snapchat and Instagram now also feature map-based content. All these media products rely on user-generated content as a core element of their service, but there is a lack of synthesis on the users' motivations to contribute this data to the platform providers. In this study, we performed a literature review to uncover users' motivations to participate in location-based crowdsourcing and contribute shared content on these platforms. Among our findings, we show that spatial and temporal aspects, social effects, technical elements, motivational mechanisms, practical value offered to the contributors and individual differences need to be considered in motivating users to contribute shared content. We present recommendations for designers, suggest which terminology to use around this topic and propose an agenda for future research." ;
    dcterms:identifier "3706598.3714184" ;
    chi:hasAuthor chi:person_183758, chi:person_183736, chi:person_184367, chi:person_186030, chi:person_187344, chi:person_186816, chi:person_187413 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:aimsAtGoal chi:IncreaseEngagement .

chi:result_188558_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188559 rdf:type chi:Paper ;
    dcterms:title "AMUSE: Human-AI Collaborative Songwriting with Multimodal Inspirations" ;
    dcterms:abstract "Songwriting is often driven by multimodal inspirations, such as imagery, narratives, or existing music, yet songwriters remain unsupported by current music AI systems in incorporating these multimodal inputs into their creative processes. We introduce Amuse, a songwriting assistant that transforms multimodal (image, text, or audio) inputs into chord progressions that can be seamlessly incorporated into songwriters' creative process. A key feature of Amuse is its novel method for generating coherent chords that are relevant to music keywords in the absence of datasets with paired examples of multimodal inputs and chords. Specifically, we propose a method that leverages multimodal language models to convert multimodal inputs into noisy chord suggestions and uses a unimodal chord model to filter the suggestions. A user study with songwriters shows that Amuse effectively supports transforming multimodal ideas into coherent musical suggestions, enhancing users' agency and creativity throughout the songwriting process." ;
    dcterms:identifier "3706598.3713818" ;
    chi:hasAuthor chi:person_183160, chi:person_187761, chi:person_187813 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:paperIncludesStudy chi:study_188559_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188559_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188559_InterfaceArtifact .

chi:study_188559_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188559 ;
    chi:reportsResult chi:result_188559_QualitativeResult .

chi:artifact_188559_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188559 .

chi:artifact_188559_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188559 .

chi:result_188559_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188560 rdf:type chi:Paper ;
    dcterms:title "Perspectives on Mixed-Ability Competition" ;
    dcterms:abstract "Competition is typically centered on balance, fairness, and symmetric play. However, in mixed-ability competition, symmetric play is often not possible or desirable. Currently, it is not clear what can or should be done in the pursuit of the design of inclusive competitive experiences (in sports and games).  In this paper, we interview 15 people with motor or visual disabilities who actively engage in competitive activities (e.g., Paralympics, competitive gaming). We focus on understanding engagement and fairness perspectives within mixed-ability competitive scenarios, highlighting the obstacles and opportunities these interactions present. We relied on thematic analysis to examine the motivations to compete, team structures and roles, perspectives on ability disclosure and rankings, and a reflection on the role of technology in mediating competition. We contribute with an understanding of (1) how competition is experienced, (2) key factors influencing inclusive and fair competition, and (3) reflections for the design of inclusive competitive experiences. " ;
    dcterms:identifier "3706598.3713867" ;
    chi:hasAuthor chi:person_186692, chi:person_185100, chi:person_184478 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:AccessibilityNavigationSupport ;
    chi:paperIncludesStudy chi:study_188560_InterviewStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility .

chi:study_188560_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188560 ;
    chi:reportsResult chi:result_188560_QualitativeResult .

chi:result_188560_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188561 rdf:type chi:Paper ;
    dcterms:title "Fly Away: Evaluating the Impact of Motion Fidelity on Optimized User Interface Design via Bayesian Optimization in Automated Urban Air Mobility Simulations" ;
    dcterms:abstract "Automated Urban Air Mobility (UAM) can improve passenger transportation and reduce congestion, but its success depends on passenger trust. While initial research addresses passengers' information needs, questions remain about how to simulate air taxi flights and how these simulations impact users and interface requirements.  We conducted a between-subjects study (N=40), examining the influence of motion fidelity in Virtual-Reality-simulated air taxi flights on user effects and interface design. Our study compared simulations with and without motion cues using a 3-Degrees-of-Freedom motion chair. Optimizing the interface design across six objectives, such as trust and mental demand, we used multi-objective Bayesian optimization to determine the most effective design trade-offs. Our results indicate that motion fidelity decreases users' trust, understanding, and acceptance, highlighting the need to consider motion fidelity in future UAM studies to approach realism. However, minimal evidence was found for differences or equality in the optimized interface designs, suggesting personalized interface designs." ;
    dcterms:identifier "3706598.3713288" ;
    chi:hasAuthor chi:person_184602, chi:person_182889, chi:person_185585, chi:person_183011, chi:person_185564 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction:ImmersiveTrainingAndSimulation ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction:ImmersiveTrainingAndSimulation ;
    chi:paperIncludesStudy chi:study_188561_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188561_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188561_DeviceArtifact .

chi:study_188561_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188561 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188561_StatisticalResult .

chi:artifact_188561_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188561 .

chi:artifact_188561_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188561 .

chi:result_188561_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188562 rdf:type chi:Paper ;
    dcterms:title "Investigating User Perceptions of Epilepsy-Related Seizure Triggers in Mobile Apps: An Analysis of User Reviews" ;
    dcterms:abstract "Individuals with reflex epilepsy may have seizures caused by stimuli including flashing lights, colors, motion, and patterns. Many studies have investigated seizure-inducing content in multimedia, but studies addressing seizure triggers in mobile apps are still scarce. Hence, we examined user reviews aiming to identify and describe seizure triggers in mobile apps based on user's reported experiences. Our findings reveal significant patterns of how apps can unintentionally harm users with epilepsy, highlighting the need for improved design practices and more comprehensive accessibility guidelines, which are mainly focused on flashy content and animation. More specifically, we present evidences indicating that users do experience seizures triggered by mobile app interaction, which are not solely limited to multimedia interaction. Most seizure triggers are associated with flashy content and less frequently by color schemes, motion, transitions, glitches, and bugs. In addition, videos and advertisements are the most seizure-inducing content reported by users. " ;
    dcterms:identifier "3706598.3713378" ;
    chi:hasAuthor chi:person_187997, chi:person_187995 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188562_QualitativeStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188562_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188562_InterfaceArtifact .

chi:study_188562_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188562 ;
    chi:reportsResult chi:result_188562_QualitativeResult .

chi:artifact_188562_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188562 .

chi:artifact_188562_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188562 .

chi:result_188562_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188564 rdf:type chi:Paper ;
    dcterms:title "\"It's Too Much On Top of Your Own Food Drama'': Exploring Food Allergy Identity and Experience Through Social Media" ;
    dcterms:abstract "This paper provides an in-depth view of people's experiences with food allergies, focusing on their social media use and its influences on healthy habits and identities. Through 18 interviews, our study examined how information and identity work on social media influences health behaviors, social interactions, self-expression, and navigation of algorithms for those with food allergies. Social media functions as both a source of empowerment and community and a platform for stigma and emotional distress. Our findings highlight how individuals manage their food allergy identity and online visibility on algorithm-driven platforms. The concept of ``on-and-off identities'' is introduced to capture this complex identity work. Design considerations for HCI include: 1) creating mindful social media experiences that support agency while addressing vulnerability in identity and information work, and 2) reflections on the challenges of evolving health contexts and social media ecologies. We urge HCI researchers and designers to adopt a holistic perspective on identity and information work to better support marginalized populations. " ;
    dcterms:identifier "3706598.3714126" ;
    chi:hasAuthor chi:person_184402, chi:person_187622, chi:person_184157 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:aboutTopic chi:OnlineSelfDisclosureAndIdentity ;
    chi:paperIncludesStudy chi:study_188564_InterviewStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility .

chi:study_188564_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188564 ;
    chi:reportsResult chi:result_188564_QualitativeResult .

chi:result_188564_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188565 rdf:type chi:Paper ;
    dcterms:title "Embodied Measurement: Tangible Interactions to Enhance the Validity of Self-Report Measures" ;
    dcterms:abstract "This work introduces the concept of Embodied Measurement (EM), designed to improve the validity and inclusivity of cognitive load assessments by incorporating physical interactions that mirror mental effort. We implemented a haptic force-feedback turning knob as an alternative to traditional Likert-scale ratings and compared it with visual (mouse-based) and combined (haptic and visual) modalities. Participants completed a cognitive load task with varying difficulty levels using each modality, while biosignals such as heart rate variability, skin conductance, and pupil size were recorded to objectively assess cognitive load. In addition, qualitative feedback was gathered to explore participants' experiences with each input method. Our findings highlight the potential of EM to offer more tangible and intuitive ways of measuring cognitive load, with the combined modality providing the most comprehensive feedback. This study contributes to human-computer interaction (HCI) research by proposing new approaches for measuring cognitive and emotional effort through physical interaction." ;
    dcterms:identifier "3706598.3714055" ;
    chi:hasAuthor chi:person_186500, chi:person_184503, chi:person_186684, chi:person_183679, chi:person_184475, chi:person_186160 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:paperIncludesStudy chi:study_188565_UserStudy ;
    chi:paperIncludesStudy chi:study_188565_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:ReduceCognitiveLoad ;
    chi:proposesArtifact chi:artifact_188565_InputDeviceArtifact ;
    chi:proposesArtifact chi:artifact_188565_InterfaceArtifact .

chi:study_188565_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188565 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:hasMeasure chi:HeartRateMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188565_QualitativeResult ;
    chi:reportsResult chi:result_188565_StatisticalResult .

chi:study_188565_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188565 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:hasMeasure chi:HeartRateMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188565_QualitativeResult ;
    chi:reportsResult chi:result_188565_StatisticalResult .

chi:artifact_188565_InputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188565 .

chi:artifact_188565_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188565 .

chi:result_188565_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188565_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188566 rdf:type chi:Paper ;
    dcterms:title "StructVizor: Interactive Profiling of Semi-Structured Textual Data" ;
    dcterms:abstract "Data profiling plays a critical role in understanding the structure of complex datasets and supporting numerous downstream tasks, such as social media analytics and financial fraud detection. While existing research predominantly focuses on structured data formats, a substantial portion of semi-structured textual data still requires ad-hoc and arduous manual profiling to extract and comprehend its internal structures. In this work, we propose StructVizor, an interactive profiling system that facilitates sensemaking and transformation of semi-structured textual data. Our tool mainly addresses two challenges: a) extracting and visualizing the diverse structural patterns within data, such as how information is organized or related, and b) enabling users to efficiently perform various wrangling operations on textual data. Through automatic data parsing and structure mining,  StructVizor enables visual analytics of structural patterns, while incorporating novel interactions to enable profile-based data wrangling. A comparative user study involving 12 participants demonstrates the system's usability and its effectiveness in supporting exploratory data analysis and transformation tasks." ;
    dcterms:identifier "3706598.3713484" ;
    chi:hasAuthor chi:person_185405, chi:person_186651, chi:person_185458, chi:person_184390, chi:person_187341 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:CollaborativeVisualizationTools ;
    chi:paperIncludesStudy chi:study_188566_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188566_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188566_InterfaceArtifact .

chi:study_188566_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188566 ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:reportsResult chi:result_188566_QualitativeResult ;
    chi:reportsResult chi:result_188566_StatisticalResult .

chi:artifact_188566_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188566 .

chi:artifact_188566_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188566 .

chi:result_188566_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188566_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188567 rdf:type chi:Paper ;
    dcterms:title "The Sky is the Limit: Understanding How Generative AI can Enhance Screen Reader Users' Experience with Productivity Applications" ;
    dcterms:abstract "Productivity applications including word processors, spreadsheets, and presentation tools are crucial in work, education, and personal settings. Blind users typically access these tools via screen readers (SRs) and face significant accessibility and usability challenges. Recent advancements in Generative AI (GenAI) may address these challenges by enabling natural language interactions and contextual task understanding. However, there is limited understanding of SR users’ needs and attitudes toward GenAI assistance in these applications. We surveyed 99 SR users to gain a holistic understanding of the challenges they face when using productivity applications, the impact of these challenges on their productivity and independence, and their initial perceptions of AI assistance. Driven by their enthusiasm, we conducted interviews with 16 SR users to explore their attitudes toward GenAI and its potential usefulness in productivity applications. Our findings highlight its need to support existing SR workflows and the importance of enabling customization and task verification." ;
    dcterms:identifier "3706598.3713634" ;
    chi:hasAuthor chi:person_185589, chi:person_183991, chi:person_186902, chi:person_186060 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188567_UserStudy ;
    chi:paperIncludesStudy chi:study_188567_InterviewStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188567_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188567_InterfaceArtifact .

chi:study_188567_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188567 ;
    chi:reportsResult chi:result_188567_QualitativeResult ;
    chi:reportsResult chi:result_188567_StatisticalResult .

chi:study_188567_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188567 ;
    chi:reportsResult chi:result_188567_QualitativeResult ;
    chi:reportsResult chi:result_188567_StatisticalResult .

chi:artifact_188567_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188567 .

chi:artifact_188567_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188567 .

chi:result_188567_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188567_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188568 rdf:type chi:Paper ;
    dcterms:title "\"I Don’t Know Why I Should Use This App”: Holistic Analysis on User Engagement Challenges in Mobile Mental Health" ;
    dcterms:abstract "Over the past decade, mobile apps have been widely adopted as a digital intervention method for mental health support, offering scalable and accessible solutions to address the growing global mental health challenges. However, sustaining user engagement in real-world settings remains a major challenge in the development of these applications. This study systematically examines factors that hinder user engagement in existing mobile mental health support systems through a scoping review of the literature. After an initial identification of 1,267 papers, we conducted a final analysis of 111 empirical studies using mobile app-based mental health support systems. The study investigates the main factors that negatively affect user engagement from user and system perspectives. Based on these findings, we propose guidelines for enhancing user engagement and structuring personalized emotional interaction design along three dimensions: adaptive, continuous, and multimodal interactions. Furthermore, we discuss the potential for integration with advanced AI methods (e.g., LLM-based AI agents) as a way to achieve these design implications and suggestions. Our results provide critical insights for enhancing long-term user engagement in the development of future mental health support systems." ;
    dcterms:identifier "3706598.3713732" ;
    chi:hasAuthor chi:person_184433, chi:person_184749, chi:person_183521 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188568_SoftwareArtifact .

chi:artifact_188568_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188568 .

chi:result_188568_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188569 rdf:type chi:Paper ;
    dcterms:title "Examining the Effects of Immersive and Non-Immersive Presenter Modalities on Engagement and Social Interaction in Co-located Augmented Presentations" ;
    dcterms:abstract "Head-worn augmented reality (AR) allows audiences to be immersed and engaged in stories told by live presenters. While presenters may also be in AR to have the same level of immersion and awareness as their audience, this symmetric presentation style may diminish important social cues such as eye contact. In this work, we examine the effects this (a)symmetry has on engagement, group awareness, and social interaction in co-located one-on-one augmented presentations. We developed a presentation system incorporating 2D/3D content that audiences can view and interact with in AR, with presenters controlling and delivering the presentation in either a symmetric style in AR, or an asymmetric style with a handheld tablet. We conducted a within- and between-subjects evaluation with 12 participant pairs to examine the differences between these symmetric and asymmetric presentation modalities. From our findings, we extracted four themes and derived strategies and guidelines for designers interested in augmented presentations." ;
    dcterms:identifier "3706598.3713346" ;
    chi:hasAuthor chi:person_183363, chi:person_183971, chi:person_187388, chi:person_186546, chi:person_187760, chi:person_185837 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:EmbodiedVRInteraction ;
    chi:paperIncludesStudy chi:study_188569_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188569_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188569_InterfaceArtifact .

chi:study_188569_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188569 ;
    chi:reportsResult chi:result_188569_QualitativeResult .

chi:artifact_188569_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188569 .

chi:artifact_188569_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188569 .

chi:result_188569_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188570 rdf:type chi:Paper ;
    dcterms:title "Of Ironies and Agency: Energy Professionals’ Views on Digital Interventions and Their Users" ;
    dcterms:abstract "The efficacy of digital solutions to increase energy efficiency, including technical optimisations and behavioural influence, has long been a subject of debate within sustainable HCI (SHCI). While the viewpoints of policymakers and academics are frequently published (and often contradictory), less is known about the views of those on the ground. In this paper we ask: What are energy professionals' views of digital energy-saving interventions and their users? What are the challenges they face implementing these interventions? Based on a university campus case study with twelve semi-structured interviews and a focus group with energy and facilities' professionals, we illustrate how they strongly advocate digital efficiency as a pathway to sustainability; yet, this optimism is in apparent tension with key barriers they identify to realising 'their seamless visions', particularly the complexities of the human behaviour they are seeking to optimise. These findings underscore the seductiveness of techno-optimism and the need for more systemic change." ;
    dcterms:identifier "3706598.3713754" ;
    chi:hasAuthor chi:person_188169, chi:person_182739, chi:person_183095 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:QualitativeAnalysisSupportTools ;
    chi:paperIncludesStudy chi:study_188570_InterviewStudy .

chi:study_188570_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188570 ;
    chi:reportsResult chi:result_188570_QualitativeResult .

chi:result_188570_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188571 rdf:type chi:Paper ;
    dcterms:title "Crafting Champions: An Observation Study of Esports Coaching Processes" ;
    dcterms:abstract "As esports grows into a multi-million dollar industry of professional players and competitions, so too grows the interest in and need for professional coaching. Accordingly, there are increased demands and attempts to support and improve coaching for esports. A more comprehensive, granular understanding of the esports coaching process would provide a valuable foundation to inform opportunities to advance the domain via HCI theories and practices. However, in-depth studies of coaching practice, from the lens of HCI, are far less common in existing literature. In this paper, we take the first steps to provide such a foundation through an observation study conducted at an elite, award-winning League of Legends training academy. By analyzing 112 hours of dialogue and footage from coaching sessions, we identify pertinent activities and events that occur within the coaching process, which enable us to consider how esports coaching can be improved via theory, practice, and technology from HCI." ;
    dcterms:identifier "3706598.3713141" ;
    chi:hasAuthor chi:person_187207, chi:person_186759, chi:person_187865, chi:person_184022, chi:person_187254, chi:person_184648 ;
    chi:hasPrimaryTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:CollaborativeSensemaking ;
    chi:paperIncludesStudy chi:study_188571_FieldStudy ;
    chi:aimsAtGoal chi:PromoteLearning .

chi:study_188571_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188571 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188571_QualitativeResult .

chi:result_188571_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188572 rdf:type chi:Paper ;
    dcterms:title "Walk in Their Shoes to Navigate Your Own Path: Learning About Procrastination Through A Serious Game" ;
    dcterms:abstract "Procrastination, the voluntary delay of tasks despite potential negative consequences, has prompted numerous time and task management interventions in the HCI community. While these interventions have shown promise in addressing specific behaviors, psychological theories suggest that learning about procrastination itself may help individuals develop their own coping strategies and build mental resilience. However, little research has explored how to support this learning process through HCI approaches. We present ProcrastiMate, a text adventure game where players learn about procrastination's causes and experiment with coping strategies by guiding in-game characters in managing relatable scenarios. Our field study with 27 participants revealed that ProcrastiMate facilitated learning and self-reflection while maintaining psychological distance, motivating players to integrate newly acquired knowledge in daily life. This paper contributes empirical insights on leveraging serious games to facilitate learning about procrastination and offers design implications for addressing psychological challenges through HCI approaches." ;
    dcterms:identifier "3706598.3715271" ;
    chi:hasAuthor chi:person_187263, chi:person_188170, chi:person_186659, chi:person_185717, chi:person_187919, chi:person_183158, chi:person_184716, chi:person_183481, chi:person_185778 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:SelfReflectionAndBehaviorChange ;
    chi:paperIncludesStudy chi:study_188572_FieldStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188572_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188572_InterfaceArtifact .

chi:study_188572_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188572 ;
    chi:reportsResult chi:result_188572_QualitativeResult .

chi:artifact_188572_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188572 .

chi:artifact_188572_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188572 .

chi:result_188572_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188573 rdf:type chi:Paper ;
    dcterms:title "Stills from the Inner Ear Shorts: Collecting and Living with Data" ;
    dcterms:abstract "Data collection and representation invariably involve interpretation with various layers of translation. We designed the Inner Ear—a porcelain device that both captures and represents home vibration data—to rethink the relationship between home dwellers and their data. In this paper, we report on the deployment of the Inner Ear with seven participants in Seattle, Washington, USA. We examine stills and quotes from the Inner Ear Shorts: short documentary films that capture participants’ experiences and reflections with the Inner Ear. Our findings outline nuanced relationships with data that foreground sensorial and conscious experiences to engage with objects, spaces, and infrastructure, and deemphasize legibility to give space to memory and broaden definitions of data. We discuss how more ambiguous relationships with data can be beneficial to reconfigure everyday lives with data. We conclude with a reflection on the use of documentary filmmaking as a complementary methodological approach to synthesizing and analyzing research data." ;
    dcterms:identifier "3706598.3713525" ;
    chi:hasAuthor chi:person_187124, chi:person_186181, chi:person_187500, chi:person_185628, chi:person_183952, chi:person_186303, chi:person_184685, chi:person_187924, chi:person_185566, chi:person_187878, chi:person_187041 ;
    chi:paperIncludesStudy chi:study_188573_FieldStudy ;
    chi:paperIncludesStudy chi:study_188573_UserStudy ;
    chi:proposesArtifact chi:artifact_188573_DeviceArtifact .

chi:study_188573_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188573 ;
    chi:reportsResult chi:result_188573_QualitativeResult .

chi:study_188573_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188573 ;
    chi:reportsResult chi:result_188573_QualitativeResult .

chi:artifact_188573_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188573 .

chi:result_188573_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188574 rdf:type chi:Paper ;
    dcterms:title "Exploring the Impact of Avatar Representations in AI Chatbot Tutors on Learning Experiences" ;
    dcterms:abstract "Despite the growing prominence of Artificial Intelligence (AI) chatbots used in education, there remains a significant gap in our understanding of how interface design elements, particularly avatar representations, influence learning experiences. This paper explores the impact of different AI chatbot avatar representations on students' learning experiences through a mixed-methods within-subjects study, where participants interacted with three distinct types of AI chatbot interfaces with a common large language model (LLM) over a 14-week university course. Our findings reveal that preferences vary according to factors such as learning habits and learning activities. Avatar design also exhibits affordances for specific prompting behaviors, while the perceived human touch influenced learning experiences in nuanced ways. Additionally, real-world relationships with the individuals behind deepfakes influence these experiences. These insights suggest that the thoughtful integration of diverse avatar representations in AI chatbot systems for different learners and settings can greatly enhance learning experiences." ;
    dcterms:identifier "3706598.3713456" ;
    chi:hasAuthor chi:person_187902, chi:person_185187, chi:person_187081, chi:person_184824, chi:person_184941 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188574_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188574_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188574_SoftwareArtifact .

chi:study_188574_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188574 ;
    chi:reportsResult chi:result_188574_QualitativeResult .

chi:artifact_188574_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188574 .

chi:artifact_188574_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188574 .

chi:result_188574_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188575 rdf:type chi:Paper ;
    dcterms:title "A Qualitative Study on How Usable Security and HCI Researchers Judge the Size and Importance of Odds Ratio and Cohen's d Effect Sizes" ;
    dcterms:abstract "Researchers often place a strong focus on statistical significance when reporting the results of statistical tests. However, effect sizes are reported less frequently, and interpretation in the context of the study and the research field is even rarer. These interpretations of effect sizes are, however, necessary to understand the practical importance of a result for the community.  To explore how Usable Security & Privacy (USP) and HCI researchers interpret effect sizes and make judgments on practical importance, we conducted survey and interview studies with a total of 63 researchers at CHI and SOUPS 2023. Our studies focused on Cohen's d and odds ratios in two USP and one HCI scenario. We analyzed which artifacts researchers consider when judging effect size, and found misconceptions and variation between the participants, highlighting how difficult judging statistics can be. Based on our findings, we make concrete recommendations for improved reporting practices around effect sizes. " ;
    dcterms:identifier "3706598.3714022" ;
    chi:hasAuthor chi:person_187781, chi:person_185594, chi:person_183003, chi:person_187938 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:QualitativeAnalysisSupportTools ;
    chi:paperIncludesStudy chi:study_188575_InterviewStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking .

chi:study_188575_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188575 ;
    chi:reportsResult chi:result_188575_QualitativeResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:result_188575_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188576 rdf:type chi:Paper ;
    dcterms:title "RoboTeach: How Student Robots' Preexisting Proficiency and Learning Rate Affect Human Teachers Demonstrating Object Placement" ;
    dcterms:abstract "Social robots are employed as companions, helping in industrial and domestic environments. Adapting robots' capabilities to user needs can be achieved through teaching from human demonstrations. However, the influence of robots' preexisting proficiency and learning rate on human teachers' self-efficacy and perception of the robots is underexplored. In this paper, we simulated four robot performance types that combine: (1) preexisting proficiency (low/high) and (2) learning rate (slow/fast). We conducted a controlled lab experiment studying the impact of robots' performance type on teachers' self-efficacy, willingness to teach the robot, and perception of the robot (N=24), in which robots placed objects in suitable locations. Fast learners were perceived as more intelligent, anthropomorphic, and likable, and this caused higher teaching self-efficacy regardless of preexisting skills. Slow learners caused frustration while teaching. Moreover, participants stopped teaching robots with low preexisting skills sooner, regardless of the learning rate, indicating potential bias caused by expectations." ;
    dcterms:identifier "3706598.3713113" ;
    chi:hasAuthor chi:person_184145, chi:person_187415, chi:person_186612, chi:person_186309 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188576_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188576_DeviceArtifact .

chi:study_188576_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188576 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188576_StatisticalResult ;
    chi:reportsResult chi:result_188576_QualitativeResult .

chi:artifact_188576_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188576 .

chi:result_188576_StatisticalResult rdf:type chi:StatisticalResult .

chi:result_188576_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188577 rdf:type chi:Paper ;
    dcterms:title "\"All Day, Every Day, Listening to Trauma\": Investigating Features of Digital Interventions for Empathy-Based Stress and Burnout" ;
    dcterms:abstract "Frontline workers (FLWs) in gender-based violence (GBV) service provision regularly engage in intense emotional labor to provide survivors of GBV with essential, often life-saving, services. However, FLWs experience intense burnout, resulting in turnover rates as high as 50% annually and a critical loss of services for survivors. In order to design digital burnout interventions in a context where so few exist, we recruited 15 FLWs for a 3-stage qualitative study where they used two existing applications to reflect on, and reimagine, concrete design features necessary to address FLW burnout in GBV service provision. We contribute important findings regarding designing specifically for empathy-based stress (EBS) in frontline work contexts, preferences for activities, desired interactivity, among other requirements for interventions. We synthesize our design recommendations through an example scenario of a collaborative just-in-time adaptive intervention (co-JITAI) system that integrates peer-based support that can adapt to users’ changing needs and contexts over time. " ;
    dcterms:identifier "3706598.3713588" ;
    chi:hasAuthor chi:person_185734, chi:person_184724, chi:person_183691, chi:person_188099 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing:SelfReflectionAndBehaviorChange ;
    chi:paperIncludesStudy chi:study_188577_InterviewStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188577_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188577_InterfaceArtifact .

chi:study_188577_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188577 ;
    chi:reportsResult chi:result_188577_QualitativeResult .

chi:artifact_188577_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188577 .

chi:artifact_188577_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188577 .

chi:result_188577_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188578 rdf:type chi:Paper ;
    dcterms:title "The Voice of Endo: Leveraging Speech for an Intelligent System That Can Forecast Illness Flare-ups" ;
    dcterms:abstract "Managing complex chronic illness is challenging due to its unpredictability. This paper explores the potential of voice for automated flare-up forecasts. We conducted a six-week speculative design study with individuals with endometriosis, tasking participants to submit daily voice recordings and symptom logs. Through focus groups, we elicited their experiences with voice capture and perceptions of its usefulness in forecasting flare-ups. Participants were enthusiastic and intrigued at the potential of flare-up forecasts through the analysis of their voice. They highlighted imagined benefits from the experience of recording in supporting emotional aspects of illness and validating both day-to-day and overall illness experiences. Participants reported that their recordings revolved around their endometriosis, suggesting that the recordings’ content could further inform forecasting. We discuss potential opportunities and challenges in leveraging the voice as a data modality in human-centered AI tools that support individuals with complex chronic conditions." ;
    dcterms:identifier "3706598.3714040" ;
    chi:hasAuthor chi:person_185699, chi:person_185749, chi:person_185720, chi:person_185114 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188578_DiaryStudy ;
    chi:paperIncludesStudy chi:study_188578_FieldStudy ;
    chi:paperIncludesStudy chi:study_188578_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188578_UserStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188578_SoftwareArtifact .

chi:study_188578_DiaryStudy rdf:type chi:DiaryStudy ;
    chi:isStudyReportedIn chi:paper_188578 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188578_QualitativeResult ;
    chi:involvesParticipationPattern chi:AsynchronousParticipation .

chi:study_188578_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188578 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188578_QualitativeResult ;
    chi:involvesParticipationPattern chi:AsynchronousParticipation .

chi:study_188578_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188578 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188578_QualitativeResult ;
    chi:involvesParticipationPattern chi:AsynchronousParticipation .

chi:study_188578_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188578 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188578_QualitativeResult ;
    chi:involvesParticipationPattern chi:AsynchronousParticipation .

chi:artifact_188578_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188578 .

chi:result_188578_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188580 rdf:type chi:Paper ;
    dcterms:title "Working Together Toward Interdependence: Chatbot-Based Support for Balanced Social Interactions Between Neurodivergent and Neurotypical Individuals" ;
    dcterms:abstract "While many technologies have been developed for facilitating interaction between neurodivergent and neurotypical people to bridge communication differences and reduce social exclusion, most focus on supporting and teaching neurodivergent people to adapt to neurotypical standards and norms. To promote a more balanced approach to bridging the social gap, we conducted a 5-day diary study and semi-structured interviews with 16 participants (8 neurotypical and 8 with intellectual disability) to examine the current factors and barriers to their social interactions and to explore the design of social support chatbot systems. Our findings revealed diverging views between the groups on factors they valued in their interaction, and identified social uncertainty and differing social expectations as the main barriers to successful interactions. Based on the results, we outline three pitfalls that social support chatbots can fall into if not designed mindfully, and suggest design approaches that promote bidirectional social support and interdependence." ;
    dcterms:identifier "3706598.3713344" ;
    chi:hasAuthor chi:person_185531, chi:person_183638, chi:person_182679, chi:person_187522 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialSupportAndPeerChatbots ;
    chi:paperIncludesStudy chi:study_188580_DiaryStudy ;
    chi:paperIncludesStudy chi:study_188580_InterviewStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188580_SoftwareArtifact .

chi:study_188580_DiaryStudy rdf:type chi:DiaryStudy ;
    chi:isStudyReportedIn chi:paper_188580 ;
    chi:reportsResult chi:result_188580_QualitativeResult .

chi:study_188580_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188580 ;
    chi:reportsResult chi:result_188580_QualitativeResult .

chi:artifact_188580_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188580 .

chi:result_188580_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188581 rdf:type chi:Paper ;
    dcterms:title "Children using Tabletop Telepresence Robots for Collaboration: A Longitudinal Case Study of Hybrid and Online Intergenerational Participatory Design" ;
    dcterms:abstract "Improving telepresence for children expands educational opportunities and connects faraway family. Yet, research about child-centered physical telepresence systems (tangible interfaces for telepresence) remains sparse, despite established benefits of tangible interaction for children. To address this gap, we collaborated with child designers (ages 8-12) over 2-years of online/1-year of hybrid participatory design. Together, we adapted one approach to physical telepresence (tabletop robots) for child users. Using a case study methodology, we explore how our tabletop telepresence robot platform influenced children’s connections with one another over the 3-year study. In our analysis, we compare four vignettes representing cooperation/conflict between children while using the platform; centering theories of ownership, collaboration, and co-design roles. Through this exploration of children’s interpersonal dynamics while using the platform, we uncover four key features of tabletop telepresence robots for children: (1) Anonymous Robot Control (2) Robot/Material Distribution, (3) Robot Form/Size, and (4) Robot Stewardship." ;
    dcterms:identifier "3706598.3713746" ;
    chi:hasAuthor chi:person_182879, chi:person_186420, chi:person_182651, chi:person_184933, chi:person_187443, chi:person_183235, chi:person_186545, chi:person_183877 ;
    chi:hasPrimaryTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:paperIncludesStudy chi:study_188581_UserStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188581_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188581_InterfaceArtifact .

chi:study_188581_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188581 ;
    chi:reportsResult chi:result_188581_QualitativeResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation ;
    chi:involvesParticipationPattern chi:HybridParticipation .

chi:artifact_188581_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188581 .

chi:artifact_188581_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188581 .

chi:result_188581_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188582 rdf:type chi:Paper ;
    dcterms:title "Do Expressions Change Decisions? Exploring the Impact of AI's Explanation Tone on Decision-Making" ;
    dcterms:abstract "Explanatory information helps users to evaluate the suggestions offered by AI-driven decision support systems. With large language models, adjusting explanation expressions has become much easier. However, how these expressions influence human decision-making remains largely unexplored. This study investigated the effect of explanation tone (e.g., formal or humorous) on decision-making, focusing on AI roles and user attributes. We conducted user experiments across three scenarios depending on AI roles (assistant, second-opinion provider, and expert) using datasets designed with varying tones. The results revealed that tone significantly influenced decision-making regardless of user attributes in the second-opinion scenario, whereas its impact varied by user attributes in the assistant and expert scenarios.  In addition, older users were more influenced by tone, and highly extroverted users exhibited discrepancies between their perceptions and decisions. Furthermore, open-ended questionnaires highlighted that users expect tone adjustments to enhance their experience while emphasizing the importance of tone consistency and ethical considerations. Our findings provide crucial insights into the design of explanation expressions." ;
    dcterms:identifier "3706598.3713744" ;
    chi:hasAuthor chi:person_184284, chi:person_182721, chi:person_187005 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:ChatbotAssistedUserStudies ;
    chi:paperIncludesStudy chi:study_188582_UserStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188582_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188582_InterfaceArtifact .

chi:study_188582_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188582 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188582_QualitativeResult ;
    chi:reportsResult chi:result_188582_StatisticalResult .

chi:artifact_188582_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188582 .

chi:artifact_188582_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188582 .

chi:result_188582_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188582_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188583 rdf:type chi:Paper ;
    dcterms:title "Characterizing Photorealism and Artifacts in Diffusion Model-Generated Images" ;
    dcterms:abstract "Diffusion model-generated images can appear indistinguishable from authentic photographs, but these images often contain artifacts and implausibilities that reveal their AI-generated provenance. Given the challenge to public trust in media posed by photorealistic AI-generated images, we conducted a large-scale experiment measuring human detection accuracy on 450 diffusion-model generated images and 149 real images. Based on collecting 749,828 observations and 34,675 comments from 50,444 participants, we find that scene complexity of an image, artifact types within an image, display time of an image, and human curation of AI-generated images all play significant roles in how accurately people distinguish real from AI-generated images. Additionally, we propose a taxonomy characterizing artifacts often appearing in images generated by diffusion models. Our empirical observations and taxonomy offer nuanced insights into the capabilities and limitations of diffusion models to generate photorealistic images in 2024." ;
    dcterms:identifier "3706598.3713962" ;
    chi:hasAuthor chi:person_185138, chi:person_187911, chi:person_187756, chi:person_186329, chi:person_183750, chi:person_186263 ;
    chi:paperIncludesStudy chi:study_188583_UserStudy ;
    chi:paperIncludesStudy chi:study_188583_QualitativeStudy ;
    chi:paperIncludesStudy chi:study_188583_QuantitativeStudy ;
    chi:proposesArtifact chi:artifact_188583_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188583_InterfaceArtifact .

chi:study_188583_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188583 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188583_QualitativeResult ;
    chi:reportsResult chi:result_188583_StatisticalResult .

chi:study_188583_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188583 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188583_QualitativeResult ;
    chi:reportsResult chi:result_188583_StatisticalResult .

chi:study_188583_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188583 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188583_QualitativeResult ;
    chi:reportsResult chi:result_188583_StatisticalResult .

chi:artifact_188583_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188583 .

chi:artifact_188583_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188583 .

chi:result_188583_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188583_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188584 rdf:type chi:Paper ;
    dcterms:title "The Triangle of Misunderstanding in Interactive Virtual Narratives: Gulfs Between System, Designers and Players" ;
    dcterms:abstract "Designers of storytelling experiences in virtual reality (VR) can take advantage of the medium's realism and immersion to communicate their intentions. However, interaction freedom comes with unpredictability, raising the risk of miscommunication between the experience sought by the designer and the player's interpretation. To better understand such miscommunications, we revisit Don Norman's work on stages of action to propose a model of designer-player gulfs in VR that incorporates eight classes of communication gulfs. We designed a two-phase study where 10 participants designed VR scenarios and then played scenarios created by previous participants. Through coupled structured interviews, we identified 127 issues in VR-mediated communication that were mapped to our model to understand their impact on the player's interpretation of the narrative experience. Our work provides a roadmap to identifying sources of miscommunication in VR, a first step to conceiving principles and guidelines for achieving effective communication in storytelling experiences." ;
    dcterms:identifier "3706598.3713700" ;
    chi:hasAuthor chi:person_188128, chi:person_187306, chi:person_184186, chi:person_184769 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:EmbodiedVRInteraction ;
    chi:paperIncludesStudy chi:study_188584_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188584_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188584_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188584_SoftwareArtifact .

chi:study_188584_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188584 ;
    chi:reportsResult chi:result_188584_QualitativeResult .

chi:study_188584_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188584 ;
    chi:reportsResult chi:result_188584_QualitativeResult .

chi:artifact_188584_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188584 .

chi:artifact_188584_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188584 .

chi:result_188584_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188585 rdf:type chi:Paper ;
    dcterms:title "Designing Urban Noticing Probes for Community Animals and Cohabitation in Türkiye" ;
    dcterms:abstract "Design tools and probing, in particular, have long offered critical perspectives in HCI, broadening the understanding of who benefits from the design. Further, the designerly implementation of critical perspectives and theories using tools such as probes can support HCI designers with theoretically informed dialogical tools. However, these approaches and processes are majorly designed to understand human interactions. In this paper, we introduce urban noticing probes developed to decentre the humans in multispecies interactions by following the arts of noticing theory: noticing into, for, and through within urban relationality, focusing on the case of community animals in Türkiye. Our goal is to create a better understanding of the functions of \"urban noticing probes\" for HCI designers and researchers to (1) gain relational and reflexive awareness, (2) identify intervention spaces for multispecies cohabitation, and (3) explore future design directions for urban noticing probes." ;
    dcterms:identifier "3706598.3713977" ;
    chi:hasAuthor chi:person_185097, chi:person_184534 .

chi:result_188585_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188587 rdf:type chi:Paper ;
    dcterms:title "DistKey: Incorporating Physical Activities into Daily Workflow through Spatially Distributed Hotkeys " ;
    dcterms:abstract "It is important to motivate healthy behaviors, especially in office environments. However, there are few systems which integrate physical engagement mechanisms in such environments. This paper presents the design and evaluation of DistKey, a set of hotkeys allocated in different spatial interfaces of the workspace, enabling users to engage in some office tasks through intentional body movements. Through a within-subject experiment with 20 office workers, we compared DistKey with a traditional keyboard to assess the health benefits and effectiveness of integrating exercise into the workflow. Our results confirmed the benefits of DistKey-led healthful interactions in enhancing physical health and reducing mental stress during different tasks at work. Based on our follow-up qualitative research, a range of design insights are discussed to enlighten the design and development of future healthful spatial interfaces for increased office vitality." ;
    dcterms:identifier "3706598.3713625" ;
    chi:hasAuthor chi:person_184697, chi:person_187103, chi:person_186833, chi:person_185034, chi:person_184196 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:paperIncludesStudy chi:study_188587_BaselineComparisonStudy ;
    chi:paperIncludesStudy chi:study_188587_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188587_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188587_InputDeviceArtifact .

chi:study_188587_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188587 ;
    chi:reportsResult chi:result_188587_QualitativeResult ;
    chi:reportsResult chi:result_188587_StatisticalResult .

chi:study_188587_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188587 ;
    chi:reportsResult chi:result_188587_QualitativeResult ;
    chi:reportsResult chi:result_188587_StatisticalResult .

chi:artifact_188587_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188587 .

chi:artifact_188587_InputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188587 .

chi:result_188587_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188587_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188588 rdf:type chi:Paper ;
    dcterms:title "In the Moment of Glitch: Engaging with Misalignments in Ethical Practice" ;
    dcterms:abstract "Glitches -- moments when technologies do not work as desired -- will become increasingly common as industrially-designed robots move into complex contexts. Taking glitches to be potential sites of critical ethical reflection, we examine a glitch that occurred in the context of a collaborative research project where professional dancers with different disabilities improvised with a robotic arm. Through a first-person account, we analyse how the dancer, the robot, and the rest of the research team enacted ethics in the moment of glitch. Through this analysis, we discovered a deep and implicit ethical misalignment wherein our enactments of ethics in response to the glitch did not align with the values of the project. This prompted a critical re-engagement with our research process through which we forged a dialogue between different ethical perspectives that acted as an invitation to bring us back into ethical alignment with the project's values." ;
    dcterms:identifier "3706598.3713632" ;
    chi:hasAuthor chi:person_184419, chi:person_184796, chi:person_182665, chi:person_185216, chi:person_186058, chi:person_183966, chi:person_186230, chi:person_186860, chi:person_184451 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:ParticipatoryEthicsMethods ;
    chi:paperIncludesStudy chi:study_188588_QualitativeStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188588_DeviceArtifact .

chi:study_188588_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188588 ;
    chi:reportsResult chi:result_188588_QualitativeResult .

chi:artifact_188588_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188588 .

chi:result_188588_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188589 rdf:type chi:Paper ;
    dcterms:title "Enhancing Smartphone Eye Tracking with Cursor-Based Interactive Implicit Calibration" ;
    dcterms:abstract "The limited accuracy of eye-tracking on smartphones restricts its use. Existing RGB-camera-based eye-tracking relies on extensive datasets, which could be enhanced by continuous fine-tuning using calibration data implicitly collected from the interaction. In this context, we propose COMETIC (Cursor Operation Mediated Eye-Tracking Implicit Calibration), which introduces a cursor-based interaction and utilizes the inherent correlation between cursor and eye movement. By filtering valid cursor coordinates as proxies for the ground truth of gaze and fine-tuning the eye-tracking model with corresponding images, COMETIC enhances accuracy during the interaction. Both filtering and fine-tuning use pre-trained models and could be facilitated using personalized, dynamically updated data. Results show COMETIC achieves an average eye-tracking er- ror of 278.3 px (1.60 cm, 2.29◦), representing a 27.2% improvement compared to that without fine-tuning. We found that filtering cursor points whose actual distance to gaze is 150.0 px (0.86 cm) yields the best eye-tracking results." ;
    dcterms:identifier "3706598.3713936" ;
    chi:hasAuthor chi:person_185267, chi:person_183742, chi:person_187569, chi:person_182748, chi:person_183274, chi:person_186318, chi:person_187359, chi:person_187044 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:paperIncludesStudy chi:study_188589_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188589_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188589_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188589_DeviceArtifact .

chi:study_188589_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188589 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188589_StatisticalResult .

chi:artifact_188589_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188589 .

chi:artifact_188589_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188589 .

chi:artifact_188589_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188589 .

chi:result_188589_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188590 rdf:type chi:Paper ;
    dcterms:title "Weaving Sound Information to Support Real-Time Sensemaking of Auditory Environments: Co-Designing with a DHH User" ;
    dcterms:abstract "Current AI sound awareness systems can provide deaf and hard of hearing people with information about sounds, including discrete sound sources and transcriptions. However, synthesizing AI outputs based on DHH people’s ever-changing intents in complex auditory environments remains a challenge. In this paper, we describe the co-design process of SoundWeaver, a sound awareness system prototype that dynamically weaves AI outputs from different AI models based on users’ intents and presents synthesized information through a heads-up display. Adopting a Research through Design perspective, we created SoundWeaver with one DHH co-designer, adapting it to his personal contexts and goals (e.g., cooking at home and chatting in a game store). Through this process, we present design implications for the future of “intent-driven” AI systems for sound accessibility." ;
    dcterms:identifier "3706598.3714268" ;
    chi:hasAuthor chi:person_183934, chi:person_183900, chi:person_186945, chi:person_187845, chi:person_183107 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188590_UserStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188590_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188590_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188590_OutputDeviceArtifact .

chi:study_188590_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188590 ;
    chi:reportsResult chi:result_188590_QualitativeResult .

chi:artifact_188590_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188590 .

chi:artifact_188590_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188590 .

chi:artifact_188590_OutputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188590 .

chi:result_188590_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188591 rdf:type chi:Paper ;
    dcterms:title "Understanding Adolescents’ Perceptions of Benefits and Risks in Health AI Technologies through Design Fiction " ;
    dcterms:abstract "Despite the growing research on users’ perceptions of health AI, adolescents’ perspectives remain underexplored. This study explores adolescents’ perceived benefits and risks of health AI technologies in clinical and personal health settings. Employing Design Fiction, we conducted interviews with 16 adolescents (aged 13-17) using four fictional design scenarios that represent current and future health AI technologies as probes. Our findings revealed that with a positive yet cautious attitude, adolescents envision unique benefits and risks specific to their age group. While health AI technologies were seen as valuable learning resources, they also raised concerns about confidentiality with their parents. Additionally, we identified several factors, such as severity of health conditions and previous experience with AI, influencing their perceptions of trust and privacy in health AI. We explore how these insights can inform the future design of health AI technologies to support learning, engagement, and trust as adolescents navigate their healthcare journey. " ;
    dcterms:identifier "3706598.3713244" ;
    chi:hasAuthor chi:person_186567, chi:person_186374, chi:person_187484, chi:person_188062, chi:person_184727 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:paperIncludesStudy chi:study_188591_InterviewStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188591_InterfaceArtifact .

chi:study_188591_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188591 ;
    chi:reportsResult chi:result_188591_QualitativeResult .

chi:artifact_188591_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188591 .

chi:result_188591_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188592 rdf:type chi:Paper ;
    dcterms:title "Prompting in the Dark: Assessing Human Performance in Prompt Engineering for Data Labeling When Gold Labels Are Absent" ;
    dcterms:abstract "Millions of users prompt large language models (LLMs) for various tasks, but how good are people at prompt engineering? Do users actually get closer to their desired outcome over multiple iterations of their prompts? These questions are crucial when no gold-standard labels are available to measure progress. This paper investigates a scenario in LLM-powered data labeling, “prompting in the dark,” where users iteratively prompt LLMs to label data without using manually-labeled benchmarks. We developed PromptingSheet, a Google Sheets add-on that enables users to compose, revise, and iteratively label data through spreadsheets. Through a study with 20 participants, we found that prompting in the dark was highly unreliable—only 9 participants improved labeling accuracy after four or more iterations. Automated prompt optimization tools like DSPy also struggled when few gold labels were available. Our findings highlight the importance of gold labels and the needs, as well as the risks, of automated support in human prompt engineering, providing insights for future tool design." ;
    dcterms:identifier "3706598.3714319" ;
    chi:hasAuthor chi:person_183807, chi:person_185858, chi:person_183981 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:ChatbotAssistedUserStudies ;
    chi:paperIncludesStudy chi:study_188592_UserStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188592_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188592_InterfaceArtifact .

chi:study_188592_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188592 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188592_StatisticalResult .

chi:artifact_188592_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188592 .

chi:artifact_188592_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188592 .

chi:result_188592_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188593 rdf:type chi:Paper ;
    dcterms:title "A Systematic Review and Meta-Analysis of Research on Goals for Behavior Change" ;
    dcterms:abstract "HCI research on goals and behavior change has significantly increased over the past decade. However, while emerging work has synthesized personal informatics goals, fewer efforts have focused on also integrating HCI research on behavior change to chart future research directions.We conducted a systematic reviewof 180 papers focused on goals and behavior change from over 10 years of SIGCHI journals and conference proceedings. We further analyzed 37 papers from the data set that included evaluations of interventions’ effectiveness in-the-wild. We also reported on the effectiveness of 76 of such technology-based interventions and the meta-analysis of 28 of these interventions. We find that most research has focused on goals in the health and wellbeing domains, centered on the individual, low intrinsic goals, and partial use of theoretical constructs in technology-based interventions. We highlight opportunities for supporting multiple-domain, social, high intrinsic, and qualitative goals in HCI research for behavior change, and for more effective technology-based interventions with stronger theoretical underpinning, supporting users’ awareness of deep motives for qualitative goals." ;
    dcterms:identifier "3706598.3714072" ;
    chi:hasAuthor chi:person_185051, chi:person_183222, chi:person_182720, chi:person_184756, chi:person_187558, chi:person_186544, chi:person_185846 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:SelfReflectionAndBehaviorChange ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188593_SoftwareArtifact .

chi:artifact_188593_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188593 .

chi:result_188593_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188593_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188595 rdf:type chi:Paper ;
    dcterms:title "Super Kawaii Vocalics: Amplifying the “Cute” Factor in Computer Voice" ;
    dcterms:abstract "\"Kawaii\" is the Japanese concept of cute, which carries sociocultural connotations related to social identities and emotional responses. Yet, virtually all work to date has focused on the visual side of kawaii, including in studies of computer agents and social robots. In pursuit of formalizing the new science of kawaii vocalics, we explored what elements of voice relate to kawaii and how they might be manipulated, manually and automatically. We conducted a four-phase study (grand 𝑁 = 512) with two varieties of computer voices: text-to-speech (TTS) and game character voices. We found kawaii \"sweet spots\" through manipulation of fundamental and formant frequencies, but only for certain voices and to a certain extent. Findings also suggest a ceiling effect for the kawaii vocalics of certain voices. We offer empirical validation of the preliminary kawaii vocalics model and an elementary method for manipulating kawaii perceptions of computer voice." ;
    dcterms:identifier "3706598.3713709" ;
    chi:hasAuthor chi:person_187530, chi:person_186540, chi:person_188095, chi:person_186130, chi:person_184050, chi:person_186712 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:paperIncludesStudy chi:study_188595_UserStudy ;
    chi:paperIncludesStudy chi:study_188595_QuantitativeStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188595_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188595_OutputDeviceArtifact .

chi:study_188595_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188595 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188595_StatisticalResult .

chi:study_188595_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188595 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188595_StatisticalResult .

chi:artifact_188595_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188595 .

chi:artifact_188595_OutputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188595 .

chi:result_188595_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188596 rdf:type chi:Paper ;
    dcterms:title "The Making of Performative Accuracy in AI Training: Precision Labor and Its Consequences" ;
    dcterms:abstract "Accuracy and precision are central values in the AI communities and the technology sector. This paper provides empirical evidence on the construction and organizational management of technical accuracy, demonstrating how technology companies' preoccupation with such values leads to harm. Drawing on nine months of multi-sited ethnographic fieldwork in China, we document how AI trainers' everyday work practices, challenges, and harms stem from clients' demands for high levels of technical accuracy. We introduce the concept of precision labor to unpack the labor dimension of constructing and performing accuracy in AI training. This concept highlights the hidden and excessive labor required to reconcile the ambiguity and uncertainty involved in this process. We argue that precision labor offers a new lens to illuminate three critical aspects of AI training: 1) the negative health and financial impacts of hidden and excessive labor on AI workers; 2) emerging harms, including workers' subordinate roles to machines and financial precarity; and 3) a conceptual contribution to contexts beyond AI training. This contribution re-centers arbitrariness in technical production, highlights the excessive demands of precision labor, and examines the legitimization of labor and harm. Our study also contributes to existing scholarship on the prevailing values and invisible labor in AI production, underscoring accuracy as performative rather than self-evident and unambiguous. A precision labor lens challenges the legitimacy and sustainability of relentlessly pursuing technical accuracy, raising new questions about its consequences and ethical implications. We conclude by proposing recommendations and alternative approaches to enhance worker agency and well-being." ;
    dcterms:identifier "3706598.3713112" ;
    chi:hasAuthor chi:person_186908, chi:person_183268, chi:person_186751, chi:person_186111, chi:person_187503 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:ParticipatoryEthicsMethods ;
    chi:paperIncludesStudy chi:study_188596_FieldStudy .

chi:study_188596_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188596 ;
    chi:reportsResult chi:result_188596_QualitativeResult .

chi:result_188596_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188597 rdf:type chi:Paper ;
    dcterms:title "Breaking Barriers or Building Dependency? Exploring Team-LLM Collaboration in AI-infused Classroom Debate" ;
    dcterms:abstract "Classroom debates are a unique form of collaborative learning characterized by fast-paced, high-intensity interactions that foster critical thinking and teamwork. Despite the recognized importance of debates, the role of AI tools, particularly LLM-based systems, in supporting this dynamic learning environment has been under-explored in HCI. This study addresses this opportunity by investigating the integration of LLM-based AI into real-time classroom debates. Over four weeks, 22 students in a Design History course participated in three rounds of debates with support from ChatGPT. The findings reveal how learners prompted the AI to offer insights, collaboratively processed its outputs, and divided labor in team-AI interactions. The study also surfaces key advantages of AI usage—reducing social anxiety, breaking communication barriers, and providing scaffolding for novices—alongside risks, such as information overload and cognitive dependency, which could limit learners' autonomy. We thereby discuss a set of nuanced implications for future HCI exploration." ;
    dcterms:identifier "3706598.3713853" ;
    chi:hasAuthor chi:person_182793, chi:person_182998, chi:person_185778 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188597_FieldStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188597_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188597_InterfaceArtifact .

chi:study_188597_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188597 ;
    chi:reportsResult chi:result_188597_QualitativeResult .

chi:artifact_188597_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188597 .

chi:artifact_188597_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188597 .

chi:result_188597_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188598 rdf:type chi:Paper ;
    dcterms:title "evARything, evARywhere, all at once: Exploring Scalable Holistic Autonomous Vehicle-Cyclist Interfaces" ;
    dcterms:abstract "Cyclists need interfaces such as on-vehicle displays or augmented-reality (AR) glasses for effective communication with autonomous vehicles (AVs) when human drivers are no longer present. Interfaces must handle complex situations involving multiple AVs around a cyclist. Holistic AV-Cyclist Interfaces (HACIs) are a novel solution; they group interfaces into a multimodal interconnected system to support the rider. However, the best way to present information is uncertain. We explored this in a scenario with three AVs using CycleARcade, a new multi-user AR platform for designing and evaluating HACIs. Cyclists and HCI researchers collaboratively created and tested HACIs within CycleARcade through a novel iterative participatory design method. We synthesised three HACIs from this process and assessed them with riders in CycleARcade. Participants preferred HACIs with AR displays integrated into the environment to avoid road distractions, paired with spatial audio communicating AV proximity. These findings provide crucial input for the real-world deployment of AVs." ;
    dcterms:identifier "3706598.3713412" ;
    chi:hasAuthor chi:person_184456, chi:person_185075, chi:person_186565, chi:person_186153 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:EmbodiedVRInteraction ;
    chi:paperIncludesStudy chi:study_188598_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188598_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188598_InterfaceArtifact .

chi:study_188598_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188598 ;
    chi:reportsResult chi:result_188598_QualitativeResult .

chi:artifact_188598_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188598 .

chi:artifact_188598_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188598 .

chi:result_188598_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188599 rdf:type chi:Paper ;
    dcterms:title "LLM Powered Text Entry Decoding and Flexible Typing on Smartphones" ;
    dcterms:abstract "Large language models (LLMs) have shown exceptional performance in various language-related tasks. However, their application in keyboard decoding, which involves converting input signals (e.g. taps and gestures) into text, remains underexplored. This paper presents a fine-tuned FLAN-T5 model for decoding. It achieves 93.1% top-1 accuracy on user-drawn gestures, outperforming the widely adopted SHARK2 decoder, and 95.4% on real-word tap typing data. In particular, our decoder supports Flexible Typing, allowing users to enter a word with taps, gestures, multi-stroke gestures, and tap-gesture combinations. User study results show that Flexible Typing is beneficial and well-received by participants, where 35.9% of words were entered using word gestures, 29.0% with taps, 6.1% with multi-stroke gestures, and the remaining 29.0% using tap-gestures. Our investigation suggests that the LLM-based decoder improves decoding accuracy over existing word gesture decoders while enabling the Flexible Typing method, which enhances the overall typing experience and accommodates diverse user preferences." ;
    dcterms:identifier "3706598.3714314" ;
    chi:hasAuthor chi:person_183239, chi:person_186117, chi:person_185684, chi:person_184662 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:PointingAndSelectionPerformance ;
    chi:paperIncludesStudy chi:study_188599_UserStudy ;
    chi:paperIncludesStudy chi:study_188599_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188599_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188599_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188599_InputDeviceArtifact .

chi:study_188599_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188599 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188599_StatisticalResult .

chi:study_188599_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188599 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188599_StatisticalResult .

chi:artifact_188599_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188599 .

chi:artifact_188599_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188599 .

chi:artifact_188599_InputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188599 .

chi:result_188599_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188603 rdf:type chi:Paper ;
    dcterms:title "Building a Better Social Media Platform: Can We Codesign With Equity in Mind?" ;
    dcterms:abstract "Adolescents are frequent users of social media, with research suggesting both potential harms and positive impacts from use. Black and Hispanic/Latinx youth in particular are both early adopters and high users of social media platforms. However, adolescents–and youth of color in particular–have relatively little say in the design of such platforms. We propose youth participatory action research (YPAR) as a model for informing co-design sessions with representatives of a social networking platform to develop community-building solutions and improve youth developmental outcomes. In a four-months-long study with Black and Hispanic/Latinx teens aged 14-17 ($n = 14$), we examined how their sense of engagement and efficacy were altered by actively leading, participating in and contributing to design exercises facilitated by Instagram, one of the world's largest social media sites. Results of pre- and post- surveys indicated a significant increase in teens’ civic engagement as well as leadership efficacy. Our results contribute to the understanding of teenagers’ expectations and attitudes toward social media and how participatory methods for achieving equity in design can affect change. Theoretical and practical implications are discussed." ;
    dcterms:identifier "3706598.3713901" ;
    chi:hasAuthor chi:person_187812, chi:person_184100, chi:person_186982, chi:person_185430 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:aboutTopic chi:FuturesOfSocialPlatforms ;
    chi:paperIncludesStudy chi:study_188603_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188603_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188603_InterfaceArtifact .

chi:study_188603_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188603 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188603_StatisticalResult ;
    chi:reportsResult chi:result_188603_QualitativeResult .

chi:artifact_188603_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188603 .

chi:artifact_188603_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188603 .

chi:result_188603_StatisticalResult rdf:type chi:StatisticalResult .

chi:result_188603_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188605 rdf:type chi:Paper ;
    dcterms:title "Estimating the Effects of Encumbrance and Walking on Mixed Reality Interaction" ;
    dcterms:abstract "This paper investigates the effects of two situational impairments---encumbrance (i.e., carrying a heavy object) and walking---on interaction performance in canonical mixed reality tasks. We built Bayesian regression models of movement time, pointing offset, error rate, and throughput for target acquisition task, and throughput, UER, and CER for text entry task to estimate these effects. Our results indicate that 1.0 kg encumbrance increases selection movement time by 28%, decreases text entry throughput by 17%, and increase UER by 50%, but does not affect pointing offset. Walking led to a 63% increase in ray-cast movement time and a 51% reduction in text entry throughput. It also increased selection pointing offset by 16%, ray-cast pointing offset by 17%, and error rate by 8.4%. The interaction effect on 1.0 kg encumbrance and walking resulted in a 112% increase in ray-cast movement time. Our findings enhance the understanding of the effects of encumbrance and walking on mixed reality interaction, and contribute towards accumulating knowledge of situational impairments research in mixed reality. " ;
    dcterms:identifier "3706598.3713492" ;
    chi:hasAuthor chi:person_185319, chi:person_186703, chi:person_185652, chi:person_187961 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:paperIncludesStudy chi:study_188605_UserStudy ;
    chi:paperIncludesStudy chi:study_188605_QuantitativeStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188605_InterfaceArtifact .

chi:study_188605_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188605 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:ErrorRateMeasure ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188605_StatisticalResult .

chi:study_188605_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188605 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:ErrorRateMeasure ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188605_StatisticalResult .

chi:artifact_188605_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188605 .

chi:result_188605_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188606 rdf:type chi:Paper ;
    dcterms:title "Content-Driven Local Response: Supporting Sentence-Level and Message-Level Mobile Email Replies With and Without AI" ;
    dcterms:abstract "Mobile emailing demands efficiency in diverse situations, which motivates the use of AI. However, generated text does not always reflect how people want to respond. This challenges users with AI involvement tradeoffs not yet considered in email UIs. We address this with a new UI concept called Content-Driven Local Response (CDLR), inspired by microtasking. This allows users to insert responses into the email by selecting sentences, which additionally serves to guide AI suggestions. The concept supports combining AI for local suggestions and message-level improvements. Our user study (N=126) compared CDLR with manual typing and full reply generation. We found that CDLR supports flexible workflows with varying degrees of AI involvement, while retaining the benefits of reduced typing and errors. This work contributes a new approach to integrating AI capabilities: By redesigning the UI for workflows with and without AI, we can empower users to dynamically adjust AI involvement." ;
    dcterms:identifier "3706598.3713890" ;
    chi:hasAuthor chi:person_184380, chi:person_188018, chi:person_183864, chi:person_183266 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:paperIncludesStudy chi:study_188606_UserStudy ;
    chi:paperIncludesStudy chi:study_188606_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188606_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188606_SoftwareArtifact .

chi:study_188606_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188606 ;
    chi:hasMeasure chi:ErrorRateMeasure ;
    chi:reportsResult chi:result_188606_QualitativeResult ;
    chi:reportsResult chi:result_188606_StatisticalResult .

chi:study_188606_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188606 ;
    chi:hasMeasure chi:ErrorRateMeasure ;
    chi:reportsResult chi:result_188606_QualitativeResult ;
    chi:reportsResult chi:result_188606_StatisticalResult .

chi:artifact_188606_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188606 .

chi:artifact_188606_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188606 .

chi:result_188606_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188606_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188607 rdf:type chi:Paper ;
    dcterms:title "How Humans Communicate Programming Tasks in Natural Language and Implications For End-User Programming with LLMs" ;
    dcterms:abstract "Large language models (LLMs) like GPT-4 can convert natural-language descriptions of a task into computer code, making them a promising interface for end-user programming. We undertake a systematic analysis of how people with and without programming experience describe information-processing tasks (IPTs) in natural language, focusing on the characteristics of successful communication. Across two online between-subjects studies, we paired crowdworkers either with one another or with an LLM, asking senders (always humans) to communicate IPTs in natural language to their receiver (either a human or LLM). Both senders and receivers tried to answer test cases, the latter based on their sender's description. While participants with programming experience tended to communicate IPTs more successfully than non-programmers, this advantage was not overwhelming. Furthermore, a user interface that solicited example test cases from senders often, but not always, improved IPT communication. Allowing receivers to request clarification, though, was less successful at improving communication." ;
    dcterms:identifier "3706598.3713271" ;
    chi:hasAuthor chi:person_183664, chi:person_187688, chi:person_183374, chi:person_183604, chi:person_187572, chi:person_182760, chi:person_187667, chi:person_184188 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:ChatbotAssistedUserStudies ;
    chi:paperIncludesStudy chi:study_188607_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188607_InterfaceArtifact .

chi:study_188607_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188607 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188607_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:artifact_188607_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188607 .

chi:result_188607_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188608 rdf:type chi:Paper ;
    dcterms:title "Folk Tales of IoT: Understanding the Impact of Stories on Users' Positive and Negative Perceptions of Smart Home IoT Devices" ;
    dcterms:abstract "This study examines how anecdotal stories from friends, peers, and online sources influence non-experts’ perceptions and behaviors toward smart home IoT devices. We surveyed 263 participants, collecting narratives that either positively or negatively influenced their perception of IoT devices, which they retold in text and comic formats to encourage deeper reflection. Thematic analysis of the narratives, combined with quantitative survey data, reveals that stories significantly impact trust and willingness to use and adopt IoT devices. Negative stories, particularly those concerning security, privacy, and device unreliability, reduced trust and usage, while positive stories about home safety through monitoring and improved quality of life increased interest in IoT devices. Perceptions of different IoT devices varied based on the themes associated with the stories. The findings highlight the powerful role of storytelling in driving consumer acceptance of technology." ;
    dcterms:identifier "3706598.3713712" ;
    chi:hasAuthor chi:person_187072, chi:person_186358, chi:person_187713, chi:person_186873, chi:person_185968 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:SelfReflectionAndBehaviorChange ;
    chi:paperIncludesStudy chi:study_188608_UserStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188608_DeviceArtifact .

chi:study_188608_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188608 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188608_QualitativeResult ;
    chi:reportsResult chi:result_188608_StatisticalResult .

chi:artifact_188608_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188608 .

chi:result_188608_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188608_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188610 rdf:type chi:Paper ;
    dcterms:title "Backyard Practices: A Liminal Approach to Designing in More-than-Human Worlds" ;
    dcterms:abstract "As design researchers committed to more-than-human designing, we found we were increasingly moving our research activities outside of our institutional studios and labs into yards and balconies where we lived. In this paper, we investigate this emerging pattern through collaborative autoethnography to arrive at the notion of backyard practices. These are distinct practices that signal the value and necessity of being there in more-than-human worlds to design-with over time. We describe the features of the practice that include time as duration and intensities, liminality as more-than-human presences, and proximity. We also describe commitments that emerged that include practice decentering, consistently engage more-than-humans as participants in the process, act with not-knowing and humility, queerly design alongside, and learn to be affected." ;
    dcterms:identifier "3706598.3713291" ;
    chi:hasAuthor chi:person_184342, chi:person_186354, chi:person_186620, chi:person_186405, chi:person_185843 ;
    chi:paperIncludesStudy chi:study_188610_QualitativeStudy .

chi:study_188610_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188610 ;
    chi:reportsResult chi:result_188610_QualitativeResult .

chi:result_188610_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188611 rdf:type chi:Paper ;
    dcterms:title "Facilitating Daily Practice in Intangible Cultural Heritage through Virtual Reality: A Case Study of Traditional Chinese Flower Arrangement" ;
    dcterms:abstract "The essence of intangible cultural heritage (ICH) lies in the living knowledge and skills passed down through generations. Daily practice plays a vital role in revitalizing ICH by fostering continuous learning and improvement. However, limited resources and accessibility pose significant challenges to sustaining such practice. Virtual reality (VR) has shown promise in supporting extensive skill training. Unlike technical skill training, ICH daily practice prioritizes cultivating a deeper understanding of cultural meanings and values. This study explores VR's potential in facilitating ICH daily practice through a case study of Traditional Chinese Flower Arrangement (TCFA). By investigating TCFA learners' challenges and expectations, we designed and evaluated FloraJing, a VR system enriched with cultural elements to support sustained TCFA practice. Findings reveal that FloraJing promotes progressive reflection, and continuous enhances technical improvement and cultural understanding. We further propose design implications for VR applications aimed at fostering ICH daily practice in both knowledge and skills. " ;
    dcterms:identifier "3706598.3713409" ;
    chi:hasAuthor chi:person_187703, chi:person_182705, chi:person_185007, chi:person_184172 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:ImmersiveTrainingAndSimulation ;
    chi:paperIncludesStudy chi:study_188611_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188611_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188611_InterfaceArtifact .

chi:study_188611_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188611 ;
    chi:reportsResult chi:result_188611_QualitativeResult .

chi:artifact_188611_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188611 .

chi:artifact_188611_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188611 .

chi:result_188611_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188612 rdf:type chi:Paper ;
    dcterms:title "Toyteller: AI-powered Visual Storytelling Through Toy-Playing with Character Symbols" ;
    dcterms:abstract "We introduce Toyteller, an AI-powered storytelling system where users generate a mix of story text and visuals by directly manipulating character symbols like they are toy-playing. Anthropomorphized symbol motions can convey rich and nuanced social interactions; Toyteller leverages these motions (1) to let users steer story text generation and (2) as a visual output format that accompanies story text. We enabled motion-steered text generation and text-steered motion generation by mapping motions and text onto a shared semantic space so that large language models and motion generation models can use it as a translational layer. Technical evaluations showed that Toyteller outperforms a competitive baseline, GPT-4o. Our user study identified that toy-playing helps express intentions difficult to verbalize. However, only motions could not express all user intentions, suggesting combining it with other modalities like language. We discuss the design space of toy-playing interactions and implications for technical HCI research on human-AI interaction." ;
    dcterms:identifier "3706598.3713435" ;
    chi:hasAuthor chi:person_185789, chi:person_184173, chi:person_187169 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:paperIncludesStudy chi:study_188612_UserStudy ;
    chi:paperIncludesStudy chi:study_188612_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188612_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188612_InterfaceArtifact .

chi:study_188612_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188612 ;
    chi:reportsResult chi:result_188612_QualitativeResult ;
    chi:reportsResult chi:result_188612_StatisticalResult .

chi:study_188612_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188612 ;
    chi:reportsResult chi:result_188612_QualitativeResult ;
    chi:reportsResult chi:result_188612_StatisticalResult .

chi:artifact_188612_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188612 .

chi:artifact_188612_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188612 .

chi:result_188612_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188612_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188613 rdf:type chi:Paper ;
    dcterms:title "Oral History and Qualitative Analysis with Youth: A Method for Cultivating Attachments" ;
    dcterms:abstract "Urban environments can inhibit the formation of publics due to their distracting nature and distant social ties. Yet, forming publics is critical for bringing and mobilizing citizens around issues. In this paper, we introduce a methodology  that combines oral history collection and qualitative analysis to foster connections among youth in a North American public school. During our project, the youth interviewed classmates, guardians, and strangers from their community about the meaning of home, then collectively analyzed the oral histories using qualitative analysis techniques. Our findings highlight that this process generated unexpected connections around shared experiences despite the different backgrounds of project participants, thus fostering a sense of attachment to home as a cause for public formation. Our paper demonstrates the effectiveness of such approach in building attachments as a pre-cursor to public formation in community-centered work, while reflecting on the associated practical challenges like skill development, sustained engagement, and emotional labor." ;
    dcterms:identifier "3706598.3713687" ;
    chi:hasAuthor chi:person_187770, chi:person_185049, chi:person_184398 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188613_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188613_FieldStudy ;
    chi:aimsAtGoal chi:PromoteLearning .

chi:study_188613_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188613 ;
    chi:reportsResult chi:result_188613_QualitativeResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:study_188613_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188613 ;
    chi:reportsResult chi:result_188613_QualitativeResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:result_188613_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188614 rdf:type chi:Paper ;
    dcterms:title "Does Adding Visual Signifiers in Animated Transitions Improve Interaction Discoverability?" ;
    dcterms:abstract "Smartphones support diverse inputs, however, the multitude of devices and platforms makes it challenging for people to discover when and where interactions are meaningful.  Motivated by the effectiveness of visual signifiers in communicating interactivity, we explore the viability of integrating temporary visual signifiers in animated transitions between UI screens to promote the discoverability of swipe-revealed widgets. We implemented two transition types (Container Transform, Panels), and compared them to a baseline. We found that transitions with a standard duration did not impact the discovery of swipe-related widgets (N=33). We ran a follow-up study (N=22) with extremely slow 5000ms transitions to guarantee noticeability, but similarly found no impact on discovery of swipe-revealed widgets, diverging from previous findings for visual signifiers. This raises interesting questions about the perception and understanding of interaction signifiers, and indicates a disconnect between noticeability and discoverability, while highlighting difficulties with adapting established interface elements beyond their entrenched functionality.  " ;
    dcterms:identifier "3706598.3713914" ;
    chi:hasAuthor chi:person_183470, chi:person_187104, chi:person_187032, chi:person_184669 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:PointingAndSelectionPerformance ;
    chi:paperIncludesStudy chi:study_188614_BaselineComparisonStudy ;
    chi:paperIncludesStudy chi:study_188614_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188614_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188614_SoftwareArtifact .

chi:study_188614_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188614 ;
    chi:reportsResult chi:result_188614_StatisticalResult .

chi:study_188614_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188614 ;
    chi:reportsResult chi:result_188614_StatisticalResult .

chi:artifact_188614_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188614 .

chi:artifact_188614_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188614 .

chi:result_188614_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188615 rdf:type chi:Paper ;
    dcterms:title "The Spin Doctor: Leveraging Insensitivity to Passive Rotational & Translational Gain For Unbounded Motion-Based VR Experiences" ;
    dcterms:abstract "Research on rotational gain has been done largely under active self-motion, where users control their own movement. In multiple XR scenarios, the user is under passive self-motion: their body is moved by a training simulator, a motorised gaming chair, or a vehicle-based XR application. Users may be less sensitive to manipulation under passive motion - especially when engaged in a secondary task - meaning motion experiences could be expanded by high gains and even opposed virtual-physical motion. We identified both the perceptible and maximum comfortable thresholds of rotational gain when passively turned in a motorised chair, with and without a task, for the first time. We then applied those thresholds to an 'unbounded' in-car VR game where the user experiences an entirely different route to their physical movement. We provide the first guidelines for creating enhanced passive motion experiences and open the design space to new applications not restricted by physical movement" ;
    dcterms:identifier "3706598.3713455" ;
    chi:hasAuthor chi:person_184663, chi:person_185880, chi:person_184562, chi:person_185850, chi:person_186153 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:ImmersiveTrainingAndSimulation ;
    chi:paperIncludesStudy chi:study_188615_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188615_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188615_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188615_InterfaceArtifact .

chi:study_188615_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188615 ;
    chi:reportsResult chi:result_188615_StatisticalResult .

chi:artifact_188615_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188615 .

chi:artifact_188615_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188615 .

chi:artifact_188615_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188615 .

chi:result_188615_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188616 rdf:type chi:Paper ;
    dcterms:title "Exploring the Potential of Music Generative AI for Music-Making by Deaf and Hard of Hearing People" ;
    dcterms:abstract "Recent advancements in text-to-music generative AI (GenAI) have significantly expanded access to music creation. However, deaf and hard of hearing (DHH) individuals remain largely excluded from these developments. This study explores how music GenAI could enhance the music-making experience of DHH individuals, who often rely on hearing people to translate sounds and music. We developed a multimodal music-making assistive tool informed by focus group interviews. This tool enables DHH users to create and edit music independently through language interaction with music GenAI, supported by integrated visual and tactile feedback. Our findings from the music-making study revealed that the system empowers them to engage in independent and proactive music-making activities, increasing their confidence, fostering musical expression, and positively shifting their attitudes toward music. Contributing to inclusive art by preserving the unique sensory characteristics of DHH individuals, this study demonstrates how music GenAI can benefit a marginalized community, fostering independent creative expression." ;
    dcterms:identifier "3706598.3714298" ;
    chi:hasAuthor chi:person_182679, chi:person_186665, chi:person_185807, chi:person_183359 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188616_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188616_UserStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188616_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188616_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188616_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188616_OutputDeviceArtifact .

chi:study_188616_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188616 ;
    chi:reportsResult chi:result_188616_QualitativeResult .

chi:study_188616_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188616 ;
    chi:reportsResult chi:result_188616_QualitativeResult .

chi:artifact_188616_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188616 .

chi:artifact_188616_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188616 .

chi:artifact_188616_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188616 .

chi:artifact_188616_OutputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188616 .

chi:result_188616_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188617 rdf:type chi:Paper ;
    dcterms:title "Understanding How Psychological Distance Influences User Preferences in Conversational versus Web Search" ;
    dcterms:abstract "Conversational search offers an easier and faster alternative to conventional web search, while having downsides like a lack of source verification. Research has examined performance disparities between these two systems in various settings. However, little work has investigated how changes in the nature of a search task affect user preferences. We investigate how psychological distance - the perceived closeness of one to an event - affects user preferences between conversational and web search. We hypothesise that tasks with different psychological distances elicit different information needs, which in turn affect user preferences between systems. Our study finds that, under fixed condition ordering, greater psychological distances lead users to prefer conversational search, which they perceive as more credible, useful, enjoyable, and easy to use. We reveal qualitative reasons for these differences and provide design implications for search system designers." ;
    dcterms:identifier "3706598.3713770" ;
    chi:hasAuthor chi:person_185032, chi:person_184115, chi:person_184880, chi:person_184994, chi:person_183752, chi:person_188122 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:ChatbotAssistedUserStudies ;
    chi:paperIncludesStudy chi:study_188617_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188617_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188617_InterfaceArtifact .

chi:study_188617_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188617 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:reportsResult chi:result_188617_QualitativeResult ;
    chi:reportsResult chi:result_188617_StatisticalResult .

chi:artifact_188617_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188617 .

chi:artifact_188617_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188617 .

chi:result_188617_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188617_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188618 rdf:type chi:Paper ;
    dcterms:title "“It feels like we're not meeting the criteria\": Examining and Mitigating the Cascading Effects of Bias in Automatic Speech Recognition in Spoken Language Interfaces." ;
    dcterms:abstract "Researchers have demonstrated that Automatic Speech Recognition (ASR) systems perform differently across demographic groups (i.e. show bias), yet their downstream impact on spoken language interfaces remains unexplored. We examined this question in the context of a real-world AI-powered interface that provides tutors with feedback on the quality of their discourse. We found that the Whisper ASR had lower accuracy for Black vs. white tutors, likely due to differences in acoustic patterns of speech. The downstream automated discourse classifiers of tutor talk were correspondingly less accurate for Black tutors when presented with ASR input. As a result, although Black tutors demonstrated higher-quality discourse on human transcripts, this trend was not evident on ASR transcripts. We experimented with methods to reduce ASR bias, finding that fine-tuning the ASR on Black speech reduced, but did not eliminate, ASR bias and its downstream effects. We discuss implications for AI-based spoken language interfaces aimed at providing unbiased assessments to improve performance outcomes." ;
    dcterms:identifier "3706598.3714059" ;
    chi:hasAuthor chi:person_184462, chi:person_187274, chi:person_183200, chi:person_186985, chi:person_185340 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:AlgorithmicFairnessAndBias ;
    chi:paperIncludesStudy chi:study_188618_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188618_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188618_SoftwareArtifact .

chi:study_188618_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188618 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188618_StatisticalResult .

chi:artifact_188618_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188618 .

chi:artifact_188618_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188618 .

chi:result_188618_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188619 rdf:type chi:Paper ;
    dcterms:title "All-inclusive TORs: Cross-Cultural and Age-Sensitive Design for Take-Over Requests in Level 3 Cars " ;
    dcterms:abstract "Transitioning to manual control following a Take-Over Request (TOR) in Level 3 autonomous cars is challenging, requiring drivers to re-engage with driving after engaging with Non-Driving Related Tasks (NDRTs). Effective TOR design can mitigate this challenge. We present the first study on how culture, age, and NDRT intersect to shape TOR design. In a cross-cultural study across the UK (high traffic-law compliance) and Israel (low compliance), involving older and younger drivers, participants designed TORs for four NDRTs in a real car setting. Results revealed a universal preference for re-purposing NDRT-devices to issue TORs. Older drivers preferred tri-modal TORs that suspend the NDRT; younger drivers favoured bi-modal TORs allowing NDRT interruption management. Due to altered alert sensitivity and low law compliance, Israeli participants included a RiskMeter to assess hazard criticality. We introduce novel TOR designs and taxonomy features to guide culturally and age-sensitive TOR development, key for global Level 3 adoption." ;
    dcterms:identifier "3706598.3713451" ;
    chi:hasAuthor chi:person_186175, chi:person_186128, chi:person_186153 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:paperIncludesStudy chi:study_188619_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188619_InterfaceArtifact .

chi:study_188619_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188619 ;
    chi:reportsResult chi:result_188619_QualitativeResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:artifact_188619_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188619 .

chi:result_188619_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188620 rdf:type chi:Paper ;
    dcterms:title "The Interaction Layer: An Exploration for Co-Designing User-LLM Interactions in Parental Wellbeing Support Systems" ;
    dcterms:abstract "Parenting brings emotional and physical challenges, from balancing work, childcare, and finances to coping with exhaustion and limited personal time. Yet, one in three parents never seek support. AI systems potentially offer stigma-free, accessible, and affordable solutions. Yet, user adoption often fails due to issues with explainability and reliability. To see if these issues could be solved using a co-design approach, we developed and tested NurtureBot, a wellbeing support assistant for new parents. 32 parents co-designed the system through Asynchronous Remote Communities method, identifying the key challenge as achieving a \"successful chat.\" As part of co-design, parents role-played as NurtureBot, rewriting its dialogues to improve user understanding, control, and outcomes. The refined prototype, featuring an Interaction Layer, was evaluated by by 32 initial and 46 new parents, showing improved user experience and usability, with final CUQ score of 91.3/100, demonstrating successful interaction patterns. Our process revealed useful interaction design lessons for effective AI parenting support." ;
    dcterms:identifier "3706598.3714088" ;
    chi:hasAuthor chi:person_185505, chi:person_187401, chi:person_187906, chi:person_183376, chi:person_186227, chi:person_184286 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188620_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188620_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188620_InterfaceArtifact .

chi:study_188620_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188620 ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:reportsResult chi:result_188620_QualitativeResult ;
    chi:reportsResult chi:result_188620_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation ;
    chi:involvesParticipationPattern chi:AsynchronousParticipation .

chi:artifact_188620_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188620 .

chi:artifact_188620_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188620 .

chi:result_188620_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188620_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188621 rdf:type chi:Paper ;
    dcterms:title "\"A five-year-old could understand it\" versus \"This is way too confusing\": Exploring Non-expert Understandings and Perceptions of Cybersecurity Definitions" ;
    dcterms:abstract "Experts struggle with explaining cybersecurity in a language and tone appropriate for non-expert audiences. This communication gap may make it difficult for a broad and diverse audience to fully engage in cybersecurity. Fundamental forms of communication, such as definitions, can be for a means for experts to communicate cybersecurity concepts to non-experts. To explore how nonexperts perceive cybersecurity definitions and identify potential areas of misunderstanding and misconception, we performed a semi-structured interview study with 30 non-experts of different generations (ages) and education levels. Our findings reveal that non-experts may have incomplete mental models of cybersecurity, misinterpret terms and concepts commonly used in definitions, and express strong preferences for how cybersecurity is defined. While our study focuses on definitions, our results have broader implications for how cybersecurity should be communicated to a diverse range of individuals." ;
    dcterms:identifier "3706598.3713820" ;
    chi:hasAuthor chi:person_188175, chi:person_183872, chi:person_183780 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:DataDisclosureAndConsent ;
    chi:paperIncludesStudy chi:study_188621_InterviewStudy ;
    chi:aimsAtGoal chi:PromoteLearning .

chi:study_188621_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188621 ;
    chi:reportsResult chi:result_188621_QualitativeResult .

chi:result_188621_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188622 rdf:type chi:Paper ;
    dcterms:title "ProTAL: A Drag-and-Link Video Programming Framework for Temporal Action Localization" ;
    dcterms:abstract "Temporal Action Localization (TAL) aims to detect the start and end timestamps of actions in a video. However, the training of TAL models requires a substantial amount of manually annotated data. Data programming is an efficient method to create training labels with a series of human-defined labeling functions. However, its application in TAL faces difficulties of defining complex actions in the context of temporal video frames. In this paper, we propose ProTAL, a drag-and-link video programming framework for TAL. ProTAL enables users to define \textbf{key events} by dragging nodes representing body parts and objects and linking them to constrain the relations (direction, distance, etc.). These definitions are used to generate action labels for large-scale unlabelled videos. A semi-supervised method is then employed to train TAL models with such labels. We demonstrate the effectiveness of ProTAL through a usage scenario and a user study, providing insights into designing video programming framework." ;
    dcterms:identifier "3706598.3713741" ;
    chi:hasAuthor chi:person_185215, chi:person_186018, chi:person_186115, chi:person_186390, chi:person_186088, chi:person_187341 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:paperIncludesStudy chi:study_188622_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188622_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188622_InterfaceArtifact .

chi:study_188622_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188622 ;
    chi:reportsResult chi:result_188622_QualitativeResult .

chi:artifact_188622_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188622 .

chi:artifact_188622_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188622 .

chi:result_188622_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188623 rdf:type chi:Paper ;
    dcterms:title "Reviving Mural Art through Generative AI: A Comparative Study of AI-Generated and Hand-Crafted Recreations" ;
    dcterms:abstract "Virtual reality (VR) provides an immersive and interactive platform for presenting ancient murals, enhancing users' understanding and appreciation of these invaluable culture treasures. However, traditional hand-crafted methods for recreating murals in VR are labor-intensive, time-consuming, and require significant expertise, limiting their scalability for large-scale mural scenes. To address these challenges, we propose a comprehensive pipeline that leverages generative AI to automate the mural recreation process. This pipeline is validated by the reconstruction of Foguang Temple scene in Dunhuang Murals. A user study comparing the AI-generated scene with a hand-crafted one reveals no significant differences in presence, authenticity, engagement and enjoyment, and emotion. Additionally, our findings identify areas for improvement in AI-generated recreations, such as enhancing historical fidelity and offering customization. This work paves the way for more scalable, efficient, and accessible methods of revitalizing cultural heritage in VR, offering new opportunities for mural preservation, demonstration, and dissemination using VR." ;
    dcterms:identifier "3706598.3714157" ;
    chi:hasAuthor chi:person_183976, chi:person_185142, chi:person_186281, chi:person_184786, chi:person_185303, chi:person_185774 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:ImmersiveTrainingAndSimulation ;
    chi:paperIncludesStudy chi:study_188623_UserStudy ;
    chi:paperIncludesStudy chi:study_188623_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188623_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188623_InterfaceArtifact .

chi:study_188623_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188623 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188623_QualitativeResult ;
    chi:reportsResult chi:result_188623_StatisticalResult .

chi:study_188623_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188623 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188623_QualitativeResult ;
    chi:reportsResult chi:result_188623_StatisticalResult .

chi:artifact_188623_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188623 .

chi:artifact_188623_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188623 .

chi:result_188623_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188623_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188624 rdf:type chi:Paper ;
    dcterms:title "Project TapTap: A Longitudinal Study Exploring Non-Verbal Communication through Vibration Signals Between Teachers and Blind or Low Vision Music Learners" ;
    dcterms:abstract "While wearable haptics hold promise for making non-verbal cues like gestures and facial expressions accessible to blind or low-vision musicians, our understanding of how vibration signals can be interpreted and applied in real-world learning environments remains limited. We invited five music teachers and their seven students to participate in a ten-week longitudinal study involving observations, weekly catch-ups, group discussions, and interviews. We explored how wearable haptics could facilitate communication between sighted teachers and BLV students during one-on-one music lessons. We found that students and teachers derived particular meanings from vibration signals, including time-coded meaning, mutually agreed and intuitive meaning, and haptic metaphors. Additionally, wearable haptics significantly improved the experience of learning music for both sighted teachers and BLV students. We conclude by highlighting key design implications and outlining future research directions to create wearable haptics that significantly improve the music learning experience of BLV people." ;
    dcterms:identifier "3706598.3713298" ;
    chi:hasAuthor chi:person_184264, chi:person_186590, chi:person_187225, chi:person_182766, chi:person_184673 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:AccessibleLearningAndSupportSystems ;
    chi:paperIncludesStudy chi:study_188624_FieldStudy ;
    chi:paperIncludesStudy chi:study_188624_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188624_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188624_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188624_OutputDeviceArtifact .

chi:study_188624_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188624 ;
    chi:reportsResult chi:result_188624_QualitativeResult .

chi:study_188624_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188624 ;
    chi:reportsResult chi:result_188624_QualitativeResult .

chi:study_188624_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188624 ;
    chi:reportsResult chi:result_188624_QualitativeResult .

chi:artifact_188624_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188624 .

chi:artifact_188624_OutputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188624 .

chi:result_188624_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188628 rdf:type chi:Paper ;
    dcterms:title "Lost in Magnitudes: Exploring Visualization Designs for Large Value Ranges" ;
    dcterms:abstract "We explore the design of visualizations for values spanning multiple orders of magnitude; we call them Orders of Magnitude Values (OMVs). Visualization researchers have shown that separating OMVs into two components, the mantissa and the exponent, and encoding them separately overcomes limitations of linear and logarithmic scales. However, only a small number of such visualizations have been tested, and the design guidelines for visualizing the mantissa and exponent separately remain under-explored. To initiate this exploration, better understand the factors influencing the effectiveness of these visualizations, and create guidelines, we adopt a multi-stage workflow. We introduce a design space for visualizing mantissa and exponent, systematically generating and qualitatively evaluating all possible visualizations within it. From this evaluation, we derive guidelines. We select two visualizations that align with our guidelines and test them using a crowdsourcing experiment, showing they facilitate quantitative comparisons and increase confidence in interpretation compared to the state-of-the-art." ;
    dcterms:identifier "3706598.3713487" ;
    chi:hasAuthor chi:person_183541, chi:person_186670, chi:person_183416, chi:person_183424 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:PointingAndSelectionPerformance ;
    chi:paperIncludesStudy chi:study_188628_UserStudy ;
    chi:paperIncludesStudy chi:study_188628_QualitativeStudy ;
    chi:paperIncludesStudy chi:study_188628_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188628_InterfaceArtifact .

chi:study_188628_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188628 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188628_QualitativeResult ;
    chi:reportsResult chi:result_188628_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation ;
    chi:involvesParticipationPattern chi:AsynchronousParticipation .

chi:study_188628_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188628 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188628_QualitativeResult ;
    chi:reportsResult chi:result_188628_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation ;
    chi:involvesParticipationPattern chi:AsynchronousParticipation .

chi:study_188628_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188628 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188628_QualitativeResult ;
    chi:reportsResult chi:result_188628_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation ;
    chi:involvesParticipationPattern chi:AsynchronousParticipation .

chi:artifact_188628_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188628 .

chi:result_188628_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188628_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188630 rdf:type chi:Paper ;
    dcterms:title "Embracing Gender Diversity: Designing an Adaptive Pleasure Object for a Changing Body" ;
    dcterms:abstract "Trans and non-binary individuals undergoing hormone therapy face unique and evolving needs for sexual wellness products that current solutions often overlook. The transition process involves significant anatomical and psychological changes, highlighting the necessity for more inclusive approaches to Human-Computer Interaction and overall well-being.  Within this framework, this study presents the development of a pleasure object designed to be fluid, adaptive, and responsive to the evolving anatomical and psychological changes experienced during hormone therapy.  To this end, authors conducted comprehensive research, including an online survey on the autoerotic habits of trans and non-binary individuals, followed by three sensitive interviews and clinical integration. They observed significant themes that highlight the unique requirements and experiences of this community. By leveraging advanced technologies and selected materials, authors provide design considerations and discuss the potential of these methods to create sexual wellness products that offer meaningful and inclusive experiences for the trans and non-binary community." ;
    dcterms:identifier "3706598.3713939" ;
    chi:hasAuthor chi:person_182759, chi:person_187083, chi:person_186222 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188630_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188630_UserStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188630_DeviceArtifact .

chi:study_188630_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188630 ;
    chi:reportsResult chi:result_188630_QualitativeResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:study_188630_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188630 ;
    chi:reportsResult chi:result_188630_QualitativeResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:artifact_188630_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188630 .

chi:result_188630_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188631 rdf:type chi:Paper ;
    dcterms:title "Touching Experiences: How Older Adults Envision Ambient and Tangible Social Technology Through the Lens of Time" ;
    dcterms:abstract "Older adults face unique challenges in adopting social technology, particularly through retirement. Whereas existing digital solutions are often disconnected from the motivations of older adults, ambient and tangible technologies (ATTs) are emerging as promising social tools that integrate into users' routines and leverage familiar physical interactions. This study investigates how older adults envision ATTs to meaningfully support their social connections. Through two phases of co-design with 25 retiring older adults (55+) and 5 social partners (25+), we explore the intersection of social health, life transitions, and technology use. Our thematic analysis reveals how shifting perceptions of time influence engagement, relationship maintenance, and legacy-building. We present opportunities to align ATT design with older adults’ emotional goals, social practices, and community connections by posing design challenges, such as collective legacy building, for supporting the meaningful relationships of retiring adults as they age." ;
    dcterms:identifier "3706598.3714302" ;
    chi:hasAuthor chi:person_184310, chi:person_184982, chi:person_182919, chi:person_183575 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialSupportAndPeerChatbots ;
    chi:paperIncludesStudy chi:study_188631_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188631_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188631_InterfaceArtifact .

chi:study_188631_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188631 ;
    chi:reportsResult chi:result_188631_QualitativeResult .

chi:artifact_188631_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188631 .

chi:artifact_188631_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188631 .

chi:result_188631_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188633 rdf:type chi:Paper ;
    dcterms:title "Data Formulator 2: Iterative Creation of Data Visualizations, with AI Transforming Data Along the Way" ;
    dcterms:abstract "Data analysts often need to iterate between data transformations and chart designs to create rich visualizations for exploratory data analysis. Although many AI-powered systems have been introduced to reduce the effort of visualization authoring, existing systems are not well suited for iterative authoring. They typically require analysts to provide, in a single turn, a text-only prompt that fully describe a complex visualization.  We introduce Data Formulator 2 (DF2 for short), an AI-powered visualization system designed to overcome this limitation. DF2 blends graphical user interfaces and natural language inputs to enable users to convey their intent more effectively, while delegating data transformation to AI. Furthermore, to support efficient iteration, DF2 lets users navigate their iteration history and reuse previous designs, eliminating the need to start from scratch each time.  A user study with eight participants demonstrated that DF2 allowed participants to develop their own iteration styles to complete challenging data exploration sessions." ;
    dcterms:identifier "3706598.3713296" ;
    chi:hasAuthor chi:person_186256, chi:person_183792, chi:person_184296, chi:person_188198, chi:person_182949 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:CollaborativeVisualizationTools ;
    chi:paperIncludesStudy chi:study_188633_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188633_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188633_InterfaceArtifact .

chi:study_188633_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188633 ;
    chi:reportsResult chi:result_188633_QualitativeResult .

chi:artifact_188633_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188633 .

chi:artifact_188633_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188633 .

chi:result_188633_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188634 rdf:type chi:Paper ;
    dcterms:title "Movement Sonification of Familiar Music to Support the Agency of People with Chronic Pain" ;
    dcterms:abstract "FFAME (Filtering Familiar Audio for Movement Exploration) is a novel sonification framework aiming to facilitate movement in individuals with chronic back pain. Our personalised, music-based approach contrasts and extends prior work with predetermined tonal sonification. FFAME progressively filters selected music based on angles of the trunk. Through a qualitative analysis of reported experience of 15 participants with chronic pain and 5 physiotherapists, we identify how sonification parameters and musical characteristics affect movement and meaning-making. Music-based movement sonification proved impactful across multiple dimensions: (1) encouraging movement, (2) escaping pain-related rumination, (3) externalizing pain experiences, and (4) scaffolding physical activities. Drawing on enactivism and related philosophies, the study highlights how the semantic indeterminacy of music, combined with real-time movement sonification, created a rich, open-ended environment that supported user agency and exploration. Sonification for pain management can be creative and expressive, enabling people with pain to extend challenging movements and build movement confidence." ;
    dcterms:identifier "3706598.3713601" ;
    chi:hasAuthor chi:person_185860, chi:person_184483, chi:person_184810, chi:person_184337, chi:person_184338, chi:person_187031, chi:person_186166, chi:person_185414 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188634_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188634_UserStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188634_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188634_InterfaceArtifact .

chi:study_188634_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188634 ;
    chi:reportsResult chi:result_188634_QualitativeResult .

chi:study_188634_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188634 ;
    chi:reportsResult chi:result_188634_QualitativeResult .

chi:artifact_188634_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188634 .

chi:artifact_188634_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188634 .

chi:result_188634_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188635 rdf:type chi:Paper ;
    dcterms:title "Community Fact-Checks Trigger Moral Outrage in Replies to Misleading Posts on Social Media" ;
    dcterms:abstract "Displaying community fact-checks is a promising approach to reduce engagement with misinformation on social media. However, how users respond to misleading content emotionally after community fact-checks are displayed on posts is unclear. Here, we employ quasi-experimental methods to causally analyze changes in sentiments and (moral) emotions in replies to misleading posts following the display of community fact-checks. Our evaluation is based on a large-scale panel dataset comprising N=2,225,260 replies across 1841 source posts from X's Community Notes platform. We find that informing users about falsehoods through community fact-checks significantly increases negativity (by 7.3%), anger (by 13.2%), disgust (by 4.7%), and moral outrage (by 16.0%) in the corresponding replies. These results indicate that users perceive spreading misinformation as a violation of social norms and that those who spread misinformation should expect negative reactions once their content is debunked. We derive important implications for the design of community-based fact-checking systems." ;
    dcterms:identifier "3706598.3713909" ;
    chi:hasAuthor chi:person_185551, chi:person_182768, chi:person_183289, chi:person_183111 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:paperIncludesStudy chi:study_188635_FieldStudy ;
    chi:proposesArtifact chi:artifact_188635_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188635_InterfaceArtifact .

chi:study_188635_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188635 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188635_StatisticalResult .

chi:artifact_188635_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188635 .

chi:artifact_188635_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188635 .

chi:result_188635_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188636 rdf:type chi:Paper ;
    dcterms:title "Wordplay: Accessible, Multilingual, Interactive Typography" ;
    dcterms:abstract "Educational programming languages (EPLs) are rarely designed to be both accessible and multilingual. We describe a 30-month community-engaged case study to surface design challenges at this intersection, creating Wordplay, an accessible, multilingual platform for youth to program interactive typography. Wordplay combines functional programming, multilingual text, multimodal editors, time travel debugging, and teacher- and youth-centered community governance. Across five 2-hour focus group sessions, a group of 6 multilingual students and teachers affirmed many of the platform’s design choices, but reinforced that design at the margins was unfinished, including support for limited internet access, decade-old devices, and high turnover of device use by students with different access, language, and attentional needs. The group also highlighted open source platforms like GitHub as unsuitable for engaging youth. These findings suggest that EPLs that are both accessible and language-inclusive are feasible, but that there remain many design tensions between language design, learnability, accessibility, culture, and governance." ;
    dcterms:identifier "3706598.3713196" ;
    chi:hasAuthor chi:person_187805, chi:person_183290, chi:person_183838 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:AccessibleLearningAndSupportSystems ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:AccessibleLearningAndSupportSystems ;
    chi:aboutTopic chi:LearningAndEducation:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188636_UserStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188636_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188636_InterfaceArtifact .

chi:study_188636_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188636 ;
    chi:reportsResult chi:result_188636_QualitativeResult .

chi:artifact_188636_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188636 .

chi:artifact_188636_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188636 .

chi:result_188636_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188637 rdf:type chi:Paper ;
    dcterms:title "Inter(sectional) Alia(s): Ambiguity in Voice Agent Identity via Intersectional Japanese Self-Referents" ;
    dcterms:abstract "Conversational agents that mimic people have raised questions about the ethics of anthropomorphizing machines with human social identity cues. Critics have also questioned assumptions of identity neutrality in humanlike agents. Recent work has revealed that intersectional Japanese pronouns can elicit complex and sometimes evasive impressions of agent identity. Yet, the role of other ``neutral'' non-pronominal self-referents (NPSR) and voice as a socially expressive medium remains unexplored. In a crowdsourcing study, Japanese participants (N=204) evaluated three ChatGPT voices (Juniper, Breeze, and Ember) using seven self-referents. We found strong evidence of voice gendering alongside the potential of intersectional self-referents to evade gendering, i.e., ambiguity through neutrality and elusiveness. Notably, perceptions of age and formality intersected with gendering as per sociolinguistic theories, especially ぼく (boku) and わたくし (watakushi). This work provides a nuanced take on agent identity perceptions and champions intersectional and culturally-sensitive work on voice agents." ;
    dcterms:identifier "3706598.3713323" ;
    chi:hasAuthor chi:person_184455, chi:person_186540, chi:person_184712, chi:person_186712 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:aboutTopic chi:FuturesOfSocialPlatforms ;
    chi:paperIncludesStudy chi:study_188637_UserStudy ;
    chi:proposesArtifact chi:artifact_188637_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188637_OutputDeviceArtifact .

chi:study_188637_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188637 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188637_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation ;
    chi:involvesParticipationPattern chi:AsynchronousParticipation .

chi:artifact_188637_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188637 .

chi:artifact_188637_OutputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188637 .

chi:result_188637_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188638 rdf:type chi:Paper ;
    dcterms:title "Seeing with the Hands: A Sensory Substitution That Supports Manual Interactions" ;
    dcterms:abstract "Sensory-substitution devices enable perceiving objects by translating one modality (e.g., vision) into another (e.g., tactile). While many explored the placement of the haptic-output (e.g., torso, forehead), the camera’s location remains largely unexplored—typically seeing from the eyes’ perspective. Instead, we propose that seeing & feeling information from the hands’ perspective could enhance flexibility & expressivity of sensory-substitution devices to support manual interactions with physical objects. To this end, we engineered a back-of-the-hand electrotactile-display that renders tactile images from a wrist-mounted camera, allowing the user’s hand to feel objects while reaching & hovering. We conducted a study with sighted/Blind-or-Low-Vision participants who used our eyes vs. hand tactile-perspectives to manipulate bottles and soldering-irons, etc. We found that while both tactile perspectives provided comparable performance, when offered the opportunity to choose, all participants found value in also using the hands’ perspective. Moreover, we observed behaviors when “seeing with the hands” that suggest a more ergonomic object-manipulation. We believe these insights extend the landscape of sensory-substitution devices." ;
    dcterms:identifier "3706598.3713419" ;
    chi:hasAuthor chi:person_182918, chi:person_182877, chi:person_185022, chi:person_183578 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188638_UserStudy ;
    chi:paperIncludesStudy chi:study_188638_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188638_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188638_OutputDeviceArtifact .

chi:study_188638_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188638 ;
    chi:hasMeasure chi:PerformanceMeasure ;
    chi:reportsResult chi:result_188638_QualitativeResult ;
    chi:reportsResult chi:result_188638_StatisticalResult .

chi:study_188638_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188638 ;
    chi:hasMeasure chi:PerformanceMeasure ;
    chi:reportsResult chi:result_188638_QualitativeResult ;
    chi:reportsResult chi:result_188638_StatisticalResult .

chi:artifact_188638_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188638 .

chi:artifact_188638_OutputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188638 .

chi:result_188638_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188638_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188640 rdf:type chi:Paper ;
    dcterms:title "Ego vs. Exo and Active vs. Passive: Investigating the Individual and Combined Effects of Viewpoint and Navigation on Spatial Immersion and Understanding in Immersive Storytelling" ;
    dcterms:abstract "Visual storytelling combines visuals and narratives to communicate important insights. While web-based visual storytelling is well-established, leveraging the next generation of digital technologies for visual storytelling, specifically immersive technologies, remains underexplored. We investigated the impact of the story viewpoint (from the audience's perspective) and navigation (when progressing through the story) on spatial immersion and understanding. First, we collected web-based 3D stories and elicited design considerations from three VR developers. We then adapted four selected web-based stories to an immersive format. Finally, we conducted a user study (N=24) to examine egocentric and exocentric viewpoints, active and passive navigation, and the combinations they form. Our results indicated significantly higher preferences for egocentric+active (higher agency and engagement) and exocentric+passive (higher focus on content). We also found a marginal significance of viewpoints on story understanding and a strong significance of navigation on spatial immersion." ;
    dcterms:identifier "3706598.3713849" ;
    chi:hasAuthor chi:person_185272, chi:person_185882, chi:person_183683, chi:person_182992, chi:person_187664, chi:person_184536, chi:person_183378 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction:ImmersiveTrainingAndSimulation ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction:ImmersiveTrainingAndSimulation ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance:SpatialNavigationPerformance ;
    chi:paperIncludesStudy chi:study_188640_UserStudy ;
    chi:paperIncludesStudy chi:study_188640_InterviewStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188640_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188640_SoftwareArtifact .

chi:study_188640_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188640 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188640_StatisticalResult ;
    chi:reportsResult chi:result_188640_QualitativeResult .

chi:study_188640_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188640 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188640_StatisticalResult ;
    chi:reportsResult chi:result_188640_QualitativeResult .

chi:artifact_188640_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188640 .

chi:artifact_188640_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188640 .

chi:result_188640_StatisticalResult rdf:type chi:StatisticalResult .

chi:result_188640_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188641 rdf:type chi:Paper ;
    dcterms:title "\"I use video calling in all areas of my life\": Understanding the Video Calling Experiences of Chronically Ill People" ;
    dcterms:abstract "Since the Covid-19 pandemic, video calling (VC) has become a staple means of daily communication. Beyond socializing, VC in the United States (U.S.) now supports remote work, healthcare and education. The sudden ubiquity of VC could have presented both advantages and challenges for chronically ill people. However, our understanding of chronically ill people's experiences with VC remains limited. To address this gap, we conducted the largest online survey study (N=55) on chronically ill people's VC experiences in the U.S.--investigating their routines, facilitators and barriers. Our quantitative and qualitative findings established that chronically ill people heavily depend on VC to cope with everyday life. At the same time, VC can also detrimentally exacerbate cognitive (e.g., brain fog), emotional (e.g., self-consciousness) and physical challenges (e.g., migraines) for chronically ill people. In response, we offer actionable design opportunities to improve the accessibility and experience of VC for chronically ill people." ;
    dcterms:identifier "3706598.3713193" ;
    chi:hasAuthor chi:person_183241, chi:person_188045, chi:person_184482, chi:person_184299, chi:person_187327, chi:person_184441, chi:person_183479, chi:person_184181 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188641_UserStudy ;
    chi:paperIncludesStudy chi:study_188641_QuantitativeStudy ;
    chi:paperIncludesStudy chi:study_188641_QualitativeStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility .

chi:study_188641_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188641 ;
    chi:reportsResult chi:result_188641_QualitativeResult ;
    chi:reportsResult chi:result_188641_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation ;
    chi:involvesParticipationPattern chi:AsynchronousParticipation .

chi:study_188641_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188641 ;
    chi:reportsResult chi:result_188641_QualitativeResult ;
    chi:reportsResult chi:result_188641_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation ;
    chi:involvesParticipationPattern chi:AsynchronousParticipation .

chi:study_188641_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188641 ;
    chi:reportsResult chi:result_188641_QualitativeResult ;
    chi:reportsResult chi:result_188641_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation ;
    chi:involvesParticipationPattern chi:AsynchronousParticipation .

chi:result_188641_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188641_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188642 rdf:type chi:Paper ;
    dcterms:title "VeriPlan: Integrating Formal Verification and LLMs into End-User Planning" ;
    dcterms:abstract "Automated planning is traditionally the domain of experts, utilized in fields like manufacturing and healthcare with the aid of expert planning tools. Recent advancements in LLMs have made planning more accessible to everyday users due to their potential to assist users with complex planning tasks. However, LLMs face several application challenges within end-user planning, including consistency, accuracy, and user trust issues. This paper introduces VeriPlan, a system that applies formal verification techniques, specifically model checking, to enhance the reliability and flexibility of LLMs for end-user planning. In addition to the LLM planner, VeriPlan includes three additional core features---a rule translator, flexibility sliders, and a model checker---that engage users in the verification process. Through a user study ($n=12$), we evaluate VeriPlan, demonstrating improvements in the perceived quality, usability, and user satisfaction of LLMs. Our work shows the effective integration of formal verification and user-control features with LLMs for end-user planning tasks." ;
    dcterms:identifier "3706598.3714113" ;
    chi:hasAuthor chi:person_185572, chi:person_183883, chi:person_183242, chi:person_186516, chi:person_183712 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:paperIncludesStudy chi:study_188642_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188642_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188642_InterfaceArtifact .

chi:study_188642_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188642 ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:reportsResult chi:result_188642_StatisticalResult .

chi:artifact_188642_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188642 .

chi:artifact_188642_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188642 .

chi:result_188642_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188643 rdf:type chi:Paper ;
    dcterms:title "Management, Cooperation, and Sustainability: Unpacking the Data Practices of Housing Cooperatives" ;
    dcterms:abstract "Despite significant work in HCI on understanding the role of data tools for non-profits and grassroots communities, there has been limited focus on cooperatives. This paper examines the role of financial, social, and building upkeep data in a non-profit cooperative housing organization in Toronto, Canada (alias named NXI). Through a 16-month-long ethnographic study, including 24 interviews, we investigate the role of and tensions in data practices related to NXI’s daily maintenance and operations, cooperation, and sustainability. We find that NXI’s current data practices are functional and meaningful—sometimes requiring team workarounds—in the short term. However, various tensions and deficiencies in data practices hamper NXI’s sustainability. By contextualizing the temporal affordances of data, we propose design implications for data tools to align effectively with the practices of cooperatives and enhance organizational sustainability. Finally, we discuss how data designers and researchers, organizations or grassroots communities, and financial technology designers can benefit from our work, especially with regard to the maintenance and sustainability of small-scale organizations." ;
    dcterms:identifier "3706598.3713121" ;
    chi:hasAuthor chi:person_182723, chi:person_183010, chi:person_187770 ;
    chi:hasPrimaryTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188643_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188643_FieldStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking .

chi:study_188643_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188643 ;
    chi:reportsResult chi:result_188643_QualitativeResult .

chi:study_188643_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188643 ;
    chi:reportsResult chi:result_188643_QualitativeResult .

chi:result_188643_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188644 rdf:type chi:Paper ;
    dcterms:title "More Attention, Transformation, Acceleration, and Exploration: Freelance Developers' Take on Hypes" ;
    dcterms:abstract "Despite growing economic importance, freelance software developers face unfavorable conditions on freelance platforms. Among others, they need to deal with the consequences of elevated expectations emerging during technology hypes. Despite this, the impact of hype on freelancers remains underexplored, limiting our ability to guide them through these intense periods and inform the design of freelance platforms.  Through interviews with 52 freelance developers pursuing projects involving generative AI (GenAI), we identify technology hypes as a significant force shaping freelancers’ careers. Based on the interviews, we offer a multifaceted perspective on hype as a phenomenon. We reveal that technological hypes negatively impact the career prospects and well-being of some freelancers while empowering others to advance their careers or transition into new areas. We identify four clusters of freelance developers based on their experiences with and reactions to the GenAI hype. This study positions technology hype as a critical factor shaping the freelance economy." ;
    dcterms:identifier "3706598.3713097" ;
    chi:hasAuthor chi:person_186730, chi:person_185886, chi:person_187384 ;
    chi:hasPrimaryTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188644_InterviewStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking .

chi:study_188644_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188644 ;
    chi:reportsResult chi:result_188644_QualitativeResult .

chi:result_188644_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188645 rdf:type chi:Paper ;
    dcterms:title "Gig2Gether: Datasharing to Empower, Unify and Demistify Gig Work" ;
    dcterms:abstract "The wide adoption of platformized work has generated remarkable advancements in the labor patterns and mobility of modern society. Underpinning such progress, gig workers are exposed to unprecedented challenges and accountabilities: lack of data transparency, social and physical isolation, as well as insufficient infrastructural safeguards. Gig2Gether presents a space designed for workers to engage in an initial experience of voluntarily contributing anecdotal and statistical data to affect policy and build solidarity across platforms by exchanging unifying and diverse experiences. Our 7-day field study with 16 active workers from three distinct platforms and work domains showed existing affordances of data-sharing: facilitating mutual support across platforms, as well as enabling financial reflection and planning. Additionally, workers envisioned future uses cases of data-sharing for collectivism (e.g., collaborative examinations of algorithmic speculations) and informing policy (e.g., around safety and pay), which motivated (latent) worker desiderata of additional capabilities and data metrics. Based on these findings, we discuss remaining challenges to address and how data-sharing tools can complement existing structures to maximize worker empowerment and policy impact." ;
    dcterms:identifier "3706598.3714398" ;
    chi:hasAuthor chi:person_183029, chi:person_186410, chi:person_184575, chi:person_185388, chi:person_186438, chi:person_187887, chi:person_187352, chi:person_186484, chi:person_183823 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:paperIncludesStudy chi:study_188645_FieldStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188645_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188645_InterfaceArtifact .

chi:study_188645_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188645 ;
    chi:reportsResult chi:result_188645_QualitativeResult .

chi:artifact_188645_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188645 .

chi:artifact_188645_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188645 .

chi:result_188645_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188646 rdf:type chi:Paper ;
    dcterms:title "Spatial Heterogeneity in Distributed Mixed Reality Collaboration" ;
    dcterms:abstract "Collaborative Mixed Reality (MR) enables embodied meetings for distributed collaborators working across a variety of locations. However, providing a coherent experience for all users regardless of the spatial configurations of their respective physical environments is a central challenge. We present the Spatial Heterogeneity Framework, which breaks the problem into four core components: the activity zones, heterogeneity ladder, blended proxemics, and MR solutions matrix. We explain the interplay between these components, demonstrating their interconnectivity via a case study. Our framework enables researchers to navigate differences and trade-offs between solutions for distributed MR collaboration.  It also supports designers to think about the role of space, technology, and social behaviours in MR collaboration. Ultimately, our contributions advance the field by conceptualising the challenges of spatial heterogeneity and strategies to overcome them." ;
    dcterms:identifier "3706598.3714033" ;
    chi:hasAuthor chi:person_186895, chi:person_184234, chi:person_183357, chi:person_186703 ;
    chi:hasPrimaryTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188646_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188646_InterfaceArtifact .

chi:artifact_188646_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188646 .

chi:artifact_188646_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188646 .

chi:result_188646_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188647 rdf:type chi:Paper ;
    dcterms:title "The Role of Initial Acceptance Attitudes Toward AI Decisions in Algorithmic Recourse" ;
    dcterms:abstract "Algorithmic recourse provides counterfactual suggestions to individuals who receive unfavorable AI decisions; the aim is to help them understand the reasoning and guide future actions.  While most research focuses on generating reasonable and actionable recourse, it often overlooks how individuals' initial reactions to AI decisions influence their perceptions of subsequent recourses and their ultimate acceptance of the decision.  To explore this, we conducted a user experiment (N=534) simulating an automobile loan application scenario.  Statistical analysis revealed that participants who initially reacted negatively to the AI decision perceived the recourse as less reasonable and actionable, reinforcing their negative attitudes.  However, when the recourse was perceived as explaining decision criteria or proposing realistic action plans, participants' attitudes shifted from negative to positive.  These findings offer design implications for recourse systems that enhance the acceptance of individuals negatively affected by AI decisions." ;
    dcterms:identifier "3706598.3713573" ;
    chi:hasAuthor chi:person_183342, chi:person_184574, chi:person_187777 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:AlgorithmicFairnessAndBias ;
    chi:paperIncludesStudy chi:study_188647_UserStudy ;
    chi:paperIncludesStudy chi:study_188647_QuantitativeStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188647_InterfaceArtifact .

chi:study_188647_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188647 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188647_StatisticalResult .

chi:study_188647_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188647 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188647_StatisticalResult .

chi:artifact_188647_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188647 .

chi:result_188647_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188648 rdf:type chi:Paper ;
    dcterms:title "LumaDreams: Designing Positive Dream Meaning-Making for Daily Empowerment" ;
    dcterms:abstract "Dreams contribute to cognitive and emotional health, yet tools for everyday dream engagement remain largely underexplored outside clinical settings. In this paper, we introduce LumaDreams, a mobile application designed to foster daily empowerment through positive dream transformation using generative AI. Informed by meaning-making theories, LumaDreams enables users to journal dreams through sketches and text, which are then transformed into positive images and stories for users to revisit and reflect on. We conducted a mixed-method study with 14 participants over 14 days. Our findings show that LumaDreams strengthened participants’ daily empowerment through cognitive and emotional shifts that arise from the positive meaning-making process. Qualitative insights further revealed how users’ perceptions and trust of AI-driven dream transformation were shaped through their interactions. In conclusion, we propose an inspiring approach that enables users to co-create positive meanings in dream experiences with generative AI, promoting cognitive and emotional shifts, fostering positive mindsets, and ultimately strengthening daily empowerment." ;
    dcterms:identifier "3706598.3713495" ;
    chi:hasAuthor chi:person_183151, chi:person_183704, chi:person_185778, chi:person_183442 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:SelfReflectionAndBehaviorChange ;
    chi:paperIncludesStudy chi:study_188648_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188648_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188648_InterfaceArtifact .

chi:study_188648_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188648 ;
    chi:reportsResult chi:result_188648_QualitativeResult .

chi:artifact_188648_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188648 .

chi:artifact_188648_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188648 .

chi:result_188648_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188649 rdf:type chi:Paper ;
    dcterms:title "HarmonyCut: Supporting Creative Chinese Paper-cutting Design with Form and Connotation Harmony" ;
    dcterms:abstract "Chinese paper-cutting, an Intangible Cultural Heritage (ICH), faces challenges from the erosion of traditional culture due to the prevalence of realism alongside limited public access to cultural elements. While generative AI can enhance paper-cutting design with its extensive knowledge base and efficient production capabilities, it often struggles to align content with cultural meaning due to users' and models' lack of comprehensive paper-cutting knowledge. To address these issues, we conducted a formative study (N=7) to identify the workflow and design space, including four core factors (Function, Subject Matter, Style, and Method of Expression) and a key element (Pattern). We then developed HarmonyCut, a generative AI-based tool that translates abstract intentions into creative and structured ideas. This tool facilitates the exploration of suggested related content (knowledge, works, and patterns), enabling users to select, combine, and adjust elements for creative paper-cutting design. A user study (N=16) and an expert evaluation (N=3) demonstrated that HarmonyCut effectively provided relevant knowledge, aiding the ideation of diverse paper-cutting designs and maintaining design quality within the design space to ensure alignment between form and cultural connotation.  " ;
    dcterms:identifier "3706598.3714159" ;
    chi:hasAuthor chi:person_185657, chi:person_182963, chi:person_186970, chi:person_183014, chi:person_185818 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:paperIncludesStudy chi:study_188649_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188649_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188649_InterfaceArtifact .

chi:study_188649_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188649 ;
    chi:reportsResult chi:result_188649_QualitativeResult .

chi:artifact_188649_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188649 .

chi:artifact_188649_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188649 .

chi:result_188649_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188650 rdf:type chi:Paper ;
    dcterms:title "Beyond Bridging Divides: Examining the Goals of Digital Inclusion Practice in Post-Digital Societies" ;
    dcterms:abstract "The widespread digitalisation of critical civic services in contexts of economic austerity, neoliberalism, and the COVID-19 pandemic, has renewed focus in HCI on interventions to enable digital access for populations considered ‘digitally excluded’. While digital inclusion (DI) practitioners play a critical role in this area, their perspectives remain under-explored in HCI. This paper reports on a series of asset-based engagements with digital inclusion practitioners in the North East of England. These engagements explored the values, assets, and needs comprising their practices and used these insights as design material to ideate strategies for future intervention. We contribute findings describing the complexities, contradictions, and diversity of digital inclusion practices and efforts. Based on these findings, we argue for a shift towards considering DI practice through the lens of care, and provide directions for future HCI research to support DI practitioners in doing care work." ;
    dcterms:identifier "3706598.3713902" ;
    chi:hasAuthor chi:person_183526, chi:person_182774, chi:person_184545 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188650_FieldStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility .

chi:study_188650_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188650 ;
    chi:reportsResult chi:result_188650_QualitativeResult .

chi:result_188650_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188651 rdf:type chi:Paper ;
    dcterms:title "YouthCare: Building a Personalized Collaborative Video Censorship Tool to Support Parent-Child Joint Media Engagement" ;
    dcterms:abstract "To mitigate the negative impacts of online videos on teenagers, existing research and platforms have implemented various parental mediation mechanisms, such as Parent-Child Joint Media Engagement (JME). However, JME generally relies heavily on parents' time, knowledge, and experience. To fill this gap, we aim to design an automatic tool to help parents/children censor videos more effectively and efficiently in JME. For this goal, we first conducted a formative study to identify the needs and expectations of teenagers and parents for such a system. Based on the findings, we designed YouthCare, a personalized collaborative video censorship tool that supports parents and children to collaboratively filter out inappropriate content and select appropriate content in JME. An evaluation with 10 parent-child pairs demonstrated YouthCare's several strengths in supporting video censorship, while also highlighting some potential problems. These findings inspire us to propose several insights for the future design of par" ;
    dcterms:identifier "3706598.3713360" ;
    chi:hasAuthor chi:person_186345, chi:person_186528, chi:person_186870, chi:person_187074, chi:person_185324, chi:person_186577, chi:person_184098, chi:person_187533 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:aboutTopic chi:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188651_UserStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188651_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188651_InterfaceArtifact .

chi:study_188651_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188651 ;
    chi:reportsResult chi:result_188651_QualitativeResult .

chi:artifact_188651_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188651 .

chi:artifact_188651_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188651 .

chi:result_188651_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188652 rdf:type chi:Paper ;
    dcterms:title "Identifying Critical Points of Departure for the Design of Self-Fashioning Technologies" ;
    dcterms:abstract "Designing technologies that clothe, adorn, or are otherwise placed on the body raises questions concerning the role they will play in dressing ourselves. We situate self-fashioning – or the process through which we stylise and present our bodies – as a complex practice where a series of social, material, and contextual factors shape how we present ourselves. Informed by reflective discussions and projective design tools, we contribute three critical points of departure for self-fashioning technologies: (i) Purposeful examining discomfort as an ongoing phenomenon, (ii) Supporting mimesis and visibility as qualities to be negotiated, and (iii) Envisioning the multiplicity of the body. We call for the design community to help devise fashionable technologies that are sensitive, caring, and responsive to the complexities of fashioning our bodies." ;
    dcterms:identifier "3706598.3714175" ;
    chi:hasAuthor chi:person_185528, chi:person_184419, chi:person_188033, chi:person_183796, chi:person_186120, chi:person_184459, chi:person_186667 ;
    chi:paperIncludesStudy chi:study_188652_QualitativeStudy .

chi:study_188652_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188652 ;
    chi:reportsResult chi:result_188652_QualitativeResult .

chi:result_188652_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188653 rdf:type chi:Paper ;
    dcterms:title "Fear, Fun or None: A Qualitative Quest Towards Unlocking Cybersecurity Attitudes" ;
    dcterms:abstract "Employees, once seen as the weakest link in organizational cybersecurity, are now recognized as crucial defenders against malicious attacks. Thus, understanding employee attitudes towards cybersecurity, a major factor driving security behavior, is essential for protecting organizations. Using semi-structured interviews and focus groups, this study holistically explores attitudes toward cybersecurity, its influencing factors, and the employees’ needs for fostering positive attitudes. The study offers in-depth insights into affective, cognitive, and behavioral components of attitudes, ranging from annoyance and fear to appreciation for cybersecurity measures. Influencing key factors include (in)direct cybersecurity experiences and individual perceptions - both highlighting social influences. For developing positive attitudes, employees express needs related to the company's social and cultural framework, communication styles, educational contents and formats. The study contributes to developing effective security strategies that address the individual, social, and organizational factors that shape cybersecurity attitudes, ultimately promoting a stronger organizational security." ;
    dcterms:identifier "3706598.3713538" ;
    chi:hasAuthor chi:person_185989, chi:person_183517, chi:person_186445, chi:person_184322 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:TargetedEthicsInterventions ;
    chi:paperIncludesStudy chi:study_188653_InterviewStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking .

chi:study_188653_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188653 ;
    chi:reportsResult chi:result_188653_QualitativeResult .

chi:result_188653_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188654 rdf:type chi:Paper ;
    dcterms:title "\"We're utterly ill-prepared to deal with something like this\": Teachers' Perspectives on Student Generation of Synthetic Nonconsensual Explicit Imagery" ;
    dcterms:abstract "Synthetic nonconsensual explicit imagery, also referred to as \"deepfake nudes\", is becoming faster and easier to generate. In the last year, synthetic nonconsensual explicit imagery was reported in at least ten US middle and high schools, generated by students of other students. Teachers are at the front lines of this new form of image abuse and have a valuable perspective on threat models in this context. We interviewed 17 US teachers to understand their opinions and concerns about synthetic nonconsensual explicit imagery in schools. No teachers knew of it happening at their schools, but most expected it to be a growing issue. Teachers proposed many interventions, such as improving reporting mechanisms, focusing on consent in sex education, and updating technology policies. However, teachers disagreed about appropriate consequences for students who create such images. We unpack our findings relative to differing models of justice, sexual violence, and sociopolitical challenges within schools. " ;
    dcterms:identifier "3706598.3713226" ;
    chi:hasAuthor chi:person_187514, chi:person_184621, chi:person_186492, chi:person_187106 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:TargetedEthicsInterventions ;
    chi:paperIncludesStudy chi:study_188654_InterviewStudy ;
    chi:aimsAtGoal chi:PromoteLearning .

chi:study_188654_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188654 ;
    chi:reportsResult chi:result_188654_QualitativeResult .

chi:result_188654_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188656 rdf:type chi:Paper ;
    dcterms:title "Investigating Users' Decision-making for Data Privacy Controls in the Context of Internet of Things (IoT) Devices Using an Incentive-compatible Lottery Study" ;
    dcterms:abstract "While companies are increasingly moving towards the ‘pay for privacy’ model, it is unclear how consumers make privacy decisions under this model. Toward that, we conducted an incentive-compatible lottery study on Prolific to understand the factors behind users’ choice to have additional data privacy controls. With 265 United States participants across two device risk conditions (High-risk: camera vs. Low-risk: light bulb) and three cash conditions ($9.99 vs. $19.99 vs. $29.99), results reveal that device risk and cash offerings influence participants’ lottery choice. We further observed an interaction effect between participants’ technical literacy and cash option. Specifically, technical participants chose the data privacy controls instead of cash at a higher rate when the cash condition was $29.99. In contrast, less technical participants favored the privacy option at a higher rate when the cash condition was $9.99. Implications of our findings for user data privacy are discussed in the paper." ;
    dcterms:identifier "3706598.3713251" ;
    chi:hasAuthor chi:person_187525, chi:person_187586 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:DataDisclosureAndConsent ;
    chi:paperIncludesStudy chi:study_188656_UserStudy ;
    chi:paperIncludesStudy chi:study_188656_QuantitativeStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking .

chi:study_188656_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188656 ;
    chi:reportsResult chi:result_188656_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:study_188656_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188656 ;
    chi:reportsResult chi:result_188656_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:result_188656_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188657 rdf:type chi:Paper ;
    dcterms:title "Are We On Track? AI-Assisted Active and Passive Goal Reflection During Meetings" ;
    dcterms:abstract "Meetings often suffer from a lack of intentionality, such as unclear goals and straying off-topic. Identifying goals and maintaining their clarity throughout a meeting is challenging, as discussions and uncertainties evolve. Yet meeting technologies predominantly fail to support meeting intentionality. AI-assisted reflection is a promising approach. To explore this, we conducted a technology probe study with 15 knowledge workers, integrating their real meeting data into two AI-assisted reflection probes: a passive and active design. Participants identified goal clarification as a foundational aspect of reflection. Goal clarity enabled people to assess when their meetings were off-track and reprioritize accordingly. Passive AI intervention helped participants maintain focus through non-intrusive feedback, while active AI intervention, though effective at triggering immediate reflection and action, risked disrupting the conversation flow.  We identify three key design dimensions for AI-assisted reflection systems, and provide insights into design trade-offs, emphasizing the need to adapt intervention intensity and timing, balance democratic input with efficiency, and offer user control to foster intentional, goal-oriented behavior during meetings and beyond." ;
    dcterms:identifier "3706598.3714052" ;
    chi:hasAuthor chi:person_187066, chi:person_183419, chi:person_184505, chi:person_187728, chi:person_183144, chi:person_187998 ;
    chi:hasPrimaryTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:paperIncludesStudy chi:study_188657_FieldStudy ;
    chi:paperIncludesStudy chi:study_188657_UserStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188657_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188657_InterfaceArtifact .

chi:study_188657_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188657 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188657_QualitativeResult .

chi:study_188657_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188657 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188657_QualitativeResult .

chi:artifact_188657_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188657 .

chi:artifact_188657_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188657 .

chi:result_188657_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188658 rdf:type chi:Paper ;
    dcterms:title "Bridging Borders, Breaking Biases: Envisioning Technologies to Support North Korean Defectors in South Korea " ;
    dcterms:abstract "North Korean defectors (NKDs) face significant challenges when transitioning to South Korean society. Leaving their homes permanently and adapting to a new, digitally connected environment for the first time presents difficulties, compounded by the pervasive stigma associated with their identities. Although technology alone cannot solve these issues, it can play a role in easing their transition. In this study, we conducted eight speculative co-creation sessions with 22 NKDs to identify their main challenges and envision potential technological interventions. We propose the conceptualization of thirteen technologies aimed at addressing key issues NKDs face related to identity stigma, disconnection from their past, and challenges of adapting to a highly digital society. Through this empirical research on underrepresented populations undergoing significant life transitions, we provide insights into how future technologies can support other marginalized individuals as they navigate pervasive stigma and establish new lives in a digital society." ;
    dcterms:identifier "3706598.3713752" ;
    chi:hasAuthor chi:person_184087, chi:person_185446, chi:person_185608, chi:person_183113, chi:person_186781 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188658_UserStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188658_SoftwareArtifact .

chi:study_188658_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188658 ;
    chi:reportsResult chi:result_188658_QualitativeResult .

chi:artifact_188658_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188658 .

chi:result_188658_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188659 rdf:type chi:Paper ;
    dcterms:title "GistVis: Automatic Generation of Word-scale Visualizations from Data-rich Documents" ;
    dcterms:abstract "Data-rich documents are ubiquitous in various applications, yet they often rely solely on textual descriptions to convey data insights. Prior research primarily focused on providing visualization-centric augmentation to data-rich documents. However, few have explored using automatically generated word-scale visualizations to enhance the document-centric reading process. As an exploratory step, we propose GistVis, an automatic pipeline that extracts and visualizes data insight from text descriptions. GistVis decomposes the generation process into four modules: Discoverer, Annotator, Extractor, and Visualizer, with the first three modules utilizing the capabilities of large language models and the fourth using visualization design knowledge. Technical evaluation including a comparative study on Discoverer and an ablation study on Annotator reveals decent performance of GistVis. Meanwhile, the user study (N=12) showed that GistVis could generate satisfactory word-scale visualizations, indicating its effectiveness in facilitating users' understanding of data-rich documents (+5.6% accuracy) while significantly reducing their mental demand (p=0.016) and perceived effort (p=0.033)." ;
    dcterms:identifier "3706598.3713881" ;
    chi:hasAuthor chi:person_185460, chi:person_185407, chi:person_187881, chi:person_183136, chi:person_188135, chi:person_183794, chi:person_184161 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:CollaborativeVisualizationTools ;
    chi:paperIncludesStudy chi:study_188659_BaselineComparisonStudy ;
    chi:paperIncludesStudy chi:study_188659_UserStudy ;
    chi:aimsAtGoal chi:ReduceCognitiveLoad ;
    chi:proposesArtifact chi:artifact_188659_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188659_InterfaceArtifact .

chi:study_188659_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188659 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188659_StatisticalResult .

chi:study_188659_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188659 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188659_StatisticalResult .

chi:artifact_188659_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188659 .

chi:artifact_188659_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188659 .

chi:result_188659_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188660 rdf:type chi:Paper ;
    dcterms:title "Understanding Mental Wellbeing and Tools for Support with Taiwanese Emerging Adults: An Eastern Cultural Perspective" ;
    dcterms:abstract "Mental wellbeing has become a crucial aspect of overall health and has drawn increased attention to mental health concerns. Research in human-computer interaction (HCI) has explored how technologies can support mental wellbeing and address mental health issues. However, current research predominantly reflects Western cultural perspectives, leaving gaps in our understanding of mental wellbeing, coping strategies, and digital tools for mental wellbeing support from Eastern cultural viewpoints. To start to address this disparity, we interviewed 19 Taiwanese emerging adults aged between 18 and 29—a demographic uniquely susceptible to mental health challenges due to the transitional nature of this life phase. We explored their conceptualization of mental wellbeing, the challenges they encounter, the strategies they employ for managing mental wellbeing, and the role of digital tools in this process. The results highlight the intricate influence of cultural, political, social, and individual factors, and their interactions on mental wellbeing. " ;
    dcterms:identifier "3706598.3713143" ;
    chi:hasAuthor chi:person_185678, chi:person_185148, chi:person_183572 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:AccessibilityNavigationSupport ;
    chi:paperIncludesStudy chi:study_188660_InterviewStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188660_SoftwareArtifact .

chi:study_188660_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188660 ;
    chi:reportsResult chi:result_188660_QualitativeResult .

chi:artifact_188660_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188660 .

chi:result_188660_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188661 rdf:type chi:Paper ;
    dcterms:title "Understanding and Empowering Intelligence Analysts: User-Centered Design for Deepfake Detection Tools" ;
    dcterms:abstract "Intelligence analysts must quickly and accurately examine and report on information in multiple modalities, including video, audio, and images. With the rise of Generative AI and deepfakes, analysts face unprecedented challenges, and require effective, reliable, and explainable media detection and analysis tools. This work explores analysts' requirements for deepfake detection tools and explainability features. From a study of 30 practitioners from the United States Intelligence Community, we identified the need for a comprehensive and explainable solution that incorporates a wide variety of methods and supports the production of intelligence reports. In response, we propose a design for an analyst-centered tool, and introduce a digital media forensics ontology to support analysts’ interactions with the tool and understanding of its results. We conducted a study grounded in work-related tasks as an initial evaluation of this approach, and report on its potential to assist analysts and areas for improvement in future work." ;
    dcterms:identifier "3706598.3713711" ;
    chi:hasAuthor chi:person_187497, chi:person_184693, chi:person_185693, chi:person_186037 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:CollaborativeVisualizationTools ;
    chi:paperIncludesStudy chi:study_188661_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188661_UserStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188661_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188661_InterfaceArtifact .

chi:study_188661_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188661 ;
    chi:reportsResult chi:result_188661_QualitativeResult .

chi:study_188661_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188661 ;
    chi:reportsResult chi:result_188661_QualitativeResult .

chi:artifact_188661_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188661 .

chi:artifact_188661_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188661 .

chi:result_188661_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188662 rdf:type chi:Paper ;
    dcterms:title "The Walking Meditation Mat: Leveraging Targeted Heat Sensation to Guide Attention Inward" ;
    dcterms:abstract "We present the walking meditation mat research, leveraging targeted heat to help meditators focus attention inward. The mat, measuring three meters in length, is designed with 10 visual signifiers and 10 corresponding heater pads arranged in a step-by-step pattern. Walking meditation is challenging, as it requires both inward and outward attention. In a qualitative study we studied the walking meditation experience with or without heat, evaluating the impact of the mat’s visual signifiers and the gentle feet-focused targeted heat during the walking experience. Our findings reveal the tension participants experience between external design factors and their internal meditation process. Visual signifiers were more commonly associated with outward attention, dizziness and imbalance, while targeted heat affordances were more commonly associated with attention to bodily sensations, calmness, grounding, and reflection. We conclude with insights regarding the role of targeted heat in balancing inward and outward attention in walking meditation and introspective processes." ;
    dcterms:identifier "3706598.3713208" ;
    chi:hasAuthor chi:person_187282, chi:person_184448 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:paperIncludesStudy chi:study_188662_QualitativeStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188662_DeviceArtifact .

chi:study_188662_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188662 ;
    chi:reportsResult chi:result_188662_QualitativeResult .

chi:artifact_188662_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188662 .

chi:result_188662_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188663 rdf:type chi:Paper ;
    dcterms:title "Ink Restorer: Virtual Restoration of Ancient Chinese Paintings Inheriting Traditional Restoration Processes" ;
    dcterms:abstract "The restoration of ancient Chinese paintings plays an essential role in protection and inheritance of Asian culture. A traditional restoration process consists of four stages: Xi (washing), Jie (separating), Bu (mending), and Quan (completing). However, it is difficult for the public to experience this process due to high professional requirement and time consumption. We conduct a questionnaire survey and interview experts in our formative study. The questionnaire result shows the public express strong interest in virtual restoration. Experts believe virtual restoration is an experience valuable for the public. We introduce Ink-Restorer, a tool designed for experiencing virtual restoration for ancient paintings. Its design follows the traditional restoration process, and it adopts image segmentation and generation techniques to simplify detailed restoration for users. We recruit 60 users to evaluate Ink-Restorer and invite experts to evaluate restoration results. Ink-Restorer significantly improves user experience, cultural understanding, and restoration quality." ;
    dcterms:identifier "3706598.3714190" ;
    chi:hasAuthor chi:person_185757, chi:person_184912, chi:person_184135, chi:person_185449, chi:person_183706, chi:person_185650, chi:person_186453, chi:person_184925, chi:person_184319 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction:EmbodiedVRInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction:EmbodiedVRInteraction ;
    chi:paperIncludesStudy chi:study_188663_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188663_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188663_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188663_InterfaceArtifact .

chi:study_188663_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188663 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188663_QualitativeResult ;
    chi:reportsResult chi:result_188663_StatisticalResult .

chi:study_188663_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188663 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188663_QualitativeResult ;
    chi:reportsResult chi:result_188663_StatisticalResult .

chi:artifact_188663_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188663 .

chi:artifact_188663_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188663 .

chi:result_188663_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188663_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188664 rdf:type chi:Paper ;
    dcterms:title "Fostering Appropriate Reliance on Large Language Models: The Role of Explanations, Sources, and Inconsistencies" ;
    dcterms:abstract "Large language models (LLMs) can produce erroneous responses that sound fluent and convincing, raising the risk that users will rely on these responses as if they were correct. Mitigating such overreliance is a key challenge. Through a think-aloud study in which participants use an LLM-infused application to answer objective questions, we identify several features of LLM responses that shape users' reliance: explanations (supporting details for answers), inconsistencies in explanations, and sources. Through a large-scale, pre-registered, controlled experiment (N=308), we isolate and study the effects of these features on users' reliance, accuracy, and other measures.We find that the presence of explanations increases reliance on both correct and incorrect responses. However, we observe less reliance on incorrect responses when sources are provided or when explanations exhibit inconsistencies. We discuss the implications of these findings for fostering appropriate reliance on LLMs." ;
    dcterms:identifier "3706598.3714020" ;
    chi:hasAuthor chi:person_187864, chi:person_187273, chi:person_186715, chi:person_184816, chi:person_185888 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:ChatbotAssistedUserStudies ;
    chi:paperIncludesStudy chi:study_188664_ThinkAloudStudy ;
    chi:paperIncludesStudy chi:study_188664_BaselineComparisonStudy ;
    chi:paperIncludesStudy chi:study_188664_UserStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188664_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188664_InterfaceArtifact .

chi:study_188664_ThinkAloudStudy rdf:type chi:ThinkAloudStudy ;
    chi:isStudyReportedIn chi:paper_188664 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188664_QualitativeResult ;
    chi:reportsResult chi:result_188664_StatisticalResult .

chi:study_188664_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188664 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188664_QualitativeResult ;
    chi:reportsResult chi:result_188664_StatisticalResult .

chi:study_188664_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188664 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188664_QualitativeResult ;
    chi:reportsResult chi:result_188664_StatisticalResult .

chi:artifact_188664_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188664 .

chi:artifact_188664_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188664 .

chi:result_188664_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188664_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188665 rdf:type chi:Paper ;
    dcterms:title "Chorus of the Past: Toward Designing a Multi-agent Conversational Reminiscence System with Digital Artifacts for Older Adults" ;
    dcterms:abstract "Reminiscence has been shown to provide benefits for older adults, but traditionally relies on personal photos as memory cues and interactions with real people who may not always be available. We present ReminiBuddy, a novel LLM-powered multi-agent conversational system, which allows older adults to engage with two distinct agents—one embodying an older identity and the other a younger identity—while using not only personal photos but also 3D models of generic nostalgic objects as memory cues. Our study, with older adult participants, found that the conversational approach both enjoyable and beneficial for reminiscence. While the younger agent was perceived as more emotionally engaging, the older one fostered greater resonance in content. Personal photos prompted autobiographical memories, whereas 3D generic nostalgic objects evoked shared memories of an era, contributing to a more multifaceted reminiscence experience. We further present design implications for better supporting older adults in reminiscing with LLM-powered conversational agents." ;
    dcterms:identifier "3706598.3713810" ;
    chi:hasAuthor chi:person_186911, chi:person_185865, chi:person_183282, chi:person_186469, chi:person_184646, chi:person_186274, chi:person_184572, chi:person_183716, chi:person_186008, chi:person_184172 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:SocialComputing ;
    chi:paperIncludesStudy chi:study_188665_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188665_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188665_InterfaceArtifact .

chi:study_188665_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188665 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188665_QualitativeResult .

chi:artifact_188665_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188665 .

chi:artifact_188665_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188665 .

chi:result_188665_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188666 rdf:type chi:Paper ;
    dcterms:title "Toward Enabling Natural Conversation with Older Adults via the Design of LLM-Powered Voice Agents that Support Interruptions and Backchannels" ;
    dcterms:abstract "Voice agents can construct meaningful conversations with older adults to offer various benefits, such as providing emotional companionship and assisting with memory recall. However, such conversations often follow the simple turn-taking pattern and lack interruption and backchannel of natural human conversation. Previous research has shown that this rigid turn-taking pattern lacks interactivity and initiative, limiting the flexible communication between older adults and voice agents. To address these issues and create a more natural conversational voice agent, we first conducted a formative study to identify common usage of interruption in the natural conversations of older adults. We then designed an LLM-powered Barge-in agent that supports interruption and backchannel. Our within-subject exploratory study showed that participants felt that conversations with Barge-in agents were more natural, engaging, and fluent than with the No barge-in agent. We further present design implications for creating more natural and human-like voice agents for older adults." ;
    dcterms:identifier "3706598.3714228" ;
    chi:hasAuthor chi:person_183543, chi:person_184599, chi:person_186274, chi:person_184401, chi:person_185063, chi:person_187918, chi:person_184172 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188666_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188666_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188666_InterfaceArtifact .

chi:study_188666_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188666 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188666_QualitativeResult ;
    chi:reportsResult chi:result_188666_StatisticalResult .

chi:artifact_188666_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188666 .

chi:artifact_188666_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188666 .

chi:result_188666_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188666_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188667 rdf:type chi:Paper ;
    dcterms:title "Small, Medium, Large? A Meta-Study of Effect Sizes at CHI to Aid Interpretation of Effect Sizes and Power Calculation" ;
    dcterms:abstract "Statistical reporting, especially of effect sizes, is at the root of many methodological issues in quantitative research at CHI. Effect sizes are necessary for assessing practical relevance of results, a-priori power analysis, and meta-analyses, but currently, they are often not reported. Interpretations in the context of the study and the research field are also rare. To aid to researchers in reporting and contextualizing their effect sizes within their research field as well as choosing effect sizes for power analysis, we conducted a meta-study of quantitative CHI papers. We extracted statistics from all quantitative CHI papers published between 2019-2023 (N=1692). Based on effect sizes and the papers' CCS categories, we present effect size distributions in 12 CHI research fields. Through an additional qualitative analysis of 67 quantitative CHI'23 publications, we identify five categories of approaches that researchers take when interpreting effect size: Comparing test-specific values, assigning size labels, using a statistical or methodological reference frame, comparing different observations and interpreting for the big picture. " ;
    dcterms:identifier "3706598.3713671" ;
    chi:hasAuthor chi:person_187781, chi:person_184603, chi:person_184176, chi:person_183603, chi:person_186640, chi:person_187938 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:paperIncludesStudy chi:study_188667_QuantitativeStudy ;
    chi:paperIncludesStudy chi:study_188667_QualitativeStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking .

chi:study_188667_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188667 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188667_QualitativeResult ;
    chi:reportsResult chi:result_188667_StatisticalResult .

chi:study_188667_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188667 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188667_QualitativeResult ;
    chi:reportsResult chi:result_188667_StatisticalResult .

chi:result_188667_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188667_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188668 rdf:type chi:Paper ;
    dcterms:title "HaptiCoil: Soft Programmable Buttons with Hydraulically Coupled Haptic Feedback and Sensing" ;
    dcterms:abstract "We present HaptiCoil, an embedded system and interaction method for prototyping low-cost, compact, and customizable wide bandwidth (1-500 Hz) soft haptic buttons. HaptiCoil devices are built using mass-produced, waterproof planar micro-speakers which are adapted to direct energy to the skin using a novel hydraulic coupling mechanism. They can sense force input, using a measurement of self-inductance, and provide output in a single package, yielding a flexible all-in-one button solution. Our devices offer a wider perceptual range of tactile stimuli than industry standard approaches, while maintaining comparable power threshold levels (typical threshold under 40 mW). We detail the construction and underlying principles of our approach, as well as an extensive physical quantification of both input and output. We share psychophysical data on device bandwidth, and show three illustrative examples of how HaptiCoil buttons can implemented in use cases such as spatial computing, digital inking, and remote control. " ;
    dcterms:identifier "3706598.3713175" ;
    chi:hasAuthor chi:person_186399, chi:person_186587, chi:person_187875 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:paperIncludesStudy chi:study_188668_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188668_InputDeviceArtifact ;
    chi:proposesArtifact chi:artifact_188668_OutputDeviceArtifact ;
    chi:proposesArtifact chi:artifact_188668_DeviceArtifact .

chi:study_188668_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188668 ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188668_StatisticalResult .

chi:artifact_188668_InputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188668 .

chi:artifact_188668_OutputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188668 .

chi:artifact_188668_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188668 .

chi:result_188668_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188669 rdf:type chi:Paper ;
    dcterms:title "\"Business on WhatsApp is tough now—but am I really a businesswoman?\" Exploring Challenges with Adapting to Changes in WhatsApp Business" ;
    dcterms:abstract "This study examines how WhatsApp has evolved from a personal communication tool to a professional platform, focusing on its use by small business owners in India. Initially embraced in smaller, rural communities for its ease of use and familiarity, WhatsApp played a crucial role in local economies. However, as Meta introduced WhatsApp Business with new, formalized features, users encountered challenges in adapting to the more complex and costly platform. Interviews with 14 small business owners revealed that while they adapted creatively, they felt marginalized by the advanced tools. This research contributes to HCI literature by exploring the transition from personal to professional use and introduces the concept of Coercive Professionalization. It highlights how standardization by large tech companies affects marginalized users, exacerbating power imbalances and reinforcing digital colonialism, concluding with design implications for supporting community-based appropriations. " ;
    dcterms:identifier "3706598.3713988" ;
    chi:hasAuthor chi:person_186417 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:aboutTopic chi:FuturesOfSocialPlatforms ;
    chi:paperIncludesStudy chi:study_188669_InterviewStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188669_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188669_InterfaceArtifact .

chi:study_188669_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188669 ;
    chi:reportsResult chi:result_188669_QualitativeResult .

chi:artifact_188669_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188669 .

chi:artifact_188669_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188669 .

chi:result_188669_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188670 rdf:type chi:Paper ;
    dcterms:title "To Rely or Not to Rely? Evaluating Interventions for Appropriate Reliance on Large Language Models" ;
    dcterms:abstract "As Large Language Models become integral to decision-making, optimism about their power is tempered with concern over their errors. Users may over-rely on LLM advice that is confidently stated but wrong, or under-rely due to mistrust. Reliance interventions have been developed to help users of LLMs, but they lack rigorous evaluation for appropriate reliance. We benchmark the performance of three relevant interventions by conducting a randomized online experiment with 400 participants attempting two challenging tasks: LSAT logical reasoning and image-based numerical estimation. For each question, participants first answered independently, then received LLM advice modified by one of three reliance interventions and answered the question again. Our findings indicate that while interventions reduce over-reliance, they generally fail to improve appropriate reliance. Furthermore, people became more confident after making wrong reliance decisions in certain contexts, demonstrating poor calibration. Based on our findings, we discuss implications for designing effective reliance interventions in human-LLM collaboration." ;
    dcterms:identifier "3706598.3714097" ;
    chi:hasAuthor chi:person_185745, chi:person_187087, chi:person_188188 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:TargetedEthicsInterventions ;
    chi:paperIncludesStudy chi:study_188670_UserStudy ;
    chi:paperIncludesStudy chi:study_188670_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188670_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188670_InterfaceArtifact .

chi:study_188670_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188670 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188670_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:study_188670_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188670 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188670_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:artifact_188670_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188670 .

chi:artifact_188670_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188670 .

chi:result_188670_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188671 rdf:type chi:Paper ;
    dcterms:title "Supporting Mobile Reading While Walking with Automatic and Customized Font Size Adaptations" ;
    dcterms:abstract "The pervasive use of mobile devices for information consumption makes reading on-the-go an unavoidable daily occurrence, whereby walking creates a natural situational impairment for reading. In this work, we quantify the impact of walking on reading performance and compare automatic system adaptations with user customizations for mitigating these impacts. We collected user interactions and mobile sensor data of reading while walking in a controlled lab study with 45 participants. We found that automatic font size adjustment by viewing distance mitigated the performance degradation from walking, yielding faster reading speed and increased comfort. Furthermore, exposure to the automatic adaptation functionality influences user customization behavior and preferences for reading while walking. We discuss implications and provide design suggestions for personalizing interfaces when reading on-the-go, including blending system recommendation with user customization, offering multiple points of customization through appropriately-timed prompts, and refining recommendations based on observed preferences." ;
    dcterms:identifier "3706598.3713367" ;
    chi:hasAuthor chi:person_185265, chi:person_185729, chi:person_185826, chi:person_186916 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:ErrorRatesAndTaskCompletion ;
    chi:paperIncludesStudy chi:study_188671_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188671_InterfaceArtifact .

chi:study_188671_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188671 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188671_StatisticalResult ;
    chi:reportsResult chi:result_188671_QualitativeResult .

chi:artifact_188671_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188671 .

chi:result_188671_StatisticalResult rdf:type chi:StatisticalResult .

chi:result_188671_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188672 rdf:type chi:Paper ;
    dcterms:title "Voxel Invention Kit: Reconfigurable Building Blocks for Prototyping Interactive Electronic Structures" ;
    dcterms:abstract "Prototyping large, electronically integrated structures is challenging and often results in unwieldy wiring, weak mechanical properties, expensive iterations, or limited reusability. While many electronics prototyping kits exist for small-scale objects, relatively few methods exist to freely iterate large and sturdy structures with integrated electronics. To address this gap, we present the Voxel Invention Kit (VIK), which uses reconfigurable blocks that assemble into high-stiffness, lightweight structures with integrated electronics. We do this by creating cubic blocks composed of PCBs that carry electrical routing and components and can be (re)configured with simple tools into a variety of structures. To ensure structural stability without expertise, we created a tool to configure structures and simulate applied loads, which we validated with mechanical testing data. Using VIK, we produced devices reconfigured from a shared set of voxels: multiple iterations of a customizable AV lounge seat, a dance floor game, and a force-sensing bridge. " ;
    dcterms:identifier "3706598.3713948" ;
    chi:hasAuthor chi:person_187095, chi:person_186855, chi:person_183899, chi:person_187373, chi:person_182925 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:proposesArtifact chi:artifact_188672_DeviceArtifact .

chi:artifact_188672_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188672 .

chi:paper_188673 rdf:type chi:Paper ;
    dcterms:title "TutorCraftEase: Enhancing Pedagogical Question Creation with Large Language Models" ;
    dcterms:abstract "Pedagogical questions are crucial for fostering student engagement and learning. In daily teaching, teachers pose hundreds of questions to assess understanding, enhance learning outcomes, and facilitate the transfer of theory-rich content. However, even experienced teachers often struggle to generate a large volume of effective pedagogical questions. To address this, we introduce TutorCraftEase, an interactive generation system that leverages large language models (LLMs) to assist teachers in creating pedagogical questions. TutorCraftEase enables the rapid generation of questions at varying difficulty levels with a single click, while also allowing for manual review and refinement. In a comparative user study with 39 participants, we evaluated TutorCraftEase against a traditional manual authoring tool and a basic LLM tool. The results show that TutorCraftEase can generate pedagogical questions comparable in quality to those created by experienced teachers, while significantly reducing their workload and time." ;
    dcterms:identifier "3706598.3713731" ;
    chi:hasAuthor chi:person_185019, chi:person_183696, chi:person_182664, chi:person_186271, chi:person_183480, chi:person_188049, chi:person_186078, chi:person_187589, chi:person_184283 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188673_UserStudy ;
    chi:paperIncludesStudy chi:study_188673_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188673_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188673_InterfaceArtifact .

chi:study_188673_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188673 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:reportsResult chi:result_188673_StatisticalResult .

chi:study_188673_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188673 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:reportsResult chi:result_188673_StatisticalResult .

chi:artifact_188673_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188673 .

chi:artifact_188673_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188673 .

chi:result_188673_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188674 rdf:type chi:Paper ;
    dcterms:title "Technologies for Children’s AI Learning: Design Features and Future Opportunities" ;
    dcterms:abstract "With the growing integration of AI into daily life, various technologies have been developed to teach children about AI. However, differences in their designs highlight the need for a thorough understanding of these tools to make the most of current technological resources and guide the effective development of future learning tools. Through a systematic search, we identified 64 different AI learning tools for children and analyzed their design features, including both static design features (i.e., presentation formats and learning content) and interactive design features (i.e., learning activity types and design features that potentially enhance the effectiveness of the activities). Our findings reveal the current trends and gaps in the design of children’s AI learning technologies. Based on these insights, we reflect on future design opportunities and provide recommendations for creating new, effective learning technologies to advance AI education for the next generations." ;
    dcterms:identifier "3706598.3713443" ;
    chi:hasAuthor chi:person_184973, chi:person_186293 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188674_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188674_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188674_DeviceArtifact .

chi:artifact_188674_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188674 .

chi:artifact_188674_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188674 .

chi:artifact_188674_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188674 .

chi:result_188674_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188675 rdf:type chi:Paper ;
    dcterms:title "Creativity Supportive Ecosystems: A Framework for Understanding Function and Disruption in Online Art Worlds" ;
    dcterms:abstract "The online art world is a double-edged sword: the Internet’s vibrant culture of open, cooperative art-sharing also attracts nonconsensual reuse and appropriation. Artists continually navigate supportive and challenging interactions on social platforms, including community-shifting disruptions; the reuse of creative work for training generative AI is only the latest such disruption. Research into creativity support tools (CSTs) often centers artifact-making, leaving the HCI community with few strategies to understand the downstream impacts CSTs can make on artifact-sharing. Seeking a framework that captures this, we develop the creativity supportive ecosystem through interviews with 20 online artists, and 8 data “stewards” with experience reusing creative data for training GenAI. We use the CSE to describe how creative communities perceive and respond to disruption, identifying opportunities to empower artists in their collective negotiations with disruptive technologies like GenAI: by centering artists as producers of value, identifying creative and alternative data practices, and empowering inter-community flexibility." ;
    dcterms:identifier "3706598.3713734" ;
    chi:hasAuthor chi:person_183544, chi:person_184896, chi:person_183055 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:paperIncludesStudy chi:study_188675_InterviewStudy .

chi:study_188675_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188675 ;
    chi:reportsResult chi:result_188675_QualitativeResult .

chi:result_188675_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188676 rdf:type chi:Paper ;
    dcterms:title " “I am a Technology Creator”: Black Girls as Technosocial Change Agents in a Culturally-Responsive Robotics Camp" ;
    dcterms:abstract "Black girls and women have long been creators in computing spaces. However, much computing education positions Black girls as workers who execute tasks for others' purposes. Our work takes a different approach by positioning Black girls as technosocial change agents who challenge dominant narratives and construct more liberating identities and social relations as they create new technologies. We draw on data from seven Black girls, ages 9-12, who participated in a 20-hour culturally responsive computing (CRC) camp focused on robotics. Using a thematic analysis approach, we explore how these Black girls demonstrate and enhance their technosocial change agency (TSCA) throughout the camp. We identify themes related to how creating technology helps Black girls refine and fulfill their definitions of technical creators and develop agency through technology creation. We discuss computing education and technology design recommendations within the TSCA framework to support learners' emerging TSCA in future CRC programs." ;
    dcterms:identifier "3706598.3713242" ;
    chi:hasAuthor chi:person_187935, chi:person_185279, chi:person_182855, chi:person_185211, chi:person_183053, chi:person_184811, chi:person_185437, chi:person_182865 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:paperIncludesStudy chi:study_188676_QualitativeStudy ;
    chi:aimsAtGoal chi:PromoteLearning .

chi:study_188676_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188676 ;
    chi:reportsResult chi:result_188676_QualitativeResult .

chi:result_188676_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188677 rdf:type chi:Paper ;
    dcterms:title "A Systematic Review of Fitts’ Law in 3D Extended Reality" ;
    dcterms:abstract "Fitts' law is widely used as an evaluation tool for pointing or selection tasks, evolving into diverse applications, including 3D extended reality (XR) environments like virtual, augmented, and mixed reality. Despite standards like ISO 9241:411, the application of Fitts' law varies significantly across studies, complicating comparisons and undermining the reliability of findings in 3D XR research. To address this, we conducted a systematic review of 119 publications, focusing on 122 studies that used Fitts' law in 3D XR user experiments. Our analysis shows that over half of these studies referenced Fitts' law without thoroughly investigating throughput, movement time, or error rate. We performed an in-depth meta-analysis to examine how Fitts' law is incorporated into research. By highlighting trends and inconsistencies, and making recommendations this review aims to guide researchers in designing and performing more effective and consistent Fitts-based studies in 3D XR, enhancing the quality and impact of future research." ;
    dcterms:identifier "3706598.3713623" ;
    chi:hasAuthor chi:person_187427, chi:person_184512, chi:person_187142, chi:person_184624 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:SpatialNavigationPerformance ;
    chi:aimsAtGoal chi:ImproveUsability .

chi:result_188677_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188677_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188678 rdf:type chi:Paper ;
    dcterms:title "VRCaptions: Design Captions for DHH Users in Multiplayer Communication in VR" ;
    dcterms:abstract "Accessing auditory information remains challenging for DHH individuals in real-world situations and multiplayer VR interactions. To improve this, we investigated caption designs that specialize in the needs of DHH users in multiplayer VR settings. First, we conducted three co-design workshops with DHH participants, social workers, and designers to gather insights into the specific needs of design directions for DHH users in the context of a room escape game in VR. We further refined our designs with 13 DHH users to determine the most preferred features. Based on this, we developed VRCaptions, a caption prototype for DHH users to better experience multiplayer conversations in VR. We lastly invited two mixed-hearing groups to participate in the VR room escape game with our VRCaptions to validate. The results demonstrate that VRCaptions can enhance the ability of DHH participants to access information and reduce the barrier to communication in VR." ;
    dcterms:identifier "3706598.3714186" ;
    chi:hasAuthor chi:person_187212, chi:person_186810, chi:person_187226, chi:person_183098, chi:person_185778, chi:person_187706 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:AccessibilityNavigationSupport ;
    chi:paperIncludesStudy chi:study_188678_UserStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188678_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188678_InterfaceArtifact .

chi:study_188678_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188678 ;
    chi:reportsResult chi:result_188678_QualitativeResult .

chi:artifact_188678_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188678 .

chi:artifact_188678_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188678 .

chi:result_188678_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188679 rdf:type chi:Paper ;
    dcterms:title "AiGet: Transforming Everyday Moments into Hidden Knowledge Discovery with AI Assistance on Smart Glasses" ;
    dcterms:abstract "Unlike the free exploration of childhood, the demands of daily life reduce our motivation to explore our surroundings, leading to missed opportunities for informal learning. Traditional tools for knowledge acquisition are reactive, relying on user initiative and limiting their ability to uncover hidden interests. Through formative studies, we introduce AiGet, a proactive AI assistant integrated with AR smart glasses, designed to seamlessly embed informal learning into low-demand daily activities (e.g., casual walking and shopping). AiGet analyzes real-time user gaze patterns, environmental context, and user profiles, leveraging large language models to deliver personalized, context-aware knowledge with low disruption to primary tasks. In-lab evaluations and real-world testing, including continued use over multiple days, demonstrate AiGet’s effectiveness in uncovering overlooked yet surprising interests, enhancing primary task enjoyment, reviving curiosity, and deepening connections with the environment. We further propose design guidelines for AI-assisted informal learning, focused on transforming everyday moments into enriching learning experiences." ;
    dcterms:identifier "3706598.3713953" ;
    chi:hasAuthor chi:person_186156, chi:person_186385, chi:person_184469, chi:person_185002, chi:person_185567, chi:person_184440, chi:person_187411 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188679_UserStudy ;
    chi:paperIncludesStudy chi:study_188679_FieldStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188679_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188679_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188679_DeviceArtifact .

chi:study_188679_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188679 ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188679_QualitativeResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:study_188679_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188679 ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188679_QualitativeResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:artifact_188679_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188679 .

chi:artifact_188679_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188679 .

chi:artifact_188679_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188679 .

chi:result_188679_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188680 rdf:type chi:Paper ;
    dcterms:title "AvatARoid: A Motion-Mapped AR Overlay to Bridge the Embodiment Gap Between Robots and Teleoperators in Robot-Mediated Telepresence" ;
    dcterms:abstract "Robot-mediated telepresence promises to facilitate effective social interaction between remote teleoperators and on-site users. However, disparities between the robot's form and the teleoperator's representation cause perceptual conflict in on-site users, degrading interaction quality. We introduce AvatARoid, a novel design that bridges this embodiment gap by superimposing the teleoperator's motion-mapped AR avatar overlay on a humanoid. We evaluated our design in a mixed-method study (n=48) using an immersive simulation where participants interacted with a confederate teleoperator, presented in either (a) a humanoid robot, (b) a humanoid robot with video, or (c) AvatARoid. Results suggest AvatARoid significantly improved teleoperator embodiment for on-site users, particularly enhancing co-location, and control perceptions, and providing richer non-verbal gestures. In contrast, video and baseline conditions often resulted in a pronounced disconnect between the teleoperator and the robot for on-site users. Our study offers new insights into designing novel teleoperator representations to promote social interaction in robot-mediated telepresence." ;
    dcterms:identifier "3706598.3713812" ;
    chi:hasAuthor chi:person_186921, chi:person_185760, chi:person_185976, chi:person_185035 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:EmbodiedVRInteraction ;
    chi:paperIncludesStudy chi:study_188680_UserStudy ;
    chi:paperIncludesStudy chi:study_188680_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188680_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188680_DeviceArtifact .

chi:study_188680_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188680 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188680_QualitativeResult ;
    chi:reportsResult chi:result_188680_StatisticalResult .

chi:study_188680_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188680 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188680_QualitativeResult ;
    chi:reportsResult chi:result_188680_StatisticalResult .

chi:artifact_188680_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188680 .

chi:artifact_188680_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188680 .

chi:result_188680_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188680_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188681 rdf:type chi:Paper ;
    dcterms:title "Deconstructing Depression Stigma: Integrating AI-driven Data Collection and Analysis with Causal Knowledge Graphs" ;
    dcterms:abstract "Mental-illness stigma is a persistent social problem, hampering both treatment-seeking and recovery. Accordingly, there is a pressing need to understand it more clearly, but analyzing the relevant data is highly labor-intensive. Therefore, we designed a chatbot to engage participants in conversations; coded those conversations qualitatively with AI assistance; and, based on those coding results, built causal knowledge graphs to decode stigma. The results we obtained from 1,002 participants demonstrate that conversation with our chatbot can elicit rich information about people’s attitudes toward depression, while our AI-assisted coding was strongly consistent with human-expert coding. Our novel approach combining large language models (LLMs) and causal knowledge graphs uncovered patterns in individual responses and illustrated the interrelationships of psychological constructs in the dataset as a whole. The paper also discusses these findings’ implications for HCI researchers in developing digital interventions, decomposing human psychological constructs, and fostering inclusive attitudes." ;
    dcterms:identifier "3706598.3714255" ;
    chi:hasAuthor chi:person_183150, chi:person_187541, chi:person_186363, chi:person_185032, chi:person_185527, chi:person_185245, chi:person_188122 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:ChatbotAssistedUserStudies ;
    chi:paperIncludesStudy chi:study_188681_UserStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188681_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188681_InterfaceArtifact .

chi:study_188681_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188681 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188681_QualitativeResult ;
    chi:reportsResult chi:result_188681_StatisticalResult .

chi:artifact_188681_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188681 .

chi:artifact_188681_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188681 .

chi:result_188681_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188681_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188682 rdf:type chi:Paper ;
    dcterms:title "Using Anonymous Discussion Platforms to Support Open Conversations about Cybersecurity in Organisations" ;
    dcterms:abstract "People-centred security is critical for the security of an organisation, but we know that it comes at a cost. Recently the academic literature base has started to focus on how security might be understood and promoted as a facet of the overall culture of an organisation. This work sets out to understand the experiences of employees and management when using an anonymous online discussion platform to discuss cybersecurity policies. Following a 2-week deployment in a large UK educational institution, we found that anonymity helped individuals share their experiences, and that these experiences helped others understand more about the rationale for security policies. However, we also found that anonymity negatively impacted on individuals’ ability to discuss specific problems and follow up on incidents. We discuss the opportunities and challenges of using anonymous discussion platforms in organisations for improving the security culture through social participation and a more transparent listening culture. " ;
    dcterms:identifier "3706598.3713290" ;
    chi:hasAuthor chi:person_183224, chi:person_186813, chi:person_184825, chi:person_186131, chi:person_184218 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialSupportAndPeerChatbots ;
    chi:paperIncludesStudy chi:study_188682_FieldStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188682_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188682_InterfaceArtifact .

chi:study_188682_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188682 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188682_QualitativeResult ;
    chi:involvesParticipationPattern chi:AsynchronousParticipation .

chi:artifact_188682_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188682 .

chi:artifact_188682_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188682 .

chi:result_188682_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188685 rdf:type chi:Paper ;
    dcterms:title "\"When Two Wrongs Don't Make a Right\" - Examining Confirmation Bias and the Role of Time Pressure During Human-AI Collaboration in Computational Pathology" ;
    dcterms:abstract "Artificial intelligence (AI)-based decision support systems hold promise for enhancing diagnostic accuracy and efficiency in computational pathology. However, human-AI collaboration can introduce and amplify cognitive biases, like confirmation bias caused by false confirmation when erroneous human opinions are reinforced by inaccurate AI output. This bias may increase under time pressure, a ubiquitous factor in routine pathology, as it strains practitioners' cognitive resources. We quantified confirmation bias triggered by AI-induced false confirmation and examined the role of time constraints in a web-based experiment, where trained pathology experts (n=28) estimated tumor cell percentages. Our results suggest that AI integration fuels confirmation bias, evidenced by a statistically significant positive linear-mixed-effects model coefficient linking AI recommendations mirroring flawed human judgment and alignment with system advice. Conversely, time pressure appeared to weaken this relationship. These findings highlight potential risks of AI in healthcare and aim to support the safe integration of clinical decision support systems." ;
    dcterms:identifier "3706598.3713319" ;
    chi:hasAuthor chi:person_185934, chi:person_184530, chi:person_184185, chi:person_187901, chi:person_183579, chi:person_182828, chi:person_184834, chi:person_186071, chi:person_184066, chi:person_184974, chi:person_187116, chi:person_182839, chi:person_187557, chi:person_186435, chi:person_186157, chi:person_184004, chi:person_182956, chi:person_188113, chi:person_184492, chi:person_183243, chi:person_184084, chi:person_182962, chi:person_185018, chi:person_186686, chi:person_183475, chi:person_184614, chi:person_183301 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:TargetedEthicsInterventions ;
    chi:paperIncludesStudy chi:study_188685_UserStudy ;
    chi:paperIncludesStudy chi:study_188685_QuantitativeStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188685_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188685_InterfaceArtifact .

chi:study_188685_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188685 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188685_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:study_188685_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188685 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188685_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:artifact_188685_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188685 .

chi:artifact_188685_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188685 .

chi:result_188685_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188686 rdf:type chi:Paper ;
    dcterms:title "CompAct: Designing Interconnected Compliant Mechanisms with Targeted Actuation Transmissions" ;
    dcterms:abstract "Compliant mechanisms enable the creation of compact and easy-to-fabricate devices for tangible interaction. This work explores interconnected compliant mechanisms consisting of multiple joints and rigid bodies to transmit and process displacements as signals that result from physical interactions. As these devices are difficult to design due to their vast and complex design space, we developed a graph-based design algorithm and computational tool to help users program and customize such computational functions and procedurally model physical designs. When combined with active materials with actuation and sensing capabilities, these devices can also render and detect haptic interaction. Our design examples demonstrate the tool’s capability to respond to relevant HCI concepts, including building modular physical interface toolkits, encrypting tangible interactions, and customizing user augmentation for accessibility. We believe the tool will facilitate the generation of new interfaces with enriched affordance." ;
    dcterms:identifier "3706598.3714307" ;
    chi:hasAuthor chi:person_184409, chi:person_183687, chi:person_182663, chi:person_184465, chi:person_183198, chi:person_185665, chi:person_184039 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188686_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188686_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188686_DeviceArtifact .

chi:artifact_188686_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188686 .

chi:artifact_188686_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188686 .

chi:artifact_188686_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188686 .

chi:paper_188687 rdf:type chi:Paper ;
    dcterms:title "\"I'd Never Actually Realized How Big An Impact It Had Until Now\": Perspectives of University Students with Disabilities on Generative Artificial Intelligence" ;
    dcterms:abstract "Prior research on the experiences of students with disabilities in higher education has surfaced a number of barriers that prevent full inclusion. Generative artificial intelligence (GenAI) has begun to attract interest for its potential to address longstanding barriers to access. However, little is known about the impact of these tools on the living and learning experiences of post-secondary students with disabilities. As a mixed-abilities team, we investigated student experiences with GenAI tools by collecting survey and interview responses from 62 and 21 students with disabilities, respectively, across two universities to measure students' use of GenAI tools and their perspectives on the impact of these tools in ways related to disability, university support, and sense of belonging. Despite concerns over potential risks of GenAI and unclear university policies, students described GenAI tools as a useful resource for personalizing learning, promoting self-care, and assisting with important self-advocacy work. Guidance demonstrating safe, acceptable uses of GenAI tools, along with clear policies and resources that acknowledge diverse student needs, were desired. We discuss implications of these tools for accessibility and inclusion in higher education." ;
    dcterms:identifier "3706598.3714121" ;
    chi:hasAuthor chi:person_185960, chi:person_187994, chi:person_185854, chi:person_188015, chi:person_182757 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:paperIncludesStudy chi:study_188687_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188687_UserStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility .

chi:study_188687_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188687 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188687_QualitativeResult ;
    chi:reportsResult chi:result_188687_StatisticalResult .

chi:study_188687_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188687 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188687_QualitativeResult ;
    chi:reportsResult chi:result_188687_StatisticalResult .

chi:result_188687_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188687_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188688 rdf:type chi:Paper ;
    dcterms:title "Investigating the Effects of Simulated Eye Contact in Video Call Interviews" ;
    dcterms:abstract "Some people suggest that deliberately watching the camera during video calls can simulate eye contact and help build trust. In this study, we investigated the effects of simulated eye contact in video calls and job interviews through an experimental study and a survey. Study 1 involved participants in a mock interview as an interviewer, where a confederate interviewee simulated eye contact half the time. The gaze patterns of the participants were tracked to understand the effects. In Study 2, we conducted an online survey to confirm the findings of Study 1 on a larger scale by asking those with experience interviewing to evaluate interviewees based on interview videos, half of which simulated eye contact. The results of both studies indicate that simulated eye contact had little impact on their evaluation compared to common belief. We discuss how the results motivate future work and how computational approaches to correcting eye gaze can be deceptive." ;
    dcterms:identifier "3706598.3713282" ;
    chi:hasAuthor chi:person_186251, chi:person_183423, chi:person_186080, chi:person_183425, chi:person_186065 ;
    chi:hasPrimaryTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:RemoteTeamCoordination ;
    chi:paperIncludesStudy chi:study_188688_UserStudy ;
    chi:paperIncludesStudy chi:study_188688_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188688_InterfaceArtifact .

chi:study_188688_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188688 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188688_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation ;
    chi:involvesParticipationPattern chi:AsynchronousParticipation .

chi:study_188688_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188688 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188688_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation ;
    chi:involvesParticipationPattern chi:AsynchronousParticipation .

chi:artifact_188688_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188688 .

chi:result_188688_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188689 rdf:type chi:Paper ;
    dcterms:title "Unpacking Trust Dynamics in the LLM Supply Chain: An Empirical Exploration to Foster Trustworthy LLM Production & Use" ;
    dcterms:abstract "Research on trust in AI is limited to several trustors (e.g., end-users) and trustees (especially AI systems), and empirical explorations remain in laboratory settings, overlooking factors that impact trust relations in the real world. Here, we broaden the scope of research by accounting for the supply chains that AI systems are part of. To this end, we present insights from an in-situ, empirical, study of LLM supply chains. We conducted interviews with 71 practitioners, and analyzed their (collaborative) practices using the lens of trust drawing from literature in organizational psychology. Our work reveals complex trust dynamics at the junctions of the chains, with interactions between diverse technical artifacts, individuals, or organizations. These junctions might constitute terrain for uncalibrated reliance when trustors lack supply chain knowledge or power dynamics are at play. Our findings bear implications for AI researchers and policymakers to promote AI governance that fosters calibrated trust." ;
    dcterms:identifier "3706598.3713787" ;
    chi:hasAuthor chi:person_186838, chi:person_188011, chi:person_187927, chi:person_183859, chi:person_184352 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:ParticipatoryEthicsMethods ;
    chi:paperIncludesStudy chi:study_188689_InterviewStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking .

chi:study_188689_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188689 ;
    chi:reportsResult chi:result_188689_QualitativeResult .

chi:result_188689_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188690 rdf:type chi:Paper ;
    dcterms:title "corobos: A Design for Mobile Robots Enabling Cooperative Transitions between Table and Wall Surfaces" ;
    dcterms:abstract "Swarm User Interfaces allow dynamic arrangement of user environments through the use of multiple mobile robots, but their operational range is typically confined to a single plane due to constraints imposed by their two-wheel propulsion systems. We present corobos, a proof-of-concept design that enables these robots to cooperatively transition between table (horizontal) and wall (vertical) surfaces seamlessly, without human intervention. Each robot is equipped with a uniquely designed slope structure that facilitates smooth rotation when another robot pushes it toward a target surface. Notably, this design relies solely on passive mechanical elements, eliminating the need for additional active electrical components. We investigated the design parameters of this structure and evaluated its transition success rate through experiments. Furthermore, we demonstrate various application examples to showcase the potential of corobos in enhancing user environments." ;
    dcterms:identifier "3706598.3713440" ;
    chi:hasAuthor chi:person_183580, chi:person_184445, chi:person_183597 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:paperIncludesStudy chi:study_188690_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188690_DeviceArtifact .

chi:study_188690_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188690 ;
    chi:hasMeasure chi:ErrorRateMeasure ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188690_StatisticalResult .

chi:artifact_188690_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188690 .

chi:result_188690_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188691 rdf:type chi:Paper ;
    dcterms:title "RemapVR: An Immersive Authoring Tool for Rapid Prototyping of Remapped Interaction in VR" ;
    dcterms:abstract "Remapping techniques in VR such as repositioning, redirection, and resizing have been extensively studied. Still, interaction designers rarely have the opportunity to use them due to high technical and knowledge barriers. In the paper, we extract common features of 24 existing remapping techniques and develop a high-fidelity immersive authoring tool, namely RemapVR, for rapidly building and experiencing prototypes of remapped space properties in VR that are unperceivable or acceptable to users. RemapVR provides designers with a series of functions for editing remappings and visualizing spatial property changes, mapping relationships between real and virtual worlds, sensory conflicts, etc. Designers can quickly build existing remappings via templates, and author new remappings by interactively recording spatial relations between input trajectory in real world and output trajectory in virtual world. User studies showed that the designs of RemapVR can effectively improve designers' authoring experience and efficiency, and support designers to author remapping prototypes that meet scene requirements and provide good user experience." ;
    dcterms:identifier "3706598.3714201" ;
    chi:hasAuthor chi:person_182715, chi:person_187029, chi:person_183454, chi:person_186431, chi:person_186348, chi:person_186469, chi:person_186328, chi:person_182754, chi:person_187589 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:paperIncludesStudy chi:study_188691_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188691_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188691_InterfaceArtifact .

chi:study_188691_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188691 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:reportsResult chi:result_188691_QualitativeResult ;
    chi:reportsResult chi:result_188691_StatisticalResult .

chi:artifact_188691_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188691 .

chi:artifact_188691_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188691 .

chi:result_188691_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188691_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188692 rdf:type chi:Paper ;
    dcterms:title "Crafting the Curve: Automating Plaster Mold Design for Ceramic Slip Casting with Shape Cast" ;
    dcterms:abstract "Shape Cast is our novel software tool designed to simplify the creation of plaster molds for ceramic slip casting by automating the 3D modeling process. Instead of needing to model molds, Shape Cast allows artists to input a single 2D profile of the desired pot. Shape Cast uses that to generate ready-to-print 3D molds for plaster, accommodating factors such as clay shrinkage and mold structural requirements. We detail the mold generation process and associated software implementation. We provide case studies demonstrating the capabilities of Shape Cast. We opened a beta version of Shape Cast to the public and 501 users have signed up creating a total of 626 fully finalized 3D models. We detail feedback from questionnaire responses of 17 users." ;
    dcterms:identifier "3706598.3713866" ;
    chi:hasAuthor chi:person_186919 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:paperIncludesStudy chi:study_188692_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188692_SoftwareArtifact .

chi:study_188692_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188692 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188692_QualitativeResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation ;
    chi:involvesParticipationPattern chi:AsynchronousParticipation .

chi:artifact_188692_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188692 .

chi:result_188692_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188693 rdf:type chi:Paper ;
    dcterms:title "\"It Might be Technically Impressive, But It’s Practically Useless to us\":  Motivations, Practices, Challenges, and Opportunities for Cross-Functional Collaboration around AI within the News Industry" ;
    dcterms:abstract "Recently, an increasing number of news organizations have integrated artificial intelligence (AI) into their workflows, leading to a further influx of AI technologists and data workers into the news industry. This has initiated cross-functional collaborations between these professionals and journalists. Although prior research has explored the impact of AI-related roles entering the news industry, there is a lack of studies on how internal cross-functional collaboration around AI unfolds between AI professionals and journalists within the news industry. Through interviews with 17 journalists, six AI technologists, and three AI workers with cross-functional experience from leading Chinese news organizations, we investigate the practices, challenges, and opportunities for internal cross-functional collaboration around AI in news industry. We first study how these journalists and AI professionals perceive existing internal cross-collaboration strategies. We explore the challenges of cross-functional collaboration and provide recommendations for enhancing future cross-functional collaboration around AI in the news industry." ;
    dcterms:identifier "3706598.3714090" ;
    chi:hasAuthor chi:person_184480, chi:person_184078, chi:person_183748, chi:person_186505, chi:person_184959 ;
    chi:hasPrimaryTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:CollaborationAndHybridWork ;
    chi:paperIncludesStudy chi:study_188693_InterviewStudy ;
    chi:aimsAtGoal chi:SupportCollaboration .

chi:study_188693_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188693 ;
    chi:reportsResult chi:result_188693_QualitativeResult .

chi:result_188693_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188694 rdf:type chi:Paper ;
    dcterms:title "T2 Coach: A Qualitative Study of an Automated Health Coach for Diabetes Self-Management" ;
    dcterms:abstract "Computational intelligence is increasingly common in interactive systems in many domains, including health. Health coaching with conversational agents (CA) can reach wide populations, but the level of computational intelligence needed for a positive coaching experience is unclear. We conducted a study with sixteen individuals with diabetes and prediabetes who used a CA for health coaching, T2 Coach. Qualitative interviews revealed that participants saw T2 Coach as reliable in helping them stay on track with self-management, appreciated the flexibility in choosing personally meaningful goals and engaging on their own terms, and felt it provided encouragement and even compared it favorably with human coaches. However, they also noted that coaching experience could be improved with more fluid conversations, more tailoring to their personal preferences and lifestyles, and more sensitivity to specific contexts, all of which require more computational intelligence. We discuss implications and design directions for more intelligent coaching CA in health." ;
    dcterms:identifier "3706598.3714404" ;
    chi:hasAuthor chi:person_183694, chi:person_184235, chi:person_184177, chi:person_185604, chi:person_185638, chi:person_183368, chi:person_183135, chi:person_185720 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188694_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188694_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188694_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188694_InterfaceArtifact .

chi:study_188694_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188694 ;
    chi:reportsResult chi:result_188694_QualitativeResult .

chi:study_188694_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188694 ;
    chi:reportsResult chi:result_188694_QualitativeResult .

chi:artifact_188694_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188694 .

chi:artifact_188694_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188694 .

chi:result_188694_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188695 rdf:type chi:Paper ;
    dcterms:title "Selective Trust: Understanding Human-AI Partnerships in Personal Health Decision-Making Process" ;
    dcterms:abstract "As artificial intelligence (AI) becomes more embedded in personal health technology, its potential to transform health decision-making through personalised recommendations is becoming significant. However, there is limited understanding of how individuals perceive AI-assisted decision-making in the context of personal health. This study investigates the impact of AI-assisted decision-making on trust in physical activity-related health decisions. By employing MoveAI, a GPT-4.0-based physical activity decision-making tool, we conducted a mixed-methods study and conducted an online survey (N=184) and semi-structured interviews (N=24) to explore this dynamic. Our findings emphasise the role of nuanced personal health recommendations and individual decision-making styles in shaping trust in AI-assisted personal health decision-making. This paper contributes to the HCI literature by elucidating the relationship between decision-making styles and trust in the AI-assisted personal health decision-making process and showing the challenges of aligning AI recommendations with individual decision-making preferences." ;
    dcterms:identifier "3706598.3713462" ;
    chi:hasAuthor chi:person_185478, chi:person_186199, chi:person_186139, chi:person_184670 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188695_UserStudy ;
    chi:paperIncludesStudy chi:study_188695_InterviewStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188695_SoftwareArtifact .

chi:study_188695_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188695 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188695_QualitativeResult ;
    chi:reportsResult chi:result_188695_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:study_188695_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188695 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188695_QualitativeResult ;
    chi:reportsResult chi:result_188695_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:artifact_188695_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188695 .

chi:result_188695_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188695_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188696 rdf:type chi:Paper ;
    dcterms:title "Everything to Gain: Combining Area Cursors with increased Control-Display Gain for Fast and Accurate Touchless Input" ;
    dcterms:abstract "Touchless displays often use mid-air gestures to control on-screen cursors for pointer interactions. Area cursors can simplify touchless cursor input by implicitly targeting nearby widgets without the cursor entering the target. However, for displays with dense target layouts, the cursor still has to arrive close to the widget, meaning the benefits of area cursors for time-to-target and effort are diminished. Through two experiments, we demonstrate for the first time that fine-tuning the mapping between hand and cursor movements (control-display gain -- CDG) can address the deficiencies of area cursors and improve the performance of touchless interaction. Across several display sizes and target densities (representative of myriad public displays used in retail, transport, museums, etc), our findings show that the forgiving nature of an area cursor compensates for the imprecision of a high CDG, helping users interact more effectively with smaller and more controlled hand/arm movements." ;
    dcterms:identifier "3706598.3714021" ;
    chi:hasAuthor chi:person_188058, chi:person_185850, chi:person_185075 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:PointingAndSelectionPerformance ;
    chi:paperIncludesStudy chi:study_188696_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188696_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188696_InputDeviceArtifact .

chi:study_188696_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188696 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:ErrorRateMeasure ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188696_StatisticalResult .

chi:artifact_188696_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188696 .

chi:artifact_188696_InputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188696 .

chi:result_188696_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188697 rdf:type chi:Paper ;
    dcterms:title "Placebo Effect of Control Settings in Feeds Are Not Always Strong" ;
    dcterms:abstract "Recent work has catalogued a variety of ``dark'' design patterns, including deception, that undermine user intent.  We focus on deceptive ``placebo'' control settings for social media that do not work.  While prior work reported that placebo controls increase feed satisfaction, we add to this body of knowledge by addressing possible placebo mechanisms, and potential side effects and confounds from the original study.  Knowledge of these placebo mechanisms can help predict potential harms to users and prioritize the most problematic cases for regulators to pursue.  In an online experiment, participants (N=762) browsed a Twitter feed with no control setting, a working control setting, or a placebo control setting.  We found a placebo effect much smaller in magnitude than originally reported.  This finding adds another objection to use of placebo controls in social media settings, while our methodology offers insights into finding confounds in placebo experiments in HCI." ;
    dcterms:identifier "3706598.3714197" ;
    chi:hasAuthor chi:person_183654, chi:person_183506, chi:person_185806, chi:person_186672, chi:person_182757 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialPersonalizationAndFeeds ;
    chi:paperIncludesStudy chi:study_188697_UserStudy ;
    chi:paperIncludesStudy chi:study_188697_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188697_InterfaceArtifact .

chi:study_188697_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188697 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188697_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:study_188697_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188697 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188697_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:artifact_188697_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188697 .

chi:result_188697_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188698 rdf:type chi:Paper ;
    dcterms:title "Emotion-aware Design in Automobiles: Embracing Technology Advancements to Enhance Human-vehicle Interaction" ;
    dcterms:abstract "The integration of emotion-aware systems in vehicles is accelerated by new technologies, including advancements in AI and ubiquitous sensing technologies. As the automotive industry shifts from technology-centred, feature-driven approaches to human-centred design, this research focuses on how to effectively incorporate emotion features into user-centred design to enhance effective human-vehicle interaction in practices. By conducting an interview study with 31 industrial design practitioners, supplemented by insights from engineers and AI experts involved in the early-stage design and development of novel in-vehicle user interfaces and systems, we examined current practices, and sampled their challenges, attitudes and expectations related to emotion-aware systems. Our findings provide critical insights to the design space of emotion-aware systems from both user and AI perspectives, inform efforts to support design practices in this evolving area, and identify opportunities for future innovation in emotion-aware in-vehicle design. Based on our findings, we propose adaptations to design practices and recommendations for further research." ;
    dcterms:identifier "3706598.3713571" ;
    chi:hasAuthor chi:person_183244, chi:person_182927, chi:person_186295, chi:person_183446, chi:person_187731, chi:person_183670, chi:person_184110 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:paperIncludesStudy chi:study_188698_InterviewStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188698_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188698_SoftwareArtifact .

chi:study_188698_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188698 ;
    chi:reportsResult chi:result_188698_QualitativeResult .

chi:artifact_188698_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188698 .

chi:artifact_188698_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188698 .

chi:result_188698_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188699 rdf:type chi:Paper ;
    dcterms:title "The Dual Model for Everyday Stress Technology: Understanding the Lived Experience of Data-Driven Stress" ;
    dcterms:abstract "Technology plays a dual role in our daily lives, both contributing to heightened stress levels and offering potential solutions for stress management. However, the lived experience of stress in everyday contexts remains underexplored, leaving a critical gap in our understanding of how stress manifests and how technology can effectively support stress management. To address this, we conducted user interviews and expert interviews with specialists in psychology, health, and stress research, complemented by an autoethnographic study. Our findings show the complexity of stress as both a subjective experience and a response shaped by socio-technical environments, leading to the construction of the Dual Model for Everyday Stress Technology. This model highlights the paradoxical nature of stress and its management in technology-mediated settings. We identify key directions for future stress-management technology design and research, with implications for creating meaningful, human-centred technologies for managing stress in everyday life." ;
    dcterms:identifier "3706598.3713174" ;
    chi:hasAuthor chi:person_184360, chi:person_185979, chi:person_186761, chi:person_187730, chi:person_186702 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:SelfReflectionAndBehaviorChange ;
    chi:paperIncludesStudy chi:study_188699_InterviewStudy ;
    chi:aimsAtGoal chi:ReduceCognitiveLoad .

chi:study_188699_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188699 ;
    chi:reportsResult chi:result_188699_QualitativeResult .

chi:result_188699_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188700 rdf:type chi:Paper ;
    dcterms:title "Seeking Inspiration through Human-LLM Interaction" ;
    dcterms:abstract "Large language model (LLM) systems have been shown to stimulate creative thinking among creators, yet empirical research on whether users can seek inspiration in their everyday lives through these technologies is lacking. This paper explores which attributes of LLMs influence inspiration-seeking processes. Focusing on use cases of travel, cooking, and self-care, we interviewed 20 participants as they explored scenarios of these use cases using LLMs. Thematic analysis revealed that the vast data of LLMs inspires users with unexpected ideas, many of which were highly personalized, and inspired participants towards being motivated to act. Participants were also sensitive to the deficiencies of LLMs, and noted how ethical issues associated with these technologies could negatively impact them applying inspirational ideas into practice. We discuss the behavioral patterns of users actively seeking inspiration via LLMs, and provide design opportunities for LLMs that make the inspiration-seeking process more human-centric." ;
    dcterms:identifier "3706598.3713259" ;
    chi:hasAuthor chi:person_182851, chi:person_187332, chi:person_187597, chi:person_183498, chi:person_184457 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:SelfReflectionAndBehaviorChange ;
    chi:paperIncludesStudy chi:study_188700_InterviewStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188700_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188700_InterfaceArtifact .

chi:study_188700_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188700 ;
    chi:reportsResult chi:result_188700_QualitativeResult .

chi:artifact_188700_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188700 .

chi:artifact_188700_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188700 .

chi:result_188700_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188701 rdf:type chi:Paper ;
    dcterms:title "Investigating How Computer Science Researchers Design Their Co-Writing Experiences With AI" ;
    dcterms:abstract "Recent advancements in AI have significantly enhanced collaboration between humans and writing assistants. However, empirical evidence is still lacking on how this collaboration unfolds in scientific writing, especially considering the variety of tools researchers can use nowadays. We conducted observations and retrospective interviews to investigate how 19 computer science researchers collaborated with intelligent writing assistants while working on their ongoing projects. We adopted a design-in-use lens to analyze the collected data, exploring how researchers adapt writing assistants during their use to overcome challenges and meet their specific needs and preferences. Our findings identify issues such as workflow disruptions and over-reliance on AI, and reveal five distinct design-in-use styles---teaching, resisting, repurposing, orchestrating, and complying---each consisting of different practices used by researchers. This study contributes to understanding the evolving landscape of human-AI co-writing in scientific research and offers insights for designing more effective writing assistants. " ;
    dcterms:identifier "3706598.3713205" ;
    chi:hasAuthor chi:person_182789, chi:person_184560, chi:person_186648, chi:person_183398 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:ChatbotAssistedUserStudies ;
    chi:paperIncludesStudy chi:study_188701_InterviewStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188701_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188701_InterfaceArtifact .

chi:study_188701_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188701 ;
    chi:reportsResult chi:result_188701_QualitativeResult .

chi:artifact_188701_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188701 .

chi:artifact_188701_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188701 .

chi:result_188701_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188702 rdf:type chi:Paper ;
    dcterms:title "SafeSpect: Safety-First  Augmented Reality Heads-up Display for Drone Inspections" ;
    dcterms:abstract "Current tablet-based interfaces for drone operations often impose a heavy cognitive load on pilots and reduce situational awareness by dividing attention between the video feed and the real world. To address these challenges, we designed a heads-up augmented reality (AR) interface that overlays in-situ information to support drone pilots in safety-critical tasks. Through participatory design workshops with professional pilots, we identified key features and developed an adaptive AR interface that dynamically switches between task and safety views to prevent information overload. We evaluated our prototype by creating a realistic building inspection task and comparing three interfaces: a 2D tablet, a static AR, and our adaptive AR design. A user study with 15 participants showed that the AR interface improved access to safety information, while the adaptive AR interface reduced cognitive load and enhanced situational awareness without compromising task performance. We offer design insights for developing safety-first heads-up AR interfaces." ;
    dcterms:identifier "3706598.3714283" ;
    chi:hasAuthor chi:person_188047, chi:person_186335, chi:person_185014, chi:person_185492 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:paperIncludesStudy chi:study_188702_UserStudy ;
    chi:paperIncludesStudy chi:study_188702_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:ReduceCognitiveLoad ;
    chi:proposesArtifact chi:artifact_188702_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188702_SoftwareArtifact .

chi:study_188702_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188702 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188702_QualitativeResult ;
    chi:reportsResult chi:result_188702_StatisticalResult .

chi:study_188702_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188702 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188702_QualitativeResult ;
    chi:reportsResult chi:result_188702_StatisticalResult .

chi:artifact_188702_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188702 .

chi:artifact_188702_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188702 .

chi:result_188702_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188702_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188703 rdf:type chi:Paper ;
    dcterms:title "A Qualitative Study of Adoption Barriers and Challenges for Passwordless Authentication in German Public Administrations" ;
    dcterms:abstract "Public administrations provide critical services and manage sensitive data for a country's citizens. Recent phishing campaigns targeting public sector employees highlight their attractiveness as targets. Deploying state-of-the-art authentication technologies, such as FIDO2, can improve overall security. We conducted a mixed-methods study in Germany to understand better the practices and challenges of deploying passwordless authentication in the public sector. First, we conducted an online survey (N=108) among German public sector employees to gain insights into their experiences and challenges. Next, we partnered with an e-government vendor and performed an in-situ experiment. We let 11 employees from the public sector experience FIDO2 under real-world conditions. Our results show that only a minority of our participants were aware of current passwordless authentication procedures. In our experiment, FIDO2-based methods left an overall positive impression. Hierarchical and heterogeneous public sector structures and the need for more technical expertise and equipment were barriers to adoption." ;
    dcterms:identifier "3706598.3713252" ;
    chi:hasAuthor chi:person_184639, chi:person_185894, chi:person_184496, chi:person_183671 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:DataDisclosureAndConsent ;
    chi:paperIncludesStudy chi:study_188703_UserStudy ;
    chi:paperIncludesStudy chi:study_188703_FieldStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188703_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188703_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188703_InputDeviceArtifact .

chi:study_188703_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188703 ;
    chi:reportsResult chi:result_188703_QualitativeResult .

chi:study_188703_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188703 ;
    chi:reportsResult chi:result_188703_QualitativeResult .

chi:artifact_188703_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188703 .

chi:artifact_188703_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188703 .

chi:artifact_188703_InputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188703 .

chi:result_188703_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188704 rdf:type chi:Paper ;
    dcterms:title "DataSentry: Building Missing Data Management System for In-the-Wild Mobile Sensor Data Collection through Multi-Year Iterative Design Approach" ;
    dcterms:abstract "Mobile sensor data collection in people’s daily lives is essential for understanding fine-grained human behaviors. However, in-the-wild data collection often results in missing data due to participant and system-related issues. While existing monitoring systems in the mobile sensing field provide an opportunity to detect missing data, they fall short in monitoring data across many participants and sensors and diagnosing the root causes of missing data, accounting for heterogeneous sensing characteristics of mobile sensor data. To address these limitations, we undertook a multi-year iterative design process to develop a system for monitoring missing data in mobile sensor data collection. Our final prototype, DataSentry, enables the detection, diagnosis, and addressing of missing data issues across many participants and sensors, considering both within- and between-person variability. Based on the iterative design process, we share our experiences, lessons learned, and design implications for developing advanced missing data management systems." ;
    dcterms:identifier "3706598.3713314" ;
    chi:hasAuthor chi:person_183863, chi:person_186506, chi:person_183596, chi:person_187691, chi:person_183792, chi:person_185610 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:paperIncludesStudy chi:study_188704_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188704_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188704_InterfaceArtifact .

chi:study_188704_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188704 ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188704_QualitativeResult .

chi:artifact_188704_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188704 .

chi:artifact_188704_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188704 .

chi:result_188704_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188705 rdf:type chi:Paper ;
    dcterms:title "Sustainability, Development, and Human–Computer Interaction" ;
    dcterms:abstract "Researchers in Human-Computer Interaction (HCI) have studied the design and use of technologies for sustainability and development, contributing to the subfields of Sustainable HCI and HCI for Development. Increasingly, there have been calls within and outside HCI for a more integrated approach to sustainable development. To identify the potential of such an approach, we present a comprehensive review of HCI scholarship on sustainability and development, combined with an analysis of interviews with researchers working in and across both subfields. Using the lens of political economy, we uncover understandings, critiques, tensions, and considerations toward advancing scholarship at the intersections of sustainability, development, and HCI. We conclude by inviting the larger Special Interest Group on Computer-Human Interaction (SIGCHI)  community to join us in collectively devising pathways for technology-mediated sustainable development." ;
    dcterms:identifier "3706598.3713663" ;
    chi:hasAuthor chi:person_184773, chi:person_186633 ;
    chi:paperIncludesStudy chi:study_188705_InterviewStudy .

chi:study_188705_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188705 ;
    chi:reportsResult chi:result_188705_QualitativeResult .

chi:result_188705_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188706 rdf:type chi:Paper ;
    dcterms:title "A Comparative Analysis of Information Gathering by Chatbots, Questionnaires, and Humans in Clinical Pre-Consultation" ;
    dcterms:abstract "Information gathering is an important capability that allows chatbots to understand and respond to users' needs, yet the effectiveness of LLM-powered chatbots at this task remains underexplored. Our work investigates this question in the context of clinical pre-consultation, wherein patients provide information to an intermediary before meeting with a physician to facilitate communication and reduce consultation inefficiencies. We conducted a study at a walk-in clinic with 45 patients who interacted with one of three conversational agents: a chatbot, a questionnaire, and a Wizard-of-Oz. We analyzed patients' messages using metrics adapted from Grice's maxims to assess the quality of information gathered at each conversation turn. We found that the Wizard and LLM were more successful than the questionnaire because they modified questions and asked follow-ups when participants provided unsatisfactory answers. However, the LLM did not ask nearly as many follow-up questions as the Wizard, particularly when participants provided unclear answers. " ;
    dcterms:identifier "3706598.3713613" ;
    chi:hasAuthor chi:person_183530, chi:person_186678, chi:person_183201, chi:person_186210 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:ChatbotAssistedUserStudies ;
    chi:paperIncludesStudy chi:study_188706_FieldStudy ;
    chi:paperIncludesStudy chi:study_188706_WizardOfOzStudy ;
    chi:paperIncludesStudy chi:study_188706_UserStudy ;
    chi:paperIncludesStudy chi:study_188706_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188706_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188706_InterfaceArtifact .

chi:study_188706_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188706 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188706_QualitativeResult ;
    chi:reportsResult chi:result_188706_StatisticalResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:study_188706_WizardOfOzStudy rdf:type chi:WizardOfOzStudy ;
    chi:isStudyReportedIn chi:paper_188706 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188706_QualitativeResult ;
    chi:reportsResult chi:result_188706_StatisticalResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:study_188706_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188706 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188706_QualitativeResult ;
    chi:reportsResult chi:result_188706_StatisticalResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:study_188706_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188706 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188706_QualitativeResult ;
    chi:reportsResult chi:result_188706_StatisticalResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:artifact_188706_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188706 .

chi:artifact_188706_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188706 .

chi:result_188706_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188706_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188707 rdf:type chi:Paper ;
    dcterms:title "Actual Achieved Gain and Optimal Perceived Gain: Modeling Human Take-over Decisions Towards Automated Vehicles' Suggestions" ;
    dcterms:abstract "Driver decision quality in take-overs is critical for effective human-Autonomous Driving System (ADS) collaboration. However, current research lacks detailed analysis of its variations. This paper introduces two metrics--Actual Achieved Gain (AAG) and Optimal Perceived Gain (OPG)--to assess decision quality, with OPG representing optimal decisions and AAG reflecting actual outcomes. Both are calculated as weighted averages of perceived gains and losses, influenced by ADS accuracy. Study 1 (N=315) used a 21-point Thurstone scale to measure perceived gains and losses—key components of AAG and OPG—across typical tasks: route selection, overtaking, and collision avoidance. Studies 2 (N=54) and 3 (N=54) modeled decision quality under varying ADS accuracy and decision time. Results show with sufficient time (>3.5s), AAG converges towards OPG, indicating rational decision-making, while limited time leads to intuitive and deterministic choices. Study 3 also linked AAG-OPG deviations to irrational behaviors. An intervention study (N=8) and a pilot (N=4) employing voice alarms and multi-modal alarms based on these deviations demonstrated AAG's potential to improve decision quality." ;
    dcterms:identifier "3706598.3713707" ;
    chi:hasAuthor chi:person_186482, chi:person_184435, chi:person_185736, chi:person_187045, chi:person_187380, chi:person_186547, chi:person_183140, chi:person_185530, chi:person_183231, chi:person_185547 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:ErrorRatesAndTaskCompletion ;
    chi:paperIncludesStudy chi:study_188707_UserStudy ;
    chi:paperIncludesStudy chi:study_188707_QuantitativeStudy ;
    chi:paperIncludesStudy chi:study_188707_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188707_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188707_InterfaceArtifact .

chi:study_188707_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188707 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188707_StatisticalResult .

chi:study_188707_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188707 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188707_StatisticalResult .

chi:study_188707_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188707 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188707_StatisticalResult .

chi:artifact_188707_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188707 .

chi:artifact_188707_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188707 .

chi:result_188707_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188708 rdf:type chi:Paper ;
    dcterms:title "A Stakeholder Value Framework for Augmentative and Alternative Communication" ;
    dcterms:abstract "End-users of augmentative and alternative communication (AAC) have diverse speech, cognitive, and motor abilities. AAC's heterogeneous user groups and persistent usability issues create a challenging and rich design space. Our work takes a value-sensitive design (VSD) approach to develop a stakeholder value framework that describes stakeholders' multi-dimensional roles and values. Our framework is based on (1) an empirical investigation---a survey and interviews---of AAC users and AAC conversation partners and (2) a conceptual investigation---a systematic literature review---of AAC HCI research. Emergent value themes were ease, fulfillment, acceptance, adaptation, safety, performance, autonomy, justice, design fulfillment, and business fulfillment. These themes inform how AAC end-users engage with AAC and how indirect stakeholders, such as AAC technologists, make choices that ultimately impact AAC users. Our stakeholder value framework and rich descriptions of AAC socio-technical barriers can inform AAC designers in making ethically sound decisions that support, not hinder, stakeholder values." ;
    dcterms:identifier "3706598.3713584" ;
    chi:hasAuthor chi:person_184979, chi:person_184182, chi:person_185676, chi:person_184043 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:AccessibilityNavigationSupport ;
    chi:paperIncludesStudy chi:study_188708_InterviewStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility .

chi:study_188708_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188708 ;
    chi:reportsResult chi:result_188708_QualitativeResult .

chi:result_188708_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188710 rdf:type chi:Paper ;
    dcterms:title "Designing Biofeedback Board Games: The Impact of Heart Rate on Player Experience" ;
    dcterms:abstract "Biofeedback provides a unique opportunity to intensify tabletop gameplay. It permits new play styles through digital integration while keeping the tactile appeal of physical components. However, integrating biofeedback systems, like heart rate (HR), into game design needs to be better understood in the literature and still needs to be explored in practice. To bridge this gap, we employed a Research through Design (RtD) approach. This included (1) gathering insights from enthusiast board game designers (𝑛 = 10), (2) conducting two participatory design workshops (𝑛 = 20), (3) prototyping game mechanics with experts (𝑛 = 5), and (4) developing the game prototype artifact One Pulse: Treasure Hunter’s.We identify practical design implementation for incorporating biofeedback, particularly related to heart rate, into tabletop games. Thus, we contribute to the field by presenting design trade-offs for incorporating HR into board games, offering valuable insights for HCI researchers and game designers." ;
    dcterms:identifier "3706598.3713543" ;
    chi:hasAuthor chi:person_182948, chi:person_184035, chi:person_184019, chi:person_185309, chi:person_186893 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:paperIncludesStudy chi:study_188710_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188710_DeviceArtifact .

chi:study_188710_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188710 ;
    chi:hasMeasure chi:HeartRateMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188710_QualitativeResult .

chi:artifact_188710_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188710 .

chi:result_188710_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188711 rdf:type chi:Paper ;
    dcterms:title "RidgeBuilder: Interactive Authoring of Expressive Ridgeline Plots" ;
    dcterms:abstract "Ridgeline plots are frequently employed to visualize the evolution or distributions of multiple series with a pile of overlapping line, area, or bar charts, highlighting the peak patterns. While traditionally viewed as small multiple visualizations, their ridge-like patterns have increasingly attracted graphic designers to create appealing customized ridgeline plots. However, many tools only support creating basic ridgeline plots and overlook their diverse layouts and styles. This paper introduces a comprehensive design space for ridgeline plots, focusing on their varied layouts and expressive styles. We present RidgeBuilder, an intuitive tool for creating expressive ridgeline plots with customizable layouts and styles. In particular, we summarize three goals for refining the layout of ridgeline plots and propose an optimization method. We assess RidgeBuilder's usability and usefulness through a reproduction study and evaluate the layout optimization algorithm through anonymized questionnaires. The effectiveness is demonstrated with a gallery of ridgeline plots created by RidgeBuilder." ;
    dcterms:identifier "3706598.3714209" ;
    chi:hasAuthor chi:person_185344, chi:person_184028, chi:person_184116, chi:person_185405, chi:person_185077, chi:person_183554, chi:person_185458, chi:person_187341 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:CollaborativeVisualizationTools ;
    chi:paperIncludesStudy chi:study_188711_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188711_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188711_InterfaceArtifact .

chi:study_188711_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188711 ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188711_QualitativeResult ;
    chi:reportsResult chi:result_188711_StatisticalResult .

chi:artifact_188711_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188711 .

chi:artifact_188711_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188711 .

chi:result_188711_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188711_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188712 rdf:type chi:Paper ;
    dcterms:title "The Centers and Margins of Modeling Humans in Well-being Technologies" ;
    dcterms:abstract "This paper critically examines the machine learning (ML) modeling of humans in three case studies of well-being technologies. Through a critical technical approach, it examines how these apps were experienced in daily life (technology in use) to surface breakdowns and to identify the assumptions about the “human” body entrenched in the ML models (technology design). To address these issues, this paper applies agential realism to decenter foundational assumptions, such as body regularity and health/illness binaries, and speculates more inclusive design and ML modeling paths that acknowledge irregularity, human-system entanglements, and uncertain transitions. This work is among the first to explore the implications of decentering theories in computational modeling of human bodies and well-being, offering insights for more inclusive technologies and speculations toward posthuman-centered ML modeling." ;
    dcterms:identifier "3706598.3713940" ;
    chi:hasAuthor chi:person_183680, chi:person_184285, chi:person_187860, chi:person_187039, chi:person_187252 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:DataDisclosureAndConsent ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188712_SoftwareArtifact .

chi:artifact_188712_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188712 .

chi:result_188712_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188713 rdf:type chi:Paper ;
    dcterms:title "Expression-in-action and Expression-on-action: A Systematic Review of Mediums for Expression in Mental Health" ;
    dcterms:abstract "Expression facilitates the externalization of personal experiences and inner states (e.g., thoughts and emotions) embedded in everyday life. Yet, in mental health contexts, expression is often marginalized or systematically and structurally excluded from technology and system design. While HCI scholarship has explored expression in specific settings to advance user experience, a comprehensive understanding of expression remains limited. This limitation constrains the design space for future technologies that support and embrace expression, resulting in a potential lack of authentic experiential data reflecting individuals’ lived experiences embedded in everyday management of mental health. Through a systematic review of $n = 105$ studies, we explore the mediums, populations, and practices of expression in mental health contexts. Our study contributes a nuanced sociotechnical understanding of expression for the HCI community, developing two concepts for enriching expression and offering insights for designing experience-rich technologies that better support expression for everyday mental health management." ;
    dcterms:identifier "3706598.3713669" ;
    chi:hasAuthor chi:person_183352, chi:person_185775, chi:person_183196, chi:person_183292 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aimsAtGoal chi:IncreaseEngagement .

chi:result_188713_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188714 rdf:type chi:Paper ;
    dcterms:title "AACessTalk: Fostering Communication between Minimally Verbal Autistic Children and Parents with Contextual Guidance and Card Recommendation" ;
    dcterms:abstract "As minimally verbal autistic (MVA) children communicate with parents through few words and nonverbal cues, parents often struggle to encourage their children to express subtle emotions and needs and to grasp their nuanced signals. We present AACessTalk, a tablet-based, AI-mediated communication system that facilitates meaningful exchanges between an MVA child and a parent. AACessTalk provides real-time guides to the parent to engage the child in conversation and, in turn, recommends contextual vocabulary cards to the child. Through a two-week deployment study with 11 MVA child-parent dyads, we examine how AACessTalk fosters everyday conversation practice and mutual engagement. Our findings show high engagement from all dyads, leading to increased frequency of conversation and turn-taking. AACessTalk also encouraged parents to explore their own interaction strategies and empowered the children to have more agency in communication. We discuss the implications of designing technologies for balanced communication dynamics in parent-MVA child interaction." ;
    dcterms:identifier "3706598.3713792" ;
    chi:hasAuthor chi:person_184045, chi:person_186943, chi:person_185311, chi:person_183246, chi:person_185361 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188714_FieldStudy ;
    chi:paperIncludesStudy chi:study_188714_UserStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188714_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188714_InterfaceArtifact .

chi:study_188714_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188714 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188714_QualitativeResult .

chi:study_188714_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188714 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188714_QualitativeResult .

chi:artifact_188714_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188714 .

chi:artifact_188714_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188714 .

chi:result_188714_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188715 rdf:type chi:Paper ;
    dcterms:title "Incorporating Sustainability in Electronics Design: Obstacles and Opportunities" ;
    dcterms:abstract "Life cycle assessment (LCA) is a methodology for holistically measuring the environmental impact of a product from initial manufacturing to end-of-life disposal. However, the extent to which LCA informs the design of computing devices remains unclear. To understand how this information is collected and applied, we interviewed 17 industry professionals with experience in LCA or electronics design, systematically coded the interviews, and investigated common themes. These themes highlight the challenge of LCA data collection and reveal distributed decision-making processes where responsibility for sustainable design choices—and their associated costs—is often ambiguous. Our analysis identifies opportunities for HCI technologies to support LCA computation and its integration into the design process to facilitate sustainability-oriented decision-making. While this work provides a nuanced discussion about sustainable design in the information and communication technologies (ICT) hardware industry, we hope our insights will also be valuable to other sectors. " ;
    dcterms:identifier "3706598.3713299" ;
    chi:hasAuthor chi:person_185065, chi:person_185323, chi:person_183717, chi:person_184992, chi:person_186894, chi:person_183148, chi:person_188041, chi:person_183836, chi:person_185790 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:paperIncludesStudy chi:study_188715_InterviewStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking .

chi:study_188715_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188715 ;
    chi:reportsResult chi:result_188715_QualitativeResult .

chi:result_188715_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188716 rdf:type chi:Paper ;
    dcterms:title "\"Why do we do this?\": Moral Stress and the Affective Experience of Ethics in Practice" ;
    dcterms:abstract "A plethora of toolkits, checklists, and workshops have been developed to bridge the well-documented gap between AI ethics principles and practice. Yet little is known about effects of such interventions on practitioners. We conducted an ethnographic investigation in a major European city organization that developed and works to integrate an ethics toolkit into city operations. We find that the integration of ethics tools by technical teams destabilises their boundaries, roles, and mandates around responsibilities and decisions. This lead to emotional discomfort and feelings of vulnerability, which neither toolkit designers nor the organization had accounted for. We leverage the concept of moral stress to argue that this affective experience is a core challenge to the successful integration of ethics tools in technical practice. Even in this best case scenario, organisational structures were not able to deal with moral stress that resulted from attempts to implement responsible technology development practices." ;
    dcterms:identifier "3706598.3713264" ;
    chi:hasAuthor chi:person_184765, chi:person_184699, chi:person_185574, chi:person_188132 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:TargetedEthicsInterventions ;
    chi:paperIncludesStudy chi:study_188716_FieldStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188716_SoftwareArtifact .

chi:study_188716_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188716 ;
    chi:reportsResult chi:result_188716_QualitativeResult .

chi:artifact_188716_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188716 .

chi:result_188716_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188717 rdf:type chi:Paper ;
    dcterms:title "Data Bias Recognition in Museum Settings: Framework Development and Contributing Factors" ;
    dcterms:abstract "Critical thinking skills are increasingly important for comprehending our data-rich society. While museums provide data for discussion, visitors may not naturally question data in such displays due to the inherent authority of a museum. To investigate what factors can help visitors recognize bias in data, we interviewed visitors after they interacted with an augmented reality data map in an interactive data exhibition. Here, we present a qualitative analysis of fifteen semi-structured interviews with visitors who engaged with mapped data from the citizen science platform iNaturalist. The study revealed that 47% of participants were able to recognize bias, and familiarity was found to be a significant factor in this ability. We propose a three-layer framework to understand the cognitive processes of bias recognition in informal learning settings and apply this framework to our data to inform future work for designing displays to promote critical engagement with data in free-choice learning contexts. " ;
    dcterms:identifier "3706598.3714092" ;
    chi:hasAuthor chi:person_186406, chi:person_186464, chi:person_182992, chi:person_184197 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188717_InterviewStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188717_InterfaceArtifact .

chi:study_188717_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188717 ;
    chi:reportsResult chi:result_188717_QualitativeResult ;
    chi:reportsResult chi:result_188717_StatisticalResult .

chi:artifact_188717_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188717 .

chi:result_188717_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188717_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188718 rdf:type chi:Paper ;
    dcterms:title "Real-Time Adaptive Industrial Robots: Improving Safety And Comfort In Human-Robot Collaboration" ;
    dcterms:abstract "Industrial robots become increasingly prevalent, resulting in a growing need for intuitive, comforting human-robot collaboration. We present a user-aware robotic system that adapts to operator behavior in real time while non-intrusively monitoring physiological signals to create a more responsive and empathetic environment. Our prototype dynamically adjusts robot speed and movement patterns to proxemics while measuring operator pupil dilation. Our user study compares this adaptive system to a non-adaptive counterpart, and demonstrates that the adaptive system significantly reduces both perceived and physiologically measured cognitive load while enhancing usability. Participants reported increased feelings of comfort, safety, trust, and a stronger sense of collaboration when working with the adaptive robot. This highlights the potential of integrating real-time physiological data into human-robot interaction paradigms. This novel approach creates more intuitive and collaborative industrial environments where robots effectively ’read’ and respond to human cognitive states, and we feature all data and code for future use." ;
    dcterms:identifier "3706598.3713889" ;
    chi:hasAuthor chi:person_187662, chi:person_183778, chi:person_183267, chi:person_182955, chi:person_185795 ;
    chi:paperIncludesStudy chi:study_188718_UserStudy ;
    chi:paperIncludesStudy chi:study_188718_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:ReduceCognitiveLoad ;
    chi:proposesArtifact chi:artifact_188718_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188718_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188718_InterfaceArtifact .

chi:study_188718_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188718 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188718_StatisticalResult ;
    chi:reportsResult chi:result_188718_QualitativeResult .

chi:study_188718_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188718 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188718_StatisticalResult ;
    chi:reportsResult chi:result_188718_QualitativeResult .

chi:artifact_188718_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188718 .

chi:artifact_188718_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188718 .

chi:artifact_188718_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188718 .

chi:result_188718_StatisticalResult rdf:type chi:StatisticalResult .

chi:result_188718_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188719 rdf:type chi:Paper ;
    dcterms:title "ZuantuSet: A Collection of Historical Chinese Visualizations and Illustrations" ;
    dcterms:abstract "Historical visualizations are a valuable resource for studying the history of visualization and inspecting the cultural context where they were created. When investigating historical visualizations, it is essential to consider contributions from different cultural frameworks to gain a comprehensive understanding. While there is extensive research on historical visualizations within the European cultural framework, this work shifts the focus to ancient China, a cultural context that remains underexplored by visualization researchers. To this aim, we propose a semi-automatic pipeline to collect, extract, and label historical Chinese visualizations. Through the pipeline, we curate ZuantuSet, a dataset with over 71K visualizations and 108K illustrations. We analyze distinctive design patterns of historical Chinese visualizations and their potential causes within the context of Chinese history and culture. We illustrate potential usage scenarios for this dataset, summarize the unique challenges and solutions associated with collecting historical Chinese visualizations, and outline future research directions." ;
    dcterms:identifier "3706598.3713276" ;
    chi:hasAuthor chi:person_185509, chi:person_182820, chi:person_187024, chi:person_186701, chi:person_186525 ;
    chi:proposesArtifact chi:artifact_188719_SoftwareArtifact .

chi:artifact_188719_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188719 .

chi:result_188719_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188720 rdf:type chi:Paper ;
    dcterms:title "Generative AI as a Playful yet Offensive Tourist: Exploring Tensions Between Playful Features and Citizen Concerns in Designing Urban Play" ;
    dcterms:abstract "Play is pivotal in fostering the emotional, social, and cultural dimensions of urban spaces. While generative AI (GAI) potentially supports playful urban interaction, a balanced and critical approach to the design opportunities and challenges is needed. This work develops iWonder, an image-to-image GAI tool engaging fourteen designers in urban explorations to identify GAI's playful features and create design ideas. Fourteen citizens then evaluated these ideas, providing expectations and critical concerns from a bottom-up perspective. Our findings reveal the dynamic interplay between users, GAI, and urban contexts, highlighting GAI's potential to facilitate playful urban experiences through generative agency, meaningful unpredictability, social performativity, and the associated offensive qualities. We propose design considerations to address citizen concerns and the `tourist metaphor' to deepen our understanding of GAI's impacts, offering insights to enhance cities' socio-cultural fabric. Overall, this research contributes to the effort to harness GAI's capabilities for urban enrichment." ;
    dcterms:identifier "3706598.3713137" ;
    chi:hasAuthor chi:person_185828, chi:person_183640, chi:person_184236, chi:person_183429 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:paperIncludesStudy chi:study_188720_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188720_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188720_InterfaceArtifact .

chi:study_188720_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188720 ;
    chi:reportsResult chi:result_188720_QualitativeResult .

chi:artifact_188720_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188720 .

chi:artifact_188720_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188720 .

chi:result_188720_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188721 rdf:type chi:Paper ;
    dcterms:title "How Students in Creative Educations Appropriate Technology: A phenomenological analysis." ;
    dcterms:abstract "Building technological literacy is an important topic in education today while at the same time, creativity is seen as a desirable skill for professional practice and education alike as it is considered a catalyst for innovation. In this paper, we present a case study where we aim to understand how students in a creative education appropriate technology. We analyze qualitative data collected from students in a STEAM higher education undergraduate program called Art&Technology: a program where students are introduced to an assortment of technological tools including software, programming, digital fabrication and physical prototyping which they employ in creating a variety of artifacts. We analyze how students learn and interact with these technologies by analyzing the collected data through a phenomenological lens of technology appropriation. We contribute with understandings on how technology is appropriated as it transforms from an object to a tool until it finally becomes equipment." ;
    dcterms:identifier "3706598.3713667" ;
    chi:hasAuthor chi:person_185221, chi:person_185784 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:paperIncludesStudy chi:study_188721_QualitativeStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188721_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188721_DeviceArtifact .

chi:study_188721_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188721 ;
    chi:reportsResult chi:result_188721_QualitativeResult .

chi:artifact_188721_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188721 .

chi:artifact_188721_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188721 .

chi:result_188721_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188722 rdf:type chi:Paper ;
    dcterms:title "Can you pass that tool?: Implications of Indirect Speech in Physical Human-Robot Collaboration" ;
    dcterms:abstract "Indirect speech acts (ISAs) are a natural pragmatic feature of human communication, allowing requests to be conveyed implicitly while maintaining subtlety and flexibility. Although advancements in speech recognition have enabled natural language interactions with robots through direct, explicit commands—providing clarity in communication—the rise of large language models presents the potential for robots to interpret ISAs. However, empirical evidence on the effects of ISAs on human-robot collaboration (HRC) remains limited. To address this, we conducted a Wizard-of-Oz study (N=36), engaging a participant and a robot in collaborative physical tasks. Our findings indicate that robots capable of understanding ISAs significantly improve human's perceived robot anthropomorphism, team performance, and trust. However, the effectiveness of ISAs is task- and context-dependent, thus requiring careful use. These results highlight the importance of appropriately integrating direct and indirect requests in HRC to enhance collaborative experiences and task performance." ;
    dcterms:identifier "3706598.3713780" ;
    chi:hasAuthor chi:person_187526, chi:person_184266, chi:person_183768, chi:person_185830, chi:person_187323, chi:person_186537 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:paperIncludesStudy chi:study_188722_WizardOfOzStudy ;
    chi:paperIncludesStudy chi:study_188722_UserStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188722_DeviceArtifact .

chi:study_188722_WizardOfOzStudy rdf:type chi:WizardOfOzStudy ;
    chi:isStudyReportedIn chi:paper_188722 ;
    chi:hasMeasure chi:PerformanceMeasure ;
    chi:hasMeasure chi:SubjectiveMeasure ;
    chi:reportsResult chi:result_188722_StatisticalResult .

chi:study_188722_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188722 ;
    chi:hasMeasure chi:PerformanceMeasure ;
    chi:hasMeasure chi:SubjectiveMeasure ;
    chi:reportsResult chi:result_188722_StatisticalResult .

chi:artifact_188722_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188722 .

chi:result_188722_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188723 rdf:type chi:Paper ;
    dcterms:title "Designing Effective Consent Mechanisms for Spontaneous Interactions in Augmented Reality" ;
    dcterms:abstract "Ubiquitous computing devices like Augmented Reality (AR) glasses allow countless spontaneous interactions - all serving different goals. AR devices rely on data transfer to personalize recommendations and adapt to the user. Today's consent mechanisms, such as privacy policies, are suitable for long-lasting interactions; however, how users can consent to fast, spontaneous interactions is unclear. We first conducted two focus groups (N=17) to identify privacy-relevant scenarios in AR. We then conducted expert interviews (N=11) with co-design activities to establish effective consent mechanisms. Based on that, we contribute (1) a validated scenario taxonomy to define privacy-relevant AR interaction scenarios, (2) a flowchart to decide on the type of mechanisms considering contextual factors, (3) a design continuum and design aspects chart to create the mechanisms, and (4) a trade-off and prediction chart to evaluate the mechanism. Thus, we contribute a conceptual framework fostering a privacy-preserving future with AR." ;
    dcterms:identifier "3706598.3713519" ;
    chi:hasAuthor chi:person_187170, chi:person_186749, chi:person_186917 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:DataDisclosureAndConsent ;
    chi:paperIncludesStudy chi:study_188723_InterviewStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188723_DeviceArtifact .

chi:study_188723_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188723 ;
    chi:reportsResult chi:result_188723_QualitativeResult .

chi:artifact_188723_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188723 .

chi:result_188723_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188724 rdf:type chi:Paper ;
    dcterms:title "Moving Towards Epistemic Autonomy: A Paradigm Shift for Centering Participant Knowledge" ;
    dcterms:abstract "Justice, epistemology, and marginalization are rich areas of study in HCI. And yet, we repeatedly find platforms and algorithms that push communities further into the margins. In this paper, we propose epistemic autonomy--—one’s ability to govern knowledge about themselves---as a necessary HCI paradigm for working with marginalized communities. We establish epistemic autonomy by applying the transfeminine principle of autonomy to the problem of epistemic injustice. To articulate the harm of violating one’s epistemic autonomy, we present six stories from two trans women:  (1) a transfem online administrator and (2) a transfem researcher. We then synthesize our definition of epistemic autonomy in research into a research paradigm. Finally, we present two variants of common HCI methods, autoethnography and asynchronous remote communities, that stem from these beliefs. We discuss how CHI is uniquely situated to champion this paradigm and, thereby, the epistemic autonomy of our research participants." ;
    dcterms:identifier "3706598.3714252" ;
    chi:hasAuthor chi:person_187645, chi:person_187686, chi:person_183848 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:ParticipatoryEthicsMethods ;
    chi:paperIncludesStudy chi:study_188724_QualitativeStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility .

chi:study_188724_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188724 ;
    chi:reportsResult chi:result_188724_QualitativeResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation ;
    chi:involvesParticipationPattern chi:AsynchronousParticipation .

chi:result_188724_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188725 rdf:type chi:Paper ;
    dcterms:title "ProxiCycle : Passively Mapping Cyclist Safety Using Smart Handlebars for Near-Miss Detection" ;
    dcterms:abstract "Active transportation is a valuable tool to prevent some of the most common causes of mortality worldwide, but is severely underutilized. The primary factors preventing cyclist adoption are safety concerns, specifically, the fear of collision from automobiles. One solution to address this concern is to direct cyclists to known safe routes to minimize risk and stress, thus making cycling more approachable. However, few localized safety priors are available, hindering safety based routing. Specifically, road user behavior is unknown. To address this issue, we develop a novel handlebar attachment to passively monitor the proximity of passing cars as a an indicator of cycling safety along historically traveled routes. We deploy this sensor with 15 experienced cyclists in a 2 month longitudinal study to source a citywide map of car passing distance. We then compare this signal to both historic collisions and perceived safety reported by experienced and inexperienced cyclists." ;
    dcterms:identifier "3706598.3713325" ;
    chi:hasAuthor chi:person_182822, chi:person_187552, chi:person_182655, chi:person_188041 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:AccessibilityNavigationSupport ;
    chi:paperIncludesStudy chi:study_188725_FieldStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188725_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188725_InputDeviceArtifact .

chi:study_188725_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188725 ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188725_StatisticalResult .

chi:artifact_188725_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188725 .

chi:artifact_188725_InputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188725 .

chi:result_188725_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188726 rdf:type chi:Paper ;
    dcterms:title "From Solo to Social: Exploring the Dynamics of Player Cooperation in a Co-located Cooperative Exergame" ;
    dcterms:abstract "Digital games offer rich social experiences and promote valuable skills, but they fall short in addressing physical inactivity. Exergames, which combine exercise with gameplay, have the potential to tackle this issue. However, current exergames are primarily single-player or competitive. To explore the social benefits of cooperative exergaming, we designed a custom co-located cooperative exergame that features three distinct forms of cooperation: Free (baseline), Coupled, and Concurrent. We conducted a within-participants, mixed-methods study (N=24) to evaluate these designs and their impact on players' enjoyment, motivation, and performance. Our findings reveal that cooperative play improves social experiences. It drives increased team identification and relatedness. Furthermore, our qualitative findings support cooperative exergame play. This has design implications for creating exergames that effectively address players' exercise and social needs. Our research contributes guidance for developers and researchers who want to create more socially enriching exergame experiences." ;
    dcterms:identifier "3706598.3713937" ;
    chi:hasAuthor chi:person_185309, chi:person_187895, chi:person_184019, chi:person_186171, chi:person_184035, chi:person_182948, chi:person_186893 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:paperIncludesStudy chi:study_188726_UserStudy ;
    chi:paperIncludesStudy chi:study_188726_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188726_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188726_InterfaceArtifact .

chi:study_188726_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188726 ;
    chi:hasMeasure chi:PerformanceMeasure ;
    chi:hasMeasure chi:SubjectiveMeasure ;
    chi:reportsResult chi:result_188726_QualitativeResult ;
    chi:reportsResult chi:result_188726_StatisticalResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:study_188726_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188726 ;
    chi:hasMeasure chi:PerformanceMeasure ;
    chi:hasMeasure chi:SubjectiveMeasure ;
    chi:reportsResult chi:result_188726_QualitativeResult ;
    chi:reportsResult chi:result_188726_StatisticalResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:artifact_188726_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188726 .

chi:artifact_188726_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188726 .

chi:result_188726_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188726_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188727 rdf:type chi:Paper ;
    dcterms:title "Triangulating on Possible Futures: Conducting User Studies on Several Futures Instead of Only One" ;
    dcterms:abstract "Plausible findings about futures are inherently difficult to obtain as they require critical, well-informed speculations backed with data. HCI scholars tackle this challenge via user studies wherein futuristic prototypes and other props concretise possible futures for participants. By observing participants' actions, researchers then can 'time travel' to see that future as reality, in action. However, such studies may yield particularised findings, inherent to study’s intricacies, and lack broader plausibility. This paper suggests that triangulation of possible futures may help researchers disentangle particularities from more generalisable findings. We explored this approach by conducting a study on two alternative futures of AI-augmented knowledge work. Some findings emerged in both futures while others were particular to only one or the other. This approach enabled cross-checking of plausibility and simultaneously afforded deeper insight. The paper discusses how triangulating possible futures renders HCI studies more future-proof and provides means for reflective anticipation of possible futures." ;
    dcterms:identifier "3706598.3713565" ;
    chi:hasAuthor chi:person_185191, chi:person_184875 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:paperIncludesStudy chi:study_188727_UserStudy ;
    chi:proposesArtifact chi:artifact_188727_InterfaceArtifact .

chi:study_188727_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188727 ;
    chi:reportsResult chi:result_188727_QualitativeResult .

chi:artifact_188727_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188727 .

chi:result_188727_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188728 rdf:type chi:Paper ;
    dcterms:title "Relatedness Technologies: An Online Compendium and Systematic Review" ;
    dcterms:abstract "Over the past decades, numerous concepts and prototypes for fostering emotional connections across distance (relatedness technologies) have been proposed. This has made it challenging for researchers and designers in Human-Computer Interaction (HCI) to maintain a comprehensive overview and effectively build on previous work. To address this, we conducted a systematic literature search (PRISMA) and collected 241 concepts and prototypes (2010-2024). We organized this corpus according to key aspects: (1) target population, (2) theoretical grounding, (3) design, (4) evaluation, and (5) ethics. Based on this, we developed the “COmpendium of RElatedness Technologies” (CORE), an open-access, searchable online database that provides researchers and practitioners with a reliable repository to inform future work. In addition, we present a systematic review of the corpus, revealing that despite its long tradition work on relatedness technologies remains characterized by limited theoretical grounding, lack of robust empirical evidence of effects, and insufficient attention to ethical considerations." ;
    dcterms:identifier "3706598.3714260" ;
    chi:hasAuthor chi:person_187075, chi:person_185305, chi:person_183962, chi:person_187286, chi:person_184664, chi:person_185481 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188728_SoftwareArtifact .

chi:artifact_188728_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188728 .

chi:result_188728_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188729 rdf:type chi:Paper ;
    dcterms:title "Raising Awareness of Location Information Vulnerabilities in Social Media Photos using LLMs" ;
    dcterms:abstract "Location privacy leaks can lead to unauthorised tracking, identity theft, and targeted attacks, compromising personal security and privacy. This study explores LLM-powered location privacy leaks associated with photo sharing on social media, focusing on user awareness, attitudes, and opinions. We developed and introduced an LLM-powered location privacy intervention app to 19 participants, who used it over a two-week period. The app prompted users to reflect on potential privacy leaks that a widely available LLM could easily detect, such as visual landmarks & cues that could reveal their location, and provided ways to conceal this information. Through in-depth interviews, we found that our intervention effectively increased users’ awareness of location privacy and the risks posed by LLMs. It also encouraged users to consider the importance of maintaining control over their privacy data and sparked discussions about the future of location privacy-preserving technologies. Based on these insights, we offer design implications to support the development of future user-centred, location privacy-preserving technologies for social media photos." ;
    dcterms:identifier "3706598.3714074" ;
    chi:hasAuthor chi:person_186899, chi:person_187026, chi:person_184918, chi:person_187961, chi:person_185830, chi:person_187323 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:paperIncludesStudy chi:study_188729_FieldStudy ;
    chi:paperIncludesStudy chi:study_188729_InterviewStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188729_SoftwareArtifact .

chi:study_188729_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188729 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188729_QualitativeResult .

chi:study_188729_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188729 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188729_QualitativeResult .

chi:artifact_188729_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188729 .

chi:result_188729_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188730 rdf:type chi:Paper ;
    dcterms:title "How Visualization Designers Perceive and Use Inspiration" ;
    dcterms:abstract "Inspiration plays an important role in design, yet its specific impact on data visualization design practice remains underexplored. This study investigates how professional visualization designers perceive and use inspiration in their practice. Through semi-structured interviews, we examine their sources of inspiration, the value they place on them, and how they navigate the balance between inspiration and imitation. Our findings reveal that designers draw from a diverse array of sources, including existing visualizations, real-world phenomena, and personal experiences. Participants describe a mix of active and passive inspiration practices, often iterating on sources to create original designs. This research offers insights into the role of inspiration in visualization practice, the need to expand visualization design theory, and the implications for the development of visualization tools that support inspiration and for training future visualization designers." ;
    dcterms:identifier "3706598.3714191" ;
    chi:hasAuthor chi:person_183692, chi:person_184055, chi:person_188040 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:paperIncludesStudy chi:study_188730_InterviewStudy .

chi:study_188730_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188730 ;
    chi:reportsResult chi:result_188730_QualitativeResult .

chi:result_188730_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188731 rdf:type chi:Paper ;
    dcterms:title "Get Real With Me: Effects of Avatar Realism on Social Presence and Comfort in Augmented Reality Remote Collaboration and Self-Disclosure" ;
    dcterms:abstract "Augmented reality (AR) is poised to transform remote communication with realistic user representations authentically simulating in-person interactions in one's own environment. While increased avatar realism is beneficial in various social contexts, as it generally fosters social presence, its impact in intimate interactions is less clear, possibly creating discomfort. We explored how varying avatar realism affects social presence and comfort in AR across different social interactions. Realism preferences were established in an online survey (N=157), informing our subsequent experiment (N=42). Participants engaged in remote AR collaboration and self-disclosure tasks with avatars ranging from abstract to realistic point-cloud. Quantitative and qualitative feedback revealed that higher avatar realism generally enhances social presence and comfort, though preferences can vary. The self-disclosure task increased social presence but reduced comfort compared to the collaboration task. This research provides an empirical analysis of avatar realism, highlighting the benefits of realistic avatars in various scenarios." ;
    dcterms:identifier "3706598.3713541" ;
    chi:hasAuthor chi:person_184521, chi:person_184635, chi:person_187371, chi:person_186593, chi:person_187983, chi:person_187751 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:CollaborationAndHybridWork ;
    chi:paperIncludesStudy chi:study_188731_UserStudy ;
    chi:paperIncludesStudy chi:study_188731_QuantitativeStudy ;
    chi:paperIncludesStudy chi:study_188731_QualitativeStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188731_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188731_SoftwareArtifact .

chi:study_188731_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188731 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188731_QualitativeResult ;
    chi:reportsResult chi:result_188731_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:study_188731_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188731 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188731_QualitativeResult ;
    chi:reportsResult chi:result_188731_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:study_188731_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188731 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188731_QualitativeResult ;
    chi:reportsResult chi:result_188731_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:artifact_188731_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188731 .

chi:artifact_188731_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188731 .

chi:result_188731_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188731_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188732 rdf:type chi:Paper ;
    dcterms:title "Slip-Grip: An Electrotactile Method to Simulate Weight" ;
    dcterms:abstract "Weight perception is crucial for immersive virtual reality (VR) interactions, yet providing weight feedback remains a significant research challenge. We introduce a novel weight simulation technique that leverages electrotactile stimulation to induce slip illusions. These slip illusions occur when users grip an object with less force than a predefined threshold, allowing the device to modulate the grip force and encourage a tighter grip. In our approach, heavier virtual weights correspond to higher required grip forces. We conducted a series of user experiments to validate our technique, confirming that it effectively induces slip illusions. We also investigated the relationship between electrotactile sensations and grip force, and changes in force, demonstrating that this association enhances the weight perception experience. Lastly, we explored the mapping between grip force and perceived weight, observing strong linearity within participants but notable variability between individuals." ;
    dcterms:identifier "3706598.3713361" ;
    chi:hasAuthor chi:person_186677, chi:person_183238, chi:person_184263, chi:person_185249, chi:person_184755, chi:person_187461, chi:person_183327, chi:person_182754, chi:person_187589, chi:person_183906 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:paperIncludesStudy chi:study_188732_UserStudy ;
    chi:proposesArtifact chi:artifact_188732_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188732_InputDeviceArtifact .

chi:study_188732_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188732 ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188732_StatisticalResult .

chi:artifact_188732_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188732 .

chi:artifact_188732_InputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188732 .

chi:result_188732_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188733 rdf:type chi:Paper ;
    dcterms:title "The Anatomy of a Plea: How Uncertainty, Visualizations & Individual Differences Shape Plea Bargain Decisions" ;
    dcterms:abstract "Plea bargains are commonly used in the criminal justice system, where they can offer potential benefits to both the prosecution and the defendant. However, research has shown that defendants often engage in poor decision-making, such as accepting the plea even when the trial sentence is likely to be less severe. While previous studies have shown some evidence that uncertainty visualizations can improve decision-making, there is a lack of research on their effectiveness in domain-specific tasks like plea bargain decision-making. In this work, we conduct a series of experiments to explore whether the presence and format of uncertainty impact plea bargain decisions, taking into account time pressure and individual differences. Our findings reveal that these factors can have a significant impact on plea bargain decisions. We also show evidence that communicating uncertainty in the form of text can elicit more optimal decisions under time-pressure conditions." ;
    dcterms:identifier "3706598.3713096" ;
    chi:hasAuthor chi:person_184251, chi:person_185422, chi:person_186063 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:TargetedEthicsInterventions ;
    chi:paperIncludesStudy chi:study_188733_UserStudy ;
    chi:paperIncludesStudy chi:study_188733_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188733_InterfaceArtifact .

chi:study_188733_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188733 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188733_StatisticalResult .

chi:study_188733_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188733 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188733_StatisticalResult .

chi:artifact_188733_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188733 .

chi:result_188733_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188734 rdf:type chi:Paper ;
    dcterms:title "Meaningful Engagement, Ethical Care, and Design Opportunities: An Ethnographic Study on Social Activities in Long-term Care" ;
    dcterms:abstract "Social activities in long-term care homes help promote residents’ wellbeing, but their effectiveness depends on residents’ engagement. To identify design opportunities for promoting meaningful engagement, we conducted an ethnographic study on organised activities in an Australian aged care home. We observed staff fostered engagement by initiating conversations, weaving residents’ backgrounds into interactions, and adapting activities to residents’ varying abilities. However, challenges included new staff members’ unfamiliarity with residents, multi-tasking, and insufficient support to engage excluded residents. Using a care ethics lens that includes relational, situated and empathetic features of care, we show that meaningful engagement is shaped by the ethical care practices embedded in staff-resident interactions and highlight opportunities for technologies to mitigate barriers hindering staff from providing ethical care in existing activities. These opportunities include: collecting and recording residents’ interests, providing conversation prompts, enhancing activity inclusiveness, and reducing language and cultural barriers." ;
    dcterms:identifier "3706598.3713755" ;
    chi:hasAuthor chi:person_184332, chi:person_184073, chi:person_183494, chi:person_187448 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188734_FieldStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement .

chi:study_188734_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188734 ;
    chi:reportsResult chi:result_188734_QualitativeResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:result_188734_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188735 rdf:type chi:Paper ;
    dcterms:title "Translation and Validation of The Video Game Demand Scale to Spanish" ;
    dcterms:abstract "With efforts to investigate the role of interactivity on user psychology in video games, scholars have demonstrated that interactivity may induce cognitive, emotional, physical (controller and exertional), and social demands of global gamers. However, existing studies are missing Latin American gamers as critical yet understudied gaming communities. Drawing on the interactivity-as-demand model, we conducted a mixed-method online survey to test measurement validity on localized versions of the video game demand scale (VGDS) for Spanish-speaking gamers (N = 195). Results showed that the Spanish-translated scale replicated the a priori five-factor structure of VGDS. Emergent themes from gamers’ comments mirrored VGDS factors, with additional insights into the cognitive demand of creative thinking, emotional demand of feeling nostalgia, physical demand of being precise, and social demand of interacting with non-player characters. These findings provide a pancultural perspective of Spanish-speaking gamers’ perceptions of their gaming while offering nuanced insights into their experiences for future research." ;
    dcterms:identifier "3706598.3713216" ;
    chi:hasAuthor chi:person_183959, chi:person_185663, chi:person_184012, chi:person_186900 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:SelfReflectionAndBehaviorChange ;
    chi:paperIncludesStudy chi:study_188735_UserStudy ;
    chi:paperIncludesStudy chi:study_188735_QuantitativeStudy ;
    chi:paperIncludesStudy chi:study_188735_QualitativeStudy .

chi:study_188735_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188735 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188735_QualitativeResult ;
    chi:reportsResult chi:result_188735_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:study_188735_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188735 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188735_QualitativeResult ;
    chi:reportsResult chi:result_188735_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:study_188735_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188735 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188735_QualitativeResult ;
    chi:reportsResult chi:result_188735_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:result_188735_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188735_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188736 rdf:type chi:Paper ;
    dcterms:title "Patient Handover in the Emergency Department Is Not Just a Point Event: Insights for Designing Information Support Tools" ;
    dcterms:abstract "Effective information support tools are challenging to design for fast-paced, information rich, and difficult to predict circumstances, particularly when information is fragmented and sources are dispersed. To explore, we conducted a field study on handover and the associated information work, which included 40 visits and 75 hours of observation and interviews with doctors in a metropolitan emergency department (ED). Beyond information exchange, we found that handovers highlight doctors' proactive approach by anticipating information needs, managing uncertainties arising from dynamic information, and developing patient care plans through multiple contingencies. Expanding on the idea of handover as a multifaceted process rather than a single event, we reinforce existing calls for greater flexibility emphasising that the ascertainment of pertinent information is an ongoing, adaptive process. This work demonstrates that deciding what constitutes relevant information is a priori indeterminate when designing information systems and support tools in environments such as EDs. We propose the preservation of specific ‘relativities’ of information—such as uncertainty, particularity, incompleteness, and temporality—in designing information support tools for dynamic, critical and multi-disciplinary work environments." ;
    dcterms:identifier "3706598.3713756" ;
    chi:hasAuthor chi:person_188187, chi:person_186127, chi:person_187936, chi:person_184275, chi:person_182804, chi:person_185121, chi:person_185194, chi:person_185023 ;
    chi:hasPrimaryTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:PhysicalDigitalWorkflowIntegration ;
    chi:paperIncludesStudy chi:study_188736_FieldStudy ;
    chi:paperIncludesStudy chi:study_188736_InterviewStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188736_SoftwareArtifact .

chi:study_188736_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188736 ;
    chi:reportsResult chi:result_188736_QualitativeResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:study_188736_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188736 ;
    chi:reportsResult chi:result_188736_QualitativeResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:artifact_188736_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188736 .

chi:result_188736_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188737 rdf:type chi:Paper ;
    dcterms:title "Mediating The Marginal: A Quantitative Analysis of Curated LGBTQ+ Content on Instagram" ;
    dcterms:abstract "Control and curation of dominant visual culture – rendering who and what is visible – is central to identity formation, particularly for LGBTQ+ communities relying on digital spaces for safe self-expression. In this work, we analyze Instagram as a site of algorithmic visual curation, performing a quantitative analysis of algorithmically mediated image feeds delivered to a gay-coded user. Our persona account exclusively followed \#gay and \#instagay feeds, and engaged in content within these discursive spaces to seed algorithmic content promotion to a normative gay user. We present an analysis of skin tone presentations, emoji usage, and engagement metrics alongside analysis of generative outputs of dominant visual trends within the \#gay search and Explore feeds. We observe content depicting darker-skinned individuals has higher engagement yet less algorithmic promotion relative to lighter skin tones, while hypermasculine and homonormative content is heavily promoted. These results suggest that, while marginalized positionalities have certainly been rendered more visible through social media platforms, this visibility is increasingly contingent on assimilation to normative ideals through algorithmically determined modes that are not necessarily consistent with user choices, preferences, or realities." ;
    dcterms:identifier "3706598.3713618" ;
    chi:hasAuthor chi:person_186467, chi:person_186745, chi:person_186036 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:AlgorithmicFairnessAndBias ;
    chi:paperIncludesStudy chi:study_188737_QuantitativeStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188737_SoftwareArtifact .

chi:study_188737_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188737 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188737_StatisticalResult .

chi:artifact_188737_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188737 .

chi:result_188737_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188738 rdf:type chi:Paper ;
    dcterms:title "What Lies Beneath? Exploring the Impact of Underlying AI Model Updates in AI-Infused Systems" ;
    dcterms:abstract "AI models are constantly evolving, with new versions released frequently. Human-AI interaction guidelines encourage notifying users about changes in model capabilities, ideally supported by thorough benchmarking. However, as AI systems integrate into domain-specific workflows, exhaustive benchmarking can become impractical, often resulting in silent or minimally communicated updates. This raises critical questions: Can users notice these updates? What cues do they rely on to distinguish between models? How do such changes affect their behavior and task performance? We address these questions through two studies in the context of facial recognition for historical photo identification: an online experiment examining users’ ability to detect model updates, followed by a diary study exploring perceptions in a real-world deployment. Our findings highlight challenges in noticing AI model updates, their impact on downstream user behavior and performance, and how they lead users to develop divergent folk theories. Drawing on these insights, we discuss strategies for effectively communicating model updates in AI-infused systems." ;
    dcterms:identifier "3706598.3713751" ;
    chi:hasAuthor chi:person_187981, chi:person_184350, chi:person_186584 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:ChatbotAssistedUserStudies ;
    chi:paperIncludesStudy chi:study_188738_UserStudy ;
    chi:paperIncludesStudy chi:study_188738_DiaryStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188738_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188738_InterfaceArtifact .

chi:study_188738_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188738 ;
    chi:hasMeasure chi:PerformanceMeasure ;
    chi:reportsResult chi:result_188738_QualitativeResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:study_188738_DiaryStudy rdf:type chi:DiaryStudy ;
    chi:isStudyReportedIn chi:paper_188738 ;
    chi:hasMeasure chi:PerformanceMeasure ;
    chi:reportsResult chi:result_188738_QualitativeResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:artifact_188738_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188738 .

chi:artifact_188738_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188738 .

chi:result_188738_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188739 rdf:type chi:Paper ;
    dcterms:title "Media Bias Detector: Designing and Implementing a Tool for Real-Time Selection and Framing Bias Analysis in News Coverage" ;
    dcterms:abstract "Mainstream media, through their decisions on what to cover and how to frame the stories they cover, can mislead readers without using outright falsehoods. Therefore, it is crucial to have tools that expose these editorial choices underlying media bias. In this paper, we introduce the \mbd, a tool for researchers, journalists, and news consumers. By integrating large language models, we provide near real-time granular insights into the topics, tone, political lean, and facts of news articles aggregated to the publisher level. We assessed the tool’s impact by interviewing 13 experts from journalism, communications, and political science, revealing key insights into usability and functionality, practical applications, and AI's role in powering media bias tools. We explored this in more depth with a follow-up survey of 150 news consumers. This work highlights opportunities for AI-driven tools that empower users to critically engage with media content, particularly in politically charged environments. " ;
    dcterms:identifier "3706598.3713716" ;
    chi:hasAuthor chi:person_186122, chi:person_185918, chi:person_187151, chi:person_183892, chi:person_185295, chi:person_184922, chi:person_184363, chi:person_183495 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188739_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188739_UserStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188739_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188739_InterfaceArtifact .

chi:study_188739_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188739 ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:reportsResult chi:result_188739_QualitativeResult ;
    chi:reportsResult chi:result_188739_StatisticalResult .

chi:study_188739_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188739 ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:reportsResult chi:result_188739_QualitativeResult ;
    chi:reportsResult chi:result_188739_StatisticalResult .

chi:artifact_188739_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188739 .

chi:artifact_188739_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188739 .

chi:result_188739_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188739_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188740 rdf:type chi:Paper ;
    dcterms:title "AutoPBL: An LLM-powered Platform to Guide and Support Individual Learners Through Self Project-based Learning" ;
    dcterms:abstract "Self project-based learning (SPBL) is a popular learning style where learners follow tutorials and build projects by themselves. SPBL combines project-based learning’s benefit of being engaging and effective with the flexibility of self-learning. However, insufficient guidance and support during SPBL may lead to unsatisfactory learning experiences and outcomes. While LLM chatbots (e.g., ChatGPT) could potentially serve as SPBL tutors, we have yet to see an SPBL platform with responsible and systematic LLM integration. To address this gap, we present AutoPBL, an interactive learning platform for SPBL learners. We examined human PBL tutors’ roles through formative interviews to inform our design. AutoPBL features an LLM-guided learning process with checkpoint questions and in-context Q&A. In a user study where 29 beginners learned machine learning through entry-level projects, we found that AutoPBL effectively improves learning outcomes and elicits better learning behavior and metacognition by clarifying current priorities and providing timely assistance." ;
    dcterms:identifier "3706598.3714261" ;
    chi:hasAuthor chi:person_186926, chi:person_184794, chi:person_184243, chi:person_187004, chi:person_187569, chi:person_187044 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188740_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188740_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188740_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188740_InterfaceArtifact .

chi:study_188740_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188740 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188740_QualitativeResult ;
    chi:reportsResult chi:result_188740_StatisticalResult .

chi:study_188740_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188740 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:reportsResult chi:result_188740_QualitativeResult ;
    chi:reportsResult chi:result_188740_StatisticalResult .

chi:artifact_188740_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188740 .

chi:artifact_188740_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188740 .

chi:result_188740_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188740_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188741 rdf:type chi:Paper ;
    dcterms:title "PalateTouch : Enabling Palate as a Touchpad to Interact with Earphones Using Acoustic Sensing" ;
    dcterms:abstract "This paper introduces PalateTouch, a hands-free earphone interaction system that leverages acoustic sensing technology to detect gestures resulting from the interaction between the tongue and the palate. By transmitting Zadoff-Chu signals and analyzing ear canal transfer function features, PalateTouch can capture subtle ear canal deformation and recognize various palate gestures used for interaction. Our proposed palate touch screening method ensures the system remains unaffected by unintended gestures from daily activities and the calibration mechanism enables our system to achieve user-independent recognition. Using only the earphone's built-in microphone and speaker, our system can distinguish nine gestures with an average F1 score of 0.92 and a false alarm rate of 0.02 across diverse conditions with 16 participants. Additionally, we have enabled real-time functionality and conducted a user study with 11 participants to evaluate PalateTouch's effectiveness in a demo application. The results demonstrate the superior performance and high usability of PalateTouch." ;
    dcterms:identifier "3706598.3713211" ;
    chi:hasAuthor chi:person_185642, chi:person_187473, chi:person_186542, chi:person_187966 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:paperIncludesStudy chi:study_188741_UserStudy ;
    chi:paperIncludesStudy chi:study_188741_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188741_InputDeviceArtifact ;
    chi:proposesArtifact chi:artifact_188741_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188741_SoftwareArtifact .

chi:study_188741_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188741 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188741_StatisticalResult .

chi:study_188741_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188741 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188741_StatisticalResult .

chi:artifact_188741_InputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188741 .

chi:artifact_188741_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188741 .

chi:artifact_188741_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188741 .

chi:result_188741_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188742 rdf:type chi:Paper ;
    dcterms:title "ReachPad: Interacting with Multiple Virtual Screens using a Single Physical Pad through Haptic Retargeting" ;
    dcterms:abstract "The advancement of Virtual Reality (VR) has expanded 2D user interfaces into 3D space. This change has introduced richer interaction modalities but also brought challenges, especially the lack of haptic feedback in mid-air interactions. Previous research has explored various methods to provide feedback for interface interactions, but most approaches require specialized haptic devices. We introduce haptic retargeting to enable users to control multiple virtual screens in VR using a simple flat pad, which serves as a single physical proxy to support seamless interaction across multiple virtual screens. We conducted user studies to explore the appropriate virtual screen size and positioning under our retargeting method and then compared various drag-and-drop methods for cross-screen interaction. Finally, we compared our method with controller-based interaction in application scenarios. " ;
    dcterms:identifier "3706598.3713629" ;
    chi:hasAuthor chi:person_182698, chi:person_185582, chi:person_184328, chi:person_187706 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:paperIncludesStudy chi:study_188742_UserStudy ;
    chi:paperIncludesStudy chi:study_188742_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188742_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188742_InterfaceArtifact .

chi:study_188742_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188742 ;
    chi:reportsResult chi:result_188742_StatisticalResult .

chi:study_188742_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188742 ;
    chi:reportsResult chi:result_188742_StatisticalResult .

chi:artifact_188742_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188742 .

chi:artifact_188742_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188742 .

chi:result_188742_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188744 rdf:type chi:Paper ;
    dcterms:title "It’s Not Always the Same Eye That Dominates: Effects of Viewing Angle, Handedness and Eye Movement in 3D" ;
    dcterms:abstract "Understanding eye dominance, the subconscious preference for one eye, has significant implications for 3D user interfaces in VR and AR, particularly in interface design and rendering.  Although HCI recognizes eye dominance, little is known about what causes it to switch from one eye to another.  To explore this, we studied eye dominance in VR, where 28 participants manually aligned a cursor with a distant target across three tasks. We manipulated the horizontal viewing angle, the hand used for alignment, and eye movement induced by target behaviour.  Our results confirm the dynamic nature of eye dominance, though with fewer switches than expected and varying influences across tasks.  This highlights the need for adaptive HCI techniques, which account for shifts in eye dominance in system design, such as gaze-based interaction, visual design, or rendering, and can improve accuracy, usability, and experience." ;
    dcterms:identifier "3706598.3713992" ;
    chi:hasAuthor chi:person_185349, chi:person_184996, chi:person_186997, chi:person_186027, chi:person_183087 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:paperIncludesStudy chi:study_188744_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188744_InterfaceArtifact .

chi:study_188744_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188744 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188744_StatisticalResult .

chi:artifact_188744_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188744 .

chi:result_188744_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188745 rdf:type chi:Paper ;
    dcterms:title "Less Talk, More Trust: Understanding Players' In-game Assessment of Communication Processes in League of Legends" ;
    dcterms:abstract "In-game team communication in online multiplayer games has shown the potential to foster efficient collaboration and positive social interactions. Yet players often associate communication within ad hoc teams with frustration and wariness. Though previous works have quantitatively analyzed communication patterns at scale, few have identified the motivations of how a player makes in-the-moment communication decisions. In this paper, we conducted an observation study with 22 League of Legends players by interviewing them during Solo Ranked games on their use of four in-game communication media (chat, pings, emotes, votes). We performed thematic analysis to understand players' in-context assessment and perception of communication attempts. We demonstrate that players evaluate communication opportunities on proximate game states bound by player expectations and norms. Our findings illustrate players' tendency to view communication, regardless of its content, as a precursor to team breakdowns. We build upon these findings to motivate effective player-oriented communication design in online games." ;
    dcterms:identifier "3706598.3714226" ;
    chi:hasAuthor chi:person_185403, chi:person_186680, chi:person_186487, chi:person_185127, chi:person_187378, chi:person_185260 ;
    chi:hasPrimaryTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:CollaborativeSensemaking ;
    chi:paperIncludesStudy chi:study_188745_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188745_UserStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188745_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188745_InterfaceArtifact .

chi:study_188745_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188745 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188745_QualitativeResult .

chi:study_188745_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188745 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188745_QualitativeResult .

chi:artifact_188745_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188745 .

chi:artifact_188745_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188745 .

chi:result_188745_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188747 rdf:type chi:Paper ;
    dcterms:title "FlexEar-Tips: Shape-Adjustable Ear Tips Using Pressure Control" ;
    dcterms:abstract " We introduce FlexEar-Tips, a dynamic ear tip system designed for the next-generation hearables. The ear tips are controlled by an air pump and solenoid valves, enabling size adjustments for comfort and functionality. FlexEar-Tips includes an air pressure sensor to monitor ear tip size, allowing it to adapt to environmental conditions and user needs. In the evaluation, we conducted a preliminary investigation of the size control accuracy and the minimum amount of variability of haptic perception in the user's ear. We then evaluated the user's ability to identify patterns in the haptic notification system, the impact on the music listening experience, the relationship between the size of the ear tips and the sound localization ability, and the impact on the reduction of humidity in the ear using a model. We proposed new interaction modalities for adaptive hearables and discussed health monitoring, immersive auditory experiences, haptics notifications, biofeedback, and sensing." ;
    dcterms:identifier "3706598.3714177" ;
    chi:hasAuthor chi:person_185454, chi:person_186286, chi:person_183284, chi:person_182950, chi:person_185301 ;
    chi:paperIncludesStudy chi:study_188747_UserStudy ;
    chi:proposesArtifact chi:artifact_188747_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188747_InputDeviceArtifact ;
    chi:proposesArtifact chi:artifact_188747_OutputDeviceArtifact .

chi:study_188747_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188747 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188747_StatisticalResult .

chi:artifact_188747_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188747 .

chi:artifact_188747_InputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188747 .

chi:artifact_188747_OutputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188747 .

chi:result_188747_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188748 rdf:type chi:Paper ;
    dcterms:title "OSINT Clinic: Co-designing AI-Augmented Collaborative OSINT Investigations for Vulnerability Assessment" ;
    dcterms:abstract "Small businesses need vulnerability assessments to identify and mitigate cyber risks. Cybersecurity clinics provide a solution by offering students hands-on experience while delivering free vulnerability assessments to local organizations. To scale this model, we propose an Open Source Intelligence (OSINT) clinic where students conduct assessments using only publicly available data. We enhance the quality of investigations in the OSINT clinic by addressing the technical and collaborative challenges. Over the duration of the 2023-24 academic year, we conducted a three-phase co-design study with six students. Our study identified key challenges in the OSINT investigations and explored how generative AI could address these performance gaps. We developed design ideas for effective AI integration based on the use of AI probes and collaboration platform features. A pilot with three small businesses highlighted both the practical benefits of AI in streamlining investigations, and limitations, including privacy concerns and difficulty in monitoring progress." ;
    dcterms:identifier "3706598.3713283" ;
    chi:hasAuthor chi:person_184708, chi:person_186584 ;
    chi:hasPrimaryTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:paperIncludesStudy chi:study_188748_UserStudy ;
    chi:paperIncludesStudy chi:study_188748_FieldStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188748_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188748_InterfaceArtifact .

chi:study_188748_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188748 ;
    chi:reportsResult chi:result_188748_QualitativeResult .

chi:study_188748_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188748 ;
    chi:reportsResult chi:result_188748_QualitativeResult .

chi:artifact_188748_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188748 .

chi:artifact_188748_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188748 .

chi:result_188748_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188749 rdf:type chi:Paper ;
    dcterms:title "Self-Disclosure in Social Virtual Reality: The Influence of Information Management Dynamics, Social Presence, and Privacy Concerns" ;
    dcterms:abstract "Social virtual reality (SVR) aims to recreate embodied social experiences similar to those offline. However, concerns about privacy and safety have hindered its widespread adoption. This study examines how information disclosure and perceived control over information in SVR are influenced by 1) boundary permeability (e.g., interruptions from an unknown external user) and 2) identifiability of one’s conversation partner (e.g., access to their offline profile). We also explore how different social presence perceptions and privacy concerns may mediate these relationships. Comparing the experiences of participants (n = 94) randomly assigned to four different mock interview scenarios, we find the perceived actorhood of one’s conversation partner mediated the positive relationship between offline profile access and disclosure. Additionally, more permeable environmental boundaries led to significantly lower levels of disclosure. Qualitative responses emphasized SVR’s limitations in saliently conveying nonverbal expressions. Implications for future research and the design of SVR as a viable communication medium are discussed." ;
    dcterms:identifier "3706598.3713213" ;
    chi:hasAuthor chi:person_183485, chi:person_187920, chi:person_186343 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:aboutTopic chi:OnlineSelfDisclosureAndIdentity ;
    chi:paperIncludesStudy chi:study_188749_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188749_InterfaceArtifact .

chi:study_188749_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188749 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188749_QualitativeResult ;
    chi:reportsResult chi:result_188749_StatisticalResult .

chi:artifact_188749_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188749 .

chi:result_188749_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188749_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188750 rdf:type chi:Paper ;
    dcterms:title "AReading with Smartphones: Understanding the Trade-offs between Enhanced Legibility and Display Switching Costs in Hybrid AR Interfaces" ;
    dcterms:abstract "This research investigates the use of hybrid user interfaces to enhance text readability in augmented reality (AR) by combining optical see-through head-mounted displays with smartphones. While this integration can improve information legibility, it may also introduce display switching side effects. The extent to which these side effects hinder user experience and when the benefits outweigh drawbacks remain unclear. To address this gap, we conducted an empirical study (N=24) to evaluate how hybrid user interfaces affect AR reading tasks across different content distances, which induce varying levels of display switching. Our findings show that hybrid user interfaces offer significant readability benefits compared to using the HMD only, reducing mental and physical demands when reading text linked to content at closer distances. However, as the distance between displays increases, the compensatory behaviors users adopt to manage increased switching costs negate these benefits, making hybrid user interfaces less effective. Based on these findings, we suggest (1) using smartphones as supplementary displays for text in reading-intensive tasks, (2) implementing adaptive display positioning to minimize switching overhead in such scenarios, and (3) adjusting the smartphone's role based on content distance for less intensive reading tasks. These insights provide guidance for optimizing smartphone integration in hybrid interfaces and enhancing AR systems for reading applications." ;
    dcterms:identifier "3706598.3713879" ;
    chi:hasAuthor chi:person_187759, chi:person_186958, chi:person_187337, chi:person_187517 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:paperIncludesStudy chi:study_188750_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188750_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188750_DeviceArtifact .

chi:study_188750_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188750 ;
    chi:hasMeasure chi:SubjectiveMeasure ;
    chi:reportsResult chi:result_188750_QualitativeResult ;
    chi:reportsResult chi:result_188750_StatisticalResult .

chi:artifact_188750_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188750 .

chi:artifact_188750_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188750 .

chi:result_188750_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188750_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188751 rdf:type chi:Paper ;
    dcterms:title "What Do We Design for When We Design \"Smart Buildings\"? - A Scoping Review of Human Experience Design Research in Buildings" ;
    dcterms:abstract "Built environments increasingly incorporate new forms of intelligence, creating opportunities for enhancing human interactive experiences with and within building spaces. This scoping review examines design interventions and discourses within the domain of \"Smart Buildings\". The goal is to identify and characterise the type of human experiences that research in this domain aims to address. Using a hybrid deductive-inductive coding approach, we analysed 192 papers related to human experiences and smart buildings from ACM Digital Library and Scopus published between 1996 and 2024. Our analysis revealed 11 distinct \"targeted human experiences\", 20 commonly used \"design mechanisms\" to achieve those design goals, as well as two typologies of \"technological interventions\". Our findings create a foundation for understanding building design research and the range of human experience they entail." ;
    dcterms:identifier "3706598.3713903" ;
    chi:hasAuthor chi:person_186832, chi:person_187465, chi:person_185958, chi:person_187000 ;
    chi:paperIncludesStudy chi:study_188751_QualitativeStudy .

chi:study_188751_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188751 ;
    chi:reportsResult chi:result_188751_QualitativeResult .

chi:result_188751_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188753 rdf:type chi:Paper ;
    dcterms:title "Understanding User Behavior in Window Selection using Dragging for Multiple Targets" ;
    dcterms:abstract "Window selection is a fundamental method in desktop environments for interacting with multiple targets, typically performed by successive operations like click-drag-release (i.e., a single sequence of dragging). Although this method is common in GUI interactions, there has been limited research to understand user behavior during window selection. This study explores user behavior and performance during window selection using dragging. We empirically studied the impact of several GUI parameters — including the size, interval, number, and layout of targets — on window selection for multiple targets. Based on well-established existing motor models, we analyzed user behavior in terms of time performance and derived a more suitable model. Additionally, our new prediction model effectively predicted time performance in partially constrained scenarios. This study provides new insights into user behavior during window selection for multiple targets. We hope that our research findings will assist GUI designers, practitioners, and researchers in testing their designs." ;
    dcterms:identifier "3706598.3713410" ;
    chi:hasAuthor chi:person_187407, chi:person_185040 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:PointingAndSelectionPerformance ;
    chi:paperIncludesStudy chi:study_188753_UserStudy ;
    chi:paperIncludesStudy chi:study_188753_QuantitativeStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188753_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188753_SoftwareArtifact .

chi:study_188753_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188753 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:reportsResult chi:result_188753_StatisticalResult .

chi:study_188753_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188753 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:reportsResult chi:result_188753_StatisticalResult .

chi:artifact_188753_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188753 .

chi:artifact_188753_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188753 .

chi:result_188753_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188754 rdf:type chi:Paper ;
    dcterms:title "Effects of LLM-based Search on Decision Making: Speed, Accuracy, and Overreliance" ;
    dcterms:abstract "Recent advances in large language models (LLMs) are transforming online applications, including search tools that accommodate complex natural language queries and provide direct responses. There are, however, concerns about the veracity of LLM-generated content due to potential for LLMs to \"hallucinate\". In two online experiments, we examined how LLM-based search affects behavior compared to traditional search and explored ways to reduce overreliance on incorrect LLM-based output. Participants assigned to LLM-based search completed tasks more quickly, with fewer but more complex queries, and reported a more satisfying experience. While decision accuracy was comparable when the LLM was correct, users overrelied on incorrect information when the model erred. In a second experiment, a color-coded highlighting system helped users detect errors, improving decision accuracy without affecting other outcomes. These findings suggest that LLM-based search tools have promise as decision aids but also highlight the importance of effectively communicating uncertainty to mitigate overreliance." ;
    dcterms:identifier "3706598.3714082" ;
    chi:hasAuthor chi:person_187120, chi:person_184363, chi:person_182824, chi:person_187135 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188754_UserStudy ;
    chi:paperIncludesStudy chi:study_188754_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188754_InterfaceArtifact .

chi:study_188754_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188754 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188754_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:study_188754_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188754 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188754_StatisticalResult ;
    chi:involvesParticipationPattern chi:RemoteParticipation .

chi:artifact_188754_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188754 .

chi:result_188754_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188755 rdf:type chi:Paper ;
    dcterms:title "Realism Drives Interpersonal Reciprocity but Yields to AI-Assisted Egocentrism in a Coordination Experiment" ;
    dcterms:abstract "Virtual reality technologies that enhance realism and artificial intelligence (AI) systems that assist human behavior are increasingly interwoven in social applications. However, how these technologies might jointly influence interpersonal coordination remains unclear. We conducted an experiment with 240 participants in 120 pairs who interacted through remote-controlled robot cars in a physical space or virtual cars in a digital space, with or without autosteering assistance, using the chicken game, an established model of interpersonal coordination. We find that both realism and AI assistance help improve user performance but through opposing mechanisms. Real-world contexts enhanced communication, fostering reciprocal actions and collective benefits. In contrast, autosteering assistance diminished the need for interpersonal coordination, shifting participants’ focus towards self-interest. Notably, when combined, the egocentric effects of autosteering assistance outweighed the prosocial effects of realism. The design of HCI systems that involve social coordination will, we believe, need to take such effects into account." ;
    dcterms:identifier "3706598.3713371" ;
    chi:hasAuthor chi:person_183850, chi:person_187189, chi:person_187078, chi:person_187333 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:paperIncludesStudy chi:study_188755_UserStudy ;
    chi:paperIncludesStudy chi:study_188755_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188755_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188755_SoftwareArtifact .

chi:study_188755_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188755 ;
    chi:hasMeasure chi:PerformanceMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188755_StatisticalResult .

chi:study_188755_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188755 ;
    chi:hasMeasure chi:PerformanceMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188755_StatisticalResult .

chi:artifact_188755_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188755 .

chi:artifact_188755_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188755 .

chi:result_188755_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188756 rdf:type chi:Paper ;
    dcterms:title "RetroSketch: A Retrospective Method for Measuring Emotions and Presence in Virtual Reality" ;
    dcterms:abstract "Virtual Reality (VR) designers and researchers often need to measure emotions and presence as they evolve over time. The experience sampling method (ESM) is a common way to achieve this, however, ESM disrupts the experience and lacks granularity. We propose RetroSketch, a new method for measuring subjective emotions and presence in VR, where users watch back their VR experience and retrospectively sketch a plot of their feelings. RetroSketch leaves the VR experience undisturbed and yields highly granular data, including information about salient events and qualitative descriptions of their feelings. We compared RetroSketch and ESM in a large study (n=140) using five different VR experiences over one-hour sessions. Our results show that RetroSketch and ESM measures are highly correlated with each other, as well as physiological measures indicative of emotion. The correlations are robust across different VR experiences and user demographics. They also highlight the impact of ESM on users' experience." ;
    dcterms:identifier "3706598.3713957" ;
    chi:hasAuthor chi:person_184370, chi:person_183230, chi:person_184850, chi:person_185874, chi:person_186205, chi:person_184103, chi:person_184219, chi:person_185863, chi:person_185439, chi:person_182869, chi:person_186260, chi:person_182965 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:EmbodiedVRInteraction ;
    chi:paperIncludesStudy chi:study_188756_UserStudy ;
    chi:paperIncludesStudy chi:study_188756_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188756_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188756_InterfaceArtifact .

chi:study_188756_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188756 ;
    chi:hasMeasure chi:PhysiologicalMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188756_QualitativeResult ;
    chi:reportsResult chi:result_188756_StatisticalResult .

chi:study_188756_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188756 ;
    chi:hasMeasure chi:PhysiologicalMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188756_QualitativeResult ;
    chi:reportsResult chi:result_188756_StatisticalResult .

chi:artifact_188756_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188756 .

chi:artifact_188756_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188756 .

chi:result_188756_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188756_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188759 rdf:type chi:Paper ;
    dcterms:title "Blending the Worlds: An evaluation of World-Fixed Visual Appearances in Automotive Augmented Reality" ;
    dcterms:abstract "With the transition to fully autonomous vehicles, non-driving related tasks (NDRTs) become increasingly important, allowing passengers to use their driving time more efficiently. In-car Augmented Reality (AR) gives the possibility to engage in NDRTs while also allowing passengers to engage with their surroundings, for example, by displaying world-fixed points of interest (POIs). This can lead to new discoveries, provide information about the environment, and improve locational awareness. To explore the optimal visualization of POIs using in-car AR, we conducted a field study (N = 38) examining six parameters: positioning, scaling, rotation, render distance, information density, and appearance. We also asked for intention of use, preferred seat positions and preferred automation level for the AR function in a post-study questionnaire. Our findings reveal user preferences and general acceptance of the AR functionality. Based on these results, we derived UX-guidelines for the visual appearance and behavior of location-based POIs in in-car AR." ;
    dcterms:identifier "3706598.3713185" ;
    chi:hasAuthor chi:person_187815, chi:person_183788, chi:person_186299, chi:person_185116, chi:person_186952, chi:person_184710 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:SpatialVRInteraction ;
    chi:paperIncludesStudy chi:study_188759_FieldStudy ;
    chi:paperIncludesStudy chi:study_188759_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188759_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188759_SoftwareArtifact .

chi:study_188759_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188759 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188759_QualitativeResult ;
    chi:reportsResult chi:result_188759_StatisticalResult .

chi:study_188759_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188759 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188759_QualitativeResult ;
    chi:reportsResult chi:result_188759_StatisticalResult .

chi:artifact_188759_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188759 .

chi:artifact_188759_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188759 .

chi:result_188759_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188759_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188760 rdf:type chi:Paper ;
    dcterms:title "What is User Engagement?:  A Systematic Review of 241 Research Articles in Human-Computer Interaction and Beyond" ;
    dcterms:abstract "User engagement (UE) is widely discussed in HCI articles, but its definition, reliability, and application remain elusive. This research conducts a systematic literature review of 241 articles from 1993 to 2023 to analyze how UE is defined and measured within the domain of HCI. Our findings reveal significant definitional inconsistencies that hinder UE’s practical application in HCI research and system design. Based on our findings, we recommend using UE as a categorical label rather than a unified construct until more systematic frameworks are established. We also highlight the need for divergent views of UE across HCI research communities as a valuable avenue to pursue. This divergent view approach can help HCI researchers focus on specific, measurable aspects of UE that align with specific community practices and norms. Our findings also suggest that until such a framework emerges, researchers should be aware of its limitations when using UE as a research construct. " ;
    dcterms:identifier "3706598.3713505" ;
    chi:hasAuthor chi:person_185905, chi:person_187596, chi:person_186974, chi:person_186187, chi:person_183210 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aimsAtGoal chi:IncreaseEngagement .

chi:result_188760_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188761 rdf:type chi:Paper ;
    dcterms:title "AR Cue Reliability for Interrupted Task Resumption Affects Users' Resumption Strategies and Performance" ;
    dcterms:abstract "Reliable augmented reality (AR) cues can support the resumption of interrupted tasks. We investigated how sub-optimal AR cue reliability (100%, 86%, 64%, or no cue) affected users’ resumption performance and strategies. In a between-subjects experiment, 120 participants conducted a physical sorting task including interruptions, and we manipulated AR cue reliability (i.e., the AR cue was present or absent at the end of interruptions). In trials with AR cue, performance with 86% and 64% reliable AR cues was as well as with 100% reliable cues. In trials without AR cue, performance with suboptimal AR cue reliability declined but was still better than with no cue. Cue reliability affected task resumption strategies of the 86% (slow but no increase in errors) and the 64% (fast but increase in errors) reliability groups differently. Our results extend reliability research to interruptions and the observed efficiency-thoroughness trade-offs in resumption strategies provide insight for design" ;
    dcterms:identifier "3706598.3713685" ;
    chi:hasAuthor chi:person_185593, chi:person_183662, chi:person_187936 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:ErrorRatesAndTaskCompletion ;
    chi:paperIncludesStudy chi:study_188761_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188761_InterfaceArtifact .

chi:study_188761_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188761 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:ErrorRateMeasure ;
    chi:reportsResult chi:result_188761_StatisticalResult .

chi:artifact_188761_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188761 .

chi:result_188761_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188762 rdf:type chi:Paper ;
    dcterms:title "A Multimodal Approach for Targeting Error Detection in Virtual Reality Using Implicit User Behavior" ;
    dcterms:abstract "Although the point-and-select interaction method has been shown to lead to user and system-initiated errors, it is still prevalent in VR scenarios. Current solutions to facilitate selection interactions exist, however they do not address the challenges caused by targeting inaccuracy. To reduce the effort required to target objects, we developed a model that quickly detected targeting errors after they occurred. The model used implicit multimodal user behavioral data to identify possible targeting outcomes. Using a dataset composed of 23 participants engaged in VR targeting tasks, we then trained a deep learning model to differentiate between correct and incorrect targeting events within 0.5 seconds of a selection, resulting in an AUC-ROC of 0.9. The utility of this model was then evaluated in a user study with 25 participants that identified that participants recovered from more errors and faster when assisted by the model. These results advance our understanding of targeting errors in VR and facilitate the design of future intelligent error-aware systems." ;
    dcterms:identifier "3706598.3713777" ;
    chi:hasAuthor chi:person_186939, chi:person_185726, chi:person_184893, chi:person_185928, chi:person_185006, chi:person_184200 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:paperIncludesStudy chi:study_188762_UserStudy ;
    chi:paperIncludesStudy chi:study_188762_QuantitativeStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188762_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188762_InterfaceArtifact .

chi:study_188762_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188762 ;
    chi:hasMeasure chi:ErrorRateMeasure ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188762_StatisticalResult .

chi:study_188762_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188762 ;
    chi:hasMeasure chi:ErrorRateMeasure ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188762_StatisticalResult .

chi:artifact_188762_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188762 .

chi:artifact_188762_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188762 .

chi:result_188762_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188763 rdf:type chi:Paper ;
    dcterms:title "Sustaining Human Agency, Attending to Its Cost: An Investigation into Generative AI Design for Non-Native Speakers' Language Use" ;
    dcterms:abstract "AI systems and tools today can generate human-like expressions on behalf of people. It raises the crucial question about how to sustain human agency in AI-mediated communication. We investigated this question in the context of machine translation (MT) assisted conversations. Our participants included 45 dyads. Each dyad consisted of one new immigrant in the United States, who leveraged MT for English information seeking as a non-native speaker, and one local native speaker, who acted as the information provider. Non-native speakers could influence the English production of their message in one of three ways: labeling the quality of MT outputs, regular post-editing without additional hints, or augmented post-editing with LLM-generated hints. Our data revealed a greater exercise of non-native speakers’ agency under the two post-editing conditions. This benefit, however, came at a significant cost to the dyadic-level communication performance. We derived insights for MT and other generative AI design from our findings. " ;
    dcterms:identifier "3706598.3713626" ;
    chi:hasAuthor chi:person_187270, chi:person_186430, chi:person_185357, chi:person_186042, chi:person_183902, chi:person_185771, chi:person_186991 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:DataDisclosureAndConsent ;
    chi:paperIncludesStudy chi:study_188763_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188763_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188763_InterfaceArtifact .

chi:study_188763_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188763 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188763_QualitativeResult ;
    chi:reportsResult chi:result_188763_StatisticalResult .

chi:artifact_188763_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188763 .

chi:artifact_188763_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188763 .

chi:result_188763_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188763_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188764 rdf:type chi:Paper ;
    dcterms:title "CorpusStudio: Surfacing Emergent Patterns In A Corpus Of Prior Work While Writing" ;
    dcterms:abstract "Many communities, including the scientific community, develop implicit writing norms. Understanding them is crucial for effective communication with that community. Writers gradually develop an implicit understanding of norms by reading papers and receiving feedback on their writing. However, it is difficult to both externalize this knowledge and apply it to one's own writing. We propose two new writing support concepts that reify document and sentence-level patterns in a given text corpus: (1) an ordered distribution over section titles and (2) given the user's draft and cursor location, many retrieved contextually relevant sentences. Recurring words in the latter are algorithmically highlighted to help users see any emergent norms. Study results (N=16) show that participants revised the structure and content using these concepts, gaining confidence in aligning with or breaking norms after reviewing many examples. These results demonstrate the value of reifying distributions over other authors’ writing choices during the writing process." ;
    dcterms:identifier "3706598.3713974" ;
    chi:hasAuthor chi:person_186100, chi:person_184856, chi:person_183266, chi:person_183703 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:QualitativeAnalysisSupportTools ;
    chi:paperIncludesStudy chi:study_188764_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188764_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188764_InterfaceArtifact .

chi:study_188764_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188764 ;
    chi:reportsResult chi:result_188764_QualitativeResult .

chi:artifact_188764_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188764 .

chi:artifact_188764_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188764 .

chi:result_188764_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188765 rdf:type chi:Paper ;
    dcterms:title "Being The Creek: Mobile Augmented Reality Experience as an Invitation for Exploring More-Than-Human Perspectives" ;
    dcterms:abstract "We introduce Being The Creek, a mobile augmented reality (MAR) experience that invites participants to take a “first-person” perspective of a historically-significant-creek by lying alongside her and getting attuned to her environment through embodied multisensory engagement. Individuals experience how the world might appear from the Creek’s perspective, from the pre-colonial respect she received from Indigenous peoples, through the industrial period when the Creek was used as a sewer, to a speculative future of collaborative survival despite capitalism. Fifteen participants of our study each experienced a range of emotions while “being” the Creek through temporal and spatial explorations. As participants moved between human-centered and creek-centered perspectives, they explored the Creek’s unique subjectivity and the human-nonhuman power relations, leading them to de-emphasize the stereotypical human-centric stance. We discuss designing mobile experiences that encourage movement beyond human-centric perspectives and encourage “noticing” for more-than-human worlds." ;
    dcterms:identifier "3706598.3713713" ;
    chi:hasAuthor chi:person_186119, chi:person_182725 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:EmbodiedVRInteraction ;
    chi:paperIncludesStudy chi:study_188765_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188765_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188765_InterfaceArtifact .

chi:study_188765_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188765 ;
    chi:reportsResult chi:result_188765_QualitativeResult .

chi:artifact_188765_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188765 .

chi:artifact_188765_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188765 .

chi:result_188765_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188766 rdf:type chi:Paper ;
    dcterms:title "What’s In Your Kit? Mental Health Technology Kits for Depression Self-Management" ;
    dcterms:abstract "This paper characterizes the mental health technology “kits” of individuals managing depression: the specific technologies on their digital devices and physical items in their environments that people turn to as part of their mental health management. We interviewed 28 individuals living across the United States who use bundles of connected tools for both individual and collaborative mental health activities. We contribute to the HCI community by conceptualizing these tool assemblages that people managing depression have constructed over time. We detail categories of tools, describe kit characteristics (intentional, adaptable, available), and present participant ideas for future mental health support technologies. We then discuss what a mental health technology kit perspective means for researchers and designers and describe design principles (building within current toolkits; creating new tools from current self-management strategies; and identifying gaps in people’s current kits) to support depression self-management across an evolving set of tools." ;
    dcterms:identifier "3706598.3713585" ;
    chi:hasAuthor chi:person_184631, chi:person_185680, chi:person_184720, chi:person_183572 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188766_InterviewStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking .

chi:study_188766_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188766 ;
    chi:reportsResult chi:result_188766_QualitativeResult .

chi:result_188766_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188767 rdf:type chi:Paper ;
    dcterms:title "Creative Writers’ Attitudes on Writing as Training Data for Large Language Models" ;
    dcterms:abstract "The use of creative writing as training data for large language models (LLMs) is highly contentious and many writers have expressed outrage at the use of their work without consent or compensation. In this paper, we seek to understand how creative writers reason about the real or hypothetical use of their writing as training data. We interviewed 33 writers with variation across genre, method of publishing, degree of professionalization, and attitudes toward and engagement with LLMs. We report on core principles that writers express (support of the creative chain, respect for writers and writing, and the human element of creativity) and how these principles can be at odds with their realistic expectations of the world (a lack of control, industry-scale impacts, and interpretation of scale). Collectively these findings demonstrate that writers have a nuanced understanding of LLMs and are more concerned with power imbalances than the technology itself. " ;
    dcterms:identifier "3706598.3713287" ;
    chi:hasAuthor chi:person_183629, chi:person_183448, chi:person_184655, chi:person_183709, chi:person_184132, chi:person_183703 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:DataDisclosureAndConsent ;
    chi:paperIncludesStudy chi:study_188767_InterviewStudy .

chi:study_188767_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188767 ;
    chi:reportsResult chi:result_188767_QualitativeResult .

chi:result_188767_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188768 rdf:type chi:Paper ;
    dcterms:title "`I don't want to watch grown-up stuff': Children's and Parents' Perspectives and Recommendations for Health-Centered Digital Media Design" ;
    dcterms:abstract "Screen time is ubiquitous in children's lives and has both positive and negative health impacts. Calls for developmentally appropriate design and restrictions on manipulative design are ongoing, yet children's and parents' perspectives to inform interventions are lacking. This research uses design workshops with children (n=16) and focus groups with their parents (n=17) to understand whether and how digital media could be more health-centered. Participants shared concerns that manipulative design may inhibit screen time limits and transitions, and present age-inappropriate content.  Participants expressed strong interest in health-centered designs incorporating nudges, moderation, and controls. Children's self-generated designs aimed to reduce negative impacts by limiting screen time (e.g., time-related feedback, changed defaults), facilitating transitions (e.g., pause capabilities), minimizing age-inappropriate content (e.g., expanded shared controls), and reducing hurtful experiences (e.g., online video game moderation). To increase positive health impacts, participants suggested promoting physical activity (e.g., suggested screen breaks) within and away from digital media." ;
    dcterms:identifier "3706598.3714039" ;
    chi:hasAuthor chi:person_185003, chi:person_185208 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188768_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement .

chi:study_188768_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188768 ;
    chi:reportsResult chi:result_188768_QualitativeResult .

chi:result_188768_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188769 rdf:type chi:Paper ;
    dcterms:title "BIASsist: Empowering News Readers via Bias Identification, Explanation, and Neutralization" ;
    dcterms:abstract "Biased news articles can distort readers' perceptions by presenting information in a way that favors or disfavors a particular point of view. Subtly embedded in the text, these biased news articles can shape our views daily without people even realizing it. To address this issue, we propose BIASsist, an LLM-based approach designed to mitigate bias in news articles. Based on existing research, we defined six types of bias and introduced three assistive components—identification, explanation, and neutralization—to provide a broader range of bias information and enhance readers' bias-awareness. We conducted a mixed-method study with 36 participants to evaluate the effectiveness of BIASsist. The results show participants' bias awareness significantly improved and their interest in identifying bias increased. Participants also tended to engage more actively in critically evaluating articles. Based on these findings, we discuss its potential to improve media literacy and critical thinking in today's information overload era." ;
    dcterms:identifier "3706598.3713531" ;
    chi:hasAuthor chi:person_183963, chi:person_188066, chi:person_182837, chi:person_183359 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness:AlgorithmicFairnessAndBias ;
    chi:aboutTopic chi:EthicsPrivacyFairness:AlgorithmicFairnessAndBias ;
    chi:paperIncludesStudy chi:study_188769_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188769_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188769_InterfaceArtifact .

chi:study_188769_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188769 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188769_QualitativeResult ;
    chi:reportsResult chi:result_188769_StatisticalResult .

chi:artifact_188769_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188769 .

chi:artifact_188769_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188769 .

chi:result_188769_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188769_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188772 rdf:type chi:Paper ;
    dcterms:title "Timing Matters: How Using LLMs at Different Timings Influences Writers' Perceptions and Ideation Outcomes in AI-Assisted Ideation" ;
    dcterms:abstract "Large Language Models (LLMs) have been widely used to support ideation in the writing process. However, whether generating ideas with the help of LLMs leads to idea fixation or idea expansion is unclear. This study examines how different timings of LLM usage - either at the beginning or after independent ideation - affect people's perceptions and ideation outcomes in a writing task. In a controlled experiment with 60 participants, we found that using LLMs from the beginning reduced the number of original ideas and lowered creative self-efficacy and self-credit, mediated by changes in autonomy and ownership. We discuss the challenges and opportunities associated with using LLMs to assist in idea generation. We propose delaying the use of LLMs to support ideation while considering users' self-efficacy, autonomy, and ownership of the ideation outcomes." ;
    dcterms:identifier "3706598.3713146" ;
    chi:hasAuthor chi:person_185527, chi:person_183642, chi:person_184754, chi:person_186743, chi:person_188122 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:ChatbotAssistedUserStudies ;
    chi:paperIncludesStudy chi:study_188772_UserStudy ;
    chi:paperIncludesStudy chi:study_188772_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188772_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188772_InterfaceArtifact .

chi:study_188772_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188772 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188772_StatisticalResult .

chi:study_188772_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188772 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188772_StatisticalResult .

chi:artifact_188772_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188772 .

chi:artifact_188772_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188772 .

chi:result_188772_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188773 rdf:type chi:Paper ;
    dcterms:title "Imagining with the Body: Speculative Designs for Women's Embodied Empowerment in Feminist Self-Defense " ;
    dcterms:abstract "Feminist self-defense combines physical self-defense with mental strength exercises through role-playing scenarios. It aims to challenge limiting beliefs about women’s abilities to respond to interpersonal violence. We present the experiences from feminist self-defense classes in Sweden and the results of a set of speculative designs that combined contribute to imagine how technology could play a role in experiencing these holistic practices. The goal is to illustrate the potential of embodied interaction design to empower beginner feminist self-defense practitioners. To do so, the study was conducted via two methods: semi-structured interviews with students and teachers, and a participatory speculative design workshop with novice practitioners. The speculative concepts demonstrate how design can support the practice of feminist self-defense. Through this study we contribute to the corpus of embodied design interventions, in this case combining design for bodily movements with feminist consciousness raising in relation to the topic of gender-based violence." ;
    dcterms:identifier "3706598.3713975" ;
    chi:hasAuthor chi:person_186393, chi:person_185480, chi:person_187308 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:EmbodiedVRInteraction ;
    chi:paperIncludesStudy chi:study_188773_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188773_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188773_InterfaceArtifact .

chi:study_188773_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188773 ;
    chi:reportsResult chi:result_188773_QualitativeResult .

chi:study_188773_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188773 ;
    chi:reportsResult chi:result_188773_QualitativeResult .

chi:artifact_188773_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188773 .

chi:result_188773_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188775 rdf:type chi:Paper ;
    dcterms:title "Gesture and Audio-Haptic Guidance Techniques to Direct Conversations with Intelligent Voice Interfaces" ;
    dcterms:abstract "Advances in large language models (LLMs) empower new interactive capabilities for wearable voice interfaces, yet traditional voice-and-audio I/O techniques limit users' ability to flexibly navigate information and manage timing for complex conversational tasks. We developed a suite of gesture and audio-haptic guidance techniques that enable users to control conversation flows and maintain awareness of possible future actions, while simultaneously contributing and receiving conversation content through voice and audio. A 14-participant exploratory study compared our parallelized I/O techniques to a baseline of voice-only interaction. The results demonstrate the efficiency of gestures and haptics for information access, while allowing system speech to be redirected and interrupted in a socially acceptable manner. The techniques also raised user awareness of how to leverage intelligent capabilities. Our findings inform design recommendations to facilitate role-based collaboration between multimodal I/O techniques and reduce users' perception of time pressure when interleaving interactions with system speech." ;
    dcterms:identifier "3706598.3714310" ;
    chi:hasAuthor chi:person_183676, chi:person_186988, chi:person_187292, chi:person_185012, chi:person_187550, chi:person_185068, chi:person_184767 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:paperIncludesStudy chi:study_188775_BaselineComparisonStudy ;
    chi:paperIncludesStudy chi:study_188775_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188775_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188775_InputDeviceArtifact ;
    chi:proposesArtifact chi:artifact_188775_OutputDeviceArtifact .

chi:study_188775_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188775 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:reportsResult chi:result_188775_QualitativeResult .

chi:study_188775_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188775 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:reportsResult chi:result_188775_QualitativeResult .

chi:artifact_188775_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188775 .

chi:artifact_188775_InputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188775 .

chi:artifact_188775_OutputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188775 .

chi:result_188775_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188776 rdf:type chi:Paper ;
    dcterms:title "In Suspense About Suspensions? The Relative Effectiveness of Suspension Durations on a Popular Social Platform" ;
    dcterms:abstract "It is common for digital platforms to issue consequences for behaviors that violate Community Standards policies. However, there is limited evidence about the relative effectiveness of consequences, particularly lengths of temporary suspensions. This paper analyzes two massive field experiments (N1 = 511,304; N2 = 262,745) on Roblox that measure the impact of suspension duration on safety- and engagement-related outcomes. The experiments show that longer suspensions are more effective than shorter ones at reducing reoffense rate, the number of consequences, and the number of user reports. Further, they suggest that the effect of longer suspensions on reoffense rate wanes over time, but persists for at least 3 weeks. Finally, they demonstrate that longer suspensions are more effective for first-time violating users. These results have significant implications for theory around digitally-enforced punishments, understanding recidivism online, and the practical implementation of product changes and policy development around consequences." ;
    dcterms:identifier "3706598.3713163" ;
    chi:hasAuthor chi:person_183582, chi:person_186472, chi:person_185410 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:paperIncludesStudy chi:study_188776_FieldStudy ;
    chi:paperIncludesStudy chi:study_188776_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188776_SoftwareArtifact .

chi:study_188776_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188776 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188776_StatisticalResult .

chi:study_188776_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188776 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188776_StatisticalResult .

chi:artifact_188776_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188776 .

chi:result_188776_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188777 rdf:type chi:Paper ;
    dcterms:title "Usability, Efficacy, and Acceptability of the U.S. Cyber Trust Mark" ;
    dcterms:abstract "The U.S. Cyber Trust Mark is intended to empower consumers and enable security by demand. But is there such a demand? To explore this, we recruited 599 participants and asked them to select their desired smart device using a simulated online marketplace. Participants were informed they would receive their selected light bulbs, and they were divided into five experimental groups based on different versions of the Mark. After the product selections, we surveyed them about their priorities and preferences. We found no significant differences between the groups as a whole. However, the subset of consumers who identified cybersecurity as most important were significantly more likely to select labeled products, spending 16.5\% more. We detail these differences and preferences, then argue that an awareness program is needed to assist consumers in better understanding the long-term economic benefits of the U.S. Cyber Trust Mark." ;
    dcterms:identifier "3706598.3713463" ;
    chi:hasAuthor chi:person_185692, chi:person_186015, chi:person_187671, chi:person_184567, chi:person_186529 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:DataDisclosureAndConsent ;
    chi:paperIncludesStudy chi:study_188777_UserStudy ;
    chi:paperIncludesStudy chi:study_188777_BaselineComparisonStudy ;
    chi:paperIncludesStudy chi:study_188777_QuantitativeStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188777_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188777_DeviceArtifact .

chi:study_188777_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188777 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188777_StatisticalResult .

chi:study_188777_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188777 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188777_StatisticalResult .

chi:study_188777_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188777 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188777_StatisticalResult .

chi:artifact_188777_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188777 .

chi:artifact_188777_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188777 .

chi:result_188777_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188778 rdf:type chi:Paper ;
    dcterms:title "Designing Virtual Funerals as a Design Fiction: A Film-Based Exploration of Near-Future Memorial Rituals" ;
    dcterms:abstract "This paper explores the design and future potential of virtual funerals, enabling both in-person and remote participation, with options to digitally revisit and update the memorial site. While virtual funerals gained prominence during the COVID-19 pandemic and are often seen as temporary, the authors argue that they hold long-term value across different contexts. To investigate future funeral practices, we created a Design Fiction film depicting our concept of virtual funerals in Japan using Diegetic Prototypes–hypothetical technologies that envision a future in which these practices are normalized. Key themes include hybrid attendance, virtual memorial spaces, and technologies that bridge in-person, remote, and revisiting participants. The authors and a professional crew created the film collaboratively to illustrate these speculative elements. This paper details the film’s production, its design rationale, and the broader implications for how HCI design and technology could shape future mourning and memorialization practices." ;
    dcterms:identifier "3706598.3713399" ;
    chi:hasAuthor chi:person_185350, chi:person_182796 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:ImmersiveTrainingAndSimulation ;
    chi:proposesArtifact chi:artifact_188778_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188778_SoftwareArtifact .

chi:artifact_188778_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188778 .

chi:artifact_188778_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188778 .

chi:result_188778_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188779 rdf:type chi:Paper ;
    dcterms:title "Co-designing Large Language Model Tools for Project-Based Learning with K12 Educators" ;
    dcterms:abstract "The emergence of generative AI, particularly large language models (LLMs), has opened the door for student-centered and active learning methods like project-based learning (PBL). However, PBL poses practical implementation challenges for educators around project design and management, assessment, and balancing student guidance with student autonomy. The following research documents a co-design process with interdisciplinary K-12 teachers to explore and address the current PBL challenges they face. Through teacher-driven interviews, collaborative workshops, and iterative design of wireframes, we gathered evidence for ways LLMs can support teachers in implementing high-quality PBL pedagogy by automating routine tasks and enhancing personalized learning. Teachers in the study advocated for supporting their professional growth and augmenting their current roles without replacing them. They also identified affordances and challenges around classroom integration, including resource requirements and constraints, ethical concerns, and potential immediate and long-term impacts. Drawing on these, we propose design guidelines for future deployment of LLM tools in PBL." ;
    dcterms:identifier "3706598.3713971" ;
    chi:hasAuthor chi:person_187464, chi:person_185921, chi:person_187700, chi:person_185463, chi:person_186642, chi:person_185126, chi:person_186734, chi:person_185624, chi:person_183381, chi:person_187290 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188779_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188779_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188779_InterfaceArtifact .

chi:study_188779_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188779 ;
    chi:reportsResult chi:result_188779_QualitativeResult .

chi:study_188779_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188779 ;
    chi:reportsResult chi:result_188779_QualitativeResult .

chi:artifact_188779_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188779 .

chi:result_188779_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188781 rdf:type chi:Paper ;
    dcterms:title "IdeationWeb: Tracking the Evolution of Design Ideas in Human-AI Co-Creation" ;
    dcterms:abstract "Due to the remarkable content generation capabilities, large language models (LLMs) have demonstrated potential in supporting early-stage conceptual design. However, current interaction paradigms often struggle to effectively facilitate multi-round idea exploration and selection, leading to random outputs, unclear iterations, and cognitive overload. To address these challenges, we propose a human-AI co-ideation framework aimed at tracking the evolution of design ideas. This framework leverages a structured idea representation, an analogy-based reasoning mechanism and interactive visualization techniques. It guides both designers and AI to systematically explore design spaces. We also develop a prototype system, IdeationWeb, which integrates an intuitive, mind map-like visual interface and interactive methods to support co-ideation. Our user study validates the framework’s feasibility, demonstrating enhanced collaboration and creativity between humans and AI. Furthermore, we identified collaborative design patterns from user behaviors, providing valuable insights for future human-AI interaction design." ;
    dcterms:identifier "3706598.3713375" ;
    chi:hasAuthor chi:person_186311, chi:person_183167, chi:person_183847, chi:person_184436 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:CollaborationAndHybridWork ;
    chi:paperIncludesStudy chi:study_188781_UserStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188781_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188781_InterfaceArtifact .

chi:study_188781_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188781 ;
    chi:reportsResult chi:result_188781_QualitativeResult .

chi:artifact_188781_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188781 .

chi:artifact_188781_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188781 .

chi:result_188781_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188782 rdf:type chi:Paper ;
    dcterms:title "\"It Helps Us Express Our Feelings Without Having To Say Anything\": Exploring Accompanying Social Play Things Designed With and For Neurodiverse Groups of Children" ;
    dcterms:abstract "Social play is crucial for children's well-being and development. However, many social play technologies fail to address the specific characteristics and needs of neurodiverse play and often overlook divergent play styles. To address this, we first conducted a co-design study with a neurodiverse group of 7 children (Age 7-8) and, based on insights from these sessions, then developed a prototype, ChromaConnect, that allowed children to express their play style to one another during play. To evaluate ChromaConnect's ability to support neurodiverse social play in different contexts, we observed children using it in both structured and unstructured play settings. Our findings show that ChromaConnect enabled children to create a common language of play, made divergent play modes more visible, and facilitated explicit expression of social play initiation. We discuss how these findings could be used to design `accompanying social play things' that are more inclusive of neurodiverse play characteristics and divergent play styles." ;
    dcterms:identifier "3706598.3713738" ;
    chi:hasAuthor chi:person_187108, chi:person_187808, chi:person_183128, chi:person_183866 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188782_UserStudy ;
    chi:paperIncludesStudy chi:study_188782_FieldStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188782_DeviceArtifact .

chi:study_188782_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188782 ;
    chi:reportsResult chi:result_188782_QualitativeResult .

chi:study_188782_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188782 ;
    chi:reportsResult chi:result_188782_QualitativeResult .

chi:artifact_188782_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188782 .

chi:result_188782_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188783 rdf:type chi:Paper ;
    dcterms:title "Briteller: Shining a Light on AI Recommendations for Children" ;
    dcterms:abstract "Understanding how AI recommendations work can help the younger generation become more informed and critical consumers of the vast amount of information they encounter daily. However, young learners with limited math and computing knowledge often find AI concepts too abstract. To address this, we developed Briteller, a light-based recommendation system that makes learning tangible. By exploring and manipulating light beams, Briteller enables children to understand an AI recommender system's core algorithmic building block, the dot product, through hands-on interactions. Initial evaluations with ten middle school students demonstrated the effectiveness of this approach, using embodied metaphors, such as  \"merging light\" to represent addition. To overcome the limitations of the physical optical setup, we further explored how AR could embody multiplication, expand data vectors with more attributes, and enhance contextual understanding. Our findings provide valuable insights for designing embodied and tangible learning experiences that make AI concepts more accessible to young learners." ;
    dcterms:identifier "3706598.3714106" ;
    chi:hasAuthor chi:person_183066, chi:person_186167, chi:person_186660, chi:person_187454, chi:person_184718, chi:person_183057, chi:person_186296 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188783_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188783_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188783_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188783_SoftwareArtifact .

chi:study_188783_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188783 ;
    chi:reportsResult chi:result_188783_QualitativeResult .

chi:artifact_188783_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188783 .

chi:artifact_188783_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188783 .

chi:artifact_188783_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188783 .

chi:result_188783_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188784 rdf:type chi:Paper ;
    dcterms:title "Savouring Slow Gifts: Reflection from the Field Study of Hybrid Gifting" ;
    dcterms:abstract "Despite the prevalence of digital gifting, designing meaningful and emotionally engaging digital gifts remains a challenge. One promising approach is Hybrid gifting, which combines digital and physical elements to improve the perceived value of gifts and provide opportunities for interpersonalisation. However, there is limited understanding of how hybridity shapes the dynamics of gifting in everyday contexts. To explore this, we developed a connected coffee machine prototype as a technology probe to study how givers personalise hybrid gifts and how recipients experience them. A study with seven pairs in intimate relationships revealed key insights: hybridity fosters slow, deliberate engagement; supports personalisation aligned with daily routines; grants recipients autonomy in receiving gifts; and reveals tensions between giver anxiety and recipient enjoyment. We discuss design implications for hybrid gifting systems that encourage recipients to savour digital gifts through slow, reflective interactions." ;
    dcterms:identifier "3706598.3714048" ;
    chi:hasAuthor chi:person_187052, chi:person_184451, chi:person_184524 ;
    chi:paperIncludesStudy chi:study_188784_FieldStudy ;
    chi:paperIncludesStudy chi:study_188784_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188784_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188784_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188784_InterfaceArtifact .

chi:study_188784_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188784 ;
    chi:reportsResult chi:result_188784_QualitativeResult .

chi:study_188784_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188784 ;
    chi:reportsResult chi:result_188784_QualitativeResult .

chi:artifact_188784_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188784 .

chi:artifact_188784_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188784 .

chi:artifact_188784_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188784 .

chi:result_188784_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188785 rdf:type chi:Paper ;
    dcterms:title "Misty: UI Prototyping Through Interactive Conceptual Blending" ;
    dcterms:abstract "UI prototyping often involves iterating and blending elements from examples such as screenshots and sketches, but current tools offer limited support for incorporating these examples. Inspired by the cognitive process of conceptual blending, we introduce a novel UI workflow that allows developers to rapidly incorporate diverse aspects from design examples into work-in-progress UIs. We prototyped this workflow as Misty. Through a exploratory first-use study with 14 frontend developers, we assessed Misty's effectiveness and gathered feedback on this workflow. Our findings suggest that Misty's conceptual blending workflow helps developers kickstart creative explorations, flexibly specify intent in different stages of prototyping, and inspires developers through serendipitous UI blends. Misty demonstrates the potential for tools that blur the boundaries between developers and designers." ;
    dcterms:identifier "3706598.3713924" ;
    chi:hasAuthor chi:person_187385, chi:person_186089, chi:person_186776, chi:person_185291, chi:person_183562 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:paperIncludesStudy chi:study_188785_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188785_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188785_InterfaceArtifact .

chi:study_188785_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188785 ;
    chi:reportsResult chi:result_188785_QualitativeResult .

chi:artifact_188785_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188785 .

chi:artifact_188785_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188785 .

chi:result_188785_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188786 rdf:type chi:Paper ;
    dcterms:title "Toward Language Justice: Exploring Multilingual Captioning for Accessibility" ;
    dcterms:abstract "A growing body of research investigates how to make captioning experiences more accessible and enjoyable to disabled people. However, prior work has focused largely on English captioning, neglecting the majority of people who are multilingual (i.e., understand or express themselves in more than one language). To address this gap, we conducted semi-structured interviews and diary logs with 13 participants who used multilingual captions for accessibility. Our findings highlight the linguistic and cultural dimensions of captioning, detailing how language features (scripts and orthography) and the inclusion/negation of cultural context shape the accessibility of captions. Despite lack of quality and availability, participants emphasized the importance of multilingual captioning to learn a new language, build community, and preserve cultural heritage. Moving toward a future where all ways of communicating are celebrated, we present ways to orient captioning research to a language justice agenda that decenters English and engages with varied levels of fluency." ;
    dcterms:identifier "3706598.3713622" ;
    chi:hasAuthor chi:person_183269, chi:person_185545, chi:person_186331, chi:person_186287, chi:person_182850 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:AccessibleLearningAndSupportSystems ;
    chi:paperIncludesStudy chi:study_188786_DiaryStudy ;
    chi:paperIncludesStudy chi:study_188786_InterviewStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188786_InterfaceArtifact .

chi:study_188786_DiaryStudy rdf:type chi:DiaryStudy ;
    chi:isStudyReportedIn chi:paper_188786 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188786_QualitativeResult .

chi:study_188786_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188786 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188786_QualitativeResult .

chi:artifact_188786_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188786 .

chi:result_188786_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188789 rdf:type chi:Paper ;
    dcterms:title "Designing for Resilience: Fostering Ponds of Stability with Computer Clubs in Palestine" ;
    dcterms:abstract "Addressing the complexities of conflict-affected regions remains a critical challenge for Human-Computer Interaction (HCI). This paper examines the establishment of computer clubs in Palestinian refugee camps, where efforts to create sustainable interventions weighed against the instability of prolonged conflict. To capture this dynamic, we introduce the notion of ‘adaptive ponds of stability,’ which extends the ‘tech public of erosion’ framework [12]. While the latter emphasizes systemic depletion of socio-technical infrastructures, adaptive ponds of stability highlight efforts to foster temporary spaces of resilience. The clubs became hubs of learning, respite, and collaboration—offering moments of routine and empowerment amidst disruption. Reflecting on this, we advocate for a paradigm shift from sustainability to resilience as the primary design goal in unstable contexts. Our findings emphasize adaptability, local agency, and cultural sensitivity that respond dynamically to context-specific challenges, offering a nuanced approach to advancing HCI interventions in conflict-affected settings." ;
    dcterms:identifier "3706598.3713253" ;
    chi:hasAuthor chi:person_186930, chi:person_185207, chi:person_187852, chi:person_184318, chi:person_184715, chi:person_183772 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188789_FieldStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188789_SoftwareArtifact .

chi:study_188789_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188789 ;
    chi:reportsResult chi:result_188789_QualitativeResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:artifact_188789_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188789 .

chi:result_188789_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188790 rdf:type chi:Paper ;
    dcterms:title "Beyond the 'Unofficial Proxy' - Navigating Technology Support for Older Adults' Banking Activities with Close Others" ;
    dcterms:abstract "In the context of extensive bank branch closures, and a rapidly ageing population, older adults’ (OAs’) reluctance to adopt digital banking platforms by themselves is concerning. However, many OAs rely on the support of close others (COs) to complete banking activities with them. This support is mostly provided through “unofficial” mechanisms such as sharing online banking credentials, which risk an OA’s privacy and security. This paper replicates a Canadian study with OAs in a UK context and extends it with co-design workshops focused on novel banking solutions for OAs and COs, helping to formalise the role of unofficial proxies within online platforms. Results show that unofficial proxy banking also occurs with COs in a UK context and co-design reveals barriers to OAs’ use of banking technology independently. We discuss recommendations for flexible, easily authenticated and easy to learn digital banking solutions for OAs in the future." ;
    dcterms:identifier "3706598.3713160" ;
    chi:hasAuthor chi:person_184848, chi:person_184323, chi:person_182739, chi:person_187604 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188790_UserStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188790_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188790_InterfaceArtifact .

chi:study_188790_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188790 ;
    chi:reportsResult chi:result_188790_QualitativeResult .

chi:artifact_188790_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188790 .

chi:artifact_188790_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188790 .

chi:result_188790_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188791 rdf:type chi:Paper ;
    dcterms:title "\"The Internet is Hard. Is Words\": Investigating Information Search Difficulties Experienced by People with Aphasia and Strategies for Combatting Them" ;
    dcterms:abstract "People rely on online information for important life tasks such as managing personal finances and understanding medical symptoms. However, due to its intrinsically language-focused nature, online search poses considerable difficulties for people with language impairments. Currently these difficulties are poorly understood. We report findings from an observation of the information search behavior of 12 people with aphasia. We identify a wide range of difficulties and strategies aimed at combating them, spanning the entire information search process. Findings include previously unreported difficulties and strategies that highlight the importance of designing search technologies to better support the complex needs of people who find language challenging, such as by facilitating word finding cueing strategies, error prevention and recovery, browsing, appropriation, text interpretation and and by decreasing reliance on language competency in general. This has the potential not only to benefit searchers with language impairments, but to make information search easier for all. " ;
    dcterms:identifier "3706598.3713808" ;
    chi:hasAuthor chi:person_184151, chi:person_183700, chi:person_185261, chi:person_188013, chi:person_184189, chi:person_184876, chi:person_184970 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188791_UserStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188791_InterfaceArtifact .

chi:study_188791_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188791 ;
    chi:reportsResult chi:result_188791_QualitativeResult .

chi:artifact_188791_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188791 .

chi:result_188791_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188792 rdf:type chi:Paper ;
    dcterms:title "ProtoPCB: Reclaiming Printed Circuit Board E-waste as Prototyping Material" ;
    dcterms:abstract "We propose an interactive tool that enables reusing printed circuit boards (PCB) as prototyping materials to implement new circuits — this extends the utility of PCBs rather than discards them as e-waste. To enable this, our tool takes a user’s desired circuit schematic and analyzes its components and connections to find methods of creating the user’s circuit on discarded PCBs (e.g., e-waste, old prototypes). In our technical evaluation, we utilized our tool across a diverse set of PCBs and input circuits to characterize how often circuits could be implemented on a different board, implemented with minor interventions (trace-cutting or bodge-wiring), or implemented on a combination of multiple boards — demonstrating how our tool assists with exhaustive matching tasks that a user would not likely perform manually. We believe our tool offers: (1) a new approach to prototyping with electronics beyond the limitations of breadboards and (2) a new approach to reducing e-waste during electronics prototyping." ;
    dcterms:identifier "3706598.3714095" ;
    chi:hasAuthor chi:person_188004, chi:person_183404, chi:person_183578 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:paperIncludesStudy chi:study_188792_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188792_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188792_InterfaceArtifact .

chi:study_188792_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188792 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188792_StatisticalResult .

chi:artifact_188792_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188792 .

chi:artifact_188792_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188792 .

chi:result_188792_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188793 rdf:type chi:Paper ;
    dcterms:title "Living Alongside Areca: Exploring Human Experiences with Things Expressing Thoughts and Emotions" ;
    dcterms:abstract "Technological advancements such as LLMs have enabled everyday things to use language, fostering increased anthropomorphism during interactions. This study employs material speculation to investigate how people experience things that express their thoughts, emotions, and intentions. We utilized Areca, an air purifier capable of keeping a diary, and placed it in the everyday spaces of eight participants over three weeks. Weekly interviews were conducted to capture participants’ evolving interactions with Areca, concluding with a session collaboratively speculating on the future of everyday things. Our findings indicate that things expressing thoughts, emotions, and intentions can be perceived as possessing agency beyond mere functionality. While some participants exhibited emotional engagement with Areca over time, responses varied, including moments of detachment. We conclude with design implications for HCI designers, offering insights into how emerging technologies may shape human-thing relationships in complex ways." ;
    dcterms:identifier "3706598.3713228" ;
    chi:hasAuthor chi:person_187652, chi:person_187748 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:paperIncludesStudy chi:study_188793_FieldStudy ;
    chi:paperIncludesStudy chi:study_188793_InterviewStudy ;
    chi:proposesArtifact chi:artifact_188793_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188793_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188793_InterfaceArtifact .

chi:study_188793_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188793 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188793_QualitativeResult .

chi:study_188793_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188793 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188793_QualitativeResult .

chi:artifact_188793_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188793 .

chi:artifact_188793_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188793 .

chi:artifact_188793_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188793 .

chi:result_188793_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188795 rdf:type chi:Paper ;
    dcterms:title "Understanding the Effects of AI-based Credibility Indicators When People Are Influenced By Both Peers and Experts" ;
    dcterms:abstract "In an era marked by rampant online misinformation, artificial intelligence (AI) technologies have emerged as tools to combat this issue. This paper examines the effects of AI-based credibility indicators in people’s online information processing under the social influence from both peers and \"experts''. Via three pre-registered, randomized experiments, we confirm the effectiveness of accurate AI-based credibility indicators to enhance people's capability in judging information veracity and reduce their propensity to share false information, even under the influence from both laypeople peers and experts. Notably, these effects remain consistent regardless of whether experts' expertise is verified, with particularly significant impacts when AI predictions disagree with experts. However, the competence of AI moderates the effects, as incorrect predictions can mislead people. Furthermore, exploratory analyses suggest that under our experimental settings, the impact of the AI-based credibility indicator is larger than that of the expert's. Additionally, AI's influence on people is partially mediated through peer influence, although people automatically discount the opinions of their laypeople peers when seeing an agreement between AI and peers' opinions. We conclude by discussing the implications of utilizing AI to combat misinformation." ;
    dcterms:identifier "3706598.3713871" ;
    chi:hasAuthor chi:person_187347, chi:person_188039, chi:person_185631, chi:person_184838 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:DataDisclosureAndConsent ;
    chi:paperIncludesStudy chi:study_188795_UserStudy ;
    chi:paperIncludesStudy chi:study_188795_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188795_InterfaceArtifact .

chi:study_188795_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188795 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188795_StatisticalResult .

chi:study_188795_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188795 ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188795_StatisticalResult .

chi:artifact_188795_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188795 .

chi:result_188795_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188796 rdf:type chi:Paper ;
    dcterms:title "\"I have never seen that for Deaf people's content:\" Deaf and Hard-of-Hearing User Experiences with Misinformation, Moderation, and Debunking on Social Media in the US" ;
    dcterms:abstract "Misinformation has been studied with various social media user groups, though not with Deaf and Hard-of-hearing (DHH) individuals. To address this gap, we conducted an interview with 15 DHH participants to explore their lived experiences with misinformation and their perspectives on common moderation and debunking approaches on social media. We found that participants often experience falsehoods, and highlighted examples specific to the DHH community such as misinformation related to American Sign Language (ASL) and Deaf culture. However, moderation interventions and debunking strategies for misinformation specific to DHH topics were lacking. Written warnings may be beneficial as long as they use language appropriate for DHH people with diverse literacy skills.  Participants found visual interventions (e.g., videos) more beneficial as long as they can be appropriately captioned – which is not always the case in practice. Our findings provide practical moderation insights for DHH social media users." ;
    dcterms:identifier "3706598.3713114" ;
    chi:hasAuthor chi:person_184458, chi:person_186312, chi:person_183260 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:SocialComputing:SocialSupportAndPeerChatbots ;
    chi:paperIncludesStudy chi:study_188796_InterviewStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility .

chi:study_188796_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188796 ;
    chi:reportsResult chi:result_188796_QualitativeResult .

chi:result_188796_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188797 rdf:type chi:Paper ;
    dcterms:title "Advancing Problem-Based Learning with Clinical Reasoning for Improved Differential Diagnosis in Medical Education" ;
    dcterms:abstract "Medical education increasingly emphasizes students' ability to apply knowledge in real-world clinical settings, focusing on evidence-based clinical reasoning and differential diagnoses. Problem-based learning (PBL) addresses traditional teaching limitations by embedding learning into meaningful contexts and promoting active participation. However, current PBL practices are often confined to medical instructional settings, limiting students' ability to self-direct and refine their approaches based on targeted improvements. Additionally, the unstructured nature of information organization during analysis poses challenges for record-keeping and subsequent review. Existing research enhances PBL realism and immersion but overlooks the construction of logic chains and evidence-based reasoning. To address these gaps, we designed e-MedLearn, a learner-centered PBL system that supports more efficient application and practice of evidence-based clinical reasoning. Through controlled study (N=19) and testing interviews (N=13), we gathered data to assess the system's impact. The findings demonstrate that e-MedLearn improves PBL experiences and provides valuable insights for advancing clinical reasoning-based learning." ;
    dcterms:identifier "3706598.3713772" ;
    chi:hasAuthor chi:person_186049, chi:person_184038, chi:person_187097, chi:person_188110, chi:person_185161, chi:person_185629 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188797_UserStudy ;
    chi:paperIncludesStudy chi:study_188797_InterviewStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188797_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188797_InterfaceArtifact .

chi:study_188797_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188797 ;
    chi:reportsResult chi:result_188797_QualitativeResult .

chi:study_188797_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188797 ;
    chi:reportsResult chi:result_188797_QualitativeResult .

chi:artifact_188797_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188797 .

chi:artifact_188797_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188797 .

chi:result_188797_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188798 rdf:type chi:Paper ;
    dcterms:title "InterFACE: Establishing a Facial Action Unit Input Vocabulary for Hands-Free Extended Reality Interactions, From VR Gaming to AR Web Browsing" ;
    dcterms:abstract "Extended Reality (XR) interactions often rely on spatial hand or controller inputs - necessitating dexterous wrist, hand and finger movements including pressing virtual buttons, pinching to select, and performing hand gestures. However, there are scenarios where such dependencies may render XR devices and apps inaccessible to users - from situational/temporary impairments such as encumbrance, to physical motor impairments. In this paper, we contribute to a growing literature considering facial input as an alternative. In a user study (N=20) we systematically evaluate the usability of 53 Facial Action Units in VR, deriving a set of optimal (comfort, effort, performance) FAUs for interaction. We then use these facial inputs to drive and evaluate (N=10) two demonstrator apps: VR locomotion, and AR web browsing, showcasing how close facial interaction can get to existing baselines, and demonstrating that FAUs offer a viable, generalizable input modality for XR devices." ;
    dcterms:identifier "3706598.3713694" ;
    chi:hasAuthor chi:person_184663, chi:person_184709, chi:person_185075, chi:person_185074, chi:person_184156, chi:person_185850 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:paperIncludesStudy chi:study_188798_UserStudy ;
    chi:paperIncludesStudy chi:study_188798_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188798_InputDeviceArtifact ;
    chi:proposesArtifact chi:artifact_188798_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188798_SoftwareArtifact .

chi:study_188798_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188798 ;
    chi:hasMeasure chi:PerformanceMeasure ;
    chi:reportsResult chi:result_188798_StatisticalResult .

chi:study_188798_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188798 ;
    chi:hasMeasure chi:PerformanceMeasure ;
    chi:reportsResult chi:result_188798_StatisticalResult .

chi:artifact_188798_InputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188798 .

chi:artifact_188798_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188798 .

chi:artifact_188798_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188798 .

chi:result_188798_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188799 rdf:type chi:Paper ;
    dcterms:title "Autonomous Regulation of Social Media Use: Implications for Self-control, Well-Being, and UX" ;
    dcterms:abstract "Much work in HCI has investigated strategies for supporting autonomous self-regulation in social media use (SMU): helping users to control their time online and ensure it serves personally valued outcomes. However, results suggest that the effectiveness and acceptability of these strategies may vary based on individual needs. Recent work has attributed this variation to motivational factors, though we currently lack data to understand how these factors influence self-regulation, user experience and well-being. We draw on Self-Determination Theory to analyse autonomous and non-autonomous patterns of motivation in 521 users of social media. Using latent profile analysis, we identify 4 ``motivational profiles'' associated with significant differences in need satisfaction, affect, and compulsive engagement.  Our results clarify distinct aspects of autonomy in SMU and identify opportunities to target and personalise design interventions; they suggest autonomous regulation can be associated with better experience and well-being, though not necessarily less time online." ;
    dcterms:identifier "3706598.3713094" ;
    chi:hasAuthor chi:person_186635, chi:person_184642, chi:person_182888 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:SelfReflectionAndBehaviorChange ;
    chi:paperIncludesStudy chi:study_188799_QuantitativeStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement .

chi:study_188799_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188799 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188799_StatisticalResult .

chi:result_188799_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188800 rdf:type chi:Paper ;
    dcterms:title "Beyond Time and Accuracy: Strategies in Visual Problem-Solving" ;
    dcterms:abstract "In this paper, we explore viewers’ strategies in visual problem-solving tasks. We build on the traditional metrics of accuracy and time to better understand the learning that occurs as individuals interact with visualizations. We conducted an in-lab eye-tracking user study with 53 participants from diverse demographic backgrounds. Using questions from the Visualization Literacy Assessment Test (VLAT), we examined participants’ problem-solving strategies. We employed a mixed-methods approach capturing quantitative data on performance and gaze patterns, as well as qualitative data through think-alouds and sketches by participants as they reported on their problem-solving approach. Our analysis reveals not only the various cognitive strategies leading to correct answers but also the nature of mistakes and the conceptual misunderstandings that underlie them. This research contributes to the enhancement of visualization design guidelines by incorporating insights into the diverse strategies and cognitive processes employed by users." ;
    dcterms:identifier "3706598.3714024" ;
    chi:hasAuthor chi:person_186766, chi:person_185156, chi:person_184065, chi:person_184267, chi:person_186608, chi:person_185266 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:CollaborativeVisualizationTools ;
    chi:paperIncludesStudy chi:study_188800_ThinkAloudStudy ;
    chi:paperIncludesStudy chi:study_188800_UserStudy ;
    chi:paperIncludesStudy chi:study_188800_QuantitativeStudy ;
    chi:paperIncludesStudy chi:study_188800_QualitativeStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188800_InterfaceArtifact .

chi:study_188800_ThinkAloudStudy rdf:type chi:ThinkAloudStudy ;
    chi:isStudyReportedIn chi:paper_188800 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188800_QualitativeResult ;
    chi:reportsResult chi:result_188800_StatisticalResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:study_188800_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188800 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188800_QualitativeResult ;
    chi:reportsResult chi:result_188800_StatisticalResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:study_188800_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188800 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188800_QualitativeResult ;
    chi:reportsResult chi:result_188800_StatisticalResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:study_188800_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188800 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:hasMeasure chi:AccuracyMeasure ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188800_QualitativeResult ;
    chi:reportsResult chi:result_188800_StatisticalResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:artifact_188800_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188800 .

chi:result_188800_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188800_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188801 rdf:type chi:Paper ;
    dcterms:title "FamiData Hub: A Speculative Design Exploration with Families on Smart Home Datafication" ;
    dcterms:abstract "Smart home technologies are becoming increasingly common in households with children. While privacy and security concerns have been widely discussed, a critical issue often overlooked is the extensive data harvesting embedded in these smart homes and its manipulative impact on children through algorithmic decision-making. In this paper, we introduce FamiData Hub, a speculative prototype designed to empower families to navigate the datafication of smart homes. Through 17 study sessions—including speculative interviews followed by co-design activities—with 30 children and 25 parents, we found that families face challenges related to smart home datafication, such as the erosion of boundaries in family spaces, loss of control over family norms, and diminished autonomy in data-driven decision-making processes. Our findings offer key design recommendations for rethinking smart home technologies to better safeguard children's data, advocating for respectful, family-centered approaches that challenge the normalization of datafication in domestic life. " ;
    dcterms:identifier "3706598.3713494" ;
    chi:hasAuthor chi:person_185608, chi:person_187623, chi:person_183113, chi:person_184183, chi:person_184672 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:DataDisclosureAndConsent ;
    chi:paperIncludesStudy chi:study_188801_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188801_UserStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188801_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188801_InterfaceArtifact .

chi:study_188801_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188801 ;
    chi:reportsResult chi:result_188801_QualitativeResult .

chi:study_188801_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188801 ;
    chi:reportsResult chi:result_188801_QualitativeResult .

chi:artifact_188801_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188801 .

chi:artifact_188801_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188801 .

chi:result_188801_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188802 rdf:type chi:Paper ;
    dcterms:title "Enhancing Pediatric Communication: The Role of an AI-Driven Chatbot in Facilitating Child-Parent-Provider Interaction" ;
    dcterms:abstract "Communication with child patients is challenging due to their developing ability to express emotions and symptoms. Additionally, healthcare providers often have limited time to offer resources to parents. By leveraging AI to facilitate free-form conversations, our study aims to design an AI-driven chatbot to bridge these gaps in child-parent-provider communication. We conducted two studies: 1) design sessions with 12 children with cancer and their parents, which informed the development of our chatbot, ARCH, and 2) an interview study with 15 pediatric care experts to identify potential challenges and refine ARCH's role in pediatric communication. Our findings highlight three key roles for ARCH: providing an expressive outlet for children, offering reassurance to parents, and serving as an assessment tool for providers. We conclude by discussing design considerations for AI-driven chatbots in pediatric communication, such as creating communication spaces, balancing the expectations of children and parents, and addressing potential cultural differences." ;
    dcterms:identifier "3706598.3713134" ;
    chi:hasAuthor chi:person_183279, chi:person_185361, chi:person_183375, chi:person_184791, chi:person_184024, chi:person_184770, chi:person_187943 ;
    chi:hasPrimaryTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialComputing ;
    chi:aboutTopic chi:SocialSupportAndPeerChatbots ;
    chi:paperIncludesStudy chi:study_188802_UserStudy ;
    chi:paperIncludesStudy chi:study_188802_InterviewStudy ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188802_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188802_InterfaceArtifact .

chi:study_188802_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188802 ;
    chi:reportsResult chi:result_188802_QualitativeResult .

chi:study_188802_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188802 ;
    chi:reportsResult chi:result_188802_QualitativeResult .

chi:artifact_188802_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188802 .

chi:artifact_188802_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188802 .

chi:result_188802_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188805 rdf:type chi:Paper ;
    dcterms:title "ProductMeta: An Interactive System for Metaphorical Product Design Ideation with Multimodal Large Language Models" ;
    dcterms:abstract "Product metaphors, which involve creating products that convey meaning through metaphorical associations, are a powerful tool in product design. However, according to our formative study, novice designers often struggle to establish coherent links between target and source, to manage the complexity of diverse mapping possibilities and to balance product usability with metaphorical expression. To address these challenges, we introduce ProductMeta, a creativity support tool designed to support novice designers in exploring and developing metaphorical product designs. ProductMeta incorporates domain knowledge and decomposes the design process into iterative modules and framework-based interfaces, fostering both divergent and convergent thinking. Through user studies, we demonstrate that ProductMeta enables novice designers to generate diverse and contextually relevant design ideas by facilitating structured exploration. We conclude with design implications for human-AI co-creation." ;
    dcterms:identifier "3706598.3713935" ;
    chi:hasAuthor chi:person_184308, chi:person_183605, chi:person_185252, chi:person_186514, chi:person_187268, chi:person_184916, chi:person_183014, chi:person_187925, chi:person_184174, chi:person_184939 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:CollaborativeVisualizationTools ;
    chi:paperIncludesStudy chi:study_188805_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188805_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188805_InterfaceArtifact .

chi:study_188805_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188805 ;
    chi:reportsResult chi:result_188805_QualitativeResult .

chi:artifact_188805_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188805 .

chi:artifact_188805_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188805 .

chi:result_188805_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188806 rdf:type chi:Paper ;
    dcterms:title "Haptic Empathy: Investigating Individual Differences in Affective Haptic Communications" ;
    dcterms:abstract "Nowadays, touch remains essential for emotional conveyance and interpersonal communication as more interactions are mediated remotely. While many studies have discussed the effectiveness of using haptics to communicate emotions, incorporating affect into haptic design still faces challenges due to individual user tactile acuity and preferences. We assessed the conveying of emotions using a two-channel haptic display, emphasizing individual differences. First, 24 participants generated 187 haptic messages reflecting their immediate sentiments after watching 8 emotionally charged film clips. Afterwards, 19 participants were asked to identify emotions from haptic messages designed by themselves and others, yielding 593 samples. Our findings indicate that the ability to decode haptic messages is linked to specific emotional traits, particularly Emotional Competence (EC) and Affect Intensity Measure (AIM). Additionally, qualitative analysis revealed three strategies participants used to create touch messages: perceptive, empathetic, and metaphorical expression." ;
    dcterms:identifier "3706598.3714139" ;
    chi:hasAuthor chi:person_187798, chi:person_185360, chi:person_185651, chi:person_187553, chi:person_184750, chi:person_187260, chi:person_183207, chi:person_183411, chi:person_187638 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:paperIncludesStudy chi:study_188806_UserStudy ;
    chi:proposesArtifact chi:artifact_188806_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188806_OutputDeviceArtifact .

chi:study_188806_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188806 ;
    chi:reportsResult chi:result_188806_QualitativeResult ;
    chi:reportsResult chi:result_188806_StatisticalResult .

chi:artifact_188806_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188806 .

chi:artifact_188806_OutputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188806 .

chi:result_188806_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188806_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188807 rdf:type chi:Paper ;
    dcterms:title "Generative AI Uses and Risks for Knowledge Workers in a Science Organization" ;
    dcterms:abstract "Generative AI could enhance scientific discovery by supporting knowledge workers in science organizations. However, the real-world applications and perceived concerns of generative AI use in these organizations are uncertain. In this paper, we report on a collaborative study with a US national laboratory with employees spanning Science and Operations about their use of generative AI tools. We surveyed 66 employees, interviewed a subset (N=22), and measured early adoption of an internal generative AI interface called Argo lab-wide. We have four findings: (1) Argo usage data shows small but increasing use by Science and Operations employees; Common current and envisioned use cases for generative AI in this context conceptually fall into either a (2) copilot or (3) workflow agent modality; and (4) Concerns include sensitive data security, academic publishing, and job impacts. Based on our findings, we make recommendations for generative AI use in science and other organizations." ;
    dcterms:identifier "3706598.3713827" ;
    chi:hasAuthor chi:person_184954, chi:person_187298, chi:person_185653 ;
    chi:hasPrimaryTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:PhysicalDigitalWorkflowIntegration ;
    chi:paperIncludesStudy chi:study_188807_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188807_UserStudy ;
    chi:paperIncludesStudy chi:study_188807_FieldStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188807_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188807_SoftwareArtifact .

chi:study_188807_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188807 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188807_QualitativeResult ;
    chi:reportsResult chi:result_188807_StatisticalResult .

chi:study_188807_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188807 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188807_QualitativeResult ;
    chi:reportsResult chi:result_188807_StatisticalResult .

chi:study_188807_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188807 ;
    chi:usesInstrument chi:LoggingInstrumentation ;
    chi:reportsResult chi:result_188807_QualitativeResult ;
    chi:reportsResult chi:result_188807_StatisticalResult .

chi:artifact_188807_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188807 .

chi:artifact_188807_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188807 .

chi:result_188807_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188807_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188808 rdf:type chi:Paper ;
    dcterms:title "Participatory AI Considerations for Advancing Racial Health Equity" ;
    dcterms:abstract "Health-related artificial intelligence (health AI) systems are being rapidly created, largely without input from racially minoritized communities who experience persistent health inequities and stand to be negatively affected if these systems are poorly designed. Addressing this problematic trend, we critically review prior work focused on the participatory design of health AI innovations (participatory AI research), surfacing eight gaps in this work that inhibit racial health equity and provide strategies for addressing these gaps. Our strategies emphasize that “participation” in design must go beyond typical focus areas of data collection, annotation, and application co-design, to also include co-generating overarching health AI agendas and policies. Further, participatory AI methods must prioritize community-centered design that supports collaborative learning around health equity and AI, addresses root causes of inequity and AI stakeholder power dynamics, centers relationalism and emotion, supports flourishing, and facilitates longitudinal design. These strategies will help catalyze research that advances racial health equity." ;
    dcterms:identifier "3706598.3713165" ;
    chi:hasAuthor chi:person_184608, chi:person_183486, chi:person_187284, chi:person_184987 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:ParticipatoryEthicsMethods ;
    chi:aimsAtGoal chi:EnhanceAccessibility .

chi:result_188808_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188810 rdf:type chi:Paper ;
    dcterms:title "From Participation to Solidarity: A Case Study on Access of Maker Spaces from Deaf and Hearing Perspectives" ;
    dcterms:abstract "This submission is an edited translation of an article previously published in German.  Participatory methods open up research in Human-Computer Interaction (HCI) that aim at involving populations that are not traditionally represented. However, they do not require researchers to actively reflect on power relationships as would be required when aiming for transformative impact. In our case study of MACH’S AUF!, we show how research on accessibility of makerspaces for deaf people allowed us to develop a methodological concept of solidarity driven research that extends classical concepts of participation.  We show how access to makerspaces has to be understood first and foremost as structured in a socio-technical manner, where communicative access for deaf people has to be provided through sign language.  Our work provides a nuanced understanding of what access to makerspaces might entail from a marginalised perspective, as well as a methodological positionality that may support transformative research endeavours in the future." ;
    dcterms:identifier "3706598.3713202" ;
    chi:hasAuthor chi:person_183816, chi:person_182872, chi:person_184726, chi:person_187846 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188810_FieldStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility .

chi:study_188810_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188810 ;
    chi:reportsResult chi:result_188810_QualitativeResult .

chi:result_188810_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188811 rdf:type chi:Paper ;
    dcterms:title "Dancing With Chains: Ideating Under Constraints With UIDEC in UI/UX Design" ;
    dcterms:abstract "UI/UX designers often work under constraints like brand identity, design norms, and industry guidelines. How these constraints impact designers' ideation and exploration processes should be addressed in creativity-support tools for design. Through an exploratory interview study, we identified three designer personas with varying views on having constraints in the ideation process, which guided the creation of UIDEC, a GenAI-powered tool for supporting creativity under constraints. UIDEC allows designers to specify project details, such as purpose, target audience, industry, and design styles, based on which it generates diverse design examples that adhere to these constraints, with minimal need to write prompts. In a user evaluation involving designers representing the identified personas, participants found UIDEC compatible with their existing ideation process and useful for creative inspiration, especially when starting new projects. Our work provides design implications to AI-powered tools that integrate constraints during UI/UX design ideation to support creativity." ;
    dcterms:identifier "3706598.3713785" ;
    chi:hasAuthor chi:person_183288, chi:person_182922, chi:person_183077, chi:person_183828, chi:person_186643 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:paperIncludesStudy chi:study_188811_InterviewStudy ;
    chi:paperIncludesStudy chi:study_188811_UserStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188811_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188811_InterfaceArtifact .

chi:study_188811_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188811 ;
    chi:reportsResult chi:result_188811_QualitativeResult .

chi:study_188811_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188811 ;
    chi:reportsResult chi:result_188811_QualitativeResult .

chi:artifact_188811_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188811 .

chi:artifact_188811_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188811 .

chi:result_188811_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188813 rdf:type chi:Paper ;
    dcterms:title "A Systematic Literature Review to Characterize Asymmetric Interaction in Collaborative Systems" ;
    dcterms:abstract "Computer-mediated collaboration often relies on symmetrical interactions between users, where all the collaborators use identical devices. However, in some cases, either due to constraints (e.g. users in different environments) or by choice (e.g. using devices with different properties), users engage in asymmetrical interactions. Addressing such asymmetries in heterogeneous systems can be difficult as there has been no systematic analysis of how to define them, or their impact on collaboration. In this paper, we characterize the asymmetries that can arise between users’ interactions within collaborative heterogeneous systems. To this end, we conduct a systematic literature review of asymmetric collaborative systems, coding their properties, including the interaction spaces, their input and output modalities, and shared feedback. We then define the dimensions of asymmetry that emerge from this review. We discuss their impact on collaboration and outline a set of challenges and opportunities for future research." ;
    dcterms:identifier "3706598.3713129" ;
    chi:hasAuthor chi:person_183904, chi:person_188134, chi:person_183979, chi:person_186951 ;
    chi:hasPrimaryTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:CollaborationAndHybridWork ;
    chi:aimsAtGoal chi:SupportCollaboration ;
    chi:proposesArtifact chi:artifact_188813_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188813_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188813_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188813_InputDeviceArtifact ;
    chi:proposesArtifact chi:artifact_188813_OutputDeviceArtifact .

chi:artifact_188813_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188813 .

chi:artifact_188813_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188813 .

chi:artifact_188813_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188813 .

chi:artifact_188813_InputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188813 .

chi:artifact_188813_OutputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188813 .

chi:result_188813_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188814 rdf:type chi:Paper ;
    dcterms:title "VisUnit: Literate Visualisation Studies Assembled from Reusable Test-Suites" ;
    dcterms:abstract "We make four contributions to lower the overhead of conducting visualisation user studies and promote the reuse and extension of their materials. (i) A declarative Javascript specification lets experimenters describe how studies are assembled from tested visualisations, datasets, tasks and chosen evaluation strategies. (ii) A VisUnit library translates these into sequences of visual stimuli and delivers them to participants. We move away from monolithic evaluation stimuli typical of previous work and construct studies around three ingredients -- visual encodings, datasets, and tasks -- that can be developed independently and recombined flexibly. (iii) This paves the way for developing benchmark data+tasks test-suites as independent, reusable resources to support multiple studies. (iv) Structuring user studies as ``literate'' visualisation notebooks brings together in the open all ingredients necessary for replication and scrutiny:  formal design specification; underlying materials; participant-facing views; and narratives justifying design and supporting reuse. " ;
    dcterms:identifier "3706598.3713104" ;
    chi:hasAuthor chi:person_186216, chi:person_185943, chi:person_182786, chi:person_186599 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:DesignAndFabricationWorkflowTools ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188814_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188814_InterfaceArtifact .

chi:artifact_188814_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188814 .

chi:artifact_188814_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188814 .

chi:paper_188815 rdf:type chi:Paper ;
    dcterms:title "WanderGuide: Indoor Map-less Robotic Guide for Exploration by Blind People" ;
    dcterms:abstract "Blind people have limited opportunities to explore an environment based on their interests. While existing navigation systems could provide them with surrounding information while navigating, they have limited scalability as they require preparing prebuilt maps. Thus, to develop a map-less robot that assists blind people in exploring, we first conducted a study with ten blind participants at a shopping mall and science museum to investigate the requirements of the system, which revealed the need for three levels of detail to describe the surroundings based on users' preferences. Then, we developed WanderGuide, with functionalities that allow users to adjust the level of detail in descriptions and verbally interact with the system to ask questions about the environment or to go to points of interest. The study with five blind participants revealed that WanderGuide could provide blind people with the enjoyable experience of wandering around without a specific destination in their minds." ;
    dcterms:identifier "3706598.3713788" ;
    chi:hasAuthor chi:person_184728, chi:person_183775, chi:person_185881, chi:person_184391, chi:person_184406 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:aboutTopic chi:AccessibilityNavigationSupport:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188815_FieldStudy ;
    chi:paperIncludesStudy chi:study_188815_UserStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility ;
    chi:proposesArtifact chi:artifact_188815_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188815_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188815_InterfaceArtifact .

chi:study_188815_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188815 ;
    chi:reportsResult chi:result_188815_QualitativeResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:study_188815_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188815 ;
    chi:reportsResult chi:result_188815_QualitativeResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:artifact_188815_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188815 .

chi:artifact_188815_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188815 .

chi:artifact_188815_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188815 .

chi:result_188815_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188816 rdf:type chi:Paper ;
    dcterms:title "Emerging Data Practices: Data Work in the Era of Large Language Models" ;
    dcterms:abstract "Data is one of the foundational aspects of making Artificial Intelligence (AI) work as intended. As large language models  (LLMs) become the epicenter of AI, it is crucial to understand better how the datasets that maintain such models are created. The emergent nature of LLMs makes it critical to understand the challenges practitioners developing Gen AI technologies face to design alternatives for better responding to Gen AI's ethical issues. In this paper, we provide such understanding by reporting on 25 interviews with practitioners who handle data in three distinct development stages of different LLMs. Our contributions are (1) empirical evidence of how uncertainty, data practices, and reliance mechanisms change across LLMs' development cycle; (2) how the unique qualities of LLMs impact data practices and their implications for the future of Gen AI technologies; and (3) provide three opportunities for HCI researchers interested in supporting practitioners developing Gen AI technologies." ;
    dcterms:identifier "3706598.3714069" ;
    chi:hasAuthor chi:person_186369, chi:person_184966, chi:person_186376, chi:person_187784 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:paperIncludesStudy chi:study_188816_InterviewStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking .

chi:study_188816_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188816 ;
    chi:reportsResult chi:result_188816_QualitativeResult .

chi:result_188816_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188817 rdf:type chi:Paper ;
    dcterms:title "Support Autonomy: Exploring Player Perspectives on AI-Supported Onboarding in Video Games" ;
    dcterms:abstract "Video game onboarding faces the challenge of teaching game mechanics in a fun and engaging way. Artificial intelligence (AI) solutions have become a quick fix to help users understand technology. However, little is known about how AI supports player onboarding in video games. To address this knowledge gap, this research explores player perspectives on AI-supported onboarding. We conducted a qualitative user study (n=20) to investigate player expectations, attitudes, and concerns about AI-supported learning experiences. Players learn primarily through the lived experience of a game and value personalized guidance during onboarding. Participants emphasized the importance of maintaining control over how AI is used during onboarding and the freedom to choose their support level. Our results suggest that players want future AI-supported onboarding systems to prioritize their agency, encourage active learning, and maintain transparency throughout the learning process. We contribute to game design research by proposing balanced, player-centric AI-supported onboarding experiences in video games." ;
    dcterms:identifier "3706598.3713576" ;
    chi:hasAuthor chi:person_183228, chi:person_187895, chi:person_184035, chi:person_182948, chi:person_186893 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188817_UserStudy ;
    chi:paperIncludesStudy chi:study_188817_QualitativeStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188817_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188817_InterfaceArtifact .

chi:study_188817_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188817 ;
    chi:reportsResult chi:result_188817_QualitativeResult .

chi:study_188817_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188817 ;
    chi:reportsResult chi:result_188817_QualitativeResult .

chi:artifact_188817_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188817 .

chi:artifact_188817_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188817 .

chi:result_188817_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188818 rdf:type chi:Paper ;
    dcterms:title "Origami Sensei: A Mixed Reality AI-Assistant" ;
    dcterms:abstract "Learning creative hands-on skills, like origami, can be difficult for beginners. Conventional instructional methods often fail to support the experiential aspect of learning with timely and personalized feedback. Despite recent advancement of AI and Extended Reality in many fields, there is a lack of research on supporting learning in creative hands-on tasks. We investigate an AI-augmented Mixed Reality approach for learning hands-on creative tasks by introducing Origami Sensei as an approach for learning origami. Origami Sensei identifies the current step and relative locations of the paper using origami detection models, and projects real-time, personalized instructions directly onto the paper. We conducted a user study (n=18) comparing it with traditional video tutorials. Our findings show that participants prefer Origami Sensei, and it increases task efficiency and learner engagement. We introduce design insights for developing AI-augmented MR systems and highlight the potential for extending this approach to other creative hands-on tasks." ;
    dcterms:identifier "3706598.3714099" ;
    chi:hasAuthor chi:person_185099, chi:person_187110, chi:person_187193, chi:person_184128, chi:person_185061 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:paperIncludesStudy chi:study_188818_UserStudy ;
    chi:paperIncludesStudy chi:study_188818_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188818_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188818_InterfaceArtifact .

chi:study_188818_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188818 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:reportsResult chi:result_188818_QualitativeResult ;
    chi:reportsResult chi:result_188818_StatisticalResult .

chi:study_188818_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188818 ;
    chi:hasMeasure chi:CompletionTimeMeasure ;
    chi:reportsResult chi:result_188818_QualitativeResult ;
    chi:reportsResult chi:result_188818_StatisticalResult .

chi:artifact_188818_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188818 .

chi:artifact_188818_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188818 .

chi:result_188818_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188818_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188819 rdf:type chi:Paper ;
    dcterms:title "Friction: Deciphering Writing Feedback into Writing Revisions through LLM-Assisted Reflection" ;
    dcterms:abstract "This paper introduces Friction, a novel interface designed to scaffold novice writers in reflective feedback-driven revisions. Effective revision requires mindful reflection upon feedback, but the scale and variability of feedback can make it challenging for novice writers to decipher it into actionable, meaningful changes. Friction leverages large language models to break down large feedback collections into manageable units, visualizes their distribution across sentences and issues through a co-located heatmap, and guides users through structured reflection and revision with adaptive hints and real-time evaluation. Our user study (N=16) showed that Friction helped users allocate more time to reflective planning, attend to more critical issues, develop more actionable and satisfactory revision plans, iterate more frequently, and ultimately produce higher-quality revisions, compared to the baseline system. These findings highlight the potential of human-AI collaboration to foster a balanced approach between maximum efficiency and deliberate reflection, supporting the development of creative mastery." ;
    dcterms:identifier "3706598.3714316" ;
    chi:hasAuthor chi:person_185671, chi:person_183051, chi:person_186459, chi:person_184060, chi:person_188043 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:QualitativeAnalysisSupportTools ;
    chi:paperIncludesStudy chi:study_188819_BaselineComparisonStudy ;
    chi:paperIncludesStudy chi:study_188819_UserStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188819_InterfaceArtifact ;
    chi:proposesArtifact chi:artifact_188819_SoftwareArtifact .

chi:study_188819_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188819 ;
    chi:reportsResult chi:result_188819_StatisticalResult ;
    chi:reportsResult chi:result_188819_QualitativeResult .

chi:study_188819_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188819 ;
    chi:reportsResult chi:result_188819_StatisticalResult ;
    chi:reportsResult chi:result_188819_QualitativeResult .

chi:artifact_188819_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188819 .

chi:artifact_188819_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188819 .

chi:result_188819_StatisticalResult rdf:type chi:StatisticalResult .

chi:result_188819_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188820 rdf:type chi:Paper ;
    dcterms:title "Invisible Light Touch: Standing Balance Improvement by Mid-Air Haptic Feedback" ;
    dcterms:abstract "Improving standing balance is critical for preventing falls and ensuring the well-being of older adults. In this paper, we present Invisible Light Touch (ILT), a mid-air haptic feedback application designed to improve standing balance by utilizing the light touch effect, a well-documented phenomenon in medical research. The light touch effect refers to improved balance when a person lightly touches a surface, such as a wall or handrail, with a force of 1 N or less. We replicate this effect utilizing focused ultrasound to create a tactile point in mid-air. When users interact with this invisible tactile point, they experience the light touch effect, which subsequently improves their balance. We conducted a pilot study with 29 participants and a user study with 25 older adults, evaluating the balance improvement by measuring the center of pressure trajectory. The results confirmed that standing balance improved significantly when using the ILT." ;
    dcterms:identifier "3706598.3713396" ;
    chi:hasAuthor chi:person_185300, chi:person_183389, chi:person_185026 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:paperIncludesStudy chi:study_188820_UserStudy ;
    chi:proposesArtifact chi:artifact_188820_DeviceArtifact ;
    chi:proposesArtifact chi:artifact_188820_OutputDeviceArtifact .

chi:study_188820_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188820 ;
    chi:usesInstrument chi:SensorInstrument ;
    chi:reportsResult chi:result_188820_StatisticalResult .

chi:artifact_188820_DeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188820 .

chi:artifact_188820_OutputDeviceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188820 .

chi:result_188820_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188821 rdf:type chi:Paper ;
    dcterms:title "TutorUp: What If Your Students Were Simulated? Training Tutors to Address Engagement Challenges in Online Learning" ;
    dcterms:abstract "With the rise of online learning, many novice tutors lack experience engaging students remotely. We introduce TutorUp, a Large Language Model (LLM)-based system that enables novice tutors to practice engagement strategies with simulated students through scenario-based training. Based on a formative study involving two surveys (N1=86, N2=102) on student engagement challenges, we summarize scenarios that mimic real teaching situations. To enhance immersion and realism, we employ a prompting strategy that simulates dynamic online learning dialogues. TutorUp provides immediate and asynchronous feedback by referencing tutor-students online session dialogues and evidence-based teaching strategies from learning science literature. In a within-subject evaluation (N=16), participants rated TutorUp significantly higher than a baseline system without simulation capabilities regarding effectiveness and usability. Our findings suggest that TutorUp provides novice tutors with more effective training to learn and apply teaching strategies to address online student engagement challenges. " ;
    dcterms:identifier "3706598.3713589" ;
    chi:hasAuthor chi:person_186284, chi:person_182836, chi:person_184324, chi:person_186428, chi:person_183869, chi:person_185721, chi:person_184117, chi:person_185358 ;
    chi:hasPrimaryTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:LearningAndEducation ;
    chi:aboutTopic chi:EngagingLearningActivities ;
    chi:paperIncludesStudy chi:study_188821_UserStudy ;
    chi:paperIncludesStudy chi:study_188821_BaselineComparisonStudy ;
    chi:aimsAtGoal chi:PromoteLearning ;
    chi:proposesArtifact chi:artifact_188821_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188821_InterfaceArtifact .

chi:study_188821_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188821 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:reportsResult chi:result_188821_StatisticalResult ;
    chi:involvesParticipationPattern chi:AsynchronousParticipation .

chi:study_188821_BaselineComparisonStudy rdf:type chi:BaselineComparisonStudy ;
    chi:isStudyReportedIn chi:paper_188821 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:hasMeasure chi:UsabilityRatingMeasure ;
    chi:reportsResult chi:result_188821_StatisticalResult ;
    chi:involvesParticipationPattern chi:AsynchronousParticipation .

chi:artifact_188821_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188821 .

chi:artifact_188821_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188821 .

chi:result_188821_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188822 rdf:type chi:Paper ;
    dcterms:title "How the Role of Generative AI Shapes Perceptions of Value in Human-AI Collaborative Work" ;
    dcterms:abstract "As artificial intelligence (AI) continues to transform the modern workplace, generative AI (GenAI) has emerged as a prominent tool capable of augmenting work processes. Defined by its ability to create or modify content, GenAI differs significantly from traditional machine learning models that classify, recognize, or predict patterns from existing data. This study explores the role of GenAI in shaping perceptions of AI’s contribution and how these perceptions influence both creators’ internal assessments of their work and their anticipation of external evaluators’ assessments. Our research develops and empirically tests a structural model through a between-subjects experiment, revealing that the role GenAI plays in the work process significantly impacts perceived enhancements in work quality and effort relative to human input. Additionally, we identify a critical trade-off between fostering worker assessments of creativity and managing perceived external assessments of the work’s value." ;
    dcterms:identifier "3706598.3713946" ;
    chi:hasAuthor chi:person_183577, chi:person_183930 ;
    chi:hasPrimaryTopic chi:CollaborationAndHybridWork ;
    chi:aboutTopic chi:CollaborationAndHybridWork ;
    chi:paperIncludesStudy chi:study_188822_UserStudy ;
    chi:paperIncludesStudy chi:study_188822_QuantitativeStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188822_SoftwareArtifact .

chi:study_188822_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188822 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188822_StatisticalResult .

chi:study_188822_QuantitativeStudy rdf:type chi:QuantitativeStudy ;
    chi:isStudyReportedIn chi:paper_188822 ;
    chi:hasMeasure chi:LikertScaleMeasure ;
    chi:reportsResult chi:result_188822_StatisticalResult .

chi:artifact_188822_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188822 .

chi:result_188822_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188823 rdf:type chi:Paper ;
    dcterms:title "Modes of Interaction with Navigation Apps" ;
    dcterms:abstract "Despite many HCI studies of diverse factors shaping users’ navigation experiences, how to design navigation systems to be adaptable to all of these factors remains a challenge. To address this challenge, we study general variations in users’ intended navigation experiences. Based on 30 interviews, we find that interactions with navigation apps can be subsumed under three “modes”: follow, modify, and background. For each mode of interaction, we highlight users’ key motivations, interactions with apps, and challenges. We propose these modes as higher-level concepts for exploring how to enable the details of navigation support to be adaptable to users’ generally intended navigation experiences. We discuss broader implications for issues of efficiency and overreliance in our experience of the physical environments through navigation apps." ;
    dcterms:identifier "3706598.3714180" ;
    chi:hasAuthor chi:person_183054, chi:person_185591 ;
    chi:hasPrimaryTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:AccessibilityNavigationSupport ;
    chi:aboutTopic chi:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188823_InterviewStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188823_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188823_InterfaceArtifact .

chi:study_188823_InterviewStudy rdf:type chi:InterviewStudy ;
    chi:isStudyReportedIn chi:paper_188823 ;
    chi:reportsResult chi:result_188823_QualitativeResult .

chi:artifact_188823_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188823 .

chi:artifact_188823_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188823 .

chi:result_188823_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188824 rdf:type chi:Paper ;
    dcterms:title "A Novel Lens on Metacognition in Visualization" ;
    dcterms:abstract "Metacognition, or the awareness and regulation of one's own cognitive processes, allows individuals to take command of their learning and decision making in various contexts. In tasks that require problem-solving and adaptive learning,  individuals with heightened metacognitive awareness tend to outperform others, as they are better equipped to regulate cognition, leading to more effective processes. On the other hand, visualization research facilitates exploration and decision making with data. We posit that metacognitive frameworks that examine how individuals think about their own thinking processes can likewise enhance visualization processes. In this paper, we review metacognition literature from the cognitive and learning science to identify opportunities in visualization to improve people's ability to reason with data. We propose the use of a metacognitive framework, serving as a starting point to inspire future research to improve visualization practices and outcomes." ;
    dcterms:identifier "3706598.3714400" ;
    chi:hasAuthor chi:person_183568, chi:person_183995, chi:person_184209, chi:person_184450, chi:person_183830 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aimsAtGoal chi:SupportDecisionMaking .

chi:paper_188825 rdf:type chi:Paper ;
    dcterms:title "Friend or Foe? Navigating and Re-configuring ``Snipers' Alley''" ;
    dcterms:abstract "In a 'digital by default’ society, essential services must be accessed online. This opens users to digital deception not only from criminal fraudsters but from a range of actors in a marketised digital economy. Using grounded empirical research from northern England, we show how supposedly 'trusted' actors, such as governments, (re)produce the insecurities and harms that they seek to prevent. Enhanced by a weakening of social institutions amid a drive for efficiency and scale, this has built a constricted, unpredictable digital channel. We conceptualise this as a ''snipers' alley''. Four key snipers articulated by participants' lived experiences are examined: 1) Governments; 2) Business; 3) Criminal Fraudsters; and 4) Friends and Family to explore how snipers are differentially experienced and transfigure through this constricted digital channel. We discuss strategies to re-configure the alley, and how crafting and adopting opportunity models can enable more equitable forms of security for all." ;
    dcterms:identifier "3706598.3713317" ;
    chi:hasAuthor chi:person_185767, chi:person_186006, chi:person_185031, chi:person_184545 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:DataDisclosureAndConsent ;
    chi:paperIncludesStudy chi:study_188825_QualitativeStudy ;
    chi:aimsAtGoal chi:EnhanceAccessibility .

chi:study_188825_QualitativeStudy rdf:type chi:QualitativeStudy ;
    chi:isStudyReportedIn chi:paper_188825 ;
    chi:reportsResult chi:result_188825_QualitativeResult .

chi:result_188825_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188826 rdf:type chi:Paper ;
    dcterms:title "Initiating the Global AI Dialogues: Laypeople Perspectives on the Future Role of genAI in Society from Nigeria, Germany and Japan" ;
    dcterms:abstract "With the rapid development and release of generative AI (genAI) applications, policy discourses primarily take place on an expert level. Little space is given to laypeople - who have to adapt to and adopt the genAI innovations - to share their opinions and experiences. Addressing this gap, we organized 6h/3.5h laypeople dialogues in Nigeria, Japan, and Germany in July and August 2024. During the dialogues, participants discussed what a desirable future in light of genAI development could look like in one of three contexts: education, public service, and arts & culture. Participants explored the consequences of technology deployment, assessed the risks, mapped stakeholders, and derived measures to achieve a desirable goal. This study contributes to policy debates on genAI by providing recommendations derived from participants' identified requirements and suggested measures for genAI to create value and to foster a socially desirable future. We reflect on the results through a cross-national lens." ;
    dcterms:identifier "3706598.3714322" ;
    chi:hasAuthor chi:person_184745, chi:person_183570, chi:person_186437, chi:person_183354, chi:person_183450, chi:person_185667, chi:person_187377, chi:person_183832 ;
    chi:hasPrimaryTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:EthicsPrivacyFairness ;
    chi:aboutTopic chi:ParticipatoryEthicsMethods ;
    chi:paperIncludesStudy chi:study_188826_UserStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking .

chi:study_188826_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188826 ;
    chi:reportsResult chi:result_188826_QualitativeResult .

chi:result_188826_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188827 rdf:type chi:Paper ;
    dcterms:title "What-if Analysis for Business Professionals: Current Practices and Future Opportunities" ;
    dcterms:abstract "What-if analysis (WIA) is essential for data-driven decision-making, allowing users to assess how changes in variables impact outcomes and explore alternative scenarios. Existing WIA research primarily supports the workflows of data scientists and analysts, and largely overlooks business professionals who engage in WIA through non-technical means. To bridge this gap, we conduct a two-part user study with 22 business professionals across marketing, sales, product, and operations roles. The first study examines their existing WIA practices, tools, and challenges. Findings reveal that business professionals perform many WIA techniques independently using rudimentary tools due to various constraints. We then implement representative WIA techniques in a visual analytics prototype and use it as a probe to conduct a follow-up study evaluating business professionals' practical use of the techniques. Results show that these techniques improve decision-making efficiency and confidence while underscoring the need for better support in data preparation, risk assessment, and domain knowledge integration. Finally, we offer design recommendations to enhance future business analytics systems." ;
    dcterms:identifier "3706598.3713672" ;
    chi:hasAuthor chi:person_186889, chi:person_185351, chi:person_183545, chi:person_183571 ;
    chi:hasPrimaryTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:HCIResearchAndDesignTools ;
    chi:aboutTopic chi:SupportTechnologiesForVulnerableUsers ;
    chi:paperIncludesStudy chi:study_188827_UserStudy ;
    chi:aimsAtGoal chi:SupportDecisionMaking ;
    chi:proposesArtifact chi:artifact_188827_SoftwareArtifact ;
    chi:proposesArtifact chi:artifact_188827_InterfaceArtifact .

chi:study_188827_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188827 ;
    chi:reportsResult chi:result_188827_QualitativeResult ;
    chi:reportsResult chi:result_188827_StatisticalResult .

chi:artifact_188827_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188827 .

chi:artifact_188827_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188827 .

chi:result_188827_QualitativeResult rdf:type chi:QualitativeResult .

chi:result_188827_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188828 rdf:type chi:Paper ;
    dcterms:title "SkinHaptics: Exploring Skin Softness Perception and Virtual Body Embodiment Techniques to Enhance Self-Haptic Interactions" ;
    dcterms:abstract "Providing haptic feedback for soft, deformable objects is challenging, requiring complex mechanical hardware combined with modeling and rendering software. As an alternative, we advance the concept of self-haptics, where the user's own body delivers physical feedback, to convey dynamically varying softness in VR. Skin can exhibit different levels of contact softness by altering the biomechanical state of the body. We propose SkinHaptics, a device-free approach that changes the states of musculoskeletal structures and virtual hand-object representations. In this study, we conduct three experiments to demonstrate SkinHaptics. Using the same scale, we measure skin softness across various hand poses and contact points and evaluate the just noticeable difference in skin softness. We investigate the effect of hand-object representations on self-haptic interactions. Our findings indicate that the visual representations have a significant influence on the embodiment of a self-haptic hand, and the degree of the hand embodiment strongly affects the haptic experience." ;
    dcterms:identifier "3706598.3713891" ;
    chi:hasAuthor chi:person_186918, chi:person_185157, chi:person_187463, chi:person_183684, chi:person_186600 ;
    chi:hasPrimaryTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:XRAndEmbodiedInteraction ;
    chi:aboutTopic chi:EmbodiedVRInteraction ;
    chi:paperIncludesStudy chi:study_188828_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188828_InterfaceArtifact .

chi:study_188828_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188828 ;
    chi:reportsResult chi:result_188828_StatisticalResult .

chi:artifact_188828_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188828 .

chi:result_188828_StatisticalResult rdf:type chi:StatisticalResult .

chi:paper_188829 rdf:type chi:Paper ;
    dcterms:title "Peek into the `White-Box': A Field Study on Bystander Engagement with Urban Robot Uncertainty" ;
    dcterms:abstract "Uncertainty inherently exists in the autonomous decision-making process of robots. Involving humans in resolving this uncertainty not only helps robots mitigate it but is also crucial for improving human-robot interactions. However, in public urban spaces filled with unpredictability, robots often face heightened uncertainty without direct human collaborators. This study investigates how robots can engage bystanders for assistance in public spaces when encountering uncertainty and examines how these interactions impact bystanders' perceptions and attitudes towards robots. We designed and tested a speculative `peephole' concept that engages bystanders in resolving urban robot uncertainty. Our design is guided by considerations of non-intrusiveness and eliciting initiative in an implicit manner, considering bystanders' unique role as non-obligated participants in relation to urban robots. Drawing from field study findings, we highlight the potential of involving bystanders to mitigate urban robots' technological imperfections to both address operational challenges and foster public acceptance of urban robots. Furthermore, we offer design implications to encourage bystanders' involvement in mitigating the imperfections." ;
    dcterms:identifier "3706598.3713790" ;
    chi:hasAuthor chi:person_185173, chi:person_183697, chi:person_183831, chi:person_183330, chi:person_183589, chi:person_183634 ;
    chi:hasPrimaryTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:InteractionTechniquesAndPerformance ;
    chi:aboutTopic chi:EmbodiedAndSpatialInputTechniques ;
    chi:paperIncludesStudy chi:study_188829_FieldStudy ;
    chi:aimsAtGoal chi:ImproveUsability ;
    chi:proposesArtifact chi:artifact_188829_InterfaceArtifact .

chi:study_188829_FieldStudy rdf:type chi:FieldStudy ;
    chi:isStudyReportedIn chi:paper_188829 ;
    chi:reportsResult chi:result_188829_QualitativeResult ;
    chi:involvesParticipationPattern chi:InPersonParticipation .

chi:artifact_188829_InterfaceArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188829 .

chi:result_188829_QualitativeResult rdf:type chi:QualitativeResult .

chi:paper_188830 rdf:type chi:Paper ;
    dcterms:title "Emotionally Challenging Games Can Satisfy Older Adults' Psychological Needs: From Empirical Study to Design Guidelines" ;
    dcterms:abstract "Older adults often struggle to meet their psychological needs due to retirement and living alone. Recent studies suggest that games featuring emotional challenge (EC) can help fulfill basic psychological needs such as autonomy, competence, and relatedness by facilitating emotional exploration. However, it remains unclear whether older adults can benefit from EC games, whether they find this genre enjoyable, and how these games should be designed to better meet their needs. This work explores older adults’ experiences and perceptions of playing EC games through two studies. The first study involved playing Detroit: Become Human, revealing that older adults derived multifaceted psychological experiences from playing the game. The second study involved a custom-designed game scenario tailored to older adults, demonstrating that meaningful choices significantly influenced autonomy need satisfaction. Based on these findings, we offer five design guidelines for developing EC games that satisfy psychological needs of older adults." ;
    dcterms:identifier "3706598.3713899" ;
    chi:hasAuthor chi:person_186928, chi:person_182664, chi:person_186220, chi:person_183518, chi:person_183824, chi:person_183704, chi:person_183458, chi:person_186078, chi:person_187589 ;
    chi:hasPrimaryTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:PersonalInformaticsAndDigitalWellbeing ;
    chi:aboutTopic chi:SelfReflectionAndBehaviorChange ;
    chi:paperIncludesStudy chi:study_188830_UserStudy ;
    chi:aimsAtGoal chi:IncreaseEngagement ;
    chi:proposesArtifact chi:artifact_188830_SoftwareArtifact .

chi:study_188830_UserStudy rdf:type chi:UserStudy ;
    chi:isStudyReportedIn chi:paper_188830 ;
    chi:reportsResult chi:result_188830_QualitativeResult .

chi:artifact_188830_SoftwareArtifact rdf:type chi:SoftwareArtifact ;
    chi:isProposedIn chi:paper_188830 .

chi:result_188830_QualitativeResult rdf:type chi:QualitativeResult .

